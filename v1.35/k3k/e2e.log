  I0127 19:53:55.212592      26 e2e.go:109] Starting e2e run "9363327e-b7dc-40b5-856e-73161be656f5" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1769543634 - will randomize all specs

Will run 441 of 7348 specs
------------------------------
[ReportBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e_test.go:154
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:69
  I0127 19:53:55.445324 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  I0127 19:53:55.446147 26 helper.go:51] Waiting up to 30m0s for all (but 0) nodes to be schedulable
  I0127 19:53:55.579246 26 e2e.go:142] Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  I0127 19:53:55.580858 26 e2e.go:153] 2 / 2 pods ready in namespace 'kube-system' in daemonset 'svclb-traefik-4c5baeff' (0 seconds elapsed)
  I0127 19:53:55.580903 26 e2e.go:245] e2e test version: v1.35.0
  I0127 19:53:55.581588 26 e2e.go:254] kube-apiserver version: v1.35.0+k3s1
  I0127 19:53:55.581670 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  I0127 19:53:55.584138 26 e2e.go:383] Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.139 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 01/27/26 19:53:55.774
  I0127 19:53:55.774324 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename var-expansion @ 01/27/26 19:53:55.774
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 19:53:56.101
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 19:53:56.321
  STEP: creating the pod with failed condition @ 01/27/26 19:53:56.323
  STEP: updating the pod @ 01/27/26 19:55:56.376
  I0127 19:55:56.894789 26 pod_client.go:187] Successfully updated pod "var-expansion-2977fab3-6293-4d0b-a076-5f2cd2410f56"
  STEP: waiting for pod running @ 01/27/26 19:55:56.894
  STEP: deleting the pod gracefully @ 01/27/26 19:55:58.901
  I0127 19:55:58.901114 26 delete.go:78] Deleting pod "var-expansion-2977fab3-6293-4d0b-a076-5f2cd2410f56" in namespace "var-expansion-1402"
  I0127 19:55:58.915030 26 delete.go:86] Wait up to 5m0s for pod "var-expansion-2977fab3-6293-4d0b-a076-5f2cd2410f56" to be fully deleted
  I0127 19:56:30.976599 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1402" for this suite. @ 01/27/26 19:56:30.979
• [155.213 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 01/27/26 19:56:30.99
  I0127 19:56:30.990450 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename chunking @ 01/27/26 19:56:30.99
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 19:56:31.007
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 19:56:31.018
  STEP: creating a large number of resources @ 01/27/26 19:56:31.022
  STEP: retrieving the first page @ 01/27/26 19:56:48.555
  I0127 19:56:48.594715 26 chunking.go:163] Retrieved 40/40 results with rv 4114 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page until the token expires @ 01/27/26 19:56:48.594
  I0127 19:57:08.597692 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 19:57:28.597784 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 19:57:48.597804 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 19:58:08.597272 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 19:58:28.598510 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 19:58:48.600781 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 19:59:08.599528 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 19:59:28.598014 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 19:59:48.600252 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 20:00:08.597784 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 20:00:28.597448 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 20:00:48.601484 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 20:01:08.599151 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 20:01:28.597723 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 20:01:48.600891 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 20:02:08.599078 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 20:02:28.597520 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 20:02:48.602138 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 20:03:08.598372 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 20:03:28.597498 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 20:03:48.597368 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 20:04:08.599234 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 20:04:28.599135 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 20:04:48.597475 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 20:05:08.597695 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDExNCwic3RhcnQiOiIvdGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0127 20:05:28.597702 26 chunking.go:177] got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  I0127 20:05:28.597742 26 chunking.go:186] Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 01/27/26 20:05:28.597
  STEP: retrieving all remaining pages @ 01/27/26 20:05:28.6
  I0127 20:05:28.603118 26 chunking.go:221] Retrieved 40/40 results with rv 5620 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NTYyMCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTE5XHUwMDAwIn0
  I0127 20:05:28.605524 26 chunking.go:221] Retrieved 40/40 results with rv 5620 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NTYyMCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTU5XHUwMDAwIn0
  I0127 20:05:28.608412 26 chunking.go:221] Retrieved 40/40 results with rv 5620 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NTYyMCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTk5XHUwMDAwIn0
  I0127 20:05:28.610882 26 chunking.go:221] Retrieved 40/40 results with rv 5620 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NTYyMCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjM5XHUwMDAwIn0
  I0127 20:05:28.613861 26 chunking.go:221] Retrieved 40/40 results with rv 5620 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NTYyMCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjc5XHUwMDAwIn0
  I0127 20:05:28.616661 26 chunking.go:221] Retrieved 40/40 results with rv 5620 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NTYyMCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzE5XHUwMDAwIn0
  I0127 20:05:28.618713 26 chunking.go:221] Retrieved 40/40 results with rv 5620 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NTYyMCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzU5XHUwMDAwIn0
  I0127 20:05:28.621561 26 chunking.go:221] Retrieved 40/40 results with rv 5620 and continue 
  I0127 20:05:28.621971 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-8559" for this suite. @ 01/27/26 20:05:28.624
• [537.642 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:836
  STEP: Creating a kubernetes client @ 01/27/26 20:05:28.633
  I0127 20:05:28.633108 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename statefulset @ 01/27/26 20:05:28.633
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:05:28.657
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:05:28.659
  STEP: Creating service test in namespace statefulset-1560 @ 01/27/26 20:05:28.661
  STEP: Creating stateful set ss in namespace statefulset-1560 @ 01/27/26 20:05:28.683
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1560 @ 01/27/26 20:05:28.706
  I0127 20:05:28.708760 26 wait.go:45] Found 0 stateful pods, waiting for 1
  I0127 20:05:38.710284 26 wait.go:55] Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
  I0127 20:05:48.710442 26 wait.go:55] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 01/27/26 20:05:48.71
  I0127 20:05:48.713199 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=statefulset-1560 exec ss-0 -- /bin/sh -x -c mv -v /localhost.crt /tmp/ || true'
  I0127 20:05:48.856050 26 builder.go:156] stderr: "+ mv -v /localhost.crt /tmp/\n"
  I0127 20:05:48.856088 26 builder.go:157] stdout: "'/localhost.crt' -> '/tmp/localhost.crt'\n"
  I0127 20:05:48.856099 26 rest.go:280] stdout of mv -v /localhost.crt /tmp/ || true on ss-0: '/localhost.crt' -> '/tmp/localhost.crt'

  I0127 20:05:48.857995 26 wait.go:55] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  I0127 20:05:58.860267 26 wait.go:55] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0127 20:05:58.860301 26 wait.go:110] Waiting for statefulset status.readyReplicas updated to 0
  I0127 20:05:58.888465 26 resource.go:151] POD   NODE                                            PHASE    GRACE  CONDITIONS
  I0127 20:05:58.888556 26 resource.go:158] ss-0  k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2  Running         [{PodReadyToStartContainers 1 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:05:39 +0000 UTC  } {Initialized 1 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:05:28 +0000 UTC  } {Ready 1 False 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:05:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady 1 False 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:05:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled 1 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:05:28 +0000 UTC  }]
  I0127 20:05:58.888566 26 resource.go:158] ss-1                                                  Pending         []
  I0127 20:05:58.888573 26 resource.go:161] 
  I0127 20:05:58.888581 26 statefulset.go:2481] StatefulSet ss has not reached scale 3, at 2
  I0127 20:05:59.891433 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 3 for another 8.982967792s
  I0127 20:06:00.894762 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 3 for another 7.979571522s
  I0127 20:06:01.898629 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 3 for another 6.97573582s
  I0127 20:06:02.902814 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 3 for another 5.972041922s
  I0127 20:06:03.905292 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 3 for another 4.968716343s
  I0127 20:06:04.908704 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 3 for another 3.966252786s
  I0127 20:06:06.132786 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 3 for another 2.961829467s
  I0127 20:06:07.442598 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 3 for another 1.737833397s
  I0127 20:06:08.445406 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 3 for another 428.916956ms
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1560 @ 01/27/26 20:06:09.446
  I0127 20:06:09.452505 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=statefulset-1560 exec ss-0 -- /bin/sh -x -c mv -v /tmp/localhost.crt / || true'
  I0127 20:06:09.555871 26 builder.go:156] stderr: "+ mv -v /tmp/localhost.crt /\n"
  I0127 20:06:09.555913 26 builder.go:157] stdout: "'/tmp/localhost.crt' -> '/localhost.crt'\n"
  I0127 20:06:09.555925 26 rest.go:280] stdout of mv -v /tmp/localhost.crt / || true on ss-0: '/tmp/localhost.crt' -> '/localhost.crt'

  I0127 20:06:09.555967 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=statefulset-1560 exec ss-1 -- /bin/sh -x -c mv -v /tmp/localhost.crt / || true'
  I0127 20:06:09.660735 26 builder.go:156] stderr: "+ mv -v /tmp/localhost.crt /\nmv: can't rename '/tmp/localhost.crt': No such file or directory\n+ true\n"
  I0127 20:06:09.660772 26 builder.go:157] stdout: "'/tmp/localhost.crt' -> '/localhost.crt'\n"
  I0127 20:06:09.660784 26 rest.go:280] stdout of mv -v /tmp/localhost.crt / || true on ss-1: '/tmp/localhost.crt' -> '/localhost.crt'

  I0127 20:06:09.660819 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=statefulset-1560 exec ss-2 -- /bin/sh -x -c mv -v /tmp/localhost.crt / || true'
  I0127 20:06:09.784623 26 builder.go:156] stderr: "+ mv -v /tmp/localhost.crt /\nmv: can't rename '/tmp/localhost.crt': No such file or directory\n+ true\n"
  I0127 20:06:09.784660 26 builder.go:157] stdout: "'/tmp/localhost.crt' -> '/localhost.crt'\n"
  I0127 20:06:09.784672 26 rest.go:280] stdout of mv -v /tmp/localhost.crt / || true on ss-2: '/tmp/localhost.crt' -> '/localhost.crt'

  I0127 20:06:09.786647 26 wait.go:55] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
  I0127 20:06:19.787947 26 wait.go:55] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0127 20:06:19.787984 26 wait.go:55] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0127 20:06:19.787995 26 wait.go:55] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 01/27/26 20:06:19.788
  I0127 20:06:19.789561 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=statefulset-1560 exec ss-0 -- /bin/sh -x -c mv -v /localhost.crt /tmp/ || true'
  I0127 20:06:19.903465 26 builder.go:156] stderr: "+ mv -v /localhost.crt /tmp/\n"
  I0127 20:06:19.903513 26 builder.go:157] stdout: "'/localhost.crt' -> '/tmp/localhost.crt'\n"
  I0127 20:06:19.903526 26 rest.go:280] stdout of mv -v /localhost.crt /tmp/ || true on ss-0: '/localhost.crt' -> '/tmp/localhost.crt'

  I0127 20:06:19.903574 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=statefulset-1560 exec ss-1 -- /bin/sh -x -c mv -v /localhost.crt /tmp/ || true'
  I0127 20:06:20.013076 26 builder.go:156] stderr: "+ mv -v /localhost.crt /tmp/\n"
  I0127 20:06:20.013116 26 builder.go:157] stdout: "'/localhost.crt' -> '/tmp/localhost.crt'\n"
  I0127 20:06:20.013136 26 rest.go:280] stdout of mv -v /localhost.crt /tmp/ || true on ss-1: '/localhost.crt' -> '/tmp/localhost.crt'

  I0127 20:06:20.013183 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=statefulset-1560 exec ss-2 -- /bin/sh -x -c mv -v /localhost.crt /tmp/ || true'
  I0127 20:06:20.119497 26 builder.go:156] stderr: "+ mv -v /localhost.crt /tmp/\n"
  I0127 20:06:20.119535 26 builder.go:157] stdout: "'/localhost.crt' -> '/tmp/localhost.crt'\n"
  I0127 20:06:20.119546 26 rest.go:280] stdout of mv -v /localhost.crt /tmp/ || true on ss-2: '/localhost.crt' -> '/tmp/localhost.crt'

  I0127 20:06:20.119560 26 wait.go:110] Waiting for statefulset status.readyReplicas updated to 0
  I0127 20:06:20.122665 26 wait.go:123] Waiting for statefulset status.readyReplicas to become 0, currently 3
  I0127 20:06:30.129670 26 wait.go:55] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0127 20:06:30.129706 26 wait.go:55] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0127 20:06:30.129715 26 wait.go:55] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I0127 20:06:30.170470 26 resource.go:151] POD   NODE                                            PHASE    GRACE  CONDITIONS
  I0127 20:06:30.170530 26 resource.go:158] ss-0  k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2  Running         [{PodReadyToStartContainers 1 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:05:39 +0000 UTC  } {Initialized 1 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:05:28 +0000 UTC  } {Ready 1 False 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:06:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady 1 False 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:06:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled 1 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:05:28 +0000 UTC  }]
  I0127 20:06:30.170552 26 resource.go:158] ss-1  k3k-k3kcluster-server-0                         Running         [{PodReadyToStartContainers 1 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:06:08 +0000 UTC  } {Initialized 1 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:05:58 +0000 UTC  } {Ready 1 False 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:06:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady 1 False 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:06:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled 1 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:05:58 +0000 UTC  }]
  I0127 20:06:30.170569 26 resource.go:158] ss-2  k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2  Running  30s    [{PodReadyToStartContainers 1 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:06:00 +0000 UTC  } {Initialized 1 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:05:58 +0000 UTC  } {Ready 1 False 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:06:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady 1 False 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:06:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled 1 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:05:58 +0000 UTC  }]
  I0127 20:06:30.170575 26 resource.go:161] 
  I0127 20:06:30.170582 26 statefulset.go:2481] StatefulSet ss has not reached scale 0, at 3
  I0127 20:06:31.176185 26 resource.go:151] POD   NODE                     PHASE   GRACE  CONDITIONS
  I0127 20:06:31.176243 26 resource.go:158] ss-1  k3k-k3kcluster-server-0  Failed  0s     [{PodReadyToStartContainers 2 False 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:06:30 +0000 UTC  } {Initialized 2 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:05:58 +0000 UTC  } {Ready 2 False 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:06:20 +0000 UTC PodFailed } {ContainersReady 2 False 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:06:20 +0000 UTC PodFailed } {PodScheduled 2 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:05:58 +0000 UTC  }]
  I0127 20:06:31.176251 26 resource.go:161] 
  I0127 20:06:31.176259 26 statefulset.go:2481] StatefulSet ss has not reached scale 0, at 1
  I0127 20:06:32.178436 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 0 for another 7.970512636s
  I0127 20:06:33.180687 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 0 for another 6.968314551s
  I0127 20:06:34.182997 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 0 for another 5.966081817s
  I0127 20:06:35.185168 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 0 for another 4.963750378s
  I0127 20:06:36.187586 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 0 for another 3.961513398s
  I0127 20:06:37.190869 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 0 for another 2.958150956s
  I0127 20:06:38.193925 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 0 for another 1.955876683s
  I0127 20:06:39.196669 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 0 for another 952.838648ms
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1560 @ 01/27/26 20:06:40.197
  I0127 20:06:40.200788 26 rest.go:153] Scaling statefulset ss to 0
  I0127 20:06:40.204797 26 wait.go:160] Waiting for statefulset status.replicas updated to 0
  I0127 20:06:40.206263 26 statefulset.go:137] Deleting all statefulset in ns statefulset-1560
  I0127 20:06:40.207900 26 rest.go:153] Scaling statefulset ss to 0
  I0127 20:06:40.210517 26 wait.go:160] Waiting for statefulset status.replicas updated to 0
  I0127 20:06:40.212257 26 rest.go:91] Deleting statefulset ss
  I0127 20:06:40.224156 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1560" for this suite. @ 01/27/26 20:06:40.226
• [71.607 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:726
  STEP: Creating a kubernetes client @ 01/27/26 20:06:40.244
  I0127 20:06:40.244829 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename statefulset @ 01/27/26 20:06:40.245
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:06:40.271
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:06:40.273
  STEP: Creating service test in namespace statefulset-4409 @ 01/27/26 20:06:40.275
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 01/27/26 20:06:40.283
  STEP: Creating stateful set ss in namespace statefulset-4409 @ 01/27/26 20:06:40.301
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4409 @ 01/27/26 20:06:40.32
  I0127 20:06:40.343396 26 wait.go:55] Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
  I0127 20:06:50.323710 26 wait.go:55] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 01/27/26 20:06:50.323
  I0127 20:06:50.325748 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=statefulset-4409 exec ss-0 -- /bin/sh -x -c mv -v /localhost.crt /tmp/ || true'
  I0127 20:06:50.436631 26 builder.go:156] stderr: "+ mv -v /localhost.crt /tmp/\n"
  I0127 20:06:50.436671 26 builder.go:157] stdout: "'/localhost.crt' -> '/tmp/localhost.crt'\n"
  I0127 20:06:50.436682 26 rest.go:280] stdout of mv -v /localhost.crt /tmp/ || true on ss-0: '/localhost.crt' -> '/tmp/localhost.crt'

  I0127 20:06:50.439039 26 wait.go:55] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  I0127 20:07:00.439329 26 wait.go:55] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0127 20:07:00.439364 26 wait.go:110] Waiting for statefulset status.readyReplicas updated to 0
  I0127 20:07:00.460353 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 1 for another 9.999998692s
  I0127 20:07:01.468085 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 1 for another 8.997473464s
  I0127 20:07:02.471147 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 1 for another 7.989377001s
  I0127 20:07:03.476751 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 1 for another 6.986959806s
  I0127 20:07:04.479784 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 1 for another 5.981162591s
  I0127 20:07:05.485792 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 1 for another 4.977487005s
  I0127 20:07:06.488323 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 1 for another 3.972326452s
  I0127 20:07:07.500696 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 1 for another 2.969503292s
  I0127 20:07:08.503426 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 1 for another 1.957130748s
  I0127 20:07:09.508431 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 1 for another 954.690348ms
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4409 @ 01/27/26 20:07:10.509
  I0127 20:07:10.512619 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=statefulset-4409 exec ss-0 -- /bin/sh -x -c mv -v /tmp/localhost.crt / || true'
  I0127 20:07:10.620046 26 builder.go:156] stderr: "+ mv -v /tmp/localhost.crt /\n"
  I0127 20:07:10.620093 26 builder.go:157] stdout: "'/tmp/localhost.crt' -> '/localhost.crt'\n"
  I0127 20:07:10.620111 26 rest.go:280] stdout of mv -v /tmp/localhost.crt / || true on ss-0: '/tmp/localhost.crt' -> '/localhost.crt'

  I0127 20:07:10.622243 26 wait.go:45] Found 1 stateful pods, waiting for 3
  I0127 20:07:20.623673 26 wait.go:55] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0127 20:07:20.623721 26 wait.go:55] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0127 20:07:20.623731 26 wait.go:55] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 01/27/26 20:07:20.623
  STEP: Scale down will halt with unhealthy stateful pod @ 01/27/26 20:07:20.623
  I0127 20:07:20.627354 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=statefulset-4409 exec ss-0 -- /bin/sh -x -c mv -v /localhost.crt /tmp/ || true'
  I0127 20:07:20.731373 26 builder.go:156] stderr: "+ mv -v /localhost.crt /tmp/\n"
  I0127 20:07:20.731417 26 builder.go:157] stdout: "'/localhost.crt' -> '/tmp/localhost.crt'\n"
  I0127 20:07:20.731429 26 rest.go:280] stdout of mv -v /localhost.crt /tmp/ || true on ss-0: '/localhost.crt' -> '/tmp/localhost.crt'

  I0127 20:07:20.731465 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=statefulset-4409 exec ss-1 -- /bin/sh -x -c mv -v /localhost.crt /tmp/ || true'
  I0127 20:07:20.834122 26 builder.go:156] stderr: "+ mv -v /localhost.crt /tmp/\n"
  I0127 20:07:20.834161 26 builder.go:157] stdout: "'/localhost.crt' -> '/tmp/localhost.crt'\n"
  I0127 20:07:20.834172 26 rest.go:280] stdout of mv -v /localhost.crt /tmp/ || true on ss-1: '/localhost.crt' -> '/tmp/localhost.crt'

  I0127 20:07:20.834211 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=statefulset-4409 exec ss-2 -- /bin/sh -x -c mv -v /localhost.crt /tmp/ || true'
  I0127 20:07:20.948604 26 builder.go:156] stderr: "+ mv -v /localhost.crt /tmp/\n"
  I0127 20:07:20.948646 26 builder.go:157] stdout: "'/localhost.crt' -> '/tmp/localhost.crt'\n"
  I0127 20:07:20.948666 26 rest.go:280] stdout of mv -v /localhost.crt /tmp/ || true on ss-2: '/localhost.crt' -> '/tmp/localhost.crt'

  I0127 20:07:20.948677 26 wait.go:110] Waiting for statefulset status.readyReplicas updated to 0
  I0127 20:07:20.950680 26 wait.go:123] Waiting for statefulset status.readyReplicas to become 0, currently 3
  I0127 20:07:30.958726 26 wait.go:55] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0127 20:07:30.958764 26 wait.go:55] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0127 20:07:30.958773 26 wait.go:55] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I0127 20:07:31.059239 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 3 for another 9.999998621s
  I0127 20:07:32.061653 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 3 for another 8.91504833s
  I0127 20:07:33.066130 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 3 for another 7.91262915s
  I0127 20:07:34.068987 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 3 for another 6.907902209s
  I0127 20:07:35.075565 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 3 for another 5.905299719s
  I0127 20:07:36.079293 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 3 for another 4.897882444s
  I0127 20:07:37.082574 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 3 for another 3.894142334s
  I0127 20:07:38.085155 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 3 for another 2.891715375s
  I0127 20:07:39.088158 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 3 for another 1.889133018s
  I0127 20:07:40.091641 26 statefulset.go:2486] Verifying statefulset ss doesn't scale past 3 for another 885.157864ms
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4409 @ 01/27/26 20:07:41.092
  I0127 20:07:41.095446 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=statefulset-4409 exec ss-0 -- /bin/sh -x -c mv -v /tmp/localhost.crt / || true'
  I0127 20:07:41.199514 26 builder.go:156] stderr: "+ mv -v /tmp/localhost.crt /\n"
  I0127 20:07:41.199560 26 builder.go:157] stdout: "'/tmp/localhost.crt' -> '/localhost.crt'\n"
  I0127 20:07:41.199570 26 rest.go:280] stdout of mv -v /tmp/localhost.crt / || true on ss-0: '/tmp/localhost.crt' -> '/localhost.crt'

  I0127 20:07:41.199624 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=statefulset-4409 exec ss-1 -- /bin/sh -x -c mv -v /tmp/localhost.crt / || true'
  I0127 20:07:41.302031 26 builder.go:156] stderr: "+ mv -v /tmp/localhost.crt /\n"
  I0127 20:07:41.302072 26 builder.go:157] stdout: "'/tmp/localhost.crt' -> '/localhost.crt'\n"
  I0127 20:07:41.302083 26 rest.go:280] stdout of mv -v /tmp/localhost.crt / || true on ss-1: '/tmp/localhost.crt' -> '/localhost.crt'

  I0127 20:07:41.302129 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=statefulset-4409 exec ss-2 -- /bin/sh -x -c mv -v /tmp/localhost.crt / || true'
  I0127 20:07:41.409056 26 builder.go:156] stderr: "+ mv -v /tmp/localhost.crt /\n"
  I0127 20:07:41.409097 26 builder.go:157] stdout: "'/tmp/localhost.crt' -> '/localhost.crt'\n"
  I0127 20:07:41.409113 26 rest.go:280] stdout of mv -v /tmp/localhost.crt / || true on ss-2: '/tmp/localhost.crt' -> '/localhost.crt'

  I0127 20:07:41.409128 26 rest.go:153] Scaling statefulset ss to 0
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 01/27/26 20:07:51.415
  I0127 20:07:51.415670 26 statefulset.go:137] Deleting all statefulset in ns statefulset-4409
  I0127 20:07:51.417408 26 rest.go:153] Scaling statefulset ss to 0
  I0127 20:07:51.421548 26 wait.go:160] Waiting for statefulset status.replicas updated to 0
  I0127 20:07:51.423862 26 rest.go:91] Deleting statefulset ss
  I0127 20:07:51.436140 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4409" for this suite. @ 01/27/26 20:07:51.438
• [71.206 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:99
  STEP: Creating a kubernetes client @ 01/27/26 20:07:51.46
  I0127 20:07:51.460237 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename cronjob @ 01/27/26 20:07:51.46
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:07:51.481
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:07:51.571
  STEP: Creating a suspended cronjob @ 01/27/26 20:07:51.573
  STEP: Ensuring no jobs are scheduled @ 01/27/26 20:07:51.581
  STEP: Ensuring no job exists by listing jobs explicitly @ 01/27/26 20:12:51.582
  STEP: Removing cronjob @ 01/27/26 20:12:51.585
  I0127 20:12:51.593496 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-8324" for this suite. @ 01/27/26 20:12:51.595
• [300.144 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:127
  STEP: Creating a kubernetes client @ 01/27/26 20:12:51.605
  I0127 20:12:51.605234 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename cronjob @ 01/27/26 20:12:51.605
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:12:51.631
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:12:51.634
  STEP: Creating a ForbidConcurrent cronjob @ 01/27/26 20:12:51.636
  STEP: Ensuring a job is scheduled @ 01/27/26 20:12:51.645
  STEP: Ensuring exactly one is scheduled @ 01/27/26 20:13:01.647
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 01/27/26 20:13:01.649
  STEP: Ensuring no more jobs are scheduled @ 01/27/26 20:13:01.651
  STEP: Removing cronjob @ 01/27/26 20:13:01.652
  I0127 20:13:01.660418 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-7232" for this suite. @ 01/27/26 20:13:01.662
• [10.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] API Server should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/apiserver.go:58
  STEP: Creating a kubernetes client @ 01/27/26 20:13:01.684
  I0127 20:13:01.684369 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename apiserver @ 01/27/26 20:13:01.685
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:13:01.736
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:13:01.738
  I0127 20:13:01.755578      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0127 20:13:01.755645 26 apiserver.go:86] Endpoints addresses: [10.42.0.12] , ports: [6443]
  I0127 20:13:01.757944 26 apiserver.go:124] EndpointSlices addresses: [10.42.0.12] , ports: [6443]
  I0127 20:13:01.758081 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apiserver-5130" for this suite. @ 01/27/26 20:13:01.763
• [0.087 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:112
  STEP: Creating a kubernetes client @ 01/27/26 20:13:01.771
  I0127 20:13:01.771881 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename resourcequota @ 01/27/26 20:13:01.772
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:13:01.788
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:13:01.8
  STEP: Counting existing ResourceQuota @ 01/27/26 20:13:01.802
  STEP: Creating a ResourceQuota @ 01/27/26 20:13:06.804
  STEP: Ensuring resource quota status is calculated @ 01/27/26 20:13:06.817
  I0127 20:13:08.822810 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc0011d1180>: 
          metadata:
            creationTimestamp: "2026-01-27T20:13:06Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:13:06Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T20:13:06Z"
            name: test-quota
            namespace: resourcequota-5449
            resourceVersion: "7830"
            uid: 7edc1c28-ce58-458b-be8f-ae0d10e65fec
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Creating a Service @ 01/27/26 20:13:08.823
  STEP: Creating a NodePort Service @ 01/27/26 20:13:08.857
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 01/27/26 20:13:08.894
  STEP: Ensuring resource quota status captures service creation @ 01/27/26 20:13:08.925
  I0127 20:13:08.928926 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc0011d17c0>: 
          metadata:
            creationTimestamp: "2026-01-27T20:13:06Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:13:06Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T20:13:08Z"
            name: test-quota
            namespace: resourcequota-5449
            resourceVersion: "7846"
            uid: 7edc1c28-ce58-458b-be8f-ae0d10e65fec
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "2"
              services.loadbalancers: "0"
              services.nodeports: "1"
  STEP: Deleting Services @ 01/27/26 20:13:08.929
  STEP: Ensuring resource quota status released usage @ 01/27/26 20:13:08.999
  I0127 20:13:09.002231 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc000fc7a40>: 
          metadata:
            creationTimestamp: "2026-01-27T20:13:06Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:13:06Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T20:13:08Z"
            name: test-quota
            namespace: resourcequota-5449
            resourceVersion: "7857"
            uid: 7edc1c28-ce58-458b-be8f-ae0d10e65fec
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  I0127 20:13:09.002694 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5449" for this suite. @ 01/27/26 20:13:09.005
• [7.241 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:148
  STEP: Creating a kubernetes client @ 01/27/26 20:13:09.012
  I0127 20:13:09.012908 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename disruption @ 01/27/26 20:13:09.013
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:13:09.039
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:13:09.042
  STEP: Waiting for the pdb to be processed @ 01/27/26 20:13:09.059
  STEP: Waiting for all pods to be running @ 01/27/26 20:13:11.122
  I0127 20:13:11.126488 26 disruption.go:696] running pods: 0 < 3
  I0127 20:13:13.126105 26 disruption.go:696] running pods: 0 < 3
  I0127 20:13:15.151208 26 disruption.go:696] running pods: 1 < 3
  I0127 20:13:17.128491 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2045" for this suite. @ 01/27/26 20:13:17.13
• [8.125 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:462
  STEP: Creating a kubernetes client @ 01/27/26 20:13:17.138
  I0127 20:13:17.138219 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename resourcequota @ 01/27/26 20:13:17.138
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:13:17.157
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:13:17.161
  STEP: Counting existing ResourceQuota @ 01/27/26 20:13:17.163
  STEP: Creating a ResourceQuota @ 01/27/26 20:13:22.178
  STEP: Ensuring resource quota status is calculated @ 01/27/26 20:13:22.202
  I0127 20:13:24.216424 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001709400>: 
          metadata:
            creationTimestamp: "2026-01-27T20:13:22Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:13:22Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T20:13:22Z"
            name: test-quota
            namespace: resourcequota-8097
            resourceVersion: "7955"
            uid: 4a122ff6-c2f0-4ed6-b36d-56c668a1b425
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Creating a ReplicaSet @ 01/27/26 20:13:24.216
  STEP: Ensuring resource quota status captures replicaset creation @ 01/27/26 20:13:24.247
  I0127 20:13:24.249569 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc00187c000>: 
          metadata:
            creationTimestamp: "2026-01-27T20:13:22Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:13:22Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T20:13:24Z"
            name: test-quota
            namespace: resourcequota-8097
            resourceVersion: "7980"
            uid: 4a122ff6-c2f0-4ed6-b36d-56c668a1b425
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "1"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Deleting a ReplicaSet @ 01/27/26 20:13:24.25
  STEP: Ensuring resource quota status released usage @ 01/27/26 20:13:24.267
  I0127 20:13:26.273114 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001a2a640>: 
          metadata:
            creationTimestamp: "2026-01-27T20:13:22Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:13:22Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T20:13:24Z"
            name: test-quota
            namespace: resourcequota-8097
            resourceVersion: "7984"
            uid: 4a122ff6-c2f0-4ed6-b36d-56c668a1b425
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  I0127 20:13:26.273529 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8097" for this suite. @ 01/27/26 20:13:26.275
• [9.145 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:574
  STEP: Creating a kubernetes client @ 01/27/26 20:13:26.284
  I0127 20:13:26.284052 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 20:13:26.284
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:13:26.312
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:13:26.314
  STEP: Setting up server cert @ 01/27/26 20:13:26.346
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 20:13:26.543
  STEP: Deploying the webhook pod @ 01/27/26 20:13:26.557
  STEP: Wait for the deployment to be ready @ 01/27/26 20:13:26.579
  I0127 20:13:26.594453 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  I0127 20:13:28.605483 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc003fdd1e0), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 20, 13, 26, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 13, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 13, 26, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 13, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c5c95bb96\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0127 20:13:30.607899 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc0038d12d0), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 20, 13, 26, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 13, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 13, 26, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 13, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c5c95bb96\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0127 20:13:32.608804 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc003fdd3f0), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 20, 13, 26, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 13, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 13, 26, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 13, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c5c95bb96\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: Deploying the webhook service @ 01/27/26 20:13:34.627
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 20:13:34.736
  I0127 20:13:34.736760 26 wait.go:65] Waiting for amount of service webhook-1318/e2e-test-webhook endpoints to be 1
  I0127 20:13:34.782571 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  STEP: Listing all of the created validation webhooks @ 01/27/26 20:13:35.778
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 01/27/26 20:13:35.802
  STEP: Deleting the collection of validation webhooks @ 01/27/26 20:13:35.831
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 01/27/26 20:13:35.858
  I0127 20:13:35.893305 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1318" for this suite. @ 01/27/26 20:13:35.897
  STEP: Destroying namespace "webhook-markers-3514" for this suite. @ 01/27/26 20:13:35.904
• [9.624 seconds]
------------------------------
S
------------------------------
[sig-apps] Job with successPolicy should succeeded when all indexes succeeded [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:486
  STEP: Creating a kubernetes client @ 01/27/26 20:13:35.908
  I0127 20:13:35.908492 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename job @ 01/27/26 20:13:35.909
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:13:35.929
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:13:36.031
  STEP: Creating an indexed job with successPolicy @ 01/27/26 20:13:36.033
  STEP: Awaiting for the job to have the interim SuccessCriteriaMet with SuccessPolicy reason condition @ 01/27/26 20:13:36.039
  STEP: Ensure that the job reaches completions @ 01/27/26 20:13:40.047
  STEP: Verifying that the job status to ensure correct final state @ 01/27/26 20:13:40.051
  I0127 20:13:40.053022 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-5434" for this suite. @ 01/27/26 20:13:40.054
• [4.155 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:88
  STEP: Creating a kubernetes client @ 01/27/26 20:13:40.063
  I0127 20:13:40.063365 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename custom-resource-definition @ 01/27/26 20:13:40.064
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:13:40.084
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:13:40.087
  I0127 20:13:40.090293 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  I0127 20:13:46.356727 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-2756" for this suite. @ 01/27/26 20:13:46.358
• [6.302 seconds]
------------------------------
SS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:622
  STEP: Creating a kubernetes client @ 01/27/26 20:13:46.365
  I0127 20:13:46.365590 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pods @ 01/27/26 20:13:46.366
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:13:46.397
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:13:46.399
  I0127 20:13:46.401905 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: creating the pod @ 01/27/26 20:13:46.402
  STEP: submitting the pod to kubernetes @ 01/27/26 20:13:46.402
  STEP: waiting for the container to be running @ 01/27/26 20:13:50.427
  I0127 20:13:50.440765 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7374" for this suite. @ 01/27/26 20:13:50.442
• [4.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:987
  STEP: Creating a kubernetes client @ 01/27/26 20:13:50.451
  I0127 20:13:50.451356 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename statefulset @ 01/27/26 20:13:50.451
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:13:50.478
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:13:50.48
  STEP: Creating service test in namespace statefulset-92 @ 01/27/26 20:13:50.482
  STEP: Creating statefulset ss in namespace statefulset-92 @ 01/27/26 20:13:50.49
  I0127 20:13:50.521866 26 wait.go:45] Found 0 stateful pods, waiting for 1
  I0127 20:14:00.512518 26 wait.go:55] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 01/27/26 20:14:00.515
  STEP: updating a scale subresource @ 01/27/26 20:14:00.516
  STEP: verifying the statefulset Spec.Replicas was modified @ 01/27/26 20:14:00.524
  STEP: Patch a scale subresource @ 01/27/26 20:14:00.526
  STEP: verifying the statefulset Spec.Replicas was modified @ 01/27/26 20:14:00.544
  I0127 20:14:00.556432 26 statefulset.go:137] Deleting all statefulset in ns statefulset-92
  I0127 20:14:00.562867 26 rest.go:153] Scaling statefulset ss to 0
  I0127 20:14:10.602043 26 wait.go:160] Waiting for statefulset status.replicas updated to 0
  I0127 20:14:10.604065 26 rest.go:91] Deleting statefulset ss
  I0127 20:14:10.615388 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-92" for this suite. @ 01/27/26 20:14:10.617
• [20.180 seconds]
------------------------------
S
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:110
  STEP: Creating a kubernetes client @ 01/27/26 20:14:10.631
  I0127 20:14:10.631123 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename runtimeclass @ 01/27/26 20:14:10.631
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:14:10.658
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:14:10.66
  I0127 20:14:12.711482 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-5522" for this suite. @ 01/27/26 20:14:12.713
• [2.090 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:1118
  STEP: Creating a kubernetes client @ 01/27/26 20:14:12.721
  I0127 20:14:12.721652 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename statefulset @ 01/27/26 20:14:12.722
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:14:12.748
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:14:12.749
  STEP: Creating service test in namespace statefulset-2619 @ 01/27/26 20:14:12.752
  STEP: Creating statefulset ss in namespace statefulset-2619 @ 01/27/26 20:14:12.763
  I0127 20:14:12.803198 26 wait.go:45] Found 0 stateful pods, waiting for 1
  I0127 20:14:22.781927 26 wait.go:55] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 01/27/26 20:14:22.785
  STEP: Getting /status @ 01/27/26 20:14:22.797
  I0127 20:14:22.800718 26 statefulset.go:1154] StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 01/27/26 20:14:22.8
  I0127 20:14:22.821813 26 statefulset.go:1174] updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 01/27/26 20:14:22.821
  I0127 20:14:22.823737 26 statefulset.go:1202] Observed &StatefulSet event: ADDED
  I0127 20:14:22.823774 26 statefulset.go:1195] Found Statefulset ss in namespace statefulset-2619 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0127 20:14:22.823786 26 statefulset.go:1206] Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 01/27/26 20:14:22.823
  I0127 20:14:22.823813 26 statefulset.go:1210] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0127 20:14:22.832246 26 statefulset.go:1214] Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 01/27/26 20:14:22.832
  I0127 20:14:22.833448 26 statefulset.go:1239] Observed &StatefulSet event: ADDED
  I0127 20:14:22.833517 26 statefulset.go:137] Deleting all statefulset in ns statefulset-2619
  I0127 20:14:22.834648 26 rest.go:153] Scaling statefulset ss to 0
  I0127 20:14:32.863992 26 wait.go:160] Waiting for statefulset status.replicas updated to 0
  I0127 20:14:32.866199 26 rest.go:91] Deleting statefulset ss
  I0127 20:14:32.886679 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-2619" for this suite. @ 01/27/26 20:14:32.888
• [20.179 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:179
  STEP: Creating a kubernetes client @ 01/27/26 20:14:32.9
  I0127 20:14:32.900791 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename replicaset @ 01/27/26 20:14:32.901
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:14:32.923
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:14:32.926
  STEP: Create a Replicaset @ 01/27/26 20:14:32.931
  STEP: Verify that the required pods have come up. @ 01/27/26 20:14:32.946
  I0127 20:14:32.957512 26 resource.go:64] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 01/27/26 20:14:32.957
  STEP: Getting /status @ 01/27/26 20:14:34.979
  I0127 20:14:34.981894 26 replica_set.go:653] Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 01/27/26 20:14:34.981
  I0127 20:14:34.992209 26 replica_set.go:673] updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 01/27/26 20:14:34.992
  I0127 20:14:34.993666 26 replica_set.go:699] Observed &ReplicaSet event: ADDED
  I0127 20:14:34.993740 26 replica_set.go:699] Observed &ReplicaSet event: MODIFIED
  I0127 20:14:34.993788 26 replica_set.go:699] Observed &ReplicaSet event: MODIFIED
  I0127 20:14:34.994110 26 replica_set.go:699] Observed &ReplicaSet event: MODIFIED
  I0127 20:14:34.994145 26 replica_set.go:692] Found replicaset test-rs in namespace replicaset-2665 with labels: map[name:sample-pod pod:agnhost] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0127 20:14:34.994159 26 replica_set.go:703] Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 01/27/26 20:14:34.994
  I0127 20:14:34.994187 26 replica_set.go:707] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0127 20:14:35.008979 26 replica_set.go:711] Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 01/27/26 20:14:35.009
  I0127 20:14:35.010553 26 replica_set.go:735] Observed &ReplicaSet event: ADDED
  I0127 20:14:35.010629 26 replica_set.go:735] Observed &ReplicaSet event: MODIFIED
  I0127 20:14:35.010688 26 replica_set.go:735] Observed &ReplicaSet event: MODIFIED
  I0127 20:14:35.010832 26 replica_set.go:735] Observed &ReplicaSet event: MODIFIED
  I0127 20:14:35.011031 26 replica_set.go:731] Observed replicaset test-rs in namespace replicaset-2665 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0127 20:14:35.011084 26 replica_set.go:735] Observed &ReplicaSet event: MODIFIED
  I0127 20:14:35.011105 26 replica_set.go:728] Found replicaset test-rs in namespace replicaset-2665 with labels: map[name:sample-pod pod:agnhost] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  I0127 20:14:35.011118 26 replica_set.go:739] Replicaset test-rs has a patched status
  I0127 20:14:35.011213 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-2665" for this suite. @ 01/27/26 20:14:35.013
• [2.121 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1078
  STEP: Creating a kubernetes client @ 01/27/26 20:14:35.021
  I0127 20:14:35.021457 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename resourcequota @ 01/27/26 20:14:35.021
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:14:35.036
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:14:35.042
  STEP: Creating resourceQuota "e2e-rq-status-7rjmd" @ 01/27/26 20:14:35.047
  I0127 20:14:35.063171 26 resource_quota.go:1114] Resource quota "e2e-rq-status-7rjmd" reports spec: hard cpu limit of 500m
  I0127 20:14:35.063201 26 resource_quota.go:1116] Resource quota "e2e-rq-status-7rjmd" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-7rjmd" /status @ 01/27/26 20:14:35.063
  STEP: Confirm /status for "e2e-rq-status-7rjmd" resourceQuota via watch @ 01/27/26 20:14:35.076
  I0127 20:14:35.077447 26 resource_quota.go:1143] observed resourceQuota "e2e-rq-status-7rjmd" in namespace "resourcequota-3354" with hard status: v1.ResourceList(nil)
  I0127 20:14:35.077510 26 resource_quota.go:1146] Found resourceQuota "e2e-rq-status-7rjmd" in namespace "resourcequota-3354" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0127 20:14:35.077524 26 resource_quota.go:1153] ResourceQuota "e2e-rq-status-7rjmd" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 01/27/26 20:14:35.079
  I0127 20:14:35.089893 26 resource_quota.go:1164] Resource quota "e2e-rq-status-7rjmd" reports spec: hard cpu limit of 1
  I0127 20:14:35.089927 26 resource_quota.go:1165] Resource quota "e2e-rq-status-7rjmd" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-7rjmd" /status @ 01/27/26 20:14:35.089
  STEP: Confirm /status for "e2e-rq-status-7rjmd" resourceQuota via watch @ 01/27/26 20:14:35.122
  I0127 20:14:35.124373 26 resource_quota.go:1187] observed resourceQuota "e2e-rq-status-7rjmd" in namespace "resourcequota-3354" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0127 20:14:35.124429 26 resource_quota.go:1190] Found resourceQuota "e2e-rq-status-7rjmd" in namespace "resourcequota-3354" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  I0127 20:14:35.124441 26 resource_quota.go:1197] ResourceQuota "e2e-rq-status-7rjmd" /status was patched
  STEP: Get "e2e-rq-status-7rjmd" /status @ 01/27/26 20:14:35.124
  I0127 20:14:35.126767 26 resource_quota.go:1208] Resourcequota "e2e-rq-status-7rjmd" reports status: hard cpu of 1
  I0127 20:14:35.126800 26 resource_quota.go:1210] Resourcequota "e2e-rq-status-7rjmd" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-7rjmd" /status before checking Spec is unchanged @ 01/27/26 20:14:35.128
  I0127 20:14:35.137159 26 resource_quota.go:1230] Resourcequota "e2e-rq-status-7rjmd" reports status: hard cpu of 2
  I0127 20:14:35.137214 26 resource_quota.go:1232] Resourcequota "e2e-rq-status-7rjmd" reports status: hard memory of 2Gi
  I0127 20:14:35.138526 26 resource_quota.go:1244] Found resourceQuota "e2e-rq-status-7rjmd" in namespace "resourcequota-3354" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  I0127 20:14:35.140310 26 resource_quota.go:1275] ResourceQuota "e2e-rq-status-7rjmd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-7rjmd", GenerateName:"", Namespace:"resourcequota-3354", SelfLink:"", UID:"121cf19d-9dc2-432e-980f-93e418d96b15", ResourceVersion:"8618", Generation:0, CreationTimestamp:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-7rjmd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0008b93b0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0008b93e0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"k3s", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0008b9410), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0127 20:14:40.144597 26 resource_quota.go:1275] ResourceQuota "e2e-rq-status-7rjmd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-7rjmd", GenerateName:"", Namespace:"resourcequota-3354", SelfLink:"", UID:"121cf19d-9dc2-432e-980f-93e418d96b15", ResourceVersion:"8618", Generation:0, CreationTimestamp:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-7rjmd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0008b9518), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0008b9548), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"k3s", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0008b9578), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0127 20:14:45.142130 26 resource_quota.go:1275] ResourceQuota "e2e-rq-status-7rjmd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-7rjmd", GenerateName:"", Namespace:"resourcequota-3354", SelfLink:"", UID:"121cf19d-9dc2-432e-980f-93e418d96b15", ResourceVersion:"8618", Generation:0, CreationTimestamp:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-7rjmd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0008b9650), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0008b9680), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"k3s", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0008b96b0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0127 20:14:50.145807 26 resource_quota.go:1275] ResourceQuota "e2e-rq-status-7rjmd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-7rjmd", GenerateName:"", Namespace:"resourcequota-3354", SelfLink:"", UID:"121cf19d-9dc2-432e-980f-93e418d96b15", ResourceVersion:"8618", Generation:0, CreationTimestamp:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-7rjmd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bf00c0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bf0108), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"k3s", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bf0138), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0127 20:14:55.141757 26 resource_quota.go:1275] ResourceQuota "e2e-rq-status-7rjmd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-7rjmd", GenerateName:"", Namespace:"resourcequota-3354", SelfLink:"", UID:"121cf19d-9dc2-432e-980f-93e418d96b15", ResourceVersion:"8618", Generation:0, CreationTimestamp:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-7rjmd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bf0228), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bf0258), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"k3s", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bf02a0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0127 20:15:00.141812 26 resource_quota.go:1275] ResourceQuota "e2e-rq-status-7rjmd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-7rjmd", GenerateName:"", Namespace:"resourcequota-3354", SelfLink:"", UID:"121cf19d-9dc2-432e-980f-93e418d96b15", ResourceVersion:"8618", Generation:0, CreationTimestamp:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-7rjmd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bf0390), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bf03c0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"k3s", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bf03f0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0127 20:15:05.145157 26 resource_quota.go:1275] ResourceQuota "e2e-rq-status-7rjmd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-7rjmd", GenerateName:"", Namespace:"resourcequota-3354", SelfLink:"", UID:"121cf19d-9dc2-432e-980f-93e418d96b15", ResourceVersion:"8618", Generation:0, CreationTimestamp:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-7rjmd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0008b97a0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0008b97d0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"k3s", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0008b9800), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0127 20:15:10.142293 26 resource_quota.go:1275] ResourceQuota "e2e-rq-status-7rjmd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-7rjmd", GenerateName:"", Namespace:"resourcequota-3354", SelfLink:"", UID:"121cf19d-9dc2-432e-980f-93e418d96b15", ResourceVersion:"8618", Generation:0, CreationTimestamp:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-7rjmd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bf04c8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bf04f8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"k3s", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bf0528), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0127 20:15:15.141635 26 resource_quota.go:1275] ResourceQuota "e2e-rq-status-7rjmd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-7rjmd", GenerateName:"", Namespace:"resourcequota-3354", SelfLink:"", UID:"121cf19d-9dc2-432e-980f-93e418d96b15", ResourceVersion:"8618", Generation:0, CreationTimestamp:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-7rjmd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bf06a8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bf06d8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"k3s", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bf0708), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0127 20:15:20.142031 26 resource_quota.go:1275] ResourceQuota "e2e-rq-status-7rjmd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-7rjmd", GenerateName:"", Namespace:"resourcequota-3354", SelfLink:"", UID:"121cf19d-9dc2-432e-980f-93e418d96b15", ResourceVersion:"8618", Generation:0, CreationTimestamp:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-7rjmd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bf07c8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bf0810), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"k3s", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bf0840), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0127 20:15:25.142099 26 resource_quota.go:1275] ResourceQuota "e2e-rq-status-7rjmd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-7rjmd", GenerateName:"", Namespace:"resourcequota-3354", SelfLink:"", UID:"121cf19d-9dc2-432e-980f-93e418d96b15", ResourceVersion:"8618", Generation:0, CreationTimestamp:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-7rjmd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0008b9938), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0008b9968), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"k3s", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0008b9998), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0127 20:15:30.145658 26 resource_quota.go:1275] ResourceQuota "e2e-rq-status-7rjmd" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-7rjmd", GenerateName:"", Namespace:"resourcequota-3354", SelfLink:"", UID:"121cf19d-9dc2-432e-980f-93e418d96b15", ResourceVersion:"8618", Generation:0, CreationTimestamp:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-7rjmd"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042dc0d8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042dc108), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"k3s", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 14, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042dc138), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0127 20:15:35.141584 26 resource_quota.go:1272] ResourceQuota "e2e-rq-status-7rjmd" Spec was unchanged and /status reset
  I0127 20:15:35.141719 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3354" for this suite. @ 01/27/26 20:15:35.143
• [60.135 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:209
  STEP: Creating a kubernetes client @ 01/27/26 20:15:35.157
  I0127 20:15:35.157096 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 20:15:35.157
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:15:35.179
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:15:35.184
  STEP: Setting up server cert @ 01/27/26 20:15:35.215
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 20:15:35.466
  STEP: Deploying the webhook pod @ 01/27/26 20:15:35.475
  STEP: Wait for the deployment to be ready @ 01/27/26 20:15:35.51
  I0127 20:15:35.518410 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 01/27/26 20:15:37.525
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 20:15:37.545
  I0127 20:15:37.545923 26 wait.go:65] Waiting for amount of service webhook-6713/e2e-test-webhook endpoints to be 1
  I0127 20:15:37.547907 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  STEP: Registering the webhook via the AdmissionRegistration API @ 01/27/26 20:15:38.549
  STEP: create a pod @ 01/27/26 20:15:38.578
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 01/27/26 20:15:40.604
  I0127 20:15:40.604893 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=webhook-6713 attach --namespace=webhook-6713 to-be-attached-pod -i -c=container1'
  I0127 20:15:40.673001 26 builder.go:145] rc: 1
  I0127 20:15:40.750772 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6713" for this suite. @ 01/27/26 20:15:40.761
  STEP: Destroying namespace "webhook-markers-1159" for this suite. @ 01/27/26 20:15:40.769
• [5.620 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1461
  STEP: Creating a kubernetes client @ 01/27/26 20:15:40.777
  I0127 20:15:40.777712 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename services @ 01/27/26 20:15:40.778
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:15:40.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:15:40.815
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-6989 @ 01/27/26 20:15:40.818
  STEP: changing the ExternalName service to type=NodePort @ 01/27/26 20:15:40.826
  I0127 20:15:40.882418 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  I0127 20:15:42.885784 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:2, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc0058a5be0), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 20, 15, 40, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 15, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 15, 42, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 15, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"externalname-service-5548c6d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0127 20:15:44.885645 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:2, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc0036ac000), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 20, 15, 40, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 15, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 15, 42, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 15, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"externalname-service-5548c6d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0127 20:15:46.952987 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:2, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc0036ac190), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 20, 15, 40, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 15, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 15, 42, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 15, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"externalname-service-5548c6d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0127 20:15:48.885973 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:2, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc0036ac310), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 20, 15, 40, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 15, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 15, 42, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 15, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"externalname-service-5548c6d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0127 20:15:50.885008 26 resource.go:344] Creating new exec pod
  I0127 20:15:52.921031 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-6989 exec execpodd5n4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0127 20:15:53.029614 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service (10.53.137.202) 80 port [tcp/http] succeeded!\n"
  I0127 20:15:53.029657 26 builder.go:157] stdout: "externalname-service-5548c6d5-79hvz"
  I0127 20:15:53.029722 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-6989 exec execpodd5n4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.137.202 80'
  I0127 20:15:53.141529 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.53.137.202 80\nConnection to 10.53.137.202 80 port [tcp/http] succeeded!\n"
  I0127 20:15:53.141570 26 builder.go:157] stdout: "externalname-service-5548c6d5-k2rbt"
  I0127 20:15:53.141649 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-6989 exec execpodd5n4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.42.0.10 31431'
  I0127 20:15:53.247309 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.42.0.10 31431\nConnection to 10.42.0.10 31431 port [tcp/*] succeeded!\n"
  I0127 20:15:53.247366 26 builder.go:157] stdout: ""
  I0127 20:15:54.142806 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-6989 exec execpodd5n4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.42.0.10 31431'
  I0127 20:15:54.253613 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.42.0.10 31431\nConnection to 10.42.0.10 31431 port [tcp/*] succeeded!\n"
  I0127 20:15:54.253653 26 builder.go:157] stdout: "externalname-service-5548c6d5-79hvz"
  I0127 20:15:54.253724 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-6989 exec execpodd5n4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.42.0.12 31431'
  I0127 20:15:54.364977 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.42.0.12 31431\nConnection to 10.42.0.12 31431 port [tcp/*] succeeded!\n"
  I0127 20:15:54.365024 26 builder.go:157] stdout: "externalname-service-5548c6d5-79hvz"
  I0127 20:15:54.365107 26 service.go:1470] Cleaning up the ExternalName to NodePort test service
  I0127 20:15:54.400326 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6989" for this suite. @ 01/27/26 20:15:54.403
• [13.633 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] VolumeAttachment Conformance should apply changes to a volumeattachment status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/volume_attachment.go:184
  STEP: Creating a kubernetes client @ 01/27/26 20:15:54.411
  I0127 20:15:54.411333 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename volumeattachment @ 01/27/26 20:15:54.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:15:54.439
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:15:54.452
  STEP: Create VolumeAttachment "va-e2e-sqrbw" on node "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2" @ 01/27/26 20:15:54.503
  STEP: Patch VolumeAttachment "va-e2e-sqrbw" on node "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2" @ 01/27/26 20:15:54.512
  STEP: Reading "va-e2e-sqrbw" Status @ 01/27/26 20:15:54.521
  STEP: Patching "va-e2e-sqrbw" Status @ 01/27/26 20:15:54.523
  I0127 20:15:54.532453 26 volume_attachment.go:228] "va-e2e-sqrbw" Status.Attached: true
  STEP: Updating "va-e2e-sqrbw" Status @ 01/27/26 20:15:54.532
  I0127 20:15:54.547052 26 volume_attachment.go:244] "va-e2e-sqrbw" Status.Attached: false
  STEP: Delete VolumeAttachment "va-e2e-sqrbw" on node "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2" @ 01/27/26 20:15:54.547
  STEP: Confirm deletion of VolumeAttachment "va-e2e-sqrbw" on node "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2" @ 01/27/26 20:15:54.563
  I0127 20:15:54.565784 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "volumeattachment-4640" for this suite. @ 01/27/26 20:15:54.604
• [0.202 seconds]
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:1160
  STEP: Creating a kubernetes client @ 01/27/26 20:15:54.613
  I0127 20:15:54.613475 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename job @ 01/27/26 20:15:54.614
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:15:54.631
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:15:54.64
  STEP: Creating a suspended job @ 01/27/26 20:15:54.648
  STEP: Patching the Job @ 01/27/26 20:15:54.658
  STEP: Watching for Job to be patched @ 01/27/26 20:15:54.693
  I0127 20:15:54.694923 26 job.go:1414] Event ADDED observed for Job e2e-2f54r in namespace job-131 with labels: map[e2e-job-label:e2e-2f54r] and annotations: map[]
  I0127 20:15:54.694955 26 job.go:1414] Event MODIFIED observed for Job e2e-2f54r in namespace job-131 with labels: map[e2e-job-label:e2e-2f54r] and annotations: map[]
  I0127 20:15:54.694975 26 job.go:1417] Event MODIFIED found for Job e2e-2f54r in namespace job-131 with labels: map[e2e-2f54r:patched e2e-job-label:e2e-2f54r] and annotations: map[]
  STEP: Updating the job @ 01/27/26 20:15:54.694
  STEP: Watching for Job to be updated @ 01/27/26 20:15:54.705
  I0127 20:15:54.706753 26 job.go:1417] Event MODIFIED found for Job e2e-2f54r in namespace job-131 with labels: map[e2e-2f54r:patched e2e-job-label:e2e-2f54r] and annotations: map[updated:true]
  I0127 20:15:54.706794 26 job.go:1240] Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 01/27/26 20:15:54.706
  I0127 20:15:54.708753 26 job.go:1247] Job: e2e-2f54r as labels: map[e2e-2f54r:patched e2e-job-label:e2e-2f54r]
  STEP: Waiting for job to complete @ 01/27/26 20:15:54.708
  STEP: Delete a job collection with a labelselector @ 01/27/26 20:16:02.775
  STEP: Watching for Job to be deleted @ 01/27/26 20:16:02.784
  I0127 20:16:02.786024 26 job.go:1414] Event MODIFIED observed for Job e2e-2f54r in namespace job-131 with labels: map[e2e-2f54r:patched e2e-job-label:e2e-2f54r] and annotations: map[updated:true]
  I0127 20:16:02.786056 26 job.go:1414] Event MODIFIED observed for Job e2e-2f54r in namespace job-131 with labels: map[e2e-2f54r:patched e2e-job-label:e2e-2f54r] and annotations: map[updated:true]
  I0127 20:16:02.786069 26 job.go:1414] Event MODIFIED observed for Job e2e-2f54r in namespace job-131 with labels: map[e2e-2f54r:patched e2e-job-label:e2e-2f54r] and annotations: map[updated:true]
  I0127 20:16:02.786237 26 job.go:1414] Event MODIFIED observed for Job e2e-2f54r in namespace job-131 with labels: map[e2e-2f54r:patched e2e-job-label:e2e-2f54r] and annotations: map[updated:true]
  I0127 20:16:02.786265 26 job.go:1414] Event MODIFIED observed for Job e2e-2f54r in namespace job-131 with labels: map[e2e-2f54r:patched e2e-job-label:e2e-2f54r] and annotations: map[updated:true]
  I0127 20:16:02.786289 26 job.go:1414] Event MODIFIED observed for Job e2e-2f54r in namespace job-131 with labels: map[e2e-2f54r:patched e2e-job-label:e2e-2f54r] and annotations: map[updated:true]
  I0127 20:16:02.786380 26 job.go:1414] Event MODIFIED observed for Job e2e-2f54r in namespace job-131 with labels: map[e2e-2f54r:patched e2e-job-label:e2e-2f54r] and annotations: map[updated:true]
  I0127 20:16:02.786485 26 job.go:1414] Event MODIFIED observed for Job e2e-2f54r in namespace job-131 with labels: map[e2e-2f54r:patched e2e-job-label:e2e-2f54r] and annotations: map[updated:true]
  I0127 20:16:02.786523 26 job.go:1414] Event MODIFIED observed for Job e2e-2f54r in namespace job-131 with labels: map[e2e-2f54r:patched e2e-job-label:e2e-2f54r] and annotations: map[updated:true]
  I0127 20:16:02.786900 26 job.go:1417] Event DELETED found for Job e2e-2f54r in namespace job-131 with labels: map[e2e-2f54r:patched e2e-job-label:e2e-2f54r] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 01/27/26 20:16:02.786
  I0127 20:16:02.788936 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-131" for this suite. @ 01/27/26 20:16:02.79
• [8.202 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 01/27/26 20:16:02.815
  I0127 20:16:02.815278 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename events @ 01/27/26 20:16:02.816
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:16:02.842
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:16:02.937
  STEP: creating a test event @ 01/27/26 20:16:02.94
  STEP: listing all events in all namespaces @ 01/27/26 20:16:02.954
  STEP: patching the test event @ 01/27/26 20:16:02.958
  STEP: fetching the test event @ 01/27/26 20:16:02.967
  STEP: updating the test event @ 01/27/26 20:16:02.969
  STEP: getting the test event @ 01/27/26 20:16:02.98
  STEP: deleting the test event @ 01/27/26 20:16:02.984
  STEP: listing all events in all namespaces @ 01/27/26 20:16:03.007
  I0127 20:16:03.011781 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-1013" for this suite. @ 01/27/26 20:16:03.014
• [0.207 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingressclass.go:270
  STEP: Creating a kubernetes client @ 01/27/26 20:16:03.022
  I0127 20:16:03.022397 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename ingressclass @ 01/27/26 20:16:03.022
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:16:03.045
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:16:03.047
  STEP: getting /apis @ 01/27/26 20:16:03.049
  STEP: getting /apis/networking.k8s.io @ 01/27/26 20:16:03.052
  STEP: getting /apis/networking.k8s.iov1 @ 01/27/26 20:16:03.052
  STEP: creating @ 01/27/26 20:16:03.054
  STEP: getting @ 01/27/26 20:16:03.088
  STEP: listing @ 01/27/26 20:16:03.09
  STEP: watching @ 01/27/26 20:16:03.091
  I0127 20:16:03.091935 26 ingressclass.go:351] starting watch
  STEP: patching @ 01/27/26 20:16:03.092
  STEP: updating @ 01/27/26 20:16:03.107
  I0127 20:16:03.115874 26 ingressclass.go:368] waiting for watch events with expected annotations
  I0127 20:16:03.115922 26 ingressclass.go:381] saw patched and updated annotations
  STEP: deleting @ 01/27/26 20:16:03.115
  STEP: deleting a collection @ 01/27/26 20:16:03.126
  I0127 20:16:03.143393 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-5032" for this suite. @ 01/27/26 20:16:03.146
• [0.139 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended (pod generation) Pod Generation custom-set generation on new pods and graceful delete [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:542
  STEP: Creating a kubernetes client @ 01/27/26 20:16:03.161
  I0127 20:16:03.161539 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pods @ 01/27/26 20:16:03.162
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:16:03.177
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:16:03.182
  STEP: creating the pod @ 01/27/26 20:16:03.184
  STEP: submitting the pod to kubernetes @ 01/27/26 20:16:03.184
  STEP: verifying the new pod's generation is 1 @ 01/27/26 20:16:05.205
  STEP: issue a graceful delete to trigger generation bump @ 01/27/26 20:16:05.205
  STEP: verifying the pod generation was bumped @ 01/27/26 20:16:05.223
  I0127 20:16:05.234832 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8029" for this suite. @ 01/27/26 20:16:05.237
• [2.084 seconds]
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:148
  STEP: Creating a kubernetes client @ 01/27/26 20:16:05.245
  I0127 20:16:05.245836 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename custom-resource-definition @ 01/27/26 20:16:05.246
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:16:05.273
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:16:05.274
  I0127 20:16:05.277236 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  I0127 20:16:05.835085 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-6170" for this suite. @ 01/27/26 20:16:05.837
• [0.615 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:903
  STEP: Creating a kubernetes client @ 01/27/26 20:16:05.861
  I0127 20:16:05.861259 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pods @ 01/27/26 20:16:05.861
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:16:05.89
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:16:05.893
  STEP: creating a Pod with a static label @ 01/27/26 20:16:05.898
  STEP: watching for Pod to be ready @ 01/27/26 20:16:05.914
  I0127 20:16:05.915572 26 pods.go:950] observed Pod pod-test in namespace pods-5491 in phase Pending with labels: map[test-pod-static:true] & conditions []
  I0127 20:16:05.922961 26 pods.go:950] observed Pod pod-test in namespace pods-5491 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled 0 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:16:05 +0000 UTC  }]
  I0127 20:16:05.953400 26 pods.go:950] observed Pod pod-test in namespace pods-5491 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers 1 False 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:16:05 +0000 UTC  } {Initialized 1 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:16:05 +0000 UTC  } {Ready 1 False 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:16:05 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady 1 False 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:16:05 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled 1 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:16:05 +0000 UTC  }]
  I0127 20:16:06.820477 26 pods.go:953] Found Pod pod-test in namespace pods-5491 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers 1 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:16:06 +0000 UTC  } {Initialized 1 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:16:05 +0000 UTC  } {Ready 1 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:16:06 +0000 UTC  } {ContainersReady 1 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:16:06 +0000 UTC  } {PodScheduled 1 True 0001-01-01 00:00:00 +0000 UTC 2026-01-27 20:16:05 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 01/27/26 20:16:06.822
  STEP: getting the Pod and ensuring that it's patched @ 01/27/26 20:16:06.844
  STEP: replacing the Pod's status Ready condition to False @ 01/27/26 20:16:06.853
  STEP: check the Pod again to ensure its Ready conditions are False @ 01/27/26 20:16:06.865
  STEP: deleting the Pod via a Collection with a LabelSelector @ 01/27/26 20:16:06.865
  STEP: watching for the Pod to be deleted @ 01/27/26 20:16:06.882
  I0127 20:16:06.883809 26 pods.go:1065] observed event type MODIFIED
  I0127 20:16:07.829161 26 pods.go:1065] observed event type MODIFIED
  I0127 20:16:08.825431 26 pods.go:1065] observed event type MODIFIED
  I0127 20:16:09.079663 26 pods.go:1065] observed event type MODIFIED
  I0127 20:16:09.834358 26 pods.go:1065] observed event type MODIFIED
  I0127 20:16:09.847267 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5491" for this suite. @ 01/27/26 20:16:09.85
• [4.004 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:262
  STEP: Creating a kubernetes client @ 01/27/26 20:16:09.865
  I0127 20:16:09.865169 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename downward-api @ 01/27/26 20:16:09.865
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:16:09.881
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:16:09.887
  STEP: Creating a pod to test downward API volume plugin @ 01/27/26 20:16:09.888
  STEP: Saw pod success @ 01/27/26 20:16:13.914
  I0127 20:16:13.916664 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downwardapi-volume-2b681c66-65be-4c42-8404-d2f6867e9c7f container client-container: <nil>
  STEP: delete the pod @ 01/27/26 20:16:13.926
  I0127 20:16:13.955404 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8125" for this suite. @ 01/27/26 20:16:13.957
• [4.102 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:916
  STEP: Creating a kubernetes client @ 01/27/26 20:16:13.966
  I0127 20:16:13.966824 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubectl @ 01/27/26 20:16:13.967
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:16:14.001
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:16:14.003
  STEP: validating api versions @ 01/27/26 20:16:14.005
  I0127 20:16:14.005121 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3104 api-versions'
  I0127 20:16:14.059490 26 builder.go:156] stderr: ""
  I0127 20:16:14.059550 26 builder.go:157] stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\ngateway.networking.k8s.io/v1\ngateway.networking.k8s.io/v1beta1\nhelm.cattle.io/v1\nhub.traefik.io/v1alpha1\nk3s.cattle.io/v1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nresource.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\ntraefik.io/v1alpha1\nv1\n"
  I0127 20:16:14.059711 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3104" for this suite. @ 01/27/26 20:16:14.062
• [0.105 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:756
  STEP: Creating a kubernetes client @ 01/27/26 20:16:14.072
  I0127 20:16:14.072087 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename sched-preemption @ 01/27/26 20:16:14.072
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:16:14.099
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:16:14.101
  I0127 20:16:14.130816 26 wait.go:53] Waiting up to 1m0s for all nodes to be ready
  I0127 20:17:14.134104 26 util.go:389] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 01/27/26 20:17:14.136
  I0127 20:17:14.136841 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename sched-preemption-path @ 01/27/26 20:17:14.137
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:17:14.159
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:17:14.161
  STEP: Finding an available node @ 01/27/26 20:17:14.163
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 01/27/26 20:17:14.163
  STEP: Explicitly delete pod here to free the resource it takes. @ 01/27/26 20:17:16.186
  I0127 20:17:16.213386 26 preemption.go:719] found a healthy node: k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2
  STEP: Adding a custom resource @ 01/27/26 20:17:16.215
  I0127 20:17:22.309774 26 preemption.go:838] pods created so far: [1 1 1]
  I0127 20:17:22.309805 26 preemption.go:839] length of pods created so far: 3
  I0127 20:17:24.326553 26 preemption.go:856] pods created so far: [2 2 1]
  STEP: Removing a custom resource @ 01/27/26 20:17:31.327
  STEP: Removing a custom resource @ 01/27/26 20:17:31.412
  STEP: Removing a custom resource @ 01/27/26 20:17:31.417
  I0127 20:17:31.423514 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-1217" for this suite. @ 01/27/26 20:17:31.425
  I0127 20:17:31.433417 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-4810" for this suite. @ 01/27/26 20:17:31.526
• [77.468 seconds]
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:157
  STEP: Creating a kubernetes client @ 01/27/26 20:17:31.54
  I0127 20:17:31.540400 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename replicaset @ 01/27/26 20:17:31.54
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:17:31.563
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:17:31.569
  I0127 20:17:31.589677 26 resource.go:64] Pod name sample-pod: Found 0 pods out of 1
  I0127 20:17:36.640116 26 resource.go:64] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 01/27/26 20:17:36.64
  STEP: Scaling up "test-rs" replicaset @ 01/27/26 20:17:36.64
  I0127 20:17:36.670140 26 replicaset.go:44] Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 01/27/26 20:17:36.67
  I0127 20:17:36.683642 26 replica_set.go:548] observed ReplicaSet test-rs in namespace replicaset-976 with ReadyReplicas 1, AvailableReplicas 1
  I0127 20:17:36.715497 26 replica_set.go:548] observed ReplicaSet test-rs in namespace replicaset-976 with ReadyReplicas 1, AvailableReplicas 1
  I0127 20:17:36.782088 26 replica_set.go:548] observed ReplicaSet test-rs in namespace replicaset-976 with ReadyReplicas 1, AvailableReplicas 1
  I0127 20:17:36.796910 26 replica_set.go:548] observed ReplicaSet test-rs in namespace replicaset-976 with ReadyReplicas 1, AvailableReplicas 1
  I0127 20:17:39.056560 26 replica_set.go:548] observed ReplicaSet test-rs in namespace replicaset-976 with ReadyReplicas 2, AvailableReplicas 2
  I0127 20:17:39.600821 26 replica_set.go:551] observed Replicaset test-rs in namespace replicaset-976 with ReadyReplicas 3 found true
  I0127 20:17:39.600966 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-976" for this suite. @ 01/27/26 20:17:39.603
• [8.074 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:717
  STEP: Creating a kubernetes client @ 01/27/26 20:17:39.614
  I0127 20:17:39.614862 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 20:17:39.615
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:17:39.641
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:17:39.643
  STEP: Setting up server cert @ 01/27/26 20:17:39.674
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 20:17:39.953
  STEP: Deploying the webhook pod @ 01/27/26 20:17:39.961
  STEP: Wait for the deployment to be ready @ 01/27/26 20:17:39.988
  I0127 20:17:40.003243 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 01/27/26 20:17:42.009
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 20:17:42.026
  I0127 20:17:42.026740 26 wait.go:65] Waiting for amount of service webhook-3375/e2e-test-webhook endpoints to be 1
  I0127 20:17:42.028613 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  STEP: creating a validating webhook with match conditions @ 01/27/26 20:17:43.03
  STEP: verifying the validating webhook match conditions @ 01/27/26 20:17:43.046
  STEP: updating the validating webhook match conditions @ 01/27/26 20:17:43.05
  STEP: verifying the validating webhook match conditions @ 01/27/26 20:17:43.067
  I0127 20:17:43.147395 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3375" for this suite. @ 01/27/26 20:17:43.15
  STEP: Destroying namespace "webhook-markers-4814" for this suite. @ 01/27/26 20:17:43.167
• [3.565 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:262
  STEP: Creating a kubernetes client @ 01/27/26 20:17:43.179
  I0127 20:17:43.179717 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 20:17:43.18
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:17:43.203
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:17:43.208
  STEP: Creating a pod to test downward API volume plugin @ 01/27/26 20:17:43.21
  STEP: Saw pod success @ 01/27/26 20:17:47.23
  I0127 20:17:47.233170 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downwardapi-volume-9b93eb68-bd70-488f-a8b4-a7010b5d090f container client-container: <nil>
  STEP: delete the pod @ 01/27/26 20:17:47.242
  I0127 20:17:47.274437 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7203" for this suite. @ 01/27/26 20:17:47.277
• [4.106 seconds]
------------------------------
SS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:448
  STEP: Creating a kubernetes client @ 01/27/26 20:17:47.285
  I0127 20:17:47.285551 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pods @ 01/27/26 20:17:47.286
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:17:47.31
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:17:47.314
  STEP: Saw pod success @ 01/27/26 20:17:53.394
  I0127 20:17:53.397387 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod client-envvars-bf111991-0746-42d6-9a0a-c6ce7a93f5c5 container env3cont: <nil>
  STEP: delete the pod @ 01/27/26 20:17:53.402
  I0127 20:17:53.429886 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6028" for this suite. @ 01/27/26 20:17:53.433
• [6.155 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Pod InPlace Resize Container guaranteed pods with multiple containers 3 containers - increase: CPU (c1,c3), memory (c2, c3) ; decrease: CPU (c2) [MinimumKubeletVersion:1.34] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pod_resize.go:205
  STEP: Creating a kubernetes client @ 01/27/26 20:17:53.44
  I0127 20:17:53.440752 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pod-resize-tests @ 01/27/26 20:17:53.441
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:17:53.469
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:17:53.47
  STEP: creating and verifying pod @ 01/27/26 20:17:53.532
  I0127 20:17:59.563753 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c mount -t cgroup2] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:17:59.563784 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:17:59.563857 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=mount+-t+cgroup2&container=c1&stderr=true&stdout=true)
  I0127 20:18:00.842771 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c1 - looking for one of the expected cgroup values [20971520] in path /sys/fs/cgroup/memory.max
  I0127 20:18:00.842812 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:00.842823 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:00.842870 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c1&stderr=true&stdout=true)
  I0127 20:18:02.443388 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c1 - looking for one of the expected cgroup values [2000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 20:18:02.443433 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:02.443445 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:02.443489 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c1&stderr=true&stdout=true)
  I0127 20:18:04.043175 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c1 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 20:18:04.043217 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:04.043237 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:04.043284 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c1&stderr=true&stdout=true)
  I0127 20:18:05.641974 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c2 - looking for one of the expected cgroup values [23068672] in path /sys/fs/cgroup/memory.max
  I0127 20:18:05.642017 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:05.642028 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:05.642085 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c2&stderr=true&stdout=true)
  I0127 20:18:06.871650 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c2 - looking for one of the expected cgroup values [2200 100000 3000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 20:18:06.871689 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:06.871700 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:06.871759 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c2&stderr=true&stdout=true)
  I0127 20:18:08.360989 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c2 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 20:18:08.361044 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:08.361057 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:08.361115 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c2&stderr=true&stdout=true)
  I0127 20:18:09.769945 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c3 - looking for one of the expected cgroup values [25165824] in path /sys/fs/cgroup/memory.max
  I0127 20:18:09.769999 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:09.770010 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:09.770059 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c3&stderr=true&stdout=true)
  I0127 20:18:11.173205 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c3 - looking for one of the expected cgroup values [2400 100000 3000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 20:18:11.173245 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:11.173256 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:11.173302 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c3&stderr=true&stdout=true)
  I0127 20:18:12.573279 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c3 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 20:18:12.573336 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:12.573348 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:12.573401 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c3&stderr=true&stdout=true)
  STEP: patching and verifying pod for resize @ 01/27/26 20:18:13.873
  I0127 20:18:15.911407 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c1 - looking for one of the expected cgroup values [20971520] in path /sys/fs/cgroup/memory.max
  I0127 20:18:15.911444 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:15.911455 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:15.911495 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c1&stderr=true&stdout=true)
  I0127 20:18:17.244165 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c1 - looking for one of the expected cgroup values [2500 100000 3000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 20:18:17.244222 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:17.244233 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:17.244298 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c1&stderr=true&stdout=true)
  I0127 20:18:18.541913 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c1 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 20:18:18.541955 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:18.541966 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:18.542021 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c1&stderr=true&stdout=true)
  I0127 20:18:19.840811 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c2 - looking for one of the expected cgroup values [28311552] in path /sys/fs/cgroup/memory.max
  I0127 20:18:19.840862 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:19.840873 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:19.840921 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c2&stderr=true&stdout=true)
  I0127 20:18:21.772796 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c2 - looking for one of the expected cgroup values [1700 100000 2000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 20:18:21.772838 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:21.772849 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:21.772894 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c2&stderr=true&stdout=true)
  I0127 20:18:23.470885 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c2 - looking for one of the expected cgroup values [1 5] in path /sys/fs/cgroup/cpu.weight
  I0127 20:18:23.470944 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:23.470955 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:23.471006 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c2&stderr=true&stdout=true)
  I0127 20:18:25.561008 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c3 - looking for one of the expected cgroup values [30408704] in path /sys/fs/cgroup/memory.max
  I0127 20:18:25.561058 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:25.561070 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:25.561117 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c3&stderr=true&stdout=true)
  I0127 20:18:26.672971 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c3 - looking for one of the expected cgroup values [2900 100000 3000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 20:18:26.673015 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:26.673026 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:26.673079 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c3&stderr=true&stdout=true)
  I0127 20:18:27.772195 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c3 - looking for one of the expected cgroup values [2 7] in path /sys/fs/cgroup/cpu.weight
  I0127 20:18:27.772238 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:27.772249 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:27.772306 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c3&stderr=true&stdout=true)
  STEP: patching and verifying pod for rollback @ 01/27/26 20:18:28.972
  I0127 20:18:31.002217 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c1 - looking for one of the expected cgroup values [20971520] in path /sys/fs/cgroup/memory.max
  I0127 20:18:31.002257 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:31.002272 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:31.002310 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c1&stderr=true&stdout=true)
  I0127 20:18:32.542235 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c1 - looking for one of the expected cgroup values [2000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 20:18:32.542289 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:32.542300 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:32.542350 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c1&stderr=true&stdout=true)
  I0127 20:18:34.141890 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c1 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 20:18:34.141931 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:34.141942 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:34.141991 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c1&stderr=true&stdout=true)
  I0127 20:18:35.741460 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c2 - looking for one of the expected cgroup values [23068672] in path /sys/fs/cgroup/memory.max
  I0127 20:18:35.741506 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:35.741516 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:35.741568 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c2&stderr=true&stdout=true)
  I0127 20:18:37.358412 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c2 - looking for one of the expected cgroup values [2200 100000 3000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 20:18:37.358457 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:37.358468 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:37.358517 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c2&stderr=true&stdout=true)
  I0127 20:18:38.671782 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c2 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 20:18:38.671822 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:38.671840 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:38.671887 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c2&stderr=true&stdout=true)
  I0127 20:18:40.160488 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c3 - looking for one of the expected cgroup values [25165824] in path /sys/fs/cgroup/memory.max
  I0127 20:18:40.160530 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:40.160551 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:40.160601 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c3&stderr=true&stdout=true)
  I0127 20:18:41.573894 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c3 - looking for one of the expected cgroup values [2400 100000 3000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 20:18:41.573936 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:41.573947 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:41.573994 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c3&stderr=true&stdout=true)
  I0127 20:18:42.973053 26 cgroups.go:379] Namespace pod-resize-tests-7400 Pod resize-test-jqm5g Container c3 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 20:18:42.973097 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-7400 PodName:resize-test-jqm5g ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:18:42.973110 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:18:42.973167 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-7400/pods/resize-test-jqm5g/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c3&stderr=true&stdout=true)
  STEP: deleting pod @ 01/27/26 20:18:44.273
  I0127 20:18:44.312044 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-resize-tests-7400" for this suite. @ 01/27/26 20:18:44.315
• [50.892 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:194
  STEP: Creating a kubernetes client @ 01/27/26 20:18:44.333
  I0127 20:18:44.333353 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 20:18:44.333
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:18:44.352
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:18:44.357
  STEP: Creating a pod to test downward API volume plugin @ 01/27/26 20:18:44.361
  STEP: Saw pod success @ 01/27/26 20:18:48.392
  I0127 20:18:48.394531 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downwardapi-volume-ec66f88d-af3d-4ddf-8de4-4cf081bbc551 container client-container: <nil>
  STEP: delete the pod @ 01/27/26 20:18:48.399
  I0127 20:18:48.423903 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9135" for this suite. @ 01/27/26 20:18:48.426
• [4.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:448
  STEP: Creating a kubernetes client @ 01/27/26 20:18:48.434
  I0127 20:18:48.434059 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename daemonsets @ 01/27/26 20:18:48.434
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:18:48.451
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:18:48.46
  I0127 20:18:48.531735 26 daemon_set.go:452] Create a RollingUpdate DaemonSet
  I0127 20:18:48.539682 26 daemon_set.go:459] Check that daemon pods launch on every node of the cluster
  I0127 20:18:48.628863 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 20:18:48.628908 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  I0127 20:18:49.544220 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 20:18:49.544257 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  I0127 20:18:50.545692 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0127 20:18:50.545726 26 fixtures.go:138] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  I0127 20:18:50.545740 26 daemon_set.go:463] Update the DaemonSet to trigger a rollout
  I0127 20:18:50.555310 26 daemon_set.go:104] Updating DaemonSet daemon-set
  I0127 20:18:51.562579 26 daemon_set.go:498] Roll back the DaemonSet before rollout is complete
  I0127 20:18:51.578561 26 daemon_set.go:104] Updating DaemonSet daemon-set
  I0127 20:18:51.579029 26 daemon_set.go:504] Make sure DaemonSet rollback is complete
  I0127 20:18:51.581806 26 daemon_set.go:1198] Wrong image for pod: daemon-set-wnjm9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.59, got: foo:non-existent.
  I0127 20:18:51.581832 26 daemon_set.go:1203] Pod daemon-set-wnjm9 is not available
  I0127 20:18:54.581911 26 daemon_set.go:1203] Pod daemon-set-59fq2 is not available
  STEP: Deleting DaemonSet "daemon-set" @ 01/27/26 20:18:54.588
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2595, will wait for the garbage collector to delete the pods @ 01/27/26 20:18:54.588
  I0127 20:18:54.648144 26 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 7.559588ms
  I0127 20:18:54.849032 26 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 200.885846ms
  I0127 20:18:56.851520 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 20:18:56.851558 26 fixtures.go:138] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0127 20:18:56.854349 26 daemon_set.go:137] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"10402"},"items":null}

  I0127 20:18:56.856501 26 daemon_set.go:142] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"10402"},"items":null}

  I0127 20:18:56.861670 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-2595" for this suite. @ 01/27/26 20:18:56.863
• [8.438 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:131
  STEP: Creating a kubernetes client @ 01/27/26 20:18:56.872
  I0127 20:18:56.872082 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename downward-api @ 01/27/26 20:18:56.872
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:18:56.905
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:18:56.906
  STEP: Creating the pod @ 01/27/26 20:18:56.909
  I0127 20:18:59.454734 26 pod_client.go:187] Successfully updated pod "labelsupdated6e692d1-d10f-4668-bef5-6dec445b7329"
  I0127 20:19:01.465779 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6316" for this suite. @ 01/27/26 20:19:01.468
• [4.604 seconds]
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:90
  STEP: Creating a kubernetes client @ 01/27/26 20:19:01.476
  I0127 20:19:01.476302 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename containers @ 01/27/26 20:19:01.477
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:19:01.503
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:19:01.505
  STEP: Creating a pod to test override all @ 01/27/26 20:19:01.508
  STEP: Saw pod success @ 01/27/26 20:19:05.526
  I0127 20:19:05.529218 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod client-containers-ad50fa28-525c-47ad-99d9-96a40c58bc98 container agnhost-container: <nil>
  STEP: delete the pod @ 01/27/26 20:19:05.533
  I0127 20:19:05.569308 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-7590" for this suite. @ 01/27/26 20:19:05.573
• [4.107 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:74
  STEP: Creating a kubernetes client @ 01/27/26 20:19:05.583
  I0127 20:19:05.583484 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 20:19:05.584
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:19:05.61
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:19:05.612
  STEP: Creating configMap with name projected-configmap-test-volume-8e90093a-721c-4c3d-9338-8d13ddda8d0b @ 01/27/26 20:19:05.614
  STEP: Creating a pod to test consume configMaps @ 01/27/26 20:19:05.622
  STEP: Saw pod success @ 01/27/26 20:19:09.646
  I0127 20:19:09.648095 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-projected-configmaps-cd6c2310-57b3-4c43-bd8a-3836518da517 container agnhost-container: <nil>
  STEP: delete the pod @ 01/27/26 20:19:09.651
  I0127 20:19:09.682906 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-270" for this suite. @ 01/27/26 20:19:09.686
• [4.112 seconds]
------------------------------
SSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 01/27/26 20:19:09.695
  I0127 20:19:09.695940 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename container-probe @ 01/27/26 20:19:09.696
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:19:09.724
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:19:09.73
  STEP: Creating pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399 @ 01/27/26 20:19:09.74
  STEP: checking the pod's current state and verifying that restartCount is present @ 01/27/26 20:19:11.761
  I0127 20:19:11.763977 26 container_probe.go:1746] Initial restart count of pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e is 0
  I0127 20:19:11.765584 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:13.769262 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:15.772294 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:17.775118 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:19.778769 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:21.782199 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:23.785574 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:25.788997 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:27.790925 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:29.793400 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:31.800064 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:33.802792 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:35.805372 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:37.808510 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:39.810659 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:41.814294 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:43.818926 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:45.822899 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:47.825858 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:49.828642 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:51.831692 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:53.834904 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:55.838579 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:57.841937 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:19:59.846784 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:20:01.849997 26 container_probe.go:1756] Get pod busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e in namespace container-probe-8399
  I0127 20:20:01.850034 26 container_probe.go:1760] Restart count of pod container-probe-8399/busybox-3771f90b-c595-4b4b-837f-bb7cefe0126e is now 1 (50.08602664s elapsed)
  STEP: deleting the pod @ 01/27/26 20:20:01.85
  I0127 20:20:01.872003 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8399" for this suite. @ 01/27/26 20:20:01.876
• [52.189 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:450
  STEP: Creating a kubernetes client @ 01/27/26 20:20:01.885
  I0127 20:20:01.885388 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pv @ 01/27/26 20:20:01.885
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:20:01.913
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:20:01.915
  STEP: Creating initial PV and PVC @ 01/27/26 20:20:01.916
  I0127 20:20:01.916984 26 pv.go:394] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-9035" @ 01/27/26 20:20:01.934
  STEP: Listing PVCs in namespace "pv-9035" @ 01/27/26 20:20:01.939
  STEP: Patching the PV "pv-9035-2zvjr" @ 01/27/26 20:20:01.951
  STEP: Patching the PVC "pvc-txcmb" @ 01/27/26 20:20:01.97
  STEP: Getting PV "pv-9035-2zvjr" @ 01/27/26 20:20:01.981
  STEP: Getting PVC "pvc-txcmb" @ 01/27/26 20:20:01.983
  STEP: Deleting PVC "pvc-txcmb" @ 01/27/26 20:20:01.988
  STEP: Confirm deletion of PVC "pvc-txcmb" @ 01/27/26 20:20:02.001
  STEP: Deleting PV "pv-9035-2zvjr" @ 01/27/26 20:20:04.01
  STEP: Confirm deletion of PV "pv-9035-2zvjr" @ 01/27/26 20:20:04.017
  STEP: Recreating another PV & PVC @ 01/27/26 20:20:06.023
  I0127 20:20:06.023571 26 pv.go:394] Creating a PV followed by a PVC
  STEP: Updating the PV "pv-9035-bfbfv" @ 01/27/26 20:20:06.051
  STEP: Updating the PVC "pvc-sklmv" @ 01/27/26 20:20:06.082
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-sklmv=updated" @ 01/27/26 20:20:06.096
  STEP: Deleting PVC "pvc-sklmv" via DeleteCollection @ 01/27/26 20:20:06.108
  STEP: Confirm deletion of PVC "pvc-sklmv" @ 01/27/26 20:20:06.128
  STEP: Deleting PV "pv-9035-bfbfv" via DeleteCollection @ 01/27/26 20:20:08.136
  STEP: Confirm deletion of PV "pv-9035-bfbfv" @ 01/27/26 20:20:08.145
  I0127 20:20:10.149626 26 persistent_volumes.go:427] AfterEach: deleting 1 PVCs and 1 PVs...
  I0127 20:20:10.149660 26 pv.go:205] Deleting PersistentVolumeClaim "pvc-sklmv"
  I0127 20:20:10.151666 26 pv.go:193] Deleting PersistentVolume "pv-9035-bfbfv"
  I0127 20:20:10.153637 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-9035" for this suite. @ 01/27/26 20:20:10.155
• [8.284 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 01/27/26 20:20:10.169
  I0127 20:20:10.169490 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename var-expansion @ 01/27/26 20:20:10.17
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:20:10.195
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:20:10.281
  I0127 20:20:12.317135 26 delete.go:78] Deleting pod "var-expansion-187595c2-90ee-4381-8aa6-9dfa8bd2d2c9" in namespace "var-expansion-19"
  I0127 20:20:12.331230 26 delete.go:86] Wait up to 5m0s for pod "var-expansion-187595c2-90ee-4381-8aa6-9dfa8bd2d2c9" to be fully deleted
  I0127 20:20:14.336813 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-19" for this suite. @ 01/27/26 20:20:14.339
• [4.183 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:357
  STEP: Creating a kubernetes client @ 01/27/26 20:20:14.352
  I0127 20:20:14.352662 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubectl @ 01/27/26 20:20:14.353
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:20:14.374
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:20:14.379
  STEP: creating a replication controller @ 01/27/26 20:20:14.385
  I0127 20:20:14.385464 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3334 create -f -'
  I0127 20:20:14.512055 26 builder.go:156] stderr: ""
  I0127 20:20:14.512094 26 builder.go:157] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 01/27/26 20:20:14.512
  I0127 20:20:14.512175 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3334 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0127 20:20:14.574438 26 builder.go:156] stderr: ""
  I0127 20:20:14.574476 26 builder.go:157] stdout: "update-demo-nautilus-76mkm update-demo-nautilus-8vhbn "
  I0127 20:20:14.574519 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3334 get pods update-demo-nautilus-76mkm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0127 20:20:14.641010 26 builder.go:156] stderr: ""
  I0127 20:20:14.641053 26 builder.go:157] stdout: ""
  I0127 20:20:14.641065 26 kubectl.go:2537] update-demo-nautilus-76mkm is created but not running
  I0127 20:20:19.644598 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3334 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0127 20:20:19.711801 26 builder.go:156] stderr: ""
  I0127 20:20:19.711881 26 builder.go:157] stdout: "update-demo-nautilus-76mkm update-demo-nautilus-8vhbn "
  I0127 20:20:19.711920 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3334 get pods update-demo-nautilus-76mkm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0127 20:20:20.140576 26 builder.go:156] stderr: ""
  I0127 20:20:20.140612 26 builder.go:157] stdout: ""
  I0127 20:20:20.140622 26 kubectl.go:2537] update-demo-nautilus-76mkm is created but not running
  I0127 20:20:25.141059 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3334 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0127 20:20:25.299307 26 builder.go:156] stderr: ""
  I0127 20:20:25.299360 26 builder.go:157] stdout: "update-demo-nautilus-76mkm update-demo-nautilus-8vhbn "
  I0127 20:20:25.299405 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3334 get pods update-demo-nautilus-76mkm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0127 20:20:25.428874 26 builder.go:156] stderr: ""
  I0127 20:20:25.428912 26 builder.go:157] stdout: ""
  I0127 20:20:25.428924 26 kubectl.go:2537] update-demo-nautilus-76mkm is created but not running
  I0127 20:20:30.430060 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3334 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0127 20:20:30.499711 26 builder.go:156] stderr: ""
  I0127 20:20:30.499755 26 builder.go:157] stdout: "update-demo-nautilus-76mkm update-demo-nautilus-8vhbn "
  I0127 20:20:30.499820 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3334 get pods update-demo-nautilus-76mkm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0127 20:20:30.633428 26 builder.go:156] stderr: ""
  I0127 20:20:30.633480 26 builder.go:157] stdout: ""
  I0127 20:20:30.633490 26 kubectl.go:2537] update-demo-nautilus-76mkm is created but not running
  I0127 20:20:35.633608 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3334 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0127 20:20:35.703096 26 builder.go:156] stderr: ""
  I0127 20:20:35.703138 26 builder.go:157] stdout: "update-demo-nautilus-76mkm update-demo-nautilus-8vhbn "
  I0127 20:20:35.703186 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3334 get pods update-demo-nautilus-76mkm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0127 20:20:35.762893 26 builder.go:156] stderr: ""
  I0127 20:20:35.762931 26 builder.go:157] stdout: "true"
  I0127 20:20:35.762975 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3334 get pods update-demo-nautilus-76mkm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0127 20:20:35.824545 26 builder.go:156] stderr: ""
  I0127 20:20:35.824592 26 builder.go:157] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0127 20:20:35.824606 26 kubectl.go:2428] validating pod update-demo-nautilus-76mkm
  I0127 20:20:35.831919 26 kubectl.go:2448] got data: {
    "image": "nautilus.jpg"
  }

  I0127 20:20:35.832001 26 kubectl.go:2453] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0127 20:20:35.832013 26 kubectl.go:2555] update-demo-nautilus-76mkm is verified up and running
  I0127 20:20:35.832048 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3334 get pods update-demo-nautilus-8vhbn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0127 20:20:35.890227 26 builder.go:156] stderr: ""
  I0127 20:20:35.890268 26 builder.go:157] stdout: "true"
  I0127 20:20:35.890307 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3334 get pods update-demo-nautilus-8vhbn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0127 20:20:35.948168 26 builder.go:156] stderr: ""
  I0127 20:20:35.948220 26 builder.go:157] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0127 20:20:35.948235 26 kubectl.go:2428] validating pod update-demo-nautilus-8vhbn
  I0127 20:20:35.952985 26 kubectl.go:2448] got data: {
    "image": "nautilus.jpg"
  }

  I0127 20:20:35.953034 26 kubectl.go:2453] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0127 20:20:35.953045 26 kubectl.go:2555] update-demo-nautilus-8vhbn is verified up and running
  STEP: using delete to clean up resources @ 01/27/26 20:20:35.953
  I0127 20:20:35.953103 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3334 delete --grace-period=0 --force -f -'
  I0127 20:20:36.016143 26 builder.go:156] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0127 20:20:36.016187 26 builder.go:157] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted from kubectl-3334 namespace\n"
  I0127 20:20:36.016233 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3334 get rc,svc -l name=update-demo --no-headers'
  I0127 20:20:36.093360 26 builder.go:156] stderr: "No resources found in kubectl-3334 namespace.\n"
  I0127 20:20:36.093400 26 builder.go:157] stdout: ""
  I0127 20:20:36.093443 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3334 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0127 20:20:36.153283 26 builder.go:156] stderr: ""
  I0127 20:20:36.153335 26 builder.go:157] stdout: ""
  I0127 20:20:36.153444 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3334" for this suite. @ 01/27/26 20:20:36.156
• [21.950 seconds]
------------------------------
SSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:135
  STEP: Creating a kubernetes client @ 01/27/26 20:20:36.302
  I0127 20:20:36.302629 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename security-context @ 01/27/26 20:20:36.303
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:20:36.572
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:20:36.732
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 01/27/26 20:20:36.734
  STEP: Saw pod success @ 01/27/26 20:20:47.216
  I0127 20:20:47.229017 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod security-context-bc7fcf4d-99d6-44a8-ba07-f28e96c562e7 container test-container: <nil>
  STEP: delete the pod @ 01/27/26 20:20:47.237
  I0127 20:20:47.259490 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-3409" for this suite. @ 01/27/26 20:20:47.262
• [10.968 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:184
  STEP: Creating a kubernetes client @ 01/27/26 20:20:47.27
  I0127 20:20:47.270478 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubelet-test @ 01/27/26 20:20:47.271
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:20:47.296
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:20:47.299
  I0127 20:20:49.322959 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-615" for this suite. @ 01/27/26 20:20:49.325
• [2.064 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:413
  STEP: Creating a kubernetes client @ 01/27/26 20:20:49.334
  I0127 20:20:49.334716 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubectl @ 01/27/26 20:20:49.335
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:20:49.371
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:20:49.374
  STEP: creating all guestbook components @ 01/27/26 20:20:49.377
  I0127 20:20:49.377573 26 kubectl.go:419] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  I0127 20:20:49.377659 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-5976 create -f -'
  I0127 20:20:49.510656 26 builder.go:156] stderr: ""
  I0127 20:20:49.510699 26 builder.go:157] stdout: "service/agnhost-replica created\n"
  I0127 20:20:49.510747 26 kubectl.go:419] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  I0127 20:20:49.510859 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-5976 create -f -'
  I0127 20:20:49.637605 26 builder.go:156] stderr: ""
  I0127 20:20:49.637647 26 builder.go:157] stdout: "service/agnhost-primary created\n"
  I0127 20:20:49.637697 26 kubectl.go:419] apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  I0127 20:20:49.637772 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-5976 create -f -'
  I0127 20:20:49.775157 26 builder.go:156] stderr: ""
  I0127 20:20:49.775196 26 builder.go:157] stdout: "service/frontend created\n"
  I0127 20:20:49.775245 26 kubectl.go:419] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.59
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  I0127 20:20:49.775344 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-5976 create -f -'
  I0127 20:20:49.874862 26 builder.go:156] stderr: ""
  I0127 20:20:49.874905 26 builder.go:157] stdout: "deployment.apps/frontend created\n"
  I0127 20:20:49.874960 26 kubectl.go:419] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.59
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0127 20:20:49.875053 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-5976 create -f -'
  I0127 20:20:49.974694 26 builder.go:156] stderr: ""
  I0127 20:20:49.974755 26 builder.go:157] stdout: "deployment.apps/agnhost-primary created\n"
  I0127 20:20:49.974821 26 kubectl.go:419] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.59
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0127 20:20:49.974923 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-5976 create -f -'
  I0127 20:20:50.078996 26 builder.go:156] stderr: ""
  I0127 20:20:50.079040 26 builder.go:157] stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 01/27/26 20:20:50.079
  I0127 20:20:50.079075 26 kubectl.go:2307] Waiting for all frontend pods to be Running.
  I0127 20:20:55.130902 26 kubectl.go:2311] Waiting for frontend to serve content.
  I0127 20:20:55.139476 26 kubectl.go:2316] Trying to add a new entry to the guestbook.
  I0127 20:20:55.147969 26 kubectl.go:2321] Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 01/27/26 20:20:55.156
  I0127 20:20:55.156915 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-5976 delete --grace-period=0 --force -f -'
  I0127 20:20:55.244489 26 builder.go:156] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0127 20:20:55.244529 26 builder.go:157] stdout: "service \"agnhost-replica\" force deleted from kubectl-5976 namespace\n"
  STEP: using delete to clean up resources @ 01/27/26 20:20:55.244
  I0127 20:20:55.244637 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-5976 delete --grace-period=0 --force -f -'
  I0127 20:20:55.333467 26 builder.go:156] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0127 20:20:55.333507 26 builder.go:157] stdout: "service \"agnhost-primary\" force deleted from kubectl-5976 namespace\n"
  STEP: using delete to clean up resources @ 01/27/26 20:20:55.333
  I0127 20:20:55.333610 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-5976 delete --grace-period=0 --force -f -'
  I0127 20:20:55.413702 26 builder.go:156] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0127 20:20:55.413743 26 builder.go:157] stdout: "service \"frontend\" force deleted from kubectl-5976 namespace\n"
  STEP: using delete to clean up resources @ 01/27/26 20:20:55.413
  I0127 20:20:55.413853 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-5976 delete --grace-period=0 --force -f -'
  I0127 20:20:55.475551 26 builder.go:156] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0127 20:20:55.475609 26 builder.go:157] stdout: "deployment.apps \"frontend\" force deleted from kubectl-5976 namespace\n"
  STEP: using delete to clean up resources @ 01/27/26 20:20:55.475
  I0127 20:20:55.475712 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-5976 delete --grace-period=0 --force -f -'
  I0127 20:20:55.547475 26 builder.go:156] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0127 20:20:55.547514 26 builder.go:157] stdout: "deployment.apps \"agnhost-primary\" force deleted from kubectl-5976 namespace\n"
  STEP: using delete to clean up resources @ 01/27/26 20:20:55.547
  I0127 20:20:55.547671 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-5976 delete --grace-period=0 --force -f -'
  I0127 20:20:55.634875 26 builder.go:156] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0127 20:20:55.634914 26 builder.go:157] stdout: "deployment.apps \"agnhost-replica\" force deleted from kubectl-5976 namespace\n"
  I0127 20:20:55.635035 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5976" for this suite. @ 01/27/26 20:20:55.639
• [6.324 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:79
  STEP: Creating a kubernetes client @ 01/27/26 20:20:55.659
  I0127 20:20:55.659025 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename validating-admission-policy @ 01/27/26 20:20:55.659
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:20:55.7
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:20:55.789
  STEP: creating the policy @ 01/27/26 20:20:55.802
  STEP: waiting until the marker is denied @ 01/27/26 20:20:55.827
  STEP: testing a replicated Deployment to be allowed @ 01/27/26 20:20:56.285
  STEP: testing a non-replicated ReplicaSet not to be denied @ 01/27/26 20:20:56.451
  I0127 20:20:57.740973 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-5272" for this suite. @ 01/27/26 20:20:58.312
• [3.603 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:107
  STEP: Creating a kubernetes client @ 01/27/26 20:20:59.261
  I0127 20:20:59.261711 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename deployment @ 01/27/26 20:20:59.262
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:20:59.495
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:20:59.521
  I0127 20:20:59.524286 26 deployment.go:758] Creating replica set "test-rolling-update-controller" (going to be adopted)
  I0127 20:20:59.905762 26 resource.go:64] Pod name sample-pod: Found 0 pods out of 1
  I0127 20:21:04.912284 26 resource.go:64] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 01/27/26 20:21:04.912
  I0127 20:21:04.912352 26 deployment.go:773] Creating deployment "test-rolling-update-deployment"
  I0127 20:21:04.966443 26 deployment.go:779] Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  I0127 20:21:05.705640 26 deployment.go:223] new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  I0127 20:21:08.208626 26 deployment.go:783] Ensuring status for deployment "test-rolling-update-deployment" is the expected
  I0127 20:21:08.210744 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc0058a4090), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 6, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 6, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 7, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-6466d5fddd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0127 20:21:10.214353 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc00192dc40), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 6, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 6, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 7, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-6466d5fddd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0127 20:21:12.466334 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, TerminatingReplicas:(*int32)(0xc00192dd90), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 6, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 6, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 10, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-6466d5fddd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0127 20:21:14.340940 26 deployment.go:788] Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  I0127 20:21:14.346470 26 deployment.go:636] Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9096",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a80fe35c-49c0-4732-987c-5d1565f607c0",
      ResourceVersion: (string) (len=5) "11413",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905142064,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905142064,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905142072,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 74 65 72  |licas":{},"f:ter|
              000001f0  6d 69 6e 61 74 69 6e 67  52 65 70 6c 69 63 61 73  |minatingReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(0),
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905142066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905142066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905142072,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905142066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-6466d5fddd\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0127 20:21:14.349373 26 deployment.go:40] New ReplicaSet "test-rolling-update-deployment-6466d5fddd" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-6466d5fddd",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9096",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4bd6eaf6-04e7-4f47-9537-a21b51641d85",
      ResourceVersion: (string) (len=5) "11399",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905142065,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6466d5fddd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "a80fe35c-49c0-4732-987c-5d1565f607c0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905142065,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 61 38 30 66 65 33  35 63 2d 34 39 63 30 2d  |\"a80fe35c-49c0-|
              00000120  34 37 33 32 2d 39 38 37  63 2d 35 64 31 35 36 35  |4732-987c-5d1565|
              00000130  66 36 30 37 63 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |f607c0\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905142070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=157) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6e 67 52  |,"f:terminatingR|
              00000090  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6466d5fddd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6466d5fddd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      TerminatingReplicas: (*int32)(0),
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0127 20:21:14.350367 26 deployment.go:45] All old ReplicaSets of Deployment "test-rolling-update-deployment":
  I0127 20:21:14.350501 26 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9096",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4a81b2ab-5090-4bd6-8aa0-5f1aee180c10",
      ResourceVersion: (string) (len=5) "11411",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905142059,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=7) "agnhost"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "a80fe35c-49c0-4732-987c-5d1565f607c0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905142059,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=535) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  61 67 6e 68 6f 73 74 5c  |ame\":\"agnhost\|
              00000110  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 69  |"}":{".":{},"f:i|
              00000120  6d 61 67 65 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |mage":{},"f:imag|
              00000130  65 50 75 6c 6c 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |ePullPolicy":{},|
              00000140  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 72  |"f:name":{},"f:r|
              00000150  65 73 6f 75 72 63 65 73  22 3a 7b 7d 2c 22 66 3a  |esources":{},"f:|
              00000160  74 65 72 6d 69 6e 61 74  69 6f 6e 4d 65 73 73 61  |terminationMessa|
              00000170  67 65 50 61 74 68 22 3a  7b 7d 2c 22 66 3a 74 65  |gePath":{},"f:te|
              00000180  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000190  50 6f 6c 69 63 79 22 3a  7b 7d 7d 7d 2c 22 66 3a  |Policy":{}}},"f:|
              000001a0  64 6e 73 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |dnsPolicy":{},"f|
              000001b0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001c0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001d0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              000001e0  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              000001f0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000200  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000210  3a 7b 7d 7d 7d 7d 7d                              |:{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905142070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 61 38 30 66 65 33 35  |"uid\":\"a80fe35|
              000000b0  63 2d 34 39 63 30 2d 34  37 33 32 2d 39 38 37 63  |c-49c0-4732-987c|
              000000c0  2d 35 64 31 35 36 35 66  36 30 37 63 30 5c 22 7d  |-5d1565f607c0\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905142071,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=83) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |as":{},"f:termin|
              00000040  61 74 69 6e 67 52 65 70  6c 69 63 61 73 22 3a 7b  |atingReplicas":{|
              00000050  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=7) "agnhost"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "pod": (string) (len=7) "agnhost",
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(0),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0127 20:21:14.353728 26 deployment.go:68] Pod "test-rolling-update-deployment-6466d5fddd-6pptd" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-6466d5fddd-6pptd",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-6466d5fddd-",
      Namespace: (string) (len=15) "deployment-9096",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "676f7f46-d749-431b-b54f-4c1e203d8df8",
      ResourceVersion: (string) (len=5) "11398",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905142066,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6466d5fddd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-6466d5fddd",
          UID: (types.UID) (len=36) "4bd6eaf6-04e7-4f47-9537-a21b51641d85",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905142066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  64 36 65 61 66 36 2d 30  |d\":\"4bd6eaf6-0|
              00000090  34 65 37 2d 34 66 34 37  2d 39 35 33 37 2d 61 32  |4e7-4f47-9537-a2|
              000000a0  31 62 35 31 36 34 31 64  38 35 5c 22 7d 22 3a 7b  |1b51641d85\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905142070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=849) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 35  |k:{\"ip\":\"10.5|
              00000320  32 2e 31 2e 35 33 5c 22  7d 22 3a 7b 22 2e 22 3a  |2.1.53\"}":{".":|
              00000330  7b 7d 2c 22 66 3a 69 70  22 3a 7b 7d 7d 7d 2c 22  |{},"f:ip":{}}},"|
              00000340  66 3a 73 74 61 72 74 54  69 6d 65 22 3a 7b 7d 7d  |f:startTime":{}}|
              00000350  7d                                                |}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-lcsfz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-lcsfz",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905142070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905142067,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905142070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905142070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905142066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.10",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.10"
        }
      },
      PodIP: (string) (len=10) "10.52.1.53",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.52.1.53"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905142067,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63905142069,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:10ed98804c877e505e17bced991682b6fd50ab1da9cddcd19935b48d645da40a",
          ContainerID: (string) (len=77) "containerd://194bd24fae4632a4ef71083ed821906334de851e1ebe9d91af0c1a3ac80ff994",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-lcsfz",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 20:21:14.356020 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9096" for this suite. @ 01/27/26 20:21:14.358
• [15.150 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:314
  STEP: Creating a kubernetes client @ 01/27/26 20:21:14.411
  I0127 20:21:14.411820 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 20:21:14.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:21:15.266
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:21:15.268
  STEP: Setting up server cert @ 01/27/26 20:21:16.336
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 20:21:16.547
  STEP: Deploying the webhook pod @ 01/27/26 20:21:16.651
  STEP: Wait for the deployment to be ready @ 01/27/26 20:21:17.361
  I0127 20:21:17.716423 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  I0127 20:21:23.021913 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc0058a47e0), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 18, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 21, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c5c95bb96\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0127 20:21:25.266410 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc001d23c20), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 18, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 21, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c5c95bb96\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0127 20:21:27.191935 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc0058a49a0), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 18, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 21, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c5c95bb96\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0127 20:21:29.857220 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc0058a4b70), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 18, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 21, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c5c95bb96\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0127 20:21:31.466978 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc001d23e70), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 18, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 21, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c5c95bb96\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0127 20:21:33.136522 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc0058a4d50), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 18, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 21, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c5c95bb96\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0127 20:21:35.176708 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc002d6c330), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 18, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 21, 21, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 21, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c5c95bb96\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: Deploying the webhook service @ 01/27/26 20:21:37.031
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 20:21:37.05
  I0127 20:21:37.050414 26 wait.go:65] Waiting for amount of service webhook-9052/e2e-test-webhook endpoints to be 1
  I0127 20:21:37.051882 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  I0127 20:21:38.053302 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9052-4647-crds.webhook.example.com via the AdmissionRegistration API @ 01/27/26 20:21:38.565
  STEP: Creating a custom resource while v1 is storage version @ 01/27/26 20:21:38.589
  STEP: Patching Custom Resource Definition to set v2 as storage @ 01/27/26 20:21:40.617
  STEP: Patching the custom resource while v2 is storage version @ 01/27/26 20:21:40.639
  I0127 20:21:41.275092 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9052" for this suite. @ 01/27/26 20:21:41.277
  STEP: Destroying namespace "webhook-markers-5214" for this suite. @ 01/27/26 20:21:41.285
• [26.881 seconds]
------------------------------
S
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:675
  STEP: Creating a kubernetes client @ 01/27/26 20:21:41.293
  I0127 20:21:41.293348 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename security-context-test @ 01/27/26 20:21:41.293
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:21:41.317
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:21:41.321
  I0127 20:21:45.354935 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-7413" for this suite. @ 01/27/26 20:21:45.357
• [4.072 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:620
  STEP: Creating a kubernetes client @ 01/27/26 20:21:45.365
  I0127 20:21:45.365664 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename field-validation @ 01/27/26 20:21:45.366
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:21:45.382
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:21:45.393
  I0127 20:21:45.395712 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  I0127 20:21:47.936909      26 warnings.go:107] "Warning: unknown field \"alpha\""
  I0127 20:21:47.936931      26 warnings.go:107] "Warning: unknown field \"beta\""
  I0127 20:21:47.936938      26 warnings.go:107] "Warning: unknown field \"delta\""
  I0127 20:21:47.936945      26 warnings.go:107] "Warning: unknown field \"epsilon\""
  I0127 20:21:47.936952      26 warnings.go:107] "Warning: unknown field \"gamma\""
  I0127 20:21:48.474653 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8698" for this suite. @ 01/27/26 20:21:48.476
• [3.125 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:128
  STEP: Creating a kubernetes client @ 01/27/26 20:21:48.491
  I0127 20:21:48.491289 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename sched-preemption @ 01/27/26 20:21:48.491
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:21:48.517
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:21:48.523
  I0127 20:21:48.553089 26 wait.go:53] Waiting up to 1m0s for all nodes to be ready
  I0127 20:22:48.558132 26 util.go:389] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 01/27/26 20:22:48.559
  STEP: Adding a custom resource @ 01/27/26 20:22:48.559
  I0127 20:22:48.601191 26 preemption.go:172] Created pod: pod0-0-sched-preemption-low-priority
  I0127 20:22:48.620429 26 preemption.go:172] Created pod: pod0-1-sched-preemption-medium-priority
  STEP: Adding a custom resource @ 01/27/26 20:22:48.62
  I0127 20:22:48.658388 26 preemption.go:172] Created pod: pod1-0-sched-preemption-medium-priority
  I0127 20:22:48.672140 26 preemption.go:172] Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 01/27/26 20:22:48.672
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 01/27/26 20:22:52.694
  STEP: Removing a custom resource @ 01/27/26 20:22:56.747
  STEP: Removing a custom resource @ 01/27/26 20:22:56.764
  I0127 20:22:56.782580 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-1232" for this suite. @ 01/27/26 20:22:56.784
• [68.301 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:249
  STEP: Creating a kubernetes client @ 01/27/26 20:22:56.792
  I0127 20:22:56.792537 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 20:22:56.793
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:22:56.809
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:22:56.814
  STEP: Setting up server cert @ 01/27/26 20:22:56.859
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 20:22:56.998
  STEP: Deploying the webhook pod @ 01/27/26 20:22:57.013
  STEP: Wait for the deployment to be ready @ 01/27/26 20:22:57.039
  I0127 20:22:57.054328 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 01/27/26 20:22:59.071
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 20:22:59.093
  I0127 20:22:59.093874 26 wait.go:65] Waiting for amount of service webhook-6104/e2e-test-webhook endpoints to be 1
  I0127 20:22:59.095940 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 01/27/26 20:23:00.097
  STEP: create a configmap that should be updated by the webhook @ 01/27/26 20:23:00.125
  I0127 20:23:00.221575 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6104" for this suite. @ 01/27/26 20:23:00.225
  STEP: Destroying namespace "webhook-markers-8865" for this suite. @ 01/27/26 20:23:00.231
• [3.449 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:104
  STEP: Creating a kubernetes client @ 01/27/26 20:23:00.241
  I0127 20:23:00.241961 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 01/27/26 20:23:00.242
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:23:00.26
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:23:00.262
  STEP: creating a target pod @ 01/27/26 20:23:00.265
  STEP: adding an ephemeral container @ 01/27/26 20:23:02.286
  STEP: verifying the pod's generation is 2 @ 01/27/26 20:23:04.316
  STEP: checking pod container endpoints @ 01/27/26 20:23:04.319
  I0127 20:23:04.319239 26 exec_util.go:63] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-6119 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:23:04.319256 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:23:04.319292 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/ephemeral-containers-test-6119/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&stderr=true&stdout=true)
  I0127 20:23:04.367074 26 exec_util.go:112] Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 01/27/26 20:23:04.376
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 01/27/26 20:23:04.378
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 01/27/26 20:23:04.4
  I0127 20:23:04.403158 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-6119" for this suite. @ 01/27/26 20:23:04.405
• [4.185 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:468
  STEP: Creating a kubernetes client @ 01/27/26 20:23:04.427
  I0127 20:23:04.427628 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename sched-pred @ 01/27/26 20:23:04.428
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:23:04.444
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:23:04.45
  I0127 20:23:04.451904 26 helper.go:125] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0127 20:23:04.508449 26 util.go:389] Waiting for terminating namespaces to be deleted...
  I0127 20:23:04.510618 26 predicates.go:120] 
  Logging pods the apiserver thinks is on node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 before test
  I0127 20:23:04.513420 26 predicates.go:958] ephemeral-containers-target-pod from ephemeral-containers-test-6119 started at 2026-01-27 20:23:00 +0000 UTC (1 container statuses recorded)
  I0127 20:23:04.513444 26 predicates.go:960] 	Container test-container-1 ready: true, restart count 0
  I0127 20:23:04.513453 26 predicates.go:958] svclb-traefik-4c5baeff-vbqt2 from kube-system started at 2026-01-27 19:41:22 +0000 UTC (2 container statuses recorded)
  I0127 20:23:04.513460 26 predicates.go:960] 	Container lb-tcp-443 ready: true, restart count 0
  I0127 20:23:04.513466 26 predicates.go:960] 	Container lb-tcp-80 ready: true, restart count 0
  I0127 20:23:04.513473 26 predicates.go:958] sonobuoy from sonobuoy started at 2026-01-27 19:52:38 +0000 UTC (1 container statuses recorded)
  I0127 20:23:04.513479 26 predicates.go:960] 	Container kube-sonobuoy ready: true, restart count 0
  I0127 20:23:04.513485 26 predicates.go:958] sonobuoy-e2e-job-211431d51fbc478c from sonobuoy started at 2026-01-27 19:52:42 +0000 UTC (2 container statuses recorded)
  I0127 20:23:04.513491 26 predicates.go:960] 	Container e2e ready: true, restart count 0
  I0127 20:23:04.513496 26 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0127 20:23:04.513502 26 predicates.go:958] sonobuoy-systemd-logs-daemon-set-7c9a66bc53524567-gzwrw from sonobuoy started at 2026-01-27 19:52:42 +0000 UTC (2 container statuses recorded)
  I0127 20:23:04.513509 26 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0127 20:23:04.513515 26 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  I0127 20:23:04.513521 26 predicates.go:120] 
  Logging pods the apiserver thinks is on node k3k-k3kcluster-server-0 before test
  I0127 20:23:04.515583 26 predicates.go:958] coredns-54bf7cdff9-hvd6n from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 20:23:04.515624 26 predicates.go:960] 	Container coredns ready: true, restart count 0
  I0127 20:23:04.515633 26 predicates.go:958] helm-install-traefik-ck8zv from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 20:23:04.515639 26 predicates.go:960] 	Container helm ready: false, restart count 1
  I0127 20:23:04.515646 26 predicates.go:958] helm-install-traefik-crd-kw4dk from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 20:23:04.515651 26 predicates.go:960] 	Container helm ready: false, restart count 0
  I0127 20:23:04.515658 26 predicates.go:958] local-path-provisioner-69879d7dd7-xrhgn from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 20:23:04.515665 26 predicates.go:960] 	Container local-path-provisioner ready: true, restart count 0
  I0127 20:23:04.515671 26 predicates.go:958] metrics-server-77dbbf84b-fkr5h from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 20:23:04.515677 26 predicates.go:960] 	Container metrics-server ready: true, restart count 0
  I0127 20:23:04.515683 26 predicates.go:958] svclb-traefik-4c5baeff-dqplp from kube-system started at 2026-01-27 19:41:06 +0000 UTC (2 container statuses recorded)
  I0127 20:23:04.515688 26 predicates.go:960] 	Container lb-tcp-443 ready: true, restart count 0
  I0127 20:23:04.515694 26 predicates.go:960] 	Container lb-tcp-80 ready: true, restart count 0
  I0127 20:23:04.515700 26 predicates.go:958] traefik-6d98778dfc-p2jdc from kube-system started at 2026-01-27 19:41:06 +0000 UTC (1 container statuses recorded)
  I0127 20:23:04.515707 26 predicates.go:960] 	Container traefik ready: true, restart count 0
  I0127 20:23:04.515714 26 predicates.go:958] sonobuoy-systemd-logs-daemon-set-7c9a66bc53524567-h78hs from sonobuoy started at 2026-01-27 19:52:42 +0000 UTC (2 container statuses recorded)
  I0127 20:23:04.515721 26 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0127 20:23:04.515733 26 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 01/27/26 20:23:04.515
  STEP: Explicitly delete pod here to free the resource it takes. @ 01/27/26 20:23:06.544
  STEP: Trying to apply a random label on the found node. @ 01/27/26 20:23:06.572
  STEP: verifying the node has the label kubernetes.io/e2e-07d7cdf8-95e8-42ae-be74-d145197bab2f 42 @ 01/27/26 20:23:06.588
  STEP: Trying to relaunch the pod, now with labels. @ 01/27/26 20:23:06.591
  STEP: removing the label kubernetes.io/e2e-07d7cdf8-95e8-42ae-be74-d145197bab2f off the node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 @ 01/27/26 20:23:08.616
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-07d7cdf8-95e8-42ae-be74-d145197bab2f @ 01/27/26 20:23:08.633
  I0127 20:23:08.634906 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-1260" for this suite. @ 01/27/26 20:23:08.636
• [4.225 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:430
  STEP: Creating a kubernetes client @ 01/27/26 20:23:08.652
  I0127 20:23:08.652334 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename replication-controller @ 01/27/26 20:23:08.652
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:23:08.668
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:23:08.673
  STEP: Creating ReplicationController "e2e-rc-n7s7n" @ 01/27/26 20:23:08.676
  I0127 20:23:08.685003 26 rc.go:799] Get Replication Controller "e2e-rc-n7s7n" to confirm replicas
  I0127 20:23:09.685991 26 rc.go:799] Get Replication Controller "e2e-rc-n7s7n" to confirm replicas
  I0127 20:23:09.688115 26 rc.go:808] Found 1 replicas for "e2e-rc-n7s7n" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-n7s7n" @ 01/27/26 20:23:09.688
  STEP: Updating a scale subresource @ 01/27/26 20:23:09.699
  STEP: Verifying replicas where modified for replication controller "e2e-rc-n7s7n" @ 01/27/26 20:23:09.711
  I0127 20:23:09.711537 26 rc.go:799] Get Replication Controller "e2e-rc-n7s7n" to confirm replicas
  I0127 20:23:10.712439 26 rc.go:799] Get Replication Controller "e2e-rc-n7s7n" to confirm replicas
  I0127 20:23:10.714576 26 rc.go:808] Found 2 replicas for "e2e-rc-n7s7n" replication controller
  I0127 20:23:10.714705 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-1833" for this suite. @ 01/27/26 20:23:10.716
• [2.073 seconds]
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:54
  STEP: Creating a kubernetes client @ 01/27/26 20:23:10.724
  I0127 20:23:10.724964 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename downward-api @ 01/27/26 20:23:10.725
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:23:10.74
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:23:10.752
  STEP: Creating a pod to test downward API volume plugin @ 01/27/26 20:23:10.753
  STEP: Saw pod success @ 01/27/26 20:23:14.77
  I0127 20:23:14.772698 26 output.go:207] Trying to get logs from node k3k-k3kcluster-server-0 pod downwardapi-volume-b7c3c853-6a05-42ac-9419-dca2b12ab14b container client-container: <nil>
  STEP: delete the pod @ 01/27/26 20:23:14.782
  I0127 20:23:14.811265 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8104" for this suite. @ 01/27/26 20:23:14.813
• [4.096 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1426
  STEP: Creating a kubernetes client @ 01/27/26 20:23:14.82
  I0127 20:23:14.820857 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubectl @ 01/27/26 20:23:14.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:23:14.843
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:23:14.848
  I0127 20:23:14.850640 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-5475 create -f -'
  I0127 20:23:14.971759 26 builder.go:156] stderr: ""
  I0127 20:23:14.971798 26 builder.go:157] stdout: "replicationcontroller/agnhost-primary created\n"
  I0127 20:23:14.971846 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-5475 create -f -'
  I0127 20:23:15.112073 26 builder.go:156] stderr: ""
  I0127 20:23:15.112118 26 builder.go:157] stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 01/27/26 20:23:15.112
  I0127 20:23:16.115586 26 framework.go:697] Selector matched 1 pods for map[app:agnhost]
  I0127 20:23:16.115636 26 framework.go:738] Found 1 / 1
  I0127 20:23:16.115650 26 framework.go:747] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0127 20:23:16.116829 26 framework.go:697] Selector matched 1 pods for map[app:agnhost]
  I0127 20:23:16.116863 26 framework.go:770] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0127 20:23:16.116905 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-5475 describe pod agnhost-primary-42sc5'
  I0127 20:23:16.184352 26 builder.go:156] stderr: ""
  I0127 20:23:16.184413 26 builder.go:157] stdout: "Name:             agnhost-primary-42sc5\nNamespace:        kubectl-5475\nPriority:         0\nService Account:  default\nNode:             k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2/10.42.0.10\nStart Time:       Tue, 27 Jan 2026 20:23:15 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.52.1.63\nIPs:\n  IP:           10.52.1.63\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://73a3ed532dda156196361b0af7ee4fd816fbb277066a77ef6458a37187403390\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.59\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:10ed98804c877e505e17bced991682b6fd50ab1da9cddcd19935b48d645da40a\n    Port:           6379/TCP (agnhost-server)\n    Host Port:      0/TCP (agnhost-server)\n    State:          Running\n      Started:      Tue, 27 Jan 2026 20:23:15 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-zfkjm (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-zfkjm:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    Optional:                false\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-5475/agnhost-primary-42sc5 to k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2\n  Normal  Pulled     1s    kubelet            spec.containers{agnhost-primary}: Container image \"registry.k8s.io/e2e-test-images/agnhost:2.59\" already present on machine and can be accessed by the pod\n  Normal  Created    1s    kubelet            spec.containers{agnhost-primary}: Container created\n  Normal  Started    1s    kubelet            spec.containers{agnhost-primary}: Container started\n"
  I0127 20:23:16.184460 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-5475 describe rc agnhost-primary'
  I0127 20:23:16.328594 26 builder.go:156] stderr: ""
  I0127 20:23:16.328644 26 builder.go:157] stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5475\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:         registry.k8s.io/e2e-test-images/agnhost:2.59\n    Port:          6379/TCP (agnhost-server)\n    Host Port:     0/TCP (agnhost-server)\n    Environment:   <none>\n    Mounts:        <none>\n  Volumes:         <none>\n  Node-Selectors:  <none>\n  Tolerations:     <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-42sc5\n"
  I0127 20:23:16.328702 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-5475 describe service agnhost-primary'
  I0127 20:23:16.402587 26 builder.go:156] stderr: ""
  I0127 20:23:16.402632 26 builder.go:157] stdout: "Name:                     agnhost-primary\nNamespace:                kubectl-5475\nLabels:                   app=agnhost\n                          role=primary\nAnnotations:              <none>\nSelector:                 app=agnhost,role=primary\nType:                     ClusterIP\nIP Family Policy:         SingleStack\nIP Families:              IPv4\nIP:                       10.53.214.150\nIPs:                      10.53.214.150\nPort:                     <unset>  6379/TCP\nTargetPort:               agnhost-server/TCP\nEndpoints:                10.52.1.63:6379\nSession Affinity:         None\nInternal Traffic Policy:  Cluster\nEvents:                   <none>\n"
  I0127 20:23:16.404829 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-5475 describe node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2'
  I0127 20:23:16.479092 26 builder.go:156] stderr: ""
  I0127 20:23:16.479176 26 builder.go:157] stdout: "Name:               k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=k3s\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/instance-type=k3s\nAnnotations:        alpha.kubernetes.io/provided-node-ip: 10.42.0.10\n                    flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"be:17:b2:4f:c0:10\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.42.0.10\n                    k3s.io/hostname: k3k-k3kcluster-agent-6fb558bc6f-6x7q6\n                    k3s.io/internal-ip: 10.42.0.10\n                    k3s.io/node-args:\n                      [\"agent\",\"--server\",\"https://10.43.197.196\",\"--token\",\"********\",\"--with-node-id\",\"true\",\"--config\",\"/opt/rancher/k3s/config.yaml\"]\n                    k3s.io/node-config-hash: UBDZJP4DL3ERAYQBKOXZBQEXTO6SK4Z3KCEGNDXUXWIDG55FXV6Q====\n                    k3s.io/node-env: {}\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 27 Jan 2026 19:41:21 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 27 Jan 2026 20:23:06 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 27 Jan 2026 20:22:01 +0000   Tue, 27 Jan 2026 19:41:21 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 27 Jan 2026 20:22:01 +0000   Tue, 27 Jan 2026 19:41:21 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 27 Jan 2026 20:22:01 +0000   Tue, 27 Jan 2026 19:41:21 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 27 Jan 2026 20:22:01 +0000   Tue, 27 Jan 2026 19:41:22 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.42.0.10\n  Hostname:    k3k-k3kcluster-agent-6fb558bc6f-6x7q6\nCapacity:\n  cpu:                8\n  ephemeral-storage:  62825452Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             32865356Ki\n  pods:               110\nAllocatable:\n  cpu:                8\n  ephemeral-storage:  61116599658\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             32865356Ki\n  pods:               110\nSystem Info:\n  Machine ID:                     \n  System UUID:                    ec2c8e1e-9ceb-5b7b-28e5-da1373b8f5e8\n  Boot ID:                        89d37f83-1860-4825-b228-ff825f25b1e7\n  Kernel Version:                 6.4.0-150600.23.33-default\n  OS Image:                       K3s v1.35.0+k3s1\n  Operating System:               linux\n  Architecture:                   amd64\n  Container Runtime Version:      containerd://2.1.5-k3s1\n  Kubelet Version:                v1.35.0+k3s1\n  Kube-Proxy Version:             \nPodCIDR:                          10.52.1.0/24\nPodCIDRs:                         10.52.1.0/24\nProviderID:                       k3s://k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2\nNon-terminated Pods:              (6 in total)\n  Namespace                       Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                       ----                                                       ------------  ----------  ---------------  -------------  ---\n  ephemeral-containers-test-6119  ephemeral-containers-target-pod                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         16s\n  kube-system                     svclb-traefik-4c5baeff-vbqt2                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         41m\n  kubectl-5475                    agnhost-primary-42sc5                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         2s\n  sonobuoy                        sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         30m\n  sonobuoy                        sonobuoy-e2e-job-211431d51fbc478c                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         30m\n  sonobuoy                        sonobuoy-systemd-logs-daemon-set-7c9a66bc53524567-gzwrw    0 (0%)        0 (0%)      0 (0%)           0 (0%)         30m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests  Limits\n  --------           --------  ------\n  cpu                0 (0%)    0 (0%)\n  memory             0 (0%)    0 (0%)\n  ephemeral-storage  0 (0%)    0 (0%)\n  hugepages-1Gi      0 (0%)    0 (0%)\n  hugepages-2Mi      0 (0%)    0 (0%)\nEvents:\n  Type    Reason                   Age   From                   Message\n  ----    ------                   ----  ----                   -------\n  Normal  CertificateExpirationOK  41m   k3s-cert-monitor       Node and Certificate Authority certificates managed by k3s are OK\n  Normal  Synced                   41m   cloud-node-controller  Node synced successfully\n  Normal  RegisteredNode           41m   node-controller        Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 event: Registered Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 in Controller\n"
  I0127 20:23:16.479226 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-5475 describe namespace kubectl-5475'
  I0127 20:23:16.542929 26 builder.go:156] stderr: ""
  I0127 20:23:16.542977 26 builder.go:157] stdout: "Name:         kubectl-5475\nLabels:       e2e-framework=kubectl\n              e2e-run=9363327e-b7dc-40b5-856e-73161be656f5\n              kubernetes.io/metadata.name=kubectl-5475\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  I0127 20:23:16.543113 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5475" for this suite. @ 01/27/26 20:23:16.545
• [1.732 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1758
  STEP: Creating a kubernetes client @ 01/27/26 20:23:16.557
  I0127 20:23:16.557413 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubectl @ 01/27/26 20:23:16.558
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:23:16.582
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:23:16.585
  I0127 20:23:16.587651 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-1199 version'
  I0127 20:23:16.638511 26 builder.go:156] stderr: ""
  I0127 20:23:16.638561 26 builder.go:157] stdout: "Client Version: v1.35.0\nKustomize Version: v5.7.1\nServer Version: v1.35.0+k3s1\n"
  I0127 20:23:16.638727 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1199" for this suite. @ 01/27/26 20:23:16.641
• [0.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1725
  STEP: Creating a kubernetes client @ 01/27/26 20:23:16.649
  I0127 20:23:16.649151 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubectl @ 01/27/26 20:23:16.649
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:23:16.677
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:23:16.679
  STEP: creating Agnhost RC @ 01/27/26 20:23:16.687
  I0127 20:23:16.687869 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-7906 create -f -'
  I0127 20:23:16.807188 26 builder.go:156] stderr: ""
  I0127 20:23:16.807226 26 builder.go:157] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 01/27/26 20:23:16.807
  I0127 20:23:17.811047 26 framework.go:697] Selector matched 1 pods for map[app:agnhost]
  I0127 20:23:17.811080 26 framework.go:738] Found 0 / 1
  I0127 20:23:18.810423 26 framework.go:697] Selector matched 1 pods for map[app:agnhost]
  I0127 20:23:18.810460 26 framework.go:738] Found 1 / 1
  I0127 20:23:18.810473 26 framework.go:747] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 01/27/26 20:23:18.81
  I0127 20:23:18.811913 26 framework.go:697] Selector matched 1 pods for map[app:agnhost]
  I0127 20:23:18.811934 26 framework.go:770] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0127 20:23:18.811965 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-7906 patch pod agnhost-primary-6q6cr -p {"metadata":{"annotations":{"x":"y"}}}'
  I0127 20:23:18.882861 26 builder.go:156] stderr: ""
  I0127 20:23:18.882902 26 builder.go:157] stdout: "pod/agnhost-primary-6q6cr patched\n"
  STEP: checking annotations @ 01/27/26 20:23:18.882
  I0127 20:23:18.885678 26 framework.go:697] Selector matched 1 pods for map[app:agnhost]
  I0127 20:23:18.885707 26 framework.go:770] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0127 20:23:18.885802 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7906" for this suite. @ 01/27/26 20:23:18.888
• [2.247 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:284
  STEP: Creating a kubernetes client @ 01/27/26 20:23:18.896
  I0127 20:23:18.896589 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 20:23:18.897
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:23:18.913
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:23:18.924
  STEP: Setting up server cert @ 01/27/26 20:23:18.954
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 20:23:19.095
  STEP: Deploying the webhook pod @ 01/27/26 20:23:19.103
  STEP: Wait for the deployment to be ready @ 01/27/26 20:23:19.125
  I0127 20:23:19.144960 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 01/27/26 20:23:21.15
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 20:23:21.171
  I0127 20:23:21.171518 26 wait.go:65] Waiting for amount of service webhook-2078/e2e-test-webhook endpoints to be 1
  I0127 20:23:21.174282 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  I0127 20:23:22.174702 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2078-4568-crds.webhook.example.com via the AdmissionRegistration API @ 01/27/26 20:23:22.684
  STEP: Creating a custom resource that should be mutated by the webhook @ 01/27/26 20:23:22.708
  I0127 20:23:25.360984 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2078" for this suite. @ 01/27/26 20:23:25.363
  STEP: Destroying namespace "webhook-markers-3997" for this suite. @ 01/27/26 20:23:25.371
• [6.484 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:250
  STEP: Creating a kubernetes client @ 01/27/26 20:23:25.38
  I0127 20:23:25.380200 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 20:23:25.38
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:23:25.396
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:23:25.408
  STEP: Creating a pod to test downward API volume plugin @ 01/27/26 20:23:25.41
  STEP: Saw pod success @ 01/27/26 20:23:29.434
  I0127 20:23:29.436265 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downwardapi-volume-3ff89438-66a9-4906-ad3a-8aca32d9e0e2 container client-container: <nil>
  STEP: delete the pod @ 01/27/26 20:23:29.44
  I0127 20:23:29.469035 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1330" for this suite. @ 01/27/26 20:23:29.471
• [4.109 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:69
  STEP: Creating a kubernetes client @ 01/27/26 20:23:29.489
  I0127 20:23:29.489380 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename emptydir-wrapper @ 01/27/26 20:23:29.49
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:23:29.506
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:23:29.607
  STEP: Cleaning up the secret @ 01/27/26 20:23:31.648
  STEP: Cleaning up the configmap @ 01/27/26 20:23:31.656
  STEP: Cleaning up the pod @ 01/27/26 20:23:31.664
  I0127 20:23:31.690808 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-6386" for this suite. @ 01/27/26 20:23:31.693
• [2.215 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Pod InPlace Resize Container guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, decrease cpu & mem on c2, c3 - net decrease [MinimumKubeletVersion:1.34] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pod_resize.go:175
  STEP: Creating a kubernetes client @ 01/27/26 20:23:31.704
  I0127 20:23:31.705011 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pod-resize-tests @ 01/27/26 20:23:31.705
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:23:31.729
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:23:31.734
  STEP: creating and verifying pod @ 01/27/26 20:23:31.793
  I0127 20:23:37.828332 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c1 - looking for one of the expected cgroup values [20971520] in path /sys/fs/cgroup/memory.max
  I0127 20:23:37.828365 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:23:37.828379 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:23:37.828411 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c1&stderr=true&stdout=true)
  I0127 20:23:39.183412 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c1 - looking for one of the expected cgroup values [2000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 20:23:39.183465 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:23:39.183475 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:23:39.183521 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c1&stderr=true&stdout=true)
  I0127 20:23:41.181841 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c1 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 20:23:41.181882 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:23:41.181893 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:23:41.181939 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c1&stderr=true&stdout=true)
  I0127 20:23:42.781382 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c2 - looking for one of the expected cgroup values [23068672] in path /sys/fs/cgroup/memory.max
  I0127 20:23:42.781441 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:23:42.781453 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:23:42.781509 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c2&stderr=true&stdout=true)
  I0127 20:23:43.969628 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c2 - looking for one of the expected cgroup values [2200 100000 3000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 20:23:43.969676 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:23:43.969688 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:23:43.969752 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c2&stderr=true&stdout=true)
  I0127 20:23:45.481325 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c2 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 20:23:45.481397 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:23:45.481421 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:23:45.481470 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c2&stderr=true&stdout=true)
  I0127 20:23:46.868843 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c3 - looking for one of the expected cgroup values [25165824] in path /sys/fs/cgroup/memory.max
  I0127 20:23:46.868892 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:23:46.868906 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:23:46.868967 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c3&stderr=true&stdout=true)
  I0127 20:23:48.100995 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c3 - looking for one of the expected cgroup values [2400 100000 3000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 20:23:48.101039 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:23:48.101050 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:23:48.101102 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c3&stderr=true&stdout=true)
  I0127 20:23:49.402578 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c3 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 20:23:49.402627 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:23:49.402640 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:23:49.402686 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c3&stderr=true&stdout=true)
  STEP: patching and verifying pod for resize @ 01/27/26 20:23:50.602
  I0127 20:23:52.628695 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c1 - looking for one of the expected cgroup values [26214400] in path /sys/fs/cgroup/memory.max
  I0127 20:23:52.628732 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:23:52.628743 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:23:52.628774 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c1&stderr=true&stdout=true)
  I0127 20:23:54.081813 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c1 - looking for one of the expected cgroup values [2500 100000 3000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 20:23:54.081861 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:23:54.081872 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:23:54.081927 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c1&stderr=true&stdout=true)
  I0127 20:23:55.482788 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c1 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 20:23:55.482831 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:23:55.482846 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:23:55.482901 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c1&stderr=true&stdout=true)
  I0127 20:23:56.582662 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c2 - looking for one of the expected cgroup values [17825792] in path /sys/fs/cgroup/memory.max
  I0127 20:23:56.582702 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:23:56.582713 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:23:56.582795 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c2&stderr=true&stdout=true)
  I0127 20:23:58.471497 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c2 - looking for one of the expected cgroup values [1700 100000 2000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 20:23:58.471537 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:23:58.471548 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:23:58.471995 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c2&stderr=true&stdout=true)
  I0127 20:24:00.268683 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c2 - looking for one of the expected cgroup values [1 5] in path /sys/fs/cgroup/cpu.weight
  I0127 20:24:00.268728 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:24:00.268760 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:24:00.268822 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c2&stderr=true&stdout=true)
  I0127 20:24:02.068625 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c3 - looking for one of the expected cgroup values [19922944] in path /sys/fs/cgroup/memory.max
  I0127 20:24:02.068667 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:24:02.068678 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:24:02.068721 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c3&stderr=true&stdout=true)
  I0127 20:24:03.714219 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c3 - looking for one of the expected cgroup values [1900 100000 2000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 20:24:03.714261 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:24:03.714272 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:24:03.714358 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c3&stderr=true&stdout=true)
  I0127 20:24:05.500473 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c3 - looking for one of the expected cgroup values [1 5] in path /sys/fs/cgroup/cpu.weight
  I0127 20:24:05.500515 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:24:05.500526 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:24:05.500589 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c3&stderr=true&stdout=true)
  STEP: patching and verifying pod for rollback @ 01/27/26 20:24:07.101
  I0127 20:24:09.130805 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c1 - looking for one of the expected cgroup values [20971520] in path /sys/fs/cgroup/memory.max
  I0127 20:24:09.130843 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:24:09.130853 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:24:09.130895 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c1&stderr=true&stdout=true)
  I0127 20:24:10.685141 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c1 - looking for one of the expected cgroup values [2000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 20:24:10.685182 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:24:10.685195 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:24:10.685266 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c1&stderr=true&stdout=true)
  I0127 20:24:12.385834 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c1 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 20:24:12.385883 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:24:12.385895 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:24:12.385942 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c1&stderr=true&stdout=true)
  I0127 20:24:14.080968 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c2 - looking for one of the expected cgroup values [23068672] in path /sys/fs/cgroup/memory.max
  I0127 20:24:14.081010 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:24:14.081021 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:24:14.081064 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c2&stderr=true&stdout=true)
  I0127 20:24:15.568795 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c2 - looking for one of the expected cgroup values [2200 100000 3000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 20:24:15.568836 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:24:15.568854 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:24:15.568899 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c2&stderr=true&stdout=true)
  I0127 20:24:16.979668 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c2 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 20:24:16.979734 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:24:16.979750 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:24:16.979818 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c2&stderr=true&stdout=true)
  I0127 20:24:18.469609 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c3 - looking for one of the expected cgroup values [25165824] in path /sys/fs/cgroup/memory.max
  I0127 20:24:18.469658 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:24:18.469669 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:24:18.469717 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c3&stderr=true&stdout=true)
  I0127 20:24:19.901246 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c3 - looking for one of the expected cgroup values [2400 100000 3000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 20:24:19.901292 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:24:19.901312 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:24:19.901356 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c3&stderr=true&stdout=true)
  I0127 20:24:21.201749 26 cgroups.go:379] Namespace pod-resize-tests-755 Pod resize-test-84rt9 Container c3 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 20:24:21.201791 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-755 PodName:resize-test-84rt9 ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:24:21.201802 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:24:21.201849 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-755/pods/resize-test-84rt9/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c3&stderr=true&stdout=true)
  STEP: deleting pod @ 01/27/26 20:24:22.402
  I0127 20:24:22.434399 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-resize-tests-755" for this suite. @ 01/27/26 20:24:22.442
• [50.750 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:300
  STEP: Creating a kubernetes client @ 01/27/26 20:24:22.455
  I0127 20:24:22.455361 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 20:24:22.455
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:24:22.486
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:24:22.488
  STEP: Setting up server cert @ 01/27/26 20:24:22.512
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 20:24:22.663
  STEP: Deploying the webhook pod @ 01/27/26 20:24:22.671
  STEP: Wait for the deployment to be ready @ 01/27/26 20:24:22.699
  I0127 20:24:22.719403 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 01/27/26 20:24:24.726
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 20:24:24.742
  I0127 20:24:24.742991 26 wait.go:65] Waiting for amount of service webhook-681/e2e-test-webhook endpoints to be 1
  I0127 20:24:24.744769 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 01/27/26 20:24:25.746
  STEP: Creating a custom resource definition that should be denied by the webhook @ 01/27/26 20:24:25.783
  I0127 20:24:25.783551 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  I0127 20:24:25.894165 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-681" for this suite. @ 01/27/26 20:24:25.899
  STEP: Destroying namespace "webhook-markers-1563" for this suite. @ 01/27/26 20:24:25.906
• [3.460 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:1047
  STEP: Creating a kubernetes client @ 01/27/26 20:24:25.915
  I0127 20:24:25.915439 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename statefulset @ 01/27/26 20:24:25.916
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:24:25.94
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:24:25.945
  STEP: Creating service test in namespace statefulset-9657 @ 01/27/26 20:24:25.947
  I0127 20:24:25.977543 26 wait.go:45] Found 0 stateful pods, waiting for 1
  I0127 20:24:35.977300 26 wait.go:55] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 01/27/26 20:24:35.98
  I0127 20:24:36.017243 26 wait.go:45] Found 1 stateful pods, waiting for 2
  I0127 20:24:45.999545 26 wait.go:55] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0127 20:24:45.999583 26 wait.go:55] Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 01/27/26 20:24:46.002
  STEP: Delete all of the StatefulSets @ 01/27/26 20:24:46.004
  STEP: Verify that StatefulSets have been deleted @ 01/27/26 20:24:46.013
  I0127 20:24:46.014702 26 statefulset.go:137] Deleting all statefulset in ns statefulset-9657
  I0127 20:24:46.027641 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-9657" for this suite. @ 01/27/26 20:24:46.038
• [20.133 seconds]
------------------------------
SS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:157
  STEP: Creating a kubernetes client @ 01/27/26 20:24:46.048
  I0127 20:24:46.048627 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename secrets @ 01/27/26 20:24:46.049
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:24:46.091
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:24:46.096
  STEP: creating a secret @ 01/27/26 20:24:46.098
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 01/27/26 20:24:46.105
  STEP: patching the secret @ 01/27/26 20:24:46.106
  STEP: deleting the secret using a LabelSelector @ 01/27/26 20:24:46.123
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 01/27/26 20:24:46.133
  I0127 20:24:46.135733 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2470" for this suite. @ 01/27/26 20:24:46.138
• [0.099 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:69
  STEP: Creating a kubernetes client @ 01/27/26 20:24:46.147
  I0127 20:24:46.147620 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename downward-api @ 01/27/26 20:24:46.148
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:24:46.163
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:24:46.168
  STEP: Creating a pod to test downward API volume plugin @ 01/27/26 20:24:46.171
  STEP: Saw pod success @ 01/27/26 20:24:50.212
  I0127 20:24:50.214400 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downwardapi-volume-cb92c58e-ba07-4a67-8610-6c902d815318 container client-container: <nil>
  STEP: delete the pod @ 01/27/26 20:24:50.22
  I0127 20:24:50.271425 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6185" for this suite. @ 01/27/26 20:24:50.274
• [4.134 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:303
  STEP: Creating a kubernetes client @ 01/27/26 20:24:50.282
  I0127 20:24:50.282084 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename aggregateddiscovery @ 01/27/26 20:24:50.282
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:24:50.303
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:24:50.304
  I0127 20:24:50.307026 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  I0127 20:24:53.383186 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-921" for this suite. @ 01/27/26 20:24:53.386
• [3.112 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:222
  STEP: Creating a kubernetes client @ 01/27/26 20:24:53.394
  I0127 20:24:53.394635 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename downward-api @ 01/27/26 20:24:53.395
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:24:53.42
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:24:53.422
  STEP: Creating a pod to test downward API volume plugin @ 01/27/26 20:24:53.424
  STEP: Saw pod success @ 01/27/26 20:24:57.444
  I0127 20:24:57.445872 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downwardapi-volume-824127a8-1ac3-4b0d-b99b-19383259e3e4 container client-container: <nil>
  STEP: delete the pod @ 01/27/26 20:24:57.449
  I0127 20:24:57.478460 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7375" for this suite. @ 01/27/26 20:24:57.481
• [4.101 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 01/27/26 20:24:57.496
  I0127 20:24:57.496214 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename secrets @ 01/27/26 20:24:57.496
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:24:57.512
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:24:57.517
  STEP: Creating secret with name secret-test-321820bb-647d-49e0-be09-a7a46ff9d891 @ 01/27/26 20:24:57.519
  STEP: Creating a pod to test consume secrets @ 01/27/26 20:24:57.527
  STEP: Saw pod success @ 01/27/26 20:25:01.562
  I0127 20:25:01.564314 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-secrets-8858908f-b241-4bb1-b89c-da9664f00ed2 container secret-volume-test: <nil>
  STEP: delete the pod @ 01/27/26 20:25:01.568
  I0127 20:25:01.597368 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5501" for this suite. @ 01/27/26 20:25:01.6
• [4.128 seconds]
------------------------------
SS
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:1091
  STEP: Creating a kubernetes client @ 01/27/26 20:25:01.624
  I0127 20:25:01.624297 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pods @ 01/27/26 20:25:01.625
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:25:01.654
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:25:01.737
  STEP: Create a pod @ 01/27/26 20:25:01.739
  STEP: patching /status @ 01/27/26 20:25:03.754
  I0127 20:25:03.776432 26 pods.go:1128] Status Message: "Patched by e2e test" and Reason: "E2E"
  I0127 20:25:03.776559 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1441" for this suite. @ 01/27/26 20:25:03.778
• [2.162 seconds]
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:890
  STEP: Creating a kubernetes client @ 01/27/26 20:25:03.786
  I0127 20:25:03.786140 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename job @ 01/27/26 20:25:03.786
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:25:03.814
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:25:03.817
  STEP: Creating a job @ 01/27/26 20:25:03.819
  STEP: Ensuring active pods == parallelism @ 01/27/26 20:25:03.828
  STEP: delete a job @ 01/27/26 20:25:05.833
  STEP: deleting Job.batch foo in namespace job-1367, will wait for the garbage collector to delete the pods @ 01/27/26 20:25:05.833
  I0127 20:25:05.894476 26 resources.go:139] Deleting Job.batch foo took: 8.544022ms
  I0127 20:25:05.994951 26 resources.go:163] Terminating Job.batch foo pods took: 100.475353ms
  STEP: Ensuring job was deleted @ 01/27/26 20:25:08.795
  I0127 20:25:08.810538 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1367" for this suite. @ 01/27/26 20:25:08.823
• [5.045 seconds]
------------------------------
S
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 01/27/26 20:25:08.83
  I0127 20:25:08.830825 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename endpointslicemirroring @ 01/27/26 20:25:08.831
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:25:08.861
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:25:08.964
  STEP: mirroring a new custom Endpoint @ 01/27/26 20:25:08.984
  I0127 20:25:08.992314      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0127 20:25:08.994543 26 endpointslicemirroring.go:98] Waiting for at least 1 EndpointSlice to exist, got 0
  STEP: mirroring an update to a custom Endpoint @ 01/27/26 20:25:10.997
  I0127 20:25:11.004623      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: mirroring deletion of a custom Endpoint @ 01/27/26 20:25:11.018
  I0127 20:25:11.026088      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0127 20:25:11.033667 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-8806" for this suite. @ 01/27/26 20:25:11.036
• [2.218 seconds]
------------------------------
SS
------------------------------
[sig-apps] Job should mark indexes as failed when the FailIndex action is matched in podFailurePolicy [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:728
  STEP: Creating a kubernetes client @ 01/27/26 20:25:11.049
  I0127 20:25:11.049164 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename job @ 01/27/26 20:25:11.05
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:25:11.065
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:25:11.077
  STEP: Creating an indexed job with failing pods matching the FailIndex action @ 01/27/26 20:25:11.082
  STEP: Awaiting for the job to fail as all indexes are failed @ 01/27/26 20:25:11.098
  STEP: Verifying the Job status fields to ensure the upper indexes didn't execute @ 01/27/26 20:25:15.105
  I0127 20:25:15.126779 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2403" for this suite. @ 01/27/26 20:25:15.129
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:447
  STEP: Creating a kubernetes client @ 01/27/26 20:25:15.137
  I0127 20:25:15.137132 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename crd-publish-openapi @ 01/27/26 20:25:15.137
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:25:15.163
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:25:15.167
  STEP: set up a multi version CRD @ 01/27/26 20:25:15.169
  I0127 20:25:15.169611 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: mark a version not serverd @ 01/27/26 20:25:18.665
  STEP: check the unserved version gets removed @ 01/27/26 20:25:18.69
  STEP: check the other version is not changed @ 01/27/26 20:25:19.556
  I0127 20:25:22.271649 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6691" for this suite. @ 01/27/26 20:25:22.275
• [7.147 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:222
  STEP: Creating a kubernetes client @ 01/27/26 20:25:22.283
  I0127 20:25:22.283953 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 20:25:22.284
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:25:22.306
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:25:22.31
  STEP: Creating a pod to test downward API volume plugin @ 01/27/26 20:25:22.313
  STEP: Saw pod success @ 01/27/26 20:25:26.337
  I0127 20:25:26.339580 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downwardapi-volume-7a812b77-047a-4373-8526-3b50fce7e8e3 container client-container: <nil>
  STEP: delete the pod @ 01/27/26 20:25:26.342
  I0127 20:25:26.371778 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2966" for this suite. @ 01/27/26 20:25:26.374
• [4.109 seconds]
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:276
  STEP: Creating a kubernetes client @ 01/27/26 20:25:26.393
  I0127 20:25:26.393066 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename namespaces @ 01/27/26 20:25:26.393
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:25:26.408
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:25:26.413
  STEP: creating a Namespace @ 01/27/26 20:25:26.425
  STEP: patching the Namespace @ 01/27/26 20:25:26.446
  STEP: get the Namespace and ensuring it has the label @ 01/27/26 20:25:26.456
  I0127 20:25:26.458097 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6595" for this suite. @ 01/27/26 20:25:26.474
  STEP: Destroying namespace "nspatchtest-1b8b330d-d561-4212-a90d-a81f5c4d87df-450" for this suite. @ 01/27/26 20:25:26.484
• [0.106 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:272
  STEP: Creating a kubernetes client @ 01/27/26 20:25:26.499
  I0127 20:25:26.499479 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename apf @ 01/27/26 20:25:26.5
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:25:26.515
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:25:26.52
  STEP: getting /apis @ 01/27/26 20:25:26.523
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 01/27/26 20:25:26.526
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 01/27/26 20:25:26.527
  STEP: creating @ 01/27/26 20:25:26.528
  STEP: getting @ 01/27/26 20:25:26.559
  STEP: listing @ 01/27/26 20:25:26.57
  STEP: watching @ 01/27/26 20:25:26.571
  I0127 20:25:26.571898 26 flowcontrol.go:397] starting watch
  STEP: patching @ 01/27/26 20:25:26.572
  STEP: updating @ 01/27/26 20:25:26.596
  I0127 20:25:26.606893 26 flowcontrol.go:426] waiting for watch events with expected annotations
  I0127 20:25:26.606944 26 flowcontrol.go:442] missing expected annotations, waiting: map[string]string(nil)
  STEP: getting /status @ 01/27/26 20:25:26.607
  STEP: patching /status @ 01/27/26 20:25:26.609
  STEP: updating /status @ 01/27/26 20:25:26.618
  STEP: deleting @ 01/27/26 20:25:26.672
  STEP: deleting a collection @ 01/27/26 20:25:26.685
  I0127 20:25:26.704257 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-900" for this suite. @ 01/27/26 20:25:26.706
• [0.220 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 01/27/26 20:25:26.719
  I0127 20:25:26.719242 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 20:25:26.719
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:25:26.734
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:25:26.74
  STEP: Creating secret with name s-test-opt-del-325d7e72-d22c-4761-aa6d-a3ff510c0a7a @ 01/27/26 20:25:26.807
  STEP: Creating secret with name s-test-opt-upd-19b045e9-4d47-4d2d-b24b-102c4e6e2bbf @ 01/27/26 20:25:26.815
  STEP: Creating the pod @ 01/27/26 20:25:26.83
  STEP: Deleting secret s-test-opt-del-325d7e72-d22c-4761-aa6d-a3ff510c0a7a @ 01/27/26 20:25:28.867
  STEP: Updating secret s-test-opt-upd-19b045e9-4d47-4d2d-b24b-102c4e6e2bbf @ 01/27/26 20:25:28.875
  STEP: Creating secret with name s-test-opt-create-19d96532-004e-4c11-a42f-e74796e3ce69 @ 01/27/26 20:25:28.889
  STEP: waiting to observe update in volume @ 01/27/26 20:25:28.896
  I0127 20:26:45.136679 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3535" for this suite. @ 01/27/26 20:26:45.138
• [78.434 seconds]
------------------------------
S
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:208
  STEP: Creating a kubernetes client @ 01/27/26 20:26:45.152
  I0127 20:26:45.152955 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pods @ 01/27/26 20:26:45.153
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:26:45.169
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:26:45.175
  STEP: creating pod @ 01/27/26 20:26:45.177
  I0127 20:26:47.200936 26 pods.go:86] Pod pod-hostip-d606da9c-b211-4701-9e78-38bfa94cf8a9 has hostIP: 10.42.0.12
  I0127 20:26:47.201064 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8087" for this suite. @ 01/27/26 20:26:47.203
• [2.059 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:307
  STEP: Creating a kubernetes client @ 01/27/26 20:26:47.211
  I0127 20:26:47.211950 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename dns @ 01/27/26 20:26:47.212
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:26:47.228
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:26:47.232
  STEP: Creating a test headless service @ 01/27/26 20:26:47.234
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8115.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-querier-2.dns-test-service-2.dns-8115.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8115.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-querier-2.dns-test-service-2.dns-8115.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8115.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service-2.dns-8115.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8115.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service-2.dns-8115.svc.cluster.local;sleep 1; done
   @ 01/27/26 20:26:47.248
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8115.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-8115.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8115.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-8115.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8115.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-8115.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8115.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-8115.svc.cluster.local;sleep 1; done
   @ 01/27/26 20:26:47.248
  STEP: creating a pod to probe DNS @ 01/27/26 20:26:47.248
  STEP: submitting the pod to kubernetes @ 01/27/26 20:26:47.248
  STEP: retrieving the pod @ 01/27/26 20:27:06.377
  STEP: looking for the results for each expected name from probers @ 01/27/26 20:27:06.467
  I0127 20:27:06.544984 26 dns_common.go:546] DNS probes using dns-8115/dns-test-282b5713-82f8-4120-adc8-79a2a5ec7542 succeeded

  STEP: deleting the pod @ 01/27/26 20:27:06.545
  STEP: deleting the test headless service @ 01/27/26 20:27:06.561
  I0127 20:27:06.582845 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-8115" for this suite. @ 01/27/26 20:27:06.687
• [19.496 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:47
  STEP: Creating a kubernetes client @ 01/27/26 20:27:06.707
  I0127 20:27:06.707518 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 20:27:06.708
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:27:06.724
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:27:06.731
  STEP: Creating configMap with name projected-configmap-test-volume-20edaed0-746e-4825-a2a8-bee7db1bc127 @ 01/27/26 20:27:06.733
  STEP: Creating a pod to test consume configMaps @ 01/27/26 20:27:06.745
  STEP: Saw pod success @ 01/27/26 20:27:10.761
  I0127 20:27:10.762816 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-projected-configmaps-a927a94b-e266-4739-8391-056f7059435a container agnhost-container: <nil>
  STEP: delete the pod @ 01/27/26 20:27:10.766
  I0127 20:27:10.801537 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1450" for this suite. @ 01/27/26 20:27:10.804
• [4.105 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/logs.go:167
  STEP: Creating a kubernetes client @ 01/27/26 20:27:10.812
  I0127 20:27:10.812421 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubectl-logs @ 01/27/26 20:27:10.812
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:27:10.845
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:27:10.849
  STEP: creating a pod @ 01/27/26 20:27:10.851
  I0127 20:27:10.851578 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-logs-6220 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.59 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  I0127 20:27:10.923632 26 builder.go:156] stderr: ""
  I0127 20:27:10.923672 26 builder.go:157] stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 01/27/26 20:27:10.923
  I0127 20:27:10.923761 26 resource.go:396] Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  I0127 20:27:12.930759 26 resource.go:418] Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 01/27/26 20:27:12.93
  I0127 20:27:12.930848 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-logs-6220 logs logs-generator logs-generator'
  I0127 20:27:12.993787 26 builder.go:156] stderr: ""
  I0127 20:27:12.993834 26 builder.go:157] stdout: "I0127 20:27:11.718252       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/9rl 349\nI0127 20:27:11.918701       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/f65 354\nI0127 20:27:12.119218       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/9f8x 429\nI0127 20:27:12.318816       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/bqsb 353\nI0127 20:27:12.519193       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/4p7 281\nI0127 20:27:12.718505       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/26r 413\nI0127 20:27:12.918881       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/lwq 583\n"
  STEP: limiting log lines @ 01/27/26 20:27:12.993
  I0127 20:27:12.993906 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-logs-6220 logs logs-generator logs-generator --tail=1'
  I0127 20:27:13.058035 26 builder.go:156] stderr: ""
  I0127 20:27:13.058077 26 builder.go:157] stdout: "I0127 20:27:12.918881       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/lwq 583\n"
  I0127 20:27:13.058088 26 logs.go:180] got output "I0127 20:27:12.918881       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/lwq 583\n"
  STEP: limiting log bytes @ 01/27/26 20:27:13.058
  I0127 20:27:13.058161 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-logs-6220 logs logs-generator logs-generator --limit-bytes=1'
  I0127 20:27:13.122048 26 builder.go:156] stderr: ""
  I0127 20:27:13.122087 26 builder.go:157] stdout: "I"
  I0127 20:27:13.122107 26 logs.go:186] got output "I"
  STEP: exposing timestamps @ 01/27/26 20:27:13.122
  I0127 20:27:13.122174 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-logs-6220 logs logs-generator logs-generator --tail=1 --timestamps'
  I0127 20:27:13.182896 26 builder.go:156] stderr: ""
  I0127 20:27:13.182938 26 builder.go:157] stdout: "2026-01-27T20:27:13.119389766Z I0127 20:27:13.119213       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/7jp8 525\n"
  I0127 20:27:13.182950 26 logs.go:192] got output "2026-01-27T20:27:13.119389766Z I0127 20:27:13.119213       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/7jp8 525\n"
  STEP: restricting to a time range @ 01/27/26 20:27:13.182
  I0127 20:27:15.683177 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-logs-6220 logs logs-generator logs-generator --since=1s'
  I0127 20:27:15.751658 26 builder.go:156] stderr: ""
  I0127 20:27:15.751706 26 builder.go:157] stdout: "I0127 20:27:14.919220       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/28k2 567\nI0127 20:27:15.118493       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/mcz 419\nI0127 20:27:15.318872       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/bwrj 525\nI0127 20:27:15.519227       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/9rx 390\nI0127 20:27:15.718409       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/m59 238\n"
  I0127 20:27:15.751744 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-logs-6220 logs logs-generator logs-generator --since=24h'
  I0127 20:27:15.821844 26 builder.go:156] stderr: ""
  I0127 20:27:15.821905 26 builder.go:157] stdout: "I0127 20:27:11.718252       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/9rl 349\nI0127 20:27:11.918701       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/f65 354\nI0127 20:27:12.119218       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/9f8x 429\nI0127 20:27:12.318816       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/bqsb 353\nI0127 20:27:12.519193       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/4p7 281\nI0127 20:27:12.718505       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/26r 413\nI0127 20:27:12.918881       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/lwq 583\nI0127 20:27:13.119213       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/7jp8 525\nI0127 20:27:13.318399       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/wjhd 238\nI0127 20:27:13.518757       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/ns/pods/g29 355\nI0127 20:27:13.719114       1 logs_generator.go:76] 10 GET /api/v1/namespaces/ns/pods/rln 240\nI0127 20:27:13.918404       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/nmb7 269\nI0127 20:27:14.118773       1 logs_generator.go:76] 12 POST /api/v1/namespaces/ns/pods/sn4t 413\nI0127 20:27:14.319129       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/ns/pods/4w87 435\nI0127 20:27:14.518424       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/zfwm 560\nI0127 20:27:14.718781       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/kube-system/pods/gp7b 339\nI0127 20:27:14.919220       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/28k2 567\nI0127 20:27:15.118493       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/mcz 419\nI0127 20:27:15.318872       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/bwrj 525\nI0127 20:27:15.519227       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/9rx 390\nI0127 20:27:15.718409       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/m59 238\n"
  I0127 20:27:15.822001 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-logs-6220 delete pod logs-generator'
  I0127 20:27:16.810201 26 builder.go:156] stderr: ""
  I0127 20:27:16.810240 26 builder.go:157] stdout: "pod \"logs-generator\" deleted from kubectl-logs-6220 namespace\n"
  I0127 20:27:16.810356 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-6220" for this suite. @ 01/27/26 20:27:16.812
• [6.007 seconds]
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Serial] [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:722
  STEP: Creating a kubernetes client @ 01/27/26 20:27:16.819
  I0127 20:27:16.819987 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename gc @ 01/27/26 20:27:16.82
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:27:16.842
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:27:16.846
  STEP: create the rc1 @ 01/27/26 20:27:16.912
  STEP: create the rc2 @ 01/27/26 20:27:16.921
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 01/27/26 20:27:23.038
  STEP: delete the rc simpletest-rc-to-be-deleted @ 01/27/26 20:27:33.748
  STEP: wait for the rc to be deleted @ 01/27/26 20:27:33.897
  I0127 20:27:39.306624 26 garbage_collector.go:770] 79 pods remaining
  I0127 20:27:39.306658 26 garbage_collector.go:777] 74 pods has nil DeletionTimestamp
  I0127 20:27:39.306666 26 garbage_collector.go:778] 
  STEP: Gathering metrics @ 01/27/26 20:27:43.957
  W0127 20:27:43.959870      26 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I0127 20:27:43.959916 26 garbage_collector.go:273] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0127 20:27:43.959980 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-227c8" in namespace "gc-7863"
  I0127 20:27:44.148302 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-24bqh" in namespace "gc-7863"
  I0127 20:27:44.343824 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-2wn59" in namespace "gc-7863"
  I0127 20:27:44.767925 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-4bpt2" in namespace "gc-7863"
  I0127 20:27:45.138162 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-4np72" in namespace "gc-7863"
  I0127 20:27:45.234094 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-4ztk5" in namespace "gc-7863"
  I0127 20:27:45.408365 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-599hp" in namespace "gc-7863"
  I0127 20:27:45.658243 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-5n6j4" in namespace "gc-7863"
  I0127 20:27:45.828817 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-5tfk7" in namespace "gc-7863"
  I0127 20:27:46.177779 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-6cdwc" in namespace "gc-7863"
  I0127 20:27:46.648638 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-6xnf9" in namespace "gc-7863"
  I0127 20:27:46.913271 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-77qdr" in namespace "gc-7863"
  I0127 20:27:47.117926 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-7n2tz" in namespace "gc-7863"
  I0127 20:27:47.322874 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-7v79n" in namespace "gc-7863"
  I0127 20:27:47.618963 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-8ncq5" in namespace "gc-7863"
  I0127 20:27:47.947648 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-8r2t2" in namespace "gc-7863"
  I0127 20:27:48.404233 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-98srh" in namespace "gc-7863"
  I0127 20:27:48.648053 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-9qtn4" in namespace "gc-7863"
  I0127 20:27:48.898944 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-9swx7" in namespace "gc-7863"
  I0127 20:27:49.158753 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-b4k8f" in namespace "gc-7863"
  I0127 20:27:49.473079 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-b8jnr" in namespace "gc-7863"
  I0127 20:27:49.547855 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-cghfx" in namespace "gc-7863"
  I0127 20:27:49.743026 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-csg5v" in namespace "gc-7863"
  I0127 20:27:49.898595 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-d2s55" in namespace "gc-7863"
  I0127 20:27:50.128264 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-d8blk" in namespace "gc-7863"
  I0127 20:27:50.572722 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-d9jvf" in namespace "gc-7863"
  I0127 20:27:50.923322 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-fj75g" in namespace "gc-7863"
  I0127 20:27:51.342848 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-frqqz" in namespace "gc-7863"
  I0127 20:27:51.427759 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-fz92r" in namespace "gc-7863"
  I0127 20:27:51.592760 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-g8zxd" in namespace "gc-7863"
  I0127 20:27:52.183107 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-gjx6h" in namespace "gc-7863"
  I0127 20:27:52.363047 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-gsjwg" in namespace "gc-7863"
  I0127 20:27:52.833566 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-h2d76" in namespace "gc-7863"
  I0127 20:27:53.017993 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-h2x8k" in namespace "gc-7863"
  I0127 20:27:53.067870 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-h82bw" in namespace "gc-7863"
  I0127 20:27:53.483617 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-h9cvw" in namespace "gc-7863"
  I0127 20:27:53.718684 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-h9hdd" in namespace "gc-7863"
  I0127 20:27:53.953137 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-hd6wd" in namespace "gc-7863"
  I0127 20:27:54.113501 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-hg9mx" in namespace "gc-7863"
  I0127 20:27:54.283004 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-hshbg" in namespace "gc-7863"
  I0127 20:27:54.698132 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-j8gj7" in namespace "gc-7863"
  I0127 20:27:55.103011 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-jbr4q" in namespace "gc-7863"
  I0127 20:27:55.327950 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-jpgfk" in namespace "gc-7863"
  I0127 20:27:55.468221 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-k72cz" in namespace "gc-7863"
  I0127 20:27:55.649302 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-k7pcc" in namespace "gc-7863"
  I0127 20:27:55.852952 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-kn9mc" in namespace "gc-7863"
  I0127 20:27:56.073021 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-kqzrr" in namespace "gc-7863"
  I0127 20:27:56.393892 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-ks8xn" in namespace "gc-7863"
  I0127 20:27:56.738745 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-l2l9g" in namespace "gc-7863"
  I0127 20:27:57.303633 26 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-l87ms" in namespace "gc-7863"
  I0127 20:27:57.758613 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-7863" for this suite. @ 01/27/26 20:27:57.76
• [41.013 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:518
  STEP: Creating a kubernetes client @ 01/27/26 20:27:57.833
  I0127 20:27:57.833683 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename apf @ 01/27/26 20:27:57.834
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:27:58.278
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:27:58.452
  STEP: getting /apis @ 01/27/26 20:27:58.455
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 01/27/26 20:27:58.459
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 01/27/26 20:27:58.46
  STEP: creating @ 01/27/26 20:27:58.46
  STEP: getting @ 01/27/26 20:27:58.987
  STEP: listing @ 01/27/26 20:27:59.183
  STEP: watching @ 01/27/26 20:27:59.185
  I0127 20:27:59.185585 26 flowcontrol.go:625] starting watch
  STEP: patching @ 01/27/26 20:27:59.186
  STEP: updating @ 01/27/26 20:27:59.252
  I0127 20:27:59.402956 26 flowcontrol.go:654] waiting for watch events with expected annotations
  STEP: getting /status @ 01/27/26 20:27:59.403
  STEP: patching /status @ 01/27/26 20:27:59.405
  STEP: updating /status @ 01/27/26 20:27:59.633
  STEP: deleting @ 01/27/26 20:27:59.709
  STEP: deleting a collection @ 01/27/26 20:27:59.97
  I0127 20:28:00.156867 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-6736" for this suite. @ 01/27/26 20:28:00.159
• [2.395 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:233
  STEP: Creating a kubernetes client @ 01/27/26 20:28:00.228
  I0127 20:28:00.228821 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename container-runtime @ 01/27/26 20:28:00.229
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:28:00.364
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:28:00.577
  STEP: create the container @ 01/27/26 20:28:00.579
  I0127 20:28:00.633185      26 warnings.go:107] "Warning: metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]"
  STEP: wait for the container to reach Succeeded @ 01/27/26 20:28:00.633
  STEP: get the container status @ 01/27/26 20:28:40.769
  STEP: the container should be terminated @ 01/27/26 20:28:40.771
  STEP: the termination message should be set @ 01/27/26 20:28:40.771
  I0127 20:28:40.771267 26 runtime.go:168] Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 01/27/26 20:28:40.771
  I0127 20:28:41.080407 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-8775" for this suite. @ 01/27/26 20:28:41.082
• [40.950 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:375
  STEP: Creating a kubernetes client @ 01/27/26 20:28:41.178
  I0127 20:28:41.178892 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 20:28:41.179
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:28:41.378
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:28:41.424
  STEP: Creating configMap with name projected-configmap-test-volume-bcdb7df4-26b3-4779-8078-e73c774b523d @ 01/27/26 20:28:41.458
  STEP: Creating a pod to test consume configMaps @ 01/27/26 20:28:41.578
  STEP: Saw pod success @ 01/27/26 20:29:04.353
  I0127 20:29:04.355312 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-projected-configmaps-f5e9db7a-5514-48f1-9243-527c41a8abef container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 01/27/26 20:29:04.365
  I0127 20:29:05.319381 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6714" for this suite. @ 01/27/26 20:29:05.322
• [24.335 seconds]
------------------------------
SS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:536
  STEP: Creating a kubernetes client @ 01/27/26 20:29:05.513
  I0127 20:29:05.513754 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename security-context-test @ 01/27/26 20:29:05.514
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:29:05.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:29:05.787
  I0127 20:29:27.157714 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-9968" for this suite. @ 01/27/26 20:29:27.194
• [22.035 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:241
  STEP: Creating a kubernetes client @ 01/27/26 20:29:27.549
  I0127 20:29:27.549201 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename crd-publish-openapi @ 01/27/26 20:29:27.549
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:29:27.768
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:29:27.771
  I0127 20:29:27.773753 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 01/27/26 20:29:29.395
  I0127 20:29:29.395991 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-8209 --namespace=crd-publish-openapi-8209 create -f -'
  I0127 20:29:31.691160 26 builder.go:156] stderr: ""
  I0127 20:29:31.691207 26 builder.go:157] stdout: "e2e-test-crd-publish-openapi-8209-9967-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0127 20:29:31.691249 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-8209 --namespace=crd-publish-openapi-8209 delete e2e-test-crd-publish-openapi-8209-9967-crds test-cr'
  I0127 20:29:31.868576 26 builder.go:156] stderr: ""
  I0127 20:29:31.868618 26 builder.go:157] stdout: "e2e-test-crd-publish-openapi-8209-9967-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted from crd-publish-openapi-8209 namespace\n"
  I0127 20:29:31.868656 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-8209 --namespace=crd-publish-openapi-8209 apply -f -'
  I0127 20:29:32.106044 26 builder.go:156] stderr: ""
  I0127 20:29:32.106080 26 builder.go:157] stdout: "e2e-test-crd-publish-openapi-8209-9967-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0127 20:29:32.106120 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-8209 --namespace=crd-publish-openapi-8209 delete e2e-test-crd-publish-openapi-8209-9967-crds test-cr'
  I0127 20:29:32.200649 26 builder.go:156] stderr: ""
  I0127 20:29:32.200710 26 builder.go:157] stdout: "e2e-test-crd-publish-openapi-8209-9967-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted from crd-publish-openapi-8209 namespace\n"
  STEP: kubectl explain works to explain CR @ 01/27/26 20:29:32.2
  I0127 20:29:32.200771 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-8209 explain e2e-test-crd-publish-openapi-8209-9967-crds'
  I0127 20:29:32.256394 26 builder.go:156] stderr: ""
  I0127 20:29:32.256445 26 builder.go:157] stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-8209-9967-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  I0127 20:29:33.892018 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8209" for this suite. @ 01/27/26 20:29:33.984
• [6.715 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 01/27/26 20:29:34.264
  I0127 20:29:34.264343 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 20:29:34.264
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:29:34.504
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:29:34.715
  STEP: Creating projection with secret that has name projected-secret-test-7e9620a4-4375-499e-a842-9b23384b8ce8 @ 01/27/26 20:29:34.799
  STEP: Creating a pod to test consume secrets @ 01/27/26 20:29:35.079
  STEP: Saw pod success @ 01/27/26 20:30:00.984
  I0127 20:30:00.986688 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-projected-secrets-b6c64af7-6d62-4c35-b105-cd636c5c43a8 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 01/27/26 20:30:00.992
  I0127 20:30:01.441990 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8968" for this suite. @ 01/27/26 20:30:01.445
• [27.475 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:190
  STEP: Creating a kubernetes client @ 01/27/26 20:30:01.74
  I0127 20:30:01.740029 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename emptydir-wrapper @ 01/27/26 20:30:01.74
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:30:01.836
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:30:01.949
  STEP: Creating 50 configmaps @ 01/27/26 20:30:01.952
  STEP: Creating RC which spawns configmap-volume pods @ 01/27/26 20:30:09.196
  I0127 20:30:09.459340 26 resource.go:64] Pod name wrapped-volume-race-c906ab79-651e-4cdf-a7cb-2a42687b4251: Found 0 pods out of 5
  I0127 20:30:15.103001 26 resource.go:64] Pod name wrapped-volume-race-c906ab79-651e-4cdf-a7cb-2a42687b4251: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 01/27/26 20:30:15.103
  STEP: Creating RC which spawns configmap-volume pods @ 01/27/26 20:30:44.086
  I0127 20:30:44.440369 26 resource.go:64] Pod name wrapped-volume-race-00e2736e-963e-4274-8716-f01a15955e9d: Found 0 pods out of 5
  I0127 20:30:49.621053 26 resource.go:64] Pod name wrapped-volume-race-00e2736e-963e-4274-8716-f01a15955e9d: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 01/27/26 20:30:49.621
  STEP: Creating RC which spawns configmap-volume pods @ 01/27/26 20:31:04.278
  I0127 20:31:04.363872 26 resource.go:64] Pod name wrapped-volume-race-7a12d041-7491-4efd-a568-2149a87e301a: Found 0 pods out of 5
  I0127 20:31:09.385743 26 resource.go:64] Pod name wrapped-volume-race-7a12d041-7491-4efd-a568-2149a87e301a: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 01/27/26 20:31:09.385
  STEP: deleting ReplicationController wrapped-volume-race-7a12d041-7491-4efd-a568-2149a87e301a in namespace emptydir-wrapper-968, will wait for the garbage collector to delete the pods @ 01/27/26 20:31:15.851
  I0127 20:31:15.914378 26 resources.go:139] Deleting ReplicationController wrapped-volume-race-7a12d041-7491-4efd-a568-2149a87e301a took: 8.578677ms
  I0127 20:31:16.015354 26 resources.go:163] Terminating ReplicationController wrapped-volume-race-7a12d041-7491-4efd-a568-2149a87e301a pods took: 100.972442ms
  STEP: deleting ReplicationController wrapped-volume-race-00e2736e-963e-4274-8716-f01a15955e9d in namespace emptydir-wrapper-968, will wait for the garbage collector to delete the pods @ 01/27/26 20:31:18.116
  I0127 20:31:18.176132 26 resources.go:139] Deleting ReplicationController wrapped-volume-race-00e2736e-963e-4274-8716-f01a15955e9d took: 6.708837ms
  I0127 20:31:18.277220 26 resources.go:163] Terminating ReplicationController wrapped-volume-race-00e2736e-963e-4274-8716-f01a15955e9d pods took: 101.089297ms
  STEP: deleting ReplicationController wrapped-volume-race-c906ab79-651e-4cdf-a7cb-2a42687b4251 in namespace emptydir-wrapper-968, will wait for the garbage collector to delete the pods @ 01/27/26 20:31:19.677
  I0127 20:31:19.740015 26 resources.go:139] Deleting ReplicationController wrapped-volume-race-c906ab79-651e-4cdf-a7cb-2a42687b4251 took: 9.736246ms
  I0127 20:31:19.840310 26 resources.go:163] Terminating ReplicationController wrapped-volume-race-c906ab79-651e-4cdf-a7cb-2a42687b4251 pods took: 100.294574ms
  STEP: Cleaning up the configMaps @ 01/27/26 20:31:20.741
  I0127 20:31:21.217389 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-968" for this suite. @ 01/27/26 20:31:21.22
• [79.488 seconds]
------------------------------
S
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 01/27/26 20:31:21.228
  I0127 20:31:21.228207 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename secrets @ 01/27/26 20:31:21.228
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:31:21.254
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:31:21.257
  STEP: Creating secret with name secret-test-fce17759-ae7b-4d4f-a3c4-bd34108eacb2 @ 01/27/26 20:31:21.3
  STEP: Creating a pod to test consume secrets @ 01/27/26 20:31:21.308
  STEP: Saw pod success @ 01/27/26 20:31:25.331
  I0127 20:31:25.333534 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-secrets-8fe6f82a-be79-4d49-98d7-630e77229490 container secret-volume-test: <nil>
  STEP: delete the pod @ 01/27/26 20:31:25.337
  I0127 20:31:25.359948 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7783" for this suite. @ 01/27/26 20:31:25.362
  STEP: Destroying namespace "secret-namespace-7742" for this suite. @ 01/27/26 20:31:25.37
• [4.150 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:74
  STEP: Creating a kubernetes client @ 01/27/26 20:31:25.378
  I0127 20:31:25.378415 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename configmap @ 01/27/26 20:31:25.379
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:31:25.4
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:31:25.405
  STEP: Creating configMap with name configmap-test-volume-a10afd96-a9f6-438f-87f2-17cdcfb4a290 @ 01/27/26 20:31:25.407
  STEP: Creating a pod to test consume configMaps @ 01/27/26 20:31:25.423
  STEP: Saw pod success @ 01/27/26 20:31:29.449
  I0127 20:31:29.450888 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-configmaps-ca3de395-53f8-4744-a37c-2737c7b9c9e5 container agnhost-container: <nil>
  STEP: delete the pod @ 01/27/26 20:31:29.454
  I0127 20:31:29.482417 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8425" for this suite. @ 01/27/26 20:31:29.484
• [4.120 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:208
  STEP: Creating a kubernetes client @ 01/27/26 20:31:29.498
  I0127 20:31:29.498958 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 20:31:29.499
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:31:29.514
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:31:29.519
  STEP: Creating a pod to test downward API volume plugin @ 01/27/26 20:31:29.521
  STEP: Saw pod success @ 01/27/26 20:31:33.553
  I0127 20:31:33.554784 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downwardapi-volume-b255e07e-3cbe-4804-880d-368bc1ad0003 container client-container: <nil>
  STEP: delete the pod @ 01/27/26 20:31:33.558
  I0127 20:31:33.585427 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6012" for this suite. @ 01/27/26 20:31:33.587
• [4.098 seconds]
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 01/27/26 20:31:33.596
  I0127 20:31:33.596531 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename watch @ 01/27/26 20:31:33.597
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:31:33.624
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:31:33.626
  STEP: creating a watch on configmaps with label A @ 01/27/26 20:31:33.64
  STEP: creating a watch on configmaps with label B @ 01/27/26 20:31:33.642
  STEP: creating a watch on configmaps with label A or B @ 01/27/26 20:31:33.644
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 01/27/26 20:31:33.645
  I0127 20:31:33.653707 26 watch.go:426] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9797  28708b88-3d4b-424c-b43c-442c80ea1e2d 16167 0 2026-01-27 20:31:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2026-01-27 20:31:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0127 20:31:33.653786 26 watch.go:426] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9797  28708b88-3d4b-424c-b43c-442c80ea1e2d 16167 0 2026-01-27 20:31:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2026-01-27 20:31:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 01/27/26 20:31:33.653
  I0127 20:31:33.662396 26 watch.go:426] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9797  28708b88-3d4b-424c-b43c-442c80ea1e2d 16168 0 2026-01-27 20:31:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2026-01-27 20:31:33 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0127 20:31:33.662465 26 watch.go:426] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9797  28708b88-3d4b-424c-b43c-442c80ea1e2d 16168 0 2026-01-27 20:31:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2026-01-27 20:31:33 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 01/27/26 20:31:33.662
  I0127 20:31:33.672673 26 watch.go:426] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9797  28708b88-3d4b-424c-b43c-442c80ea1e2d 16169 0 2026-01-27 20:31:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2026-01-27 20:31:33 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0127 20:31:33.672746 26 watch.go:426] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9797  28708b88-3d4b-424c-b43c-442c80ea1e2d 16169 0 2026-01-27 20:31:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2026-01-27 20:31:33 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 01/27/26 20:31:33.672
  I0127 20:31:33.680765 26 watch.go:426] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9797  28708b88-3d4b-424c-b43c-442c80ea1e2d 16170 0 2026-01-27 20:31:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2026-01-27 20:31:33 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0127 20:31:33.680825 26 watch.go:426] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9797  28708b88-3d4b-424c-b43c-442c80ea1e2d 16170 0 2026-01-27 20:31:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2026-01-27 20:31:33 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 01/27/26 20:31:33.68
  I0127 20:31:33.688098 26 watch.go:426] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9797  0ce0da08-e1ae-432a-9a01-c00d432b4029 16171 0 2026-01-27 20:31:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2026-01-27 20:31:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0127 20:31:33.688166 26 watch.go:426] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9797  0ce0da08-e1ae-432a-9a01-c00d432b4029 16171 0 2026-01-27 20:31:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2026-01-27 20:31:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 01/27/26 20:31:43.689
  I0127 20:31:43.697184 26 watch.go:426] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9797  0ce0da08-e1ae-432a-9a01-c00d432b4029 16218 0 2026-01-27 20:31:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2026-01-27 20:31:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0127 20:31:43.697228 26 watch.go:426] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9797  0ce0da08-e1ae-432a-9a01-c00d432b4029 16218 0 2026-01-27 20:31:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2026-01-27 20:31:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0127 20:31:53.699770 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9797" for this suite. @ 01/27/26 20:31:53.703
• [20.123 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 01/27/26 20:31:53.719
  I0127 20:31:53.719651 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 20:31:53.72
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:31:53.834
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:31:53.836
  STEP: Creating projection with secret that has name projected-secret-test-map-1d4037ab-9042-445e-a0a3-fc1a06027e0a @ 01/27/26 20:31:53.838
  STEP: Creating a pod to test consume secrets @ 01/27/26 20:31:53.863
  STEP: Saw pod success @ 01/27/26 20:31:59.913
  I0127 20:31:59.916296 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-projected-secrets-a7386d96-cfec-48bd-a9cd-4ee0a7032642 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 01/27/26 20:31:59.92
  I0127 20:31:59.950076 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7381" for this suite. @ 01/27/26 20:31:59.951
• [6.239 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:396
  STEP: Creating a kubernetes client @ 01/27/26 20:31:59.958
  I0127 20:31:59.958885 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename crd-publish-openapi @ 01/27/26 20:31:59.959
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:31:59.978
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:31:59.982
  STEP: set up a multi version CRD @ 01/27/26 20:31:59.984
  I0127 20:31:59.985309 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: rename a version @ 01/27/26 20:32:03.416
  STEP: check the new version name is served @ 01/27/26 20:32:03.435
  STEP: check the old version name is removed @ 01/27/26 20:32:04.268
  STEP: check the other version is not changed @ 01/27/26 20:32:04.94
  I0127 20:32:07.684757 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5874" for this suite. @ 01/27/26 20:32:07.69
• [7.740 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 01/27/26 20:32:07.699
  I0127 20:32:07.699243 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pod-network-test @ 01/27/26 20:32:07.699
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:32:07.722
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:32:07.724
  STEP: Performing setup for networking test in namespace pod-network-test-4199 @ 01/27/26 20:32:07.727
  STEP: creating a selector @ 01/27/26 20:32:07.728
  STEP: Creating the service pods in kubernetes @ 01/27/26 20:32:07.728
  I0127 20:32:07.728227 26 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 01/27/26 20:32:21.976
  I0127 20:32:24.015452 26 utils.go:803] Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  I0127 20:32:24.015495 26 utils.go:496] Going to poll 10.52.1.150 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  I0127 20:32:24.016742 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.52.1.150 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4199 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:32:24.016769 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:32:24.016801 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-network-test-4199/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.52.1.150+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&stderr=true&stdout=true)
  I0127 20:32:25.062665 26 utils.go:513] Found all 1 expected endpoints: [netserver-0]
  I0127 20:32:25.062702 26 utils.go:496] Going to poll 10.52.0.92 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  I0127 20:32:25.065330 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.52.0.92 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4199 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:32:25.065358 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:32:25.065396 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-network-test-4199/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.52.0.92+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&stderr=true&stdout=true)
  I0127 20:32:26.102353 26 utils.go:513] Found all 1 expected endpoints: [netserver-1]
  I0127 20:32:26.102501 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-4199" for this suite. @ 01/27/26 20:32:26.106
• [18.415 seconds]
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:141
  STEP: Creating a kubernetes client @ 01/27/26 20:32:26.114
  I0127 20:32:26.114749 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename configmap @ 01/27/26 20:32:26.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:32:26.131
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:32:26.142
  STEP: Creating configMap that has name configmap-test-emptyKey-7af81067-2da1-4e20-a471-30ed643446bf @ 01/27/26 20:32:26.145
  I0127 20:32:26.147711 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4362" for this suite. @ 01/27/26 20:32:26.207
• [0.110 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:175
  STEP: Creating a kubernetes client @ 01/27/26 20:32:26.224
  I0127 20:32:26.224984 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename crd-webhook @ 01/27/26 20:32:26.225
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:32:26.254
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:32:26.256
  STEP: Setting up server cert @ 01/27/26 20:32:26.258
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 01/27/26 20:32:26.441
  STEP: Deploying the custom resource conversion webhook pod @ 01/27/26 20:32:26.449
  STEP: Wait for the deployment to be ready @ 01/27/26 20:32:26.472
  I0127 20:32:26.477072 26 deployment.go:223] new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 01/27/26 20:32:28.483
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 20:32:28.505
  I0127 20:32:28.505521 26 wait.go:65] Waiting for amount of service crd-webhook-1271/e2e-test-crd-conversion-webhook endpoints to be 1
  I0127 20:32:28.508218 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  I0127 20:32:29.509011 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Creating a v1 custom resource @ 01/27/26 20:32:32.063
  STEP: Create a v2 custom resource @ 01/27/26 20:32:32.101
  STEP: List CRs in v1 @ 01/27/26 20:32:32.122
  STEP: List CRs in v2 @ 01/27/26 20:32:32.125
  I0127 20:32:32.731447 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-1271" for this suite. @ 01/27/26 20:32:32.737
• [6.524 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:550
  STEP: Creating a kubernetes client @ 01/27/26 20:32:32.749
  I0127 20:32:32.749535 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename container-probe @ 01/27/26 20:32:32.75
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:32:32.777
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:32:32.779
  STEP: Creating pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184 @ 01/27/26 20:32:32.781
  STEP: checking the pod's current state and verifying that restartCount is present @ 01/27/26 20:32:34.796
  I0127 20:32:34.798276 26 container_probe.go:1746] Initial restart count of pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 is 0
  I0127 20:32:34.800242 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:32:36.802992 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:32:38.806248 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:32:40.809987 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:32:42.812318 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:32:44.816010 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:32:46.819550 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:32:48.822652 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:32:50.825204 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:32:52.828917 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:32:54.832016 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:32:56.834822 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:32:58.837643 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:00.840257 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:02.842614 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:04.845802 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:06.849548 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:08.852759 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:10.856731 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:12.859676 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:14.863539 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:16.865901 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:18.869495 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:20.873074 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:22.876899 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:24.879257 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:26.881995 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:28.886443 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:30.889738 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:32.892282 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:34.895134 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:36.897498 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:38.900737 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:40.903323 26 container_probe.go:1756] Get pod test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 in namespace container-probe-9184
  I0127 20:33:40.903366 26 container_probe.go:1760] Restart count of pod container-probe-9184/test-grpc-4173e151-8e8e-43ce-bd23-2e03715646f3 is now 1 (1m6.105060897s elapsed)
  STEP: deleting the pod @ 01/27/26 20:33:40.903
  I0127 20:33:40.922998 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9184" for this suite. @ 01/27/26 20:33:40.928
• [68.200 seconds]
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:85
  STEP: Creating a kubernetes client @ 01/27/26 20:33:40.949
  I0127 20:33:40.949502 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename downward-api @ 01/27/26 20:33:40.95
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:33:40.965
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:33:41.066
  STEP: Creating a pod to test downward API volume plugin @ 01/27/26 20:33:41.068
  STEP: Saw pod success @ 01/27/26 20:33:45.1
  I0127 20:33:45.102236 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downwardapi-volume-7277a560-2d7d-4fe6-a371-3abef0de7295 container client-container: <nil>
  STEP: delete the pod @ 01/27/26 20:33:45.111
  I0127 20:33:45.139909 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9357" for this suite. @ 01/27/26 20:33:45.142
• [4.203 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:72
  STEP: Creating a kubernetes client @ 01/27/26 20:33:45.152
  I0127 20:33:45.152287 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename cronjob @ 01/27/26 20:33:45.152
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:33:45.19
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:33:45.193
  STEP: Creating a cronjob @ 01/27/26 20:33:45.195
  STEP: Ensuring more than one job is running at a time @ 01/27/26 20:33:45.205
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 01/27/26 20:35:01.207
  STEP: Removing cronjob @ 01/27/26 20:35:01.209
  I0127 20:35:01.238181 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-4713" for this suite. @ 01/27/26 20:35:01.242
• [76.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:74
  STEP: Creating a kubernetes client @ 01/27/26 20:35:01.255
  I0127 20:35:01.255780 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename crd-publish-openapi @ 01/27/26 20:35:01.256
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:35:01.282
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:35:01.379
  I0127 20:35:01.382466 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 01/27/26 20:35:02.748
  I0127 20:35:02.748776 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-6857 --namespace=crd-publish-openapi-6857 create -f -'
  I0127 20:35:04.836554 26 builder.go:156] stderr: ""
  I0127 20:35:04.836609 26 builder.go:157] stdout: "e2e-test-crd-publish-openapi-6857-330-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0127 20:35:04.836653 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-6857 --namespace=crd-publish-openapi-6857 delete e2e-test-crd-publish-openapi-6857-330-crds test-foo'
  I0127 20:35:04.899027 26 builder.go:156] stderr: ""
  I0127 20:35:04.899076 26 builder.go:157] stdout: "e2e-test-crd-publish-openapi-6857-330-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted from crd-publish-openapi-6857 namespace\n"
  I0127 20:35:04.899112 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-6857 --namespace=crd-publish-openapi-6857 apply -f -'
  I0127 20:35:04.975411 26 builder.go:156] stderr: ""
  I0127 20:35:04.975453 26 builder.go:157] stdout: "e2e-test-crd-publish-openapi-6857-330-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0127 20:35:04.975495 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-6857 --namespace=crd-publish-openapi-6857 delete e2e-test-crd-publish-openapi-6857-330-crds test-foo'
  I0127 20:35:05.041389 26 builder.go:156] stderr: ""
  I0127 20:35:05.041429 26 builder.go:157] stdout: "e2e-test-crd-publish-openapi-6857-330-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted from crd-publish-openapi-6857 namespace\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 01/27/26 20:35:05.041
  I0127 20:35:05.041507 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-6857 --namespace=crd-publish-openapi-6857 create -f -'
  I0127 20:35:05.104351 26 builder.go:145] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 01/27/26 20:35:05.104
  I0127 20:35:05.104473 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-6857 --namespace=crd-publish-openapi-6857 create -f -'
  I0127 20:35:05.161131 26 builder.go:145] rc: 1
  I0127 20:35:05.161219 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-6857 --namespace=crd-publish-openapi-6857 apply -f -'
  I0127 20:35:05.225176 26 builder.go:145] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 01/27/26 20:35:05.225
  I0127 20:35:05.225313 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-6857 --namespace=crd-publish-openapi-6857 create -f -'
  I0127 20:35:05.285956 26 builder.go:145] rc: 1
  I0127 20:35:05.286032 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-6857 --namespace=crd-publish-openapi-6857 apply -f -'
  I0127 20:35:05.350460 26 builder.go:145] rc: 1
  STEP: kubectl explain works to explain CR properties @ 01/27/26 20:35:05.35
  I0127 20:35:05.350609 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-6857 explain e2e-test-crd-publish-openapi-6857-330-crds'
  I0127 20:35:05.407654 26 builder.go:156] stderr: ""
  I0127 20:35:05.407713 26 builder.go:157] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-6857-330-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 01/27/26 20:35:05.407
  I0127 20:35:05.408011 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-6857 explain e2e-test-crd-publish-openapi-6857-330-crds.metadata'
  I0127 20:35:05.469420 26 builder.go:156] stderr: ""
  I0127 20:35:05.469552 26 builder.go:157] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-6857-330-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  I0127 20:35:05.469715 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-6857 explain e2e-test-crd-publish-openapi-6857-330-crds.spec'
  I0127 20:35:05.527276 26 builder.go:156] stderr: ""
  I0127 20:35:05.527325 26 builder.go:157] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-6857-330-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  I0127 20:35:05.527401 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-6857 explain e2e-test-crd-publish-openapi-6857-330-crds.spec.bars'
  I0127 20:35:05.592376 26 builder.go:156] stderr: ""
  I0127 20:35:05.592423 26 builder.go:157] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-6857-330-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n  enum: Great, Down\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 01/27/26 20:35:05.592
  I0127 20:35:05.592911 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-6857 explain e2e-test-crd-publish-openapi-6857-330-crds.spec.bars2'
  I0127 20:35:05.651494 26 builder.go:145] rc: 1
  I0127 20:35:07.049100 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6857" for this suite. @ 01/27/26 20:35:07.054
• [5.812 seconds]
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:706
  STEP: Creating a kubernetes client @ 01/27/26 20:35:07.067
  I0127 20:35:07.067955 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename sched-pred @ 01/27/26 20:35:07.068
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:35:07.089
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:35:07.091
  I0127 20:35:07.094808 26 helper.go:125] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0127 20:35:07.157390 26 util.go:389] Waiting for terminating namespaces to be deleted...
  I0127 20:35:07.159078 26 predicates.go:120] 
  Logging pods the apiserver thinks is on node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 before test
  I0127 20:35:07.161322 26 predicates.go:958] concurrent-29492434-n8hq7 from cronjob-4713 started at 2026-01-27 20:34:00 +0000 UTC (1 container statuses recorded)
  I0127 20:35:07.161355 26 predicates.go:960] 	Container c ready: true, restart count 0
  I0127 20:35:07.161364 26 predicates.go:958] concurrent-29492435-s2d8r from cronjob-4713 started at 2026-01-27 20:35:00 +0000 UTC (1 container statuses recorded)
  I0127 20:35:07.161371 26 predicates.go:960] 	Container c ready: true, restart count 0
  I0127 20:35:07.161379 26 predicates.go:958] svclb-traefik-4c5baeff-vbqt2 from kube-system started at 2026-01-27 19:41:22 +0000 UTC (2 container statuses recorded)
  I0127 20:35:07.161386 26 predicates.go:960] 	Container lb-tcp-443 ready: true, restart count 0
  I0127 20:35:07.161392 26 predicates.go:960] 	Container lb-tcp-80 ready: true, restart count 0
  I0127 20:35:07.161400 26 predicates.go:958] sonobuoy from sonobuoy started at 2026-01-27 19:52:38 +0000 UTC (1 container statuses recorded)
  I0127 20:35:07.161406 26 predicates.go:960] 	Container kube-sonobuoy ready: true, restart count 0
  I0127 20:35:07.161413 26 predicates.go:958] sonobuoy-e2e-job-211431d51fbc478c from sonobuoy started at 2026-01-27 19:52:42 +0000 UTC (2 container statuses recorded)
  I0127 20:35:07.161419 26 predicates.go:960] 	Container e2e ready: true, restart count 0
  I0127 20:35:07.161425 26 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0127 20:35:07.161432 26 predicates.go:958] sonobuoy-systemd-logs-daemon-set-7c9a66bc53524567-gzwrw from sonobuoy started at 2026-01-27 19:52:42 +0000 UTC (2 container statuses recorded)
  I0127 20:35:07.161440 26 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0127 20:35:07.161446 26 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  I0127 20:35:07.161452 26 predicates.go:120] 
  Logging pods the apiserver thinks is on node k3k-k3kcluster-server-0 before test
  I0127 20:35:07.163722 26 predicates.go:958] coredns-54bf7cdff9-hvd6n from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 20:35:07.163747 26 predicates.go:960] 	Container coredns ready: true, restart count 0
  I0127 20:35:07.163755 26 predicates.go:958] helm-install-traefik-ck8zv from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 20:35:07.163762 26 predicates.go:960] 	Container helm ready: false, restart count 1
  I0127 20:35:07.163769 26 predicates.go:958] helm-install-traefik-crd-kw4dk from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 20:35:07.163775 26 predicates.go:960] 	Container helm ready: false, restart count 0
  I0127 20:35:07.163782 26 predicates.go:958] local-path-provisioner-69879d7dd7-xrhgn from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 20:35:07.163788 26 predicates.go:960] 	Container local-path-provisioner ready: true, restart count 0
  I0127 20:35:07.163795 26 predicates.go:958] metrics-server-77dbbf84b-fkr5h from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 20:35:07.163801 26 predicates.go:960] 	Container metrics-server ready: true, restart count 0
  I0127 20:35:07.163807 26 predicates.go:958] svclb-traefik-4c5baeff-dqplp from kube-system started at 2026-01-27 19:41:06 +0000 UTC (2 container statuses recorded)
  I0127 20:35:07.163813 26 predicates.go:960] 	Container lb-tcp-443 ready: true, restart count 0
  I0127 20:35:07.163867 26 predicates.go:960] 	Container lb-tcp-80 ready: true, restart count 0
  I0127 20:35:07.163874 26 predicates.go:958] traefik-6d98778dfc-p2jdc from kube-system started at 2026-01-27 19:41:06 +0000 UTC (1 container statuses recorded)
  I0127 20:35:07.163881 26 predicates.go:960] 	Container traefik ready: true, restart count 0
  I0127 20:35:07.163888 26 predicates.go:958] sonobuoy-systemd-logs-daemon-set-7c9a66bc53524567-h78hs from sonobuoy started at 2026-01-27 19:52:42 +0000 UTC (2 container statuses recorded)
  I0127 20:35:07.163898 26 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0127 20:35:07.163905 26 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 01/27/26 20:35:07.163
  STEP: Explicitly delete pod here to free the resource it takes. @ 01/27/26 20:35:09.191
  STEP: Trying to apply a random label on the found node. @ 01/27/26 20:35:09.223
  STEP: verifying the node has the label kubernetes.io/e2e-2ec77cda-8e55-49e6-9e52-7dea6484a6d1 95 @ 01/27/26 20:35:09.239
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 01/27/26 20:35:09.242
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.42.0.12 on the node which pod4 resides and expect not scheduled @ 01/27/26 20:35:11.272
  STEP: removing the label kubernetes.io/e2e-2ec77cda-8e55-49e6-9e52-7dea6484a6d1 off the node k3k-k3kcluster-server-0 @ 01/27/26 20:40:11.284
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-2ec77cda-8e55-49e6-9e52-7dea6484a6d1 @ 01/27/26 20:40:11.301
  I0127 20:40:11.303954 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-4303" for this suite. @ 01/27/26 20:40:11.306
• [304.249 seconds]
------------------------------
[sig-api-machinery] OrderedNamespaceDeletion namespace deletion should delete pod first [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:492
  STEP: Creating a kubernetes client @ 01/27/26 20:40:11.316
  I0127 20:40:11.316725 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename namespacedeletion @ 01/27/26 20:40:11.317
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:40:11.343
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:40:11.345
  STEP: Creating a test namespace @ 01/27/26 20:40:11.347
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:40:11.384
  STEP: Creating a pod with finalizer in the namespace @ 01/27/26 20:40:11.432
  STEP: Waiting for the pod to have running status @ 01/27/26 20:40:11.442
  STEP: Creating a configmap "test-configmap" in namespace "nsdeletetest-1577" @ 01/27/26 20:40:13.448
  STEP: Deleting the namespace @ 01/27/26 20:40:13.456
  STEP: wait until namespace controller had time to process @ 01/27/26 20:40:13.464
  I0127 20:40:13.476301 26 namespace.go:572] Namespace "nsdeletetest-1577" does not yet have a NamespaceDeletionContentFailure condition, retrying...
  I0127 20:40:15.467628 26 namespace.go:572] Namespace "nsdeletetest-1577" does not yet have a NamespaceDeletionContentFailure condition, retrying...
  I0127 20:40:17.469265 26 namespace.go:572] Namespace "nsdeletetest-1577" does not yet have a NamespaceDeletionContentFailure condition, retrying...
  STEP: the pod should be deleted before processing deletion for other resources @ 01/27/26 20:40:19.468
  STEP: Removing finalizer from pod "test-pod" in namespace "nsdeletetest-1577" @ 01/27/26 20:40:19.471
  STEP: Waiting for the pod to not be present in the namespace @ 01/27/26 20:40:19.481
  STEP: Waiting for the namespace to be removed. @ 01/27/26 20:40:19.484
  I0127 20:40:24.487188 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespacedeletion-352" for this suite. @ 01/27/26 20:40:24.489
  STEP: Destroying namespace "nsdeletetest-1577" for this suite. @ 01/27/26 20:40:24.496
  I0127 20:40:24.498128 26 framework.go:370] Namespace nsdeletetest-1577 was already deleted
• [13.182 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:172
  STEP: Creating a kubernetes client @ 01/27/26 20:40:24.498
  I0127 20:40:24.498635 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename resourcequota @ 01/27/26 20:40:24.499
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:40:24.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:40:24.527
  STEP: Discovering how many secrets are in namespace by default @ 01/27/26 20:40:24.53
  STEP: Counting existing ResourceQuota @ 01/27/26 20:40:29.532
  STEP: Creating a ResourceQuota @ 01/27/26 20:40:34.536
  STEP: Ensuring resource quota status is calculated @ 01/27/26 20:40:34.549
  I0127 20:40:36.556627 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc00102af00>: 
          metadata:
            creationTimestamp: "2026-01-27T20:40:34Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:40:34Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T20:40:34Z"
            name: test-quota
            namespace: resourcequota-2537
            resourceVersion: "18187"
            uid: f4d03dd2-b3cb-4ecd-be2b-41022c6f3f96
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "1"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "1"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Creating a Secret @ 01/27/26 20:40:36.556
  STEP: Ensuring resource quota status captures secret creation @ 01/27/26 20:40:36.59
  I0127 20:40:36.594278 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001106f00>: 
          metadata:
            creationTimestamp: "2026-01-27T20:40:34Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:40:34Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T20:40:36Z"
            name: test-quota
            namespace: resourcequota-2537
            resourceVersion: "18194"
            uid: f4d03dd2-b3cb-4ecd-be2b-41022c6f3f96
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "1"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "1"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "1"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Deleting a secret @ 01/27/26 20:40:36.594
  STEP: Ensuring resource quota status released usage @ 01/27/26 20:40:36.602
  I0127 20:40:38.609000 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc000be92c0>: 
          metadata:
            creationTimestamp: "2026-01-27T20:40:34Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:40:34Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T20:40:36Z"
            name: test-quota
            namespace: resourcequota-2537
            resourceVersion: "18197"
            uid: f4d03dd2-b3cb-4ecd-be2b-41022c6f3f96
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "1"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "1"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  I0127 20:40:38.609689 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2537" for this suite. @ 01/27/26 20:40:38.613
• [14.122 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:189
  STEP: Creating a kubernetes client @ 01/27/26 20:40:38.62
  I0127 20:40:38.620615 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename emptydir @ 01/27/26 20:40:38.621
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:40:38.643
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:40:38.648
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 01/27/26 20:40:38.65
  STEP: Saw pod success @ 01/27/26 20:40:42.68
  I0127 20:40:42.682826 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-e21e45bc-6b1d-4743-86d7-c591d4d8cffd container test-container: <nil>
  STEP: delete the pod @ 01/27/26 20:40:42.694
  I0127 20:40:42.731720 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8177" for this suite. @ 01/27/26 20:40:42.733
• [4.122 seconds]
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:230
  STEP: Creating a kubernetes client @ 01/27/26 20:40:42.742
  I0127 20:40:42.743017 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pods @ 01/27/26 20:40:42.743
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:40:42.759
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:40:42.77
  STEP: creating the pod @ 01/27/26 20:40:42.772
  STEP: setting up watch @ 01/27/26 20:40:42.772
  STEP: submitting the pod to kubernetes @ 01/27/26 20:40:42.875
  STEP: verifying the pod is in kubernetes @ 01/27/26 20:40:42.885
  STEP: verifying pod creation was observed @ 01/27/26 20:40:42.9
  STEP: deleting the pod gracefully @ 01/27/26 20:40:44.907
  STEP: verifying pod deletion was observed @ 01/27/26 20:40:44.923
  I0127 20:40:45.878783 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-416" for this suite. @ 01/27/26 20:40:45.881
• [3.148 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:869
  STEP: Creating a kubernetes client @ 01/27/26 20:40:45.891
  I0127 20:40:45.891154 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename resourcequota @ 01/27/26 20:40:45.892
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:40:45.92
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:40:45.923
  STEP: Creating a ResourceQuota with best effort scope @ 01/27/26 20:40:45.925
  STEP: Ensuring ResourceQuota status is calculated @ 01/27/26 20:40:45.934
  I0127 20:40:47.939875 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc0017b1400>: 
          metadata:
            creationTimestamp: "2026-01-27T20:40:45Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:40:45Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:used:
                    .: {}
                    f:pods: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T20:40:45Z"
            name: quota-besteffort
            namespace: resourcequota-7616
            resourceVersion: "18267"
            uid: bd376d18-1cf3-489f-ab79-8741d7ace66a
          spec:
            hard:
              pods: "5"
            scopes:
            - BestEffort
          status:
            hard:
              pods: "5"
            used:
              pods: "0"
  STEP: Creating a ResourceQuota with not best effort scope @ 01/27/26 20:40:47.94
  STEP: Ensuring ResourceQuota status is calculated @ 01/27/26 20:40:47.947
  I0127 20:40:49.952639 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc00189a3c0>: 
          metadata:
            creationTimestamp: "2026-01-27T20:40:47Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:40:47Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:used:
                    .: {}
                    f:pods: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T20:40:47Z"
            name: quota-not-besteffort
            namespace: resourcequota-7616
            resourceVersion: "18280"
            uid: 5e952e78-e1a7-48ac-8b7b-fc57b81d7444
          spec:
            hard:
              pods: "5"
            scopes:
            - NotBestEffort
          status:
            hard:
              pods: "5"
            used:
              pods: "0"
  STEP: Creating a best-effort pod @ 01/27/26 20:40:49.952
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 01/27/26 20:40:49.98
  I0127 20:40:49.982647 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc0016c9040>: 
          metadata:
            creationTimestamp: "2026-01-27T20:40:45Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:40:45Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:used:
                    .: {}
                    f:pods: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T20:40:49Z"
            name: quota-besteffort
            namespace: resourcequota-7616
            resourceVersion: "18289"
            uid: bd376d18-1cf3-489f-ab79-8741d7ace66a
          spec:
            hard:
              pods: "5"
            scopes:
            - BestEffort
          status:
            hard:
              pods: "5"
            used:
              pods: "1"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 01/27/26 20:40:49.982
  I0127 20:40:49.988732 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc0016c9680>: 
          metadata:
            creationTimestamp: "2026-01-27T20:40:47Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:40:47Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:used:
                    .: {}
                    f:pods: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T20:40:47Z"
            name: quota-not-besteffort
            namespace: resourcequota-7616
            resourceVersion: "18280"
            uid: 5e952e78-e1a7-48ac-8b7b-fc57b81d7444
          spec:
            hard:
              pods: "5"
            scopes:
            - NotBestEffort
          status:
            hard:
              pods: "5"
            used:
              pods: "0"
  STEP: Deleting the pod @ 01/27/26 20:40:49.988
  STEP: Ensuring resource quota status released the pod usage @ 01/27/26 20:40:50.033
  I0127 20:40:50.035674 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc00189b040>: 
          metadata:
            creationTimestamp: "2026-01-27T20:40:45Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:40:45Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:used:
                    .: {}
                    f:pods: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T20:40:50Z"
            name: quota-besteffort
            namespace: resourcequota-7616
            resourceVersion: "18294"
            uid: bd376d18-1cf3-489f-ab79-8741d7ace66a
          spec:
            hard:
              pods: "5"
            scopes:
            - BestEffort
          status:
            hard:
              pods: "5"
            used:
              pods: "0"
  STEP: Creating a not best-effort pod @ 01/27/26 20:40:50.035
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 01/27/26 20:40:50.052
  I0127 20:40:50.054696 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc00189b540>: 
          metadata:
            creationTimestamp: "2026-01-27T20:40:47Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:40:47Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:used:
                    .: {}
                    f:pods: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T20:40:50Z"
            name: quota-not-besteffort
            namespace: resourcequota-7616
            resourceVersion: "18296"
            uid: 5e952e78-e1a7-48ac-8b7b-fc57b81d7444
          spec:
            hard:
              pods: "5"
            scopes:
            - NotBestEffort
          status:
            hard:
              pods: "5"
            used:
              pods: "1"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 01/27/26 20:40:50.054
  I0127 20:40:50.067361 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc0016c9cc0>: 
          metadata:
            creationTimestamp: "2026-01-27T20:40:45Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:40:45Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:used:
                    .: {}
                    f:pods: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T20:40:50Z"
            name: quota-besteffort
            namespace: resourcequota-7616
            resourceVersion: "18294"
            uid: bd376d18-1cf3-489f-ab79-8741d7ace66a
          spec:
            hard:
              pods: "5"
            scopes:
            - BestEffort
          status:
            hard:
              pods: "5"
            used:
              pods: "0"
  STEP: Deleting the pod @ 01/27/26 20:40:50.067
  STEP: Ensuring resource quota status released the pod usage @ 01/27/26 20:40:50.116
  I0127 20:40:50.119236 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc0015feb40>: 
          metadata:
            creationTimestamp: "2026-01-27T20:40:47Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:40:47Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:used:
                    .: {}
                    f:pods: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T20:40:50Z"
            name: quota-not-besteffort
            namespace: resourcequota-7616
            resourceVersion: "18301"
            uid: 5e952e78-e1a7-48ac-8b7b-fc57b81d7444
          spec:
            hard:
              pods: "5"
            scopes:
            - NotBestEffort
          status:
            hard:
              pods: "5"
            used:
              pods: "0"
  I0127 20:40:50.119450 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7616" for this suite. @ 01/27/26 20:40:50.122
• [4.246 seconds]
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:853
  STEP: Creating a kubernetes client @ 01/27/26 20:40:50.136
  I0127 20:40:50.136844 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pods @ 01/27/26 20:40:50.137
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:40:50.154
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:40:50.158
  STEP: Create set of pods @ 01/27/26 20:40:50.16
  I0127 20:40:50.175284 26 pods.go:877] created test-pod-1
  I0127 20:40:50.188340 26 pods.go:877] created test-pod-2
  I0127 20:40:50.205791 26 pods.go:877] created test-pod-3
  STEP: waiting for all 3 pods to be running @ 01/27/26 20:40:50.205
  STEP: waiting for all pods to be deleted @ 01/27/26 20:40:54.275
  I0127 20:40:54.296887 26 pods.go:1144] Pod quantity 3 is different from expected quantity 0
  I0127 20:40:55.394767 26 pods.go:1144] Pod quantity 1 is different from expected quantity 0
  I0127 20:40:56.280208 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9236" for this suite. @ 01/27/26 20:40:56.282
• [6.152 seconds]
------------------------------
S
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:355
  STEP: Creating a kubernetes client @ 01/27/26 20:40:56.288
  I0127 20:40:56.288614 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename disruption @ 01/27/26 20:40:56.289
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:40:56.302
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:40:56.311
  STEP: Creating a pdb that targets all three pods in a test replica set @ 01/27/26 20:40:56.313
  STEP: Waiting for the pdb to be processed @ 01/27/26 20:40:56.32
  STEP: First trying to evict a pod which shouldn't be evictable @ 01/27/26 20:40:58.334
  STEP: Waiting for all pods to be running @ 01/27/26 20:40:58.334
  I0127 20:40:58.345382 26 disruption.go:685] pods: 1 < 3
  I0127 20:41:00.338765 26 disruption.go:696] running pods: 0 < 3
  STEP: locating a running pod @ 01/27/26 20:41:02.338
  STEP: Updating the pdb to allow a pod to be evicted @ 01/27/26 20:41:02.345
  STEP: Waiting for the pdb to be processed @ 01/27/26 20:41:02.355
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 01/27/26 20:41:04.357
  STEP: Waiting for all pods to be running @ 01/27/26 20:41:04.357
  STEP: Waiting for the pdb to observed all healthy pods @ 01/27/26 20:41:04.359
  STEP: Patching the pdb to disallow a pod to be evicted @ 01/27/26 20:41:04.403
  STEP: Waiting for the pdb to be processed @ 01/27/26 20:41:04.442
  STEP: Waiting for all pods to be running @ 01/27/26 20:41:06.445
  STEP: locating a running pod @ 01/27/26 20:41:06.447
  STEP: Deleting the pdb to allow a pod to be evicted @ 01/27/26 20:41:06.452
  STEP: Waiting for the pdb to be deleted @ 01/27/26 20:41:06.46
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 01/27/26 20:41:06.462
  STEP: Waiting for all pods to be running @ 01/27/26 20:41:06.462
  I0127 20:41:06.576593 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-8042" for this suite. @ 01/27/26 20:41:06.578
• [10.302 seconds]
------------------------------
S
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/storageclass.go:55
  STEP: Creating a kubernetes client @ 01/27/26 20:41:06.59
  I0127 20:41:06.590978 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename csi-storageclass @ 01/27/26 20:41:06.591
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:41:06.625
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:41:06.628
  STEP: Creating a StorageClass @ 01/27/26 20:41:06.63
  STEP: Get StorageClass "e2e-867tb" @ 01/27/26 20:41:06.641
  STEP: Patching the StorageClass "e2e-867tb" @ 01/27/26 20:41:06.643
  STEP: Delete StorageClass "e2e-867tb" @ 01/27/26 20:41:06.657
  STEP: Confirm deletion of StorageClass "e2e-867tb" @ 01/27/26 20:41:06.666
  STEP: Create a replacement StorageClass @ 01/27/26 20:41:06.671
  STEP: Updating StorageClass "e2e-v2-wkqrq" @ 01/27/26 20:41:06.678
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-wkqrq=updated" @ 01/27/26 20:41:06.688
  STEP: Deleting StorageClass "e2e-v2-wkqrq" via DeleteCollection @ 01/27/26 20:41:06.693
  STEP: Confirm deletion of StorageClass "e2e-v2-wkqrq" @ 01/27/26 20:41:06.702
  I0127 20:41:06.704568 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-5097" for this suite. @ 01/27/26 20:41:06.706
• [0.123 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 01/27/26 20:41:06.714
  I0127 20:41:06.714432 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename watch @ 01/27/26 20:41:06.715
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:41:06.743
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:41:06.748
  STEP: creating a watch on configmaps with a certain label @ 01/27/26 20:41:06.75
  STEP: creating a new configmap @ 01/27/26 20:41:06.752
  STEP: modifying the configmap once @ 01/27/26 20:41:06.759
  STEP: changing the label value of the configmap @ 01/27/26 20:41:06.77
  STEP: Expecting to observe a delete notification for the watched object @ 01/27/26 20:41:06.787
  I0127 20:41:06.787736 26 watch.go:426] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7119  4af8e257-a99e-40f4-8f27-3b74607cf74a 18531 0 2026-01-27 20:41:06 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2026-01-27 20:41:06 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0127 20:41:06.787882 26 watch.go:426] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7119  4af8e257-a99e-40f4-8f27-3b74607cf74a 18532 0 2026-01-27 20:41:06 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2026-01-27 20:41:06 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0127 20:41:06.787933 26 watch.go:426] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7119  4af8e257-a99e-40f4-8f27-3b74607cf74a 18533 0 2026-01-27 20:41:06 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2026-01-27 20:41:06 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 01/27/26 20:41:06.787
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 01/27/26 20:41:06.797
  STEP: changing the label value of the configmap back @ 01/27/26 20:41:16.798
  STEP: modifying the configmap a third time @ 01/27/26 20:41:16.819
  STEP: deleting the configmap @ 01/27/26 20:41:16.837
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 01/27/26 20:41:16.849
  I0127 20:41:16.850036 26 watch.go:426] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7119  4af8e257-a99e-40f4-8f27-3b74607cf74a 18604 0 2026-01-27 20:41:06 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2026-01-27 20:41:16 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0127 20:41:16.850179 26 watch.go:426] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7119  4af8e257-a99e-40f4-8f27-3b74607cf74a 18607 0 2026-01-27 20:41:06 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2026-01-27 20:41:16 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0127 20:41:16.850228 26 watch.go:426] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7119  4af8e257-a99e-40f4-8f27-3b74607cf74a 18609 0 2026-01-27 20:41:06 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2026-01-27 20:41:16 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0127 20:41:16.850810 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-7119" for this suite. @ 01/27/26 20:41:16.855
• [10.160 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:874
  STEP: Creating a kubernetes client @ 01/27/26 20:41:16.874
  I0127 20:41:16.874824 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 20:41:16.875
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:41:16.898
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:41:16.904
  STEP: Setting up server cert @ 01/27/26 20:41:16.958
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 20:41:17.106
  STEP: Deploying the webhook pod @ 01/27/26 20:41:17.113
  STEP: Wait for the deployment to be ready @ 01/27/26 20:41:17.14
  I0127 20:41:17.144002 26 deployment.go:223] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 01/27/26 20:41:19.151
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 20:41:19.166
  I0127 20:41:19.166749 26 wait.go:65] Waiting for amount of service webhook-1879/e2e-test-webhook endpoints to be 1
  I0127 20:41:19.174137 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  STEP: creating a mutating webhook with match conditions @ 01/27/26 20:41:20.169
  STEP: create the configmap with a random name @ 01/27/26 20:41:20.196
  STEP: verify the configmap is mutated @ 01/27/26 20:41:20.211
  STEP: create the configmap with 'skip-me' name @ 01/27/26 20:41:20.211
  I0127 20:41:20.297843 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1879" for this suite. @ 01/27/26 20:41:20.312
  STEP: Destroying namespace "webhook-markers-8205" for this suite. @ 01/27/26 20:41:20.325
• [3.465 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:272
  STEP: Creating a kubernetes client @ 01/27/26 20:41:20.339
  I0127 20:41:20.339888 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 20:41:20.34
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:41:20.358
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:41:20.362
  STEP: Setting up server cert @ 01/27/26 20:41:20.393
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 20:41:20.836
  STEP: Deploying the webhook pod @ 01/27/26 20:41:20.846
  STEP: Wait for the deployment to be ready @ 01/27/26 20:41:20.868
  I0127 20:41:20.882981 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 01/27/26 20:41:22.89
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 20:41:22.912
  I0127 20:41:22.912077 26 wait.go:65] Waiting for amount of service webhook-3713/e2e-test-webhook endpoints to be 1
  I0127 20:41:22.914418 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 01/27/26 20:41:23.915
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 01/27/26 20:41:23.944
  STEP: Creating a dummy validating-webhook-configuration object @ 01/27/26 20:41:23.968
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 01/27/26 20:41:23.987
  STEP: Creating a dummy mutating-webhook-configuration object @ 01/27/26 20:41:23.995
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 01/27/26 20:41:24.012
  I0127 20:41:24.104118 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3713" for this suite. @ 01/27/26 20:41:24.118
  STEP: Destroying namespace "webhook-markers-4430" for this suite. @ 01/27/26 20:41:24.129
• [3.805 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:119
  STEP: Creating a kubernetes client @ 01/27/26 20:41:24.145
  I0127 20:41:24.145035 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename emptydir @ 01/27/26 20:41:24.145
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:41:24.16
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:41:24.166
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 01/27/26 20:41:24.167
  STEP: Saw pod success @ 01/27/26 20:41:28.197
  I0127 20:41:28.199186 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-772e53e5-24c3-42fc-bf12-fe76bde92d84 container test-container: <nil>
  STEP: delete the pod @ 01/27/26 20:41:28.203
  I0127 20:41:28.230864 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1356" for this suite. @ 01/27/26 20:41:28.234
• [4.098 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:402
  STEP: Creating a kubernetes client @ 01/27/26 20:41:28.243
  I0127 20:41:28.243560 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 20:41:28.244
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:41:28.269
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:41:28.272
  STEP: Setting up server cert @ 01/27/26 20:41:28.303
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 20:41:28.487
  STEP: Deploying the webhook pod @ 01/27/26 20:41:28.495
  STEP: Wait for the deployment to be ready @ 01/27/26 20:41:28.523
  I0127 20:41:28.530752 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 01/27/26 20:41:30.538
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 20:41:30.56
  I0127 20:41:30.560428 26 wait.go:65] Waiting for amount of service webhook-1726/e2e-test-webhook endpoints to be 1
  I0127 20:41:30.562230 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  STEP: Creating a validating webhook configuration @ 01/27/26 20:41:31.564
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 01/27/26 20:41:31.588
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 01/27/26 20:41:31.598
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 01/27/26 20:41:31.613
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 01/27/26 20:41:31.631
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 01/27/26 20:41:31.657
  I0127 20:41:31.733966 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1726" for this suite. @ 01/27/26 20:41:31.736
  STEP: Destroying namespace "webhook-markers-5814" for this suite. @ 01/27/26 20:41:31.753
• [3.531 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:432
  STEP: Creating a kubernetes client @ 01/27/26 20:41:31.775
  I0127 20:41:31.775029 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename proxy @ 01/27/26 20:41:31.775
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:41:31.802
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:41:31.804
  I0127 20:41:31.809200 26 proxy.go:439] Creating pod...
  I0127 20:41:33.823919 26 proxy.go:463] Creating service...
  I0127 20:41:33.847021 26 proxy.go:500] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-6311/pods/agnhost/proxy?method=DELETE
  I0127 20:41:33.852619 26 proxy.go:582] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0127 20:41:33.852660 26 proxy.go:500] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-6311/pods/agnhost/proxy?method=OPTIONS
  I0127 20:41:33.855306 26 proxy.go:582] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0127 20:41:33.855339 26 proxy.go:500] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-6311/pods/agnhost/proxy?method=PATCH
  I0127 20:41:33.860936 26 proxy.go:582] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0127 20:41:33.860976 26 proxy.go:500] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-6311/pods/agnhost/proxy?method=POST
  I0127 20:41:33.863001 26 proxy.go:582] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0127 20:41:33.863027 26 proxy.go:500] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-6311/pods/agnhost/proxy?method=PUT
  I0127 20:41:33.865824 26 proxy.go:582] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0127 20:41:33.865849 26 proxy.go:511] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-6311/services/e2e-proxy-test-service/proxy?method=DELETE
  I0127 20:41:33.868415 26 proxy.go:582] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0127 20:41:33.868442 26 proxy.go:511] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-6311/services/e2e-proxy-test-service/proxy?method=OPTIONS
  I0127 20:41:33.870134 26 proxy.go:582] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0127 20:41:33.870162 26 proxy.go:511] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-6311/services/e2e-proxy-test-service/proxy?method=PATCH
  I0127 20:41:33.871772 26 proxy.go:582] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0127 20:41:33.871796 26 proxy.go:511] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-6311/services/e2e-proxy-test-service/proxy?method=POST
  I0127 20:41:33.873855 26 proxy.go:582] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0127 20:41:33.873893 26 proxy.go:511] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-6311/services/e2e-proxy-test-service/proxy?method=PUT
  I0127 20:41:33.876057 26 proxy.go:582] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0127 20:41:33.876083 26 proxy.go:531] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-6311/pods/agnhost/proxy?method=GET
  I0127 20:41:33.877372 26 proxy.go:539] http.Client request:GET StatusCode:301
  I0127 20:41:33.877402 26 proxy.go:531] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-6311/services/e2e-proxy-test-service/proxy?method=GET
  I0127 20:41:33.878927 26 proxy.go:539] http.Client request:GET StatusCode:301
  I0127 20:41:33.878955 26 proxy.go:531] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-6311/pods/agnhost/proxy?method=HEAD
  I0127 20:41:33.881029 26 proxy.go:539] http.Client request:HEAD StatusCode:301
  I0127 20:41:33.881057 26 proxy.go:531] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-6311/services/e2e-proxy-test-service/proxy?method=HEAD
  I0127 20:41:33.882353 26 proxy.go:539] http.Client request:HEAD StatusCode:301
  I0127 20:41:33.882466 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-6311" for this suite. @ 01/27/26 20:41:33.884
• [2.117 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:263
  STEP: Creating a kubernetes client @ 01/27/26 20:41:33.892
  I0127 20:41:33.892437 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename dns @ 01/27/26 20:41:33.892
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:41:33.916
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:41:33.921
  STEP: Creating a test headless service @ 01/27/26 20:41:33.922
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4615.svc.cluster.local)" && echo OK > /results/agnhost_hosts@dns-querier-2.dns-test-service-2.dns-4615.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/agnhost_hosts@dns-querier-2;sleep 1; done
   @ 01/27/26 20:41:33.931
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4615.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-4615.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 01/27/26 20:41:33.931
  STEP: creating a pod to probe DNS @ 01/27/26 20:41:33.931
  STEP: submitting the pod to kubernetes @ 01/27/26 20:41:33.931
  STEP: retrieving the pod @ 01/27/26 20:41:35.965
  STEP: looking for the results for each expected name from probers @ 01/27/26 20:41:35.967
  I0127 20:41:35.978497 26 dns_common.go:546] DNS probes using dns-4615/dns-test-96fc0d1e-a3df-4d77-b225-0fd51b83ce6f succeeded

  STEP: deleting the pod @ 01/27/26 20:41:35.978
  STEP: deleting the test headless service @ 01/27/26 20:41:36.015
  I0127 20:41:36.035212 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-4615" for this suite. @ 01/27/26 20:41:36.049
• [2.168 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 01/27/26 20:41:36.061
  I0127 20:41:36.061509 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename var-expansion @ 01/27/26 20:41:36.062
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:41:36.082
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:41:36.087
  STEP: Creating a pod to test env composition @ 01/27/26 20:41:36.089
  STEP: Saw pod success @ 01/27/26 20:41:40.108
  I0127 20:41:40.110927 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod var-expansion-572a5ee7-8831-4a0d-8618-eee85c24dd4e container dapi-container: <nil>
  STEP: delete the pod @ 01/27/26 20:41:40.114
  I0127 20:41:40.142250 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8859" for this suite. @ 01/27/26 20:41:40.144
• [4.106 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
k8s.io/kubernetes/test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 01/27/26 20:41:40.167
  I0127 20:41:40.167987 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename conformance-tests @ 01/27/26 20:41:40.168
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:41:40.184
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:41:40.189
  STEP: Getting node addresses @ 01/27/26 20:41:40.191
  I0127 20:41:40.191895 26 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  I0127 20:41:40.244778 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-4803" for this suite. @ 01/27/26 20:41:40.25
• [0.097 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 01/27/26 20:41:40.264
  I0127 20:41:40.264742 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename server-version @ 01/27/26 20:41:40.265
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:41:40.291
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:41:40.293
  STEP: Request ServerVersion @ 01/27/26 20:41:40.294
  STEP: Confirm major version @ 01/27/26 20:41:40.295
  I0127 20:41:40.295667 26 server_version.go:52] Major version: 1
  STEP: Confirm minor version @ 01/27/26 20:41:40.295
  I0127 20:41:40.295694 26 server_version.go:58] cleanMinorVersion: 35
  I0127 20:41:40.295704 26 server_version.go:62] Minor version: 35
  I0127 20:41:40.296244 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-2792" for this suite. @ 01/27/26 20:41:40.345
• [0.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:163
  STEP: Creating a kubernetes client @ 01/27/26 20:41:40.355
  I0127 20:41:40.355224 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename downward-api @ 01/27/26 20:41:40.355
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:41:40.39
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:41:40.392
  STEP: Creating the pod @ 01/27/26 20:41:40.395
  I0127 20:41:42.939908 26 pod_client.go:187] Successfully updated pod "annotationupdate66beb340-1e58-4627-ab5b-fd9d2f1490ae"
  I0127 20:41:44.951575 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4716" for this suite. @ 01/27/26 20:41:44.954
• [4.607 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 01/27/26 20:41:44.962
  I0127 20:41:44.962577 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename tables @ 01/27/26 20:41:44.963
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:41:44.979
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:41:44.984
  I0127 20:41:44.991436 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-6127" for this suite. @ 01/27/26 20:41:45.055
• [0.107 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:171
  STEP: Creating a kubernetes client @ 01/27/26 20:41:45.069
  I0127 20:41:45.069420 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename disruption @ 01/27/26 20:41:45.069
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:41:45.084
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:41:45.087
  STEP: Waiting for the pdb to be processed @ 01/27/26 20:41:45.096
  STEP: Updating PodDisruptionBudget status @ 01/27/26 20:41:47.1
  STEP: Waiting for all pods to be running @ 01/27/26 20:41:47.11
  I0127 20:41:47.112590 26 disruption.go:696] running pods: 0 < 1
  STEP: locating a running pod @ 01/27/26 20:41:49.114
  STEP: Waiting for the pdb to be processed @ 01/27/26 20:41:49.126
  STEP: Patching PodDisruptionBudget status @ 01/27/26 20:41:49.139
  STEP: Waiting for the pdb to be processed @ 01/27/26 20:41:49.149
  I0127 20:41:49.150806 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-4404" for this suite. @ 01/27/26 20:41:49.157
• [4.096 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:408
  STEP: Creating a kubernetes client @ 01/27/26 20:41:49.165
  I0127 20:41:49.165162 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename job @ 01/27/26 20:41:49.165
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:41:49.187
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:41:49.191
  STEP: Creating Indexed job @ 01/27/26 20:41:49.192
  STEP: Ensuring job reaches completions @ 01/27/26 20:41:49.208
  STEP: Ensuring pods with index for job exist @ 01/27/26 20:41:57.222
  I0127 20:41:57.224867 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-3028" for this suite. @ 01/27/26 20:41:57.226
• [8.069 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 01/27/26 20:41:57.234
  I0127 20:41:57.234403 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename prestop @ 01/27/26 20:41:57.234
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:41:57.251
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:41:57.253
  STEP: Creating server pod server in namespace prestop-603 @ 01/27/26 20:41:57.256
  STEP: Waiting for pods to come up. @ 01/27/26 20:41:57.279
  STEP: Creating tester pod tester in namespace prestop-603 @ 01/27/26 20:41:59.285
  STEP: Deleting pre-stop pod @ 01/27/26 20:42:01.303
  I0127 20:42:06.324463 26 pre_stop.go:140] Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 01/27/26 20:42:06.324
  I0127 20:42:06.356866 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-603" for this suite. @ 01/27/26 20:42:06.359
• [9.133 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:798
  STEP: Creating a kubernetes client @ 01/27/26 20:42:06.368
  I0127 20:42:06.368078 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename security-context-test @ 01/27/26 20:42:06.369
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:42:06.402
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:42:06.498
  I0127 20:42:10.542906 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-4109" for this suite. @ 01/27/26 20:42:10.546
• [4.187 seconds]
------------------------------
S
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:540
  STEP: Creating a kubernetes client @ 01/27/26 20:42:10.555
  I0127 20:42:10.555240 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pods @ 01/27/26 20:42:10.555
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:42:10.581
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:42:10.583
  I0127 20:42:10.585484 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: creating the pod @ 01/27/26 20:42:10.586
  STEP: submitting the pod to kubernetes @ 01/27/26 20:42:10.586
  I0127 20:42:12.665734 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2059" for this suite. @ 01/27/26 20:42:12.668
• [2.121 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:116
  STEP: Creating a kubernetes client @ 01/27/26 20:42:12.676
  I0127 20:42:12.676604 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename replication-controller @ 01/27/26 20:42:12.677
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:42:12.703
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:42:12.705
  STEP: creating a ReplicationController @ 01/27/26 20:42:12.711
  STEP: waiting for RC to be added @ 01/27/26 20:42:12.72
  STEP: waiting for available Replicas @ 01/27/26 20:42:12.72
  STEP: patching ReplicationController @ 01/27/26 20:42:13.746
  STEP: waiting for RC to be modified @ 01/27/26 20:42:13.758
  STEP: patching ReplicationController status @ 01/27/26 20:42:13.758
  STEP: waiting for RC to be modified @ 01/27/26 20:42:13.767
  STEP: waiting for available Replicas @ 01/27/26 20:42:13.767
  STEP: fetching ReplicationController status @ 01/27/26 20:42:13.781
  STEP: patching ReplicationController scale @ 01/27/26 20:42:13.783
  STEP: waiting for RC to be modified @ 01/27/26 20:42:13.793
  STEP: waiting for ReplicationController's scale to be the max amount @ 01/27/26 20:42:13.793
  STEP: fetching ReplicationController; ensuring that it's patched @ 01/27/26 20:42:15.367
  STEP: updating ReplicationController status @ 01/27/26 20:42:15.369
  STEP: waiting for RC to be modified @ 01/27/26 20:42:15.378
  STEP: listing all ReplicationControllers @ 01/27/26 20:42:15.378
  STEP: checking that ReplicationController has expected values @ 01/27/26 20:42:15.38
  STEP: deleting ReplicationControllers by collection @ 01/27/26 20:42:15.38
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 01/27/26 20:42:15.408
  I0127 20:42:15.451214 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0127 20:42:15.451411      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-262" for this suite. @ 01/27/26 20:42:15.453
• [2.790 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1286
  STEP: Creating a kubernetes client @ 01/27/26 20:42:15.466
  I0127 20:42:15.466788 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename services @ 01/27/26 20:42:15.467
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:42:15.482
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:42:15.488
  STEP: creating service nodeport-test with type=NodePort in namespace services-3120 @ 01/27/26 20:42:15.491
  I0127 20:42:15.546123 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0127 20:42:16.451778      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:17.453080      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:42:17.549695 26 resource.go:344] Creating new exec pod
  E0127 20:42:18.453504      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:19.453761      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:42:19.578434 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-3120 exec execpodf9q86 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  I0127 20:42:19.707690 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test (10.53.99.83) 80 port [tcp/http] succeeded!\n"
  I0127 20:42:19.707739 26 builder.go:157] stdout: "nodeport-test-74bd74d757-b4tgw"
  I0127 20:42:19.707820 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-3120 exec execpodf9q86 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.99.83 80'
  I0127 20:42:19.825964 26 builder.go:156] stderr: "+ nc -v -t -w 2 10.53.99.83 80\n+ echo hostName\nConnection to 10.53.99.83 80 port [tcp/http] succeeded!\n"
  I0127 20:42:19.826007 26 builder.go:157] stdout: "nodeport-test-74bd74d757-b4tgw"
  I0127 20:42:19.826075 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-3120 exec execpodf9q86 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.42.0.10 31246'
  I0127 20:42:19.930941 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.42.0.10 31246\nConnection to 10.42.0.10 31246 port [tcp/*] succeeded!\n"
  I0127 20:42:19.930987 26 builder.go:157] stdout: ""
  E0127 20:42:20.453766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:42:20.826162 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-3120 exec execpodf9q86 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.42.0.10 31246'
  I0127 20:42:20.937072 26 builder.go:156] stderr: "+ nc -v -t -w 2 10.42.0.10 31246\n+ echo hostName\nConnection to 10.42.0.10 31246 port [tcp/*] succeeded!\n"
  I0127 20:42:20.937113 26 builder.go:157] stdout: "nodeport-test-74bd74d757-b4tgw"
  I0127 20:42:20.937172 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-3120 exec execpodf9q86 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.42.0.12 31246'
  I0127 20:42:21.047047 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.42.0.12 31246\nConnection to 10.42.0.12 31246 port [tcp/*] succeeded!\n"
  I0127 20:42:21.047091 26 builder.go:157] stdout: "nodeport-test-74bd74d757-clz74"
  I0127 20:42:21.047207 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3120" for this suite. @ 01/27/26 20:42:21.057
• [5.601 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API should provide hostIPs as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:121
  STEP: Creating a kubernetes client @ 01/27/26 20:42:21.068
  I0127 20:42:21.068416 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename downward-api @ 01/27/26 20:42:21.068
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:42:21.084
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:42:21.094
  STEP: Creating a pod to test downward api env vars @ 01/27/26 20:42:21.096
  E0127 20:42:21.453818      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:22.454893      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:23.455025      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:24.455279      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 20:42:25.163
  I0127 20:42:25.165945 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downward-api-6e180a52-c04d-457a-8a7f-60bac15c4eda container dapi-container: <nil>
  STEP: delete the pod @ 01/27/26 20:42:25.171
  I0127 20:42:25.194501 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-328" for this suite. @ 01/27/26 20:42:25.196
• [4.138 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceSlice [Conformance] [sig-node, DRA, Conformance]
k8s.io/kubernetes/test/e2e/dra/dra.go:204
  STEP: Creating a kubernetes client @ 01/27/26 20:42:25.206
  I0127 20:42:25.206496 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename dra @ 01/27/26 20:42:25.207
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:42:25.225
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:42:25.229
  STEP: Get resource.k8s.io/v1 @ 01/27/26 20:42:25.233
  I0127 20:42:25.234403      26 shared_informer.go:370] "Waiting for caches to sync"
  I0127 20:42:25.335385      26 shared_informer.go:377] "Caches are synced"
  STEP: Creating:
      <*unstructured.Unstructured | 0xc0004b17e0>: 
          metadata:
            labels:
              e2e-test.kubernetes.io: dra-8615
            name: test-dra-8615
          spec:
            driver: dra.example.com
            nodeName: no-such-node
            pool:
              generation: 1
              name: cluster
              resourceSliceCount: 1 @ 01/27/26 20:42:25.335
  STEP: Getting test-dra-8615 @ 01/27/26 20:42:25.35
  STEP: Updating:
      <*unstructured.Unstructured | 0xc00070cbb8>: 
          apiVersion: resource.k8s.io/v1
          kind: ResourceSlice
          metadata:
            creationTimestamp: "2026-01-27T20:42:25Z"
            generation: 1
            labels:
              e2e-test.kubernetes.io: dra-8615
            managedFields:
            - apiVersion: resource.k8s.io/v1
              fieldsType: FieldsV1
              fieldsV1:
                f:metadata:
                  f:labels:
                    .: {}
                    f:e2e-test.kubernetes.io: {}
                f:spec:
                  f:driver: {}
                  f:nodeName: {}
                  f:pool:
                    f:generation: {}
                    f:name: {}
                    f:resourceSliceCount: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:42:25Z"
            name: test-dra-8615
            resourceVersion: "19523"
            uid: 7ee5f344-4384-46b7-8097-5ee110cb3c7e
          spec:
            devices:
            - name: device-0
            driver: dra.example.com
            nodeName: no-such-node
            pool:
              generation: 1
              name: cluster
              resourceSliceCount: 1 @ 01/27/26 20:42:25.352
  E0127 20:42:25.456349      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:26.457313      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting test-dra-8615 @ 01/27/26 20:42:27.373
  E0127 20:42:27.457684      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Checking for existence @ 01/27/26 20:42:27.551
  STEP: Creating again:
      <*unstructured.Unstructured | 0xc0004b17e0>: 
          metadata:
            labels:
              e2e-test.kubernetes.io: dra-8615
            name: test-dra-8615
          spec:
            driver: dra.example.com
            nodeName: no-such-node
            pool:
              generation: 1
              name: cluster
              resourceSliceCount: 1 @ 01/27/26 20:42:27.553
  STEP: Patching with application/strategic-merge-patch+json:
  {"apiVersion":"resource.k8s.io/v1","kind":"ResourceSlice","metadata":{"name":"test-dra-8615","uid":"fd7f74d9-0b93-4d96-a978-55cea82fef46"},"spec":{"devices":[{"name":"device-0"}]}}
   @ 01/27/26 20:42:27.565
  STEP: Listing resource.k8s.io/v1, Resource=resourceslices collection with label selector e2e-test.kubernetes.io=dra-8615 @ 01/27/26 20:42:27.581
  STEP: Deleting resource.k8s.io/v1, Resource=resourceslices collection with label selector e2e-test.kubernetes.io=dra-8615 @ 01/27/26 20:42:27.584
  STEP: Checking for existence @ 01/27/26 20:42:27.594
  I0127 20:42:27.620477 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dra-8615" for this suite. @ 01/27/26 20:42:27.622
• [2.431 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2250
  STEP: Creating a kubernetes client @ 01/27/26 20:42:27.637
  I0127 20:42:27.637249 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename services @ 01/27/26 20:42:27.637
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:42:27.645
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:42:27.65
  STEP: creating service in namespace services-2405 @ 01/27/26 20:42:27.652
  STEP: creating service affinity-clusterip-transition in namespace services-2405 @ 01/27/26 20:42:27.652
  I0127 20:42:27.715244 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0127 20:42:28.457979      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:29.458163      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:42:29.745479 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:3, TerminatingReplicas:(*int32)(0xc000371360), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 20, 42, 27, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 42, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 42, 27, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 42, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-clusterip-transition-6c76fcb6f7\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 20:42:30.458828      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:31.459422      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:42:31.718627 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc000371490), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 20, 42, 27, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 42, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 20, 42, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 20, 42, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-clusterip-transition-6c76fcb6f7\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 20:42:32.460479      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:33.460533      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:42:33.725894 26 resource.go:344] Creating new exec pod
  E0127 20:42:34.460798      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:35.461704      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:42:35.740172 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-2405 exec execpod-affinityg24n4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  I0127 20:42:35.856745 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition (10.53.225.50) 80 port [tcp/http] succeeded!\n"
  I0127 20:42:35.856790 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 20:42:35.856854 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-2405 exec execpod-affinityg24n4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.225.50 80'
  I0127 20:42:35.961854 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.53.225.50 80\nConnection to 10.53.225.50 80 port [tcp/http] succeeded!\n"
  I0127 20:42:35.961906 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 20:42:35.972489 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-2405 exec execpod-affinityg24n4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/ ; done'
  I0127 20:42:36.144777 26 builder.go:156] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n"
  I0127 20:42:36.144839 26 builder.go:157] stdout: "\naffinity-clusterip-transition-6c76fcb6f7-bnsb5\naffinity-clusterip-transition-6c76fcb6f7-bnsb5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-bnsb5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-vg8v9\naffinity-clusterip-transition-6c76fcb6f7-bnsb5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-vg8v9\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-bnsb5\naffinity-clusterip-transition-6c76fcb6f7-vg8v9"
  I0127 20:42:36.144852 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-bnsb5
  I0127 20:42:36.144866 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-bnsb5
  I0127 20:42:36.144874 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:42:36.144881 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-bnsb5
  I0127 20:42:36.144888 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:42:36.144895 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:42:36.144903 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-vg8v9
  I0127 20:42:36.144909 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-bnsb5
  I0127 20:42:36.144922 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:42:36.144932 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:42:36.144939 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-vg8v9
  I0127 20:42:36.144949 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:42:36.144970 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:42:36.144978 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:42:36.144985 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-bnsb5
  I0127 20:42:36.144997 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-vg8v9
  I0127 20:42:36.154976 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-2405 exec execpod-affinityg24n4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/ ; done'
  I0127 20:42:36.342488 26 builder.go:156] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n"
  I0127 20:42:36.342536 26 builder.go:157] stdout: "\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-bnsb5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-vg8v9\naffinity-clusterip-transition-6c76fcb6f7-vg8v9\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-bnsb5\naffinity-clusterip-transition-6c76fcb6f7-bnsb5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-bnsb5\naffinity-clusterip-transition-6c76fcb6f7-vg8v9\naffinity-clusterip-transition-6c76fcb6f7-vg8v9\naffinity-clusterip-transition-6c76fcb6f7-vg8v9"
  I0127 20:42:36.342551 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:42:36.342563 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:42:36.342574 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:42:36.342585 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-bnsb5
  I0127 20:42:36.342592 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:42:36.342599 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-vg8v9
  I0127 20:42:36.342612 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-vg8v9
  I0127 20:42:36.342627 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:42:36.342634 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-bnsb5
  I0127 20:42:36.342641 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-bnsb5
  I0127 20:42:36.342648 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:42:36.342661 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:42:36.342673 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-bnsb5
  I0127 20:42:36.342698 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-vg8v9
  I0127 20:42:36.342710 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-vg8v9
  I0127 20:42:36.342720 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-vg8v9
  E0127 20:42:36.462823      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:37.463967      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:38.464235      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:39.465003      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:40.465089      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:41.465360      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:42.465580      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:43.465785      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:44.466216      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:45.466370      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:46.466565      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:47.466800      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:48.466856      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:49.467642      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:50.467750      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:51.468000      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:52.468839      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:53.469037      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:54.469572      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:55.470428      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:56.470626      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:57.470788      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:58.470988      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:42:59.471199      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:00.471388      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:01.471642      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:02.471907      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:03.472872      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:04.473209      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:05.473380      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:43:06.343330 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-2405 exec execpod-affinityg24n4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/ ; done'
  E0127 20:43:06.473759      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:43:06.511777 26 builder.go:156] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.225.50:80/\n"
  I0127 20:43:06.511879 26 builder.go:157] stdout: "\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5\naffinity-clusterip-transition-6c76fcb6f7-99jl5"
  I0127 20:43:06.511899 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:43:06.511908 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:43:06.511917 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:43:06.511924 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:43:06.511933 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:43:06.511942 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:43:06.511948 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:43:06.511955 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:43:06.511962 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:43:06.511968 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:43:06.511975 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:43:06.511982 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:43:06.511990 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:43:06.511997 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:43:06.512005 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:43:06.512016 26 service.go:227] Received response from host: affinity-clusterip-transition-6c76fcb6f7-99jl5
  I0127 20:43:06.512094 26 service.go:4286] Cleaning up the exec pod
  I0127 20:43:06.581390 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2405" for this suite. @ 01/27/26 20:43:06.593
• [38.991 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 01/27/26 20:43:06.628
  I0127 20:43:06.628368 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 20:43:06.629
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:43:06.644
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:43:06.655
  STEP: Creating projection with secret that has name projected-secret-test-7762a69e-72fc-425d-a6ec-21125da5d88f @ 01/27/26 20:43:06.657
  STEP: Creating a pod to test consume secrets @ 01/27/26 20:43:06.664
  E0127 20:43:07.474433      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:08.474639      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:09.475368      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:10.476191      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 20:43:10.682
  I0127 20:43:10.684990 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-projected-secrets-36000fef-034e-43ec-ba9a-3e5de702d422 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 01/27/26 20:43:10.688
  I0127 20:43:10.717281 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2768" for this suite. @ 01/27/26 20:43:10.72
• [4.101 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:158
  STEP: Creating a kubernetes client @ 01/27/26 20:43:10.729
  I0127 20:43:10.729888 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename crd-publish-openapi @ 01/27/26 20:43:10.73
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:43:10.746
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:43:10.757
  I0127 20:43:10.759163 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  E0127 20:43:11.476346      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 01/27/26 20:43:12.169
  I0127 20:43:12.169830 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-4939 --namespace=crd-publish-openapi-4939 create -f -'
  I0127 20:43:12.243190 26 builder.go:156] stderr: ""
  I0127 20:43:12.243228 26 builder.go:157] stdout: "e2e-test-crd-publish-openapi-4939-594-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0127 20:43:12.243278 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-4939 --namespace=crd-publish-openapi-4939 delete e2e-test-crd-publish-openapi-4939-594-crds test-cr'
  I0127 20:43:12.316972 26 builder.go:156] stderr: ""
  I0127 20:43:12.317010 26 builder.go:157] stdout: "e2e-test-crd-publish-openapi-4939-594-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted from crd-publish-openapi-4939 namespace\n"
  I0127 20:43:12.317046 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-4939 --namespace=crd-publish-openapi-4939 apply -f -'
  I0127 20:43:12.385648 26 builder.go:156] stderr: ""
  I0127 20:43:12.385693 26 builder.go:157] stdout: "e2e-test-crd-publish-openapi-4939-594-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0127 20:43:12.385735 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-4939 --namespace=crd-publish-openapi-4939 delete e2e-test-crd-publish-openapi-4939-594-crds test-cr'
  I0127 20:43:12.448843 26 builder.go:156] stderr: ""
  I0127 20:43:12.448882 26 builder.go:157] stdout: "e2e-test-crd-publish-openapi-4939-594-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted from crd-publish-openapi-4939 namespace\n"
  STEP: kubectl explain works to explain CR without validation schema @ 01/27/26 20:43:12.448
  I0127 20:43:12.448944 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-4939 explain e2e-test-crd-publish-openapi-4939-594-crds'
  E0127 20:43:12.477526      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:43:12.505443 26 builder.go:156] stderr: ""
  I0127 20:43:12.505490 26 builder.go:157] stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-4939-594-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0127 20:43:13.477856      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:43:13.903617 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4939" for this suite. @ 01/27/26 20:43:13.907
• [3.191 seconds]
------------------------------
S
------------------------------
[sig-network] ServiceCIDR and IPAddress API should support ServiceCIDR API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_cidrs.go:166
  STEP: Creating a kubernetes client @ 01/27/26 20:43:13.921
  I0127 20:43:13.921452 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename servicecidr @ 01/27/26 20:43:13.922
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:43:13.943
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:43:13.945
  STEP: getting @ 01/27/26 20:43:13.947
  STEP: getting /status @ 01/27/26 20:43:13.949
  STEP: listing @ 01/27/26 20:43:13.951
  STEP: watching @ 01/27/26 20:43:13.954
  I0127 20:43:13.955491 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "servicecidr-9170" for this suite. @ 01/27/26 20:43:14.014
• [0.101 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:129
  STEP: Creating a kubernetes client @ 01/27/26 20:43:14.023
  I0127 20:43:14.023107 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename emptydir @ 01/27/26 20:43:14.023
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:43:14.044
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:43:14.049
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 01/27/26 20:43:14.051
  E0127 20:43:14.477993      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:15.478105      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:16.478400      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:17.478607      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 20:43:18.069
  I0127 20:43:18.071403 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-2da65ef8-f097-4057-ac6b-70d057d8d8aa container test-container: <nil>
  STEP: delete the pod @ 01/27/26 20:43:18.075
  I0127 20:43:18.103271 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2038" for this suite. @ 01/27/26 20:43:18.105
• [4.091 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:99
  STEP: Creating a kubernetes client @ 01/27/26 20:43:18.114
  I0127 20:43:18.114740 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename emptydir @ 01/27/26 20:43:18.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:43:18.144
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:43:18.149
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 01/27/26 20:43:18.151
  E0127 20:43:18.478823      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:19.479066      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:20.480029      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:21.480134      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 20:43:22.17
  I0127 20:43:22.172149 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-e21a39eb-5e87-4e56-bd74-93e2cc999c07 container test-container: <nil>
  STEP: delete the pod @ 01/27/26 20:43:22.177
  I0127 20:43:22.200688 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9416" for this suite. @ 01/27/26 20:43:22.203
• [4.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:179
  STEP: Creating a kubernetes client @ 01/27/26 20:43:22.212
  I0127 20:43:22.212612 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename daemonsets @ 01/27/26 20:43:22.213
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:43:22.239
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:43:22.24
  STEP: Creating simple DaemonSet "daemon-set" @ 01/27/26 20:43:22.308
  STEP: Check that daemon pods launch on every node of the cluster. @ 01/27/26 20:43:22.322
  I0127 20:43:22.416654 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 20:43:22.416690 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 20:43:22.480802      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:43:23.344521 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 20:43:23.344561 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 20:43:23.481853      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:43:24.327978 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0127 20:43:24.328015 26 fixtures.go:138] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 01/27/26 20:43:24.33
  I0127 20:43:24.429880 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0127 20:43:24.429916 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 20:43:24.481991      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:43:25.432869 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0127 20:43:25.432904 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 20:43:25.483445      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:43:26.353529 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0127 20:43:26.353568 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 20:43:26.483974      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:43:27.353766 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0127 20:43:27.353799 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 20:43:27.485530      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:43:28.353585 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0127 20:43:28.353618 26 fixtures.go:138] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 01/27/26 20:43:28.356
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4169, will wait for the garbage collector to delete the pods @ 01/27/26 20:43:28.356
  I0127 20:43:28.416751 26 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 8.374657ms
  E0127 20:43:28.485904      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:43:28.517056 26 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.303551ms
  E0127 20:43:29.486864      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:30.487898      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:43:30.619559 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 20:43:30.619611 26 fixtures.go:138] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0127 20:43:30.621153 26 daemon_set.go:137] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20079"},"items":null}

  I0127 20:43:30.623370 26 daemon_set.go:142] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20079"},"items":null}

  I0127 20:43:30.628272 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4169" for this suite. @ 01/27/26 20:43:30.63
• [8.426 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:198
  STEP: Creating a kubernetes client @ 01/27/26 20:43:30.638
  I0127 20:43:30.638235 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 20:43:30.638
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:43:30.664
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:43:30.666
  STEP: Setting up server cert @ 01/27/26 20:43:30.701
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 20:43:31.074
  STEP: Deploying the webhook pod @ 01/27/26 20:43:31.083
  STEP: Wait for the deployment to be ready @ 01/27/26 20:43:31.105
  I0127 20:43:31.119796 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0127 20:43:31.488275      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:32.488915      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/27/26 20:43:33.125
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 20:43:33.144
  I0127 20:43:33.144298 26 wait.go:65] Waiting for amount of service webhook-5944/e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 01/27/26 20:43:33.151
  STEP: create a pod that should be denied by the webhook @ 01/27/26 20:43:33.183
  STEP: create a pod that causes the webhook to hang @ 01/27/26 20:43:33.196
  E0127 20:43:33.489453      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:34.489666      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:35.490193      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:36.490245      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:37.490453      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:38.490473      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:39.490730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:40.490965      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:41.491196      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:42.491478      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: create a configmap that should be denied by the webhook @ 01/27/26 20:43:43.2
  STEP: create a configmap that should be admitted by the webhook @ 01/27/26 20:43:43.21
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 01/27/26 20:43:43.224
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 01/27/26 20:43:43.228
  STEP: create a namespace that bypass the webhook @ 01/27/26 20:43:43.231
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 01/27/26 20:43:43.252
  I0127 20:43:43.341146 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5944" for this suite. @ 01/27/26 20:43:43.353
  STEP: Destroying namespace "webhook-markers-8088" for this suite. @ 01/27/26 20:43:43.37
  STEP: Destroying namespace "exempted-namespace-2585" for this suite. @ 01/27/26 20:43:43.384
• [12.756 seconds]
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 01/27/26 20:43:43.394
  I0127 20:43:43.394707 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename init-container @ 01/27/26 20:43:43.395
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:43:43.416
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:43:43.427
  STEP: creating the pod @ 01/27/26 20:43:43.433
  I0127 20:43:43.434001 26 init_container.go:294] PodSpec: initContainers in spec.initContainers
  E0127 20:43:43.491703      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:44.492794      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:45.493800      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:46.493538      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:43:46.650402 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-2287" for this suite. @ 01/27/26 20:43:46.653
• [3.266 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:85
  STEP: Creating a kubernetes client @ 01/27/26 20:43:46.66
  I0127 20:43:46.660918 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 20:43:46.661
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:43:46.688
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:43:46.69
  STEP: Creating a pod to test downward API volume plugin @ 01/27/26 20:43:46.692
  E0127 20:43:47.494209      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:48.494413      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:49.495565      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:50.496641      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 20:43:50.714
  I0127 20:43:50.717395 26 output.go:207] Trying to get logs from node k3k-k3kcluster-server-0 pod downwardapi-volume-9f7fe16e-f903-4739-9a6f-7c985da2a5ec container client-container: <nil>
  STEP: delete the pod @ 01/27/26 20:43:50.727
  I0127 20:43:50.764894 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5330" for this suite. @ 01/27/26 20:43:50.767
• [4.116 seconds]
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:775
  STEP: Creating a kubernetes client @ 01/27/26 20:43:50.776
  I0127 20:43:50.776906 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename svcaccounts @ 01/27/26 20:43:50.777
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:43:50.801
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:43:50.806
  I0127 20:43:50.810548 26 service_accounts.go:787] Got root ca configmap in namespace "svcaccounts-9732"
  I0127 20:43:50.818362 26 service_accounts.go:790] Deleted root ca configmap in namespace "svcaccounts-9732"
  STEP: waiting for a new root ca configmap created @ 01/27/26 20:43:51.319
  I0127 20:43:51.322446 26 service_accounts.go:804] Recreated root ca configmap in namespace "svcaccounts-9732"
  I0127 20:43:51.336735 26 service_accounts.go:815] Updated root ca configmap in namespace "svcaccounts-9732"
  E0127 20:43:51.497181      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: waiting for the root ca configmap reconciled @ 01/27/26 20:43:51.837
  I0127 20:43:51.839441 26 service_accounts.go:833] Reconciled root ca configmap in namespace "svcaccounts-9732"
  I0127 20:43:51.839555 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-9732" for this suite. @ 01/27/26 20:43:51.841
• [1.073 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:237
  STEP: Creating a kubernetes client @ 01/27/26 20:43:51.85
  I0127 20:43:51.850107 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 20:43:51.85
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:43:51.866
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:43:51.872
  STEP: Setting up server cert @ 01/27/26 20:43:51.921
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 20:43:52.209
  STEP: Deploying the webhook pod @ 01/27/26 20:43:52.217
  STEP: Wait for the deployment to be ready @ 01/27/26 20:43:52.242
  I0127 20:43:52.246049 26 deployment.go:223] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0127 20:43:52.497251      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:53.497562      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/27/26 20:43:54.252
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 20:43:54.267
  I0127 20:43:54.267774 26 wait.go:65] Waiting for amount of service webhook-7959/e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 01/27/26 20:43:54.281
  STEP: create a namespace for the webhook @ 01/27/26 20:43:54.305
  STEP: create a configmap should be unconditionally rejected by the webhook @ 01/27/26 20:43:54.323
  I0127 20:43:54.410033 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7959" for this suite. @ 01/27/26 20:43:54.415
  STEP: Destroying namespace "webhook-markers-1790" for this suite. @ 01/27/26 20:43:54.429
  STEP: Destroying namespace "fail-closed-namespace-1750" for this suite. @ 01/27/26 20:43:54.442
• [2.601 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:73
  STEP: Creating a kubernetes client @ 01/27/26 20:43:54.451
  I0127 20:43:54.451748 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename replication-controller @ 01/27/26 20:43:54.452
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:43:54.481
  E0127 20:43:54.498223      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:43:54.571
  STEP: Creating replication controller my-hostname-basic-e9776361-1b15-4023-8cc8-3be6cb3dfb59 @ 01/27/26 20:43:54.573
  I0127 20:43:54.584397 26 resource.go:64] Pod name my-hostname-basic-e9776361-1b15-4023-8cc8-3be6cb3dfb59: Found 0 pods out of 1
  E0127 20:43:55.498357      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:56.498959      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:57.499093      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:58.499297      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:43:59.499502      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:43:59.594967 26 resource.go:64] Pod name my-hostname-basic-e9776361-1b15-4023-8cc8-3be6cb3dfb59: Found 1 pods out of 1
  I0127 20:43:59.595006 26 rc.go:513] Ensuring all pods for ReplicationController "my-hostname-basic-e9776361-1b15-4023-8cc8-3be6cb3dfb59" are running
  I0127 20:43:59.597142 26 rc.go:529] Pod "my-hostname-basic-e9776361-1b15-4023-8cc8-3be6cb3dfb59-dd4sg" is running and ready(conditions: [{Type:PodReadyToStartContainers ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2026-01-27 20:43:55 +0000 UTC Reason: Message:} {Type:Initialized ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2026-01-27 20:43:54 +0000 UTC Reason: Message:} {Type:Ready ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2026-01-27 20:43:55 +0000 UTC Reason: Message:} {Type:ContainersReady ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2026-01-27 20:43:55 +0000 UTC Reason: Message:} {Type:PodScheduled ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2026-01-27 20:43:54 +0000 UTC Reason: Message:}])
  I0127 20:43:59.597249 26 rc.go:537] Trying to dial the pod
  STEP: trying to dial each unique pod @ 01/27/26 20:43:59.597
  I0127 20:43:59.604917 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-9314" for this suite. @ 01/27/26 20:43:59.607
• [5.165 seconds]
------------------------------
S
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:65
  STEP: Creating a kubernetes client @ 01/27/26 20:43:59.616
  I0127 20:43:59.616582 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename limitrange @ 01/27/26 20:43:59.617
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:43:59.633
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:43:59.634
  STEP: Creating a LimitRange @ 01/27/26 20:43:59.637
  STEP: Setting up watch @ 01/27/26 20:43:59.637
  STEP: Submitting a LimitRange @ 01/27/26 20:43:59.74
  STEP: Verifying LimitRange creation was observed @ 01/27/26 20:43:59.748
  STEP: Fetching the LimitRange to ensure it has proper values @ 01/27/26 20:43:59.748
  I0127 20:43:59.749452 26 limit_range.go:360] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0127 20:43:59.749487 26 limit_range.go:365] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 01/27/26 20:43:59.749
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 01/27/26 20:43:59.756
  I0127 20:43:59.764302 26 limit_range.go:360] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0127 20:43:59.764341 26 limit_range.go:365] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 01/27/26 20:43:59.764
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 01/27/26 20:43:59.779
  I0127 20:43:59.781358 26 limit_range.go:360] Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  I0127 20:43:59.781392 26 limit_range.go:365] Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 01/27/26 20:43:59.781
  STEP: Failing to create a Pod with more than max resources @ 01/27/26 20:43:59.782
  STEP: Updating a LimitRange @ 01/27/26 20:43:59.784
  STEP: Verifying LimitRange updating is effective @ 01/27/26 20:43:59.798
  E0127 20:44:00.500368      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:01.501264      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 01/27/26 20:44:01.808
  STEP: Failing to create a Pod with more than max resources @ 01/27/26 20:44:01.822
  STEP: Deleting a LimitRange @ 01/27/26 20:44:01.824
  STEP: Verifying the LimitRange was deleted @ 01/27/26 20:44:01.838
  E0127 20:44:02.501616      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:03.502119      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:04.502336      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:05.503315      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:06.503564      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:06.841954 26 limit_range.go:214] limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 01/27/26 20:44:06.842
  I0127 20:44:06.852260 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-9056" for this suite. @ 01/27/26 20:44:06.854
• [7.262 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1659
  STEP: Creating a kubernetes client @ 01/27/26 20:44:06.878
  I0127 20:44:06.878654 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubectl @ 01/27/26 20:44:06.879
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:44:06.903
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:44:06.99
  STEP: creating the pod @ 01/27/26 20:44:06.992
  I0127 20:44:06.992416 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-1668 create -f -'
  I0127 20:44:07.111522 26 builder.go:156] stderr: ""
  I0127 20:44:07.111561 26 builder.go:157] stdout: "pod/pause created\n"
  E0127 20:44:07.505221      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:08.504438      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 01/27/26 20:44:09.128
  I0127 20:44:09.128517 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-1668 label pods pause testing-label=testing-label-value'
  I0127 20:44:09.196545 26 builder.go:156] stderr: ""
  I0127 20:44:09.196585 26 builder.go:157] stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 01/27/26 20:44:09.196
  I0127 20:44:09.196644 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-1668 get pod pause -L testing-label'
  I0127 20:44:09.259913 26 builder.go:156] stderr: ""
  I0127 20:44:09.259956 26 builder.go:157] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 01/27/26 20:44:09.259
  I0127 20:44:09.260017 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-1668 label pods pause testing-label-'
  I0127 20:44:09.326693 26 builder.go:156] stderr: ""
  I0127 20:44:09.326731 26 builder.go:157] stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 01/27/26 20:44:09.326
  I0127 20:44:09.326789 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-1668 get pod pause -L testing-label'
  I0127 20:44:09.388573 26 builder.go:156] stderr: ""
  I0127 20:44:09.388646 26 builder.go:157] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
  STEP: using delete to clean up resources @ 01/27/26 20:44:09.388
  I0127 20:44:09.388800 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-1668 delete --grace-period=0 --force -f -'
  I0127 20:44:09.467639 26 builder.go:156] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0127 20:44:09.467678 26 builder.go:157] stdout: "pod \"pause\" force deleted from kubectl-1668 namespace\n"
  I0127 20:44:09.467716 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-1668 get rc,svc -l name=pause --no-headers'
  E0127 20:44:09.504507      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:09.533268 26 builder.go:156] stderr: "No resources found in kubectl-1668 namespace.\n"
  I0127 20:44:09.533309 26 builder.go:157] stdout: ""
  I0127 20:44:09.533347 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-1668 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0127 20:44:09.595587 26 builder.go:156] stderr: ""
  I0127 20:44:09.595645 26 builder.go:157] stdout: ""
  I0127 20:44:09.595764 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1668" for this suite. @ 01/27/26 20:44:09.597
• [2.728 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:247
  STEP: Creating a kubernetes client @ 01/27/26 20:44:09.606
  I0127 20:44:09.606551 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename namespaces @ 01/27/26 20:44:09.607
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:44:09.632
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:44:09.634
  STEP: Creating a test namespace @ 01/27/26 20:44:09.636
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:44:09.659
  STEP: Creating a pod in the namespace @ 01/27/26 20:44:09.661
  STEP: Waiting for the pod to have running status @ 01/27/26 20:44:09.68
  E0127 20:44:10.504877      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:11.505072      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting the namespace @ 01/27/26 20:44:11.685
  STEP: Waiting for the namespace to be removed. @ 01/27/26 20:44:11.693
  E0127 20:44:12.505779      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:13.506793      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:14.506909      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:15.507774      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:16.509020      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:17.509392      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:18.509490      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:19.509700      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:20.509954      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:21.510166      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:22.510367      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 01/27/26 20:44:22.696
  STEP: Verifying there are no pods in the namespace @ 01/27/26 20:44:22.712
  I0127 20:44:22.732025 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1658" for this suite. @ 01/27/26 20:44:22.734
  STEP: Destroying namespace "nsdeletetest-1774" for this suite. @ 01/27/26 20:44:22.743
  I0127 20:44:22.745013 26 framework.go:370] Namespace nsdeletetest-1774 was already deleted
  STEP: Destroying namespace "nsdeletetest-1751" for this suite. @ 01/27/26 20:44:22.745
• [13.146 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3472
  STEP: Creating a kubernetes client @ 01/27/26 20:44:22.753
  I0127 20:44:22.753491 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename services @ 01/27/26 20:44:22.754
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:44:22.771
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:44:22.781
  STEP: creating a collection of services @ 01/27/26 20:44:22.783
  I0127 20:44:22.783504 26 service.go:3508] Creating e2e-svc-a-9zgp6
  I0127 20:44:22.799421 26 service.go:3508] Creating e2e-svc-b-6zsxq
  I0127 20:44:22.814480 26 service.go:3508] Creating e2e-svc-c-dhlzb
  STEP: deleting service collection @ 01/27/26 20:44:22.845
  I0127 20:44:22.880250 26 service.go:3543] Collection of services has been deleted
  I0127 20:44:22.880386 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2487" for this suite. @ 01/27/26 20:44:22.882
• [0.137 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:950
  STEP: Creating a kubernetes client @ 01/27/26 20:44:22.89
  I0127 20:44:22.890974 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename resourcequota @ 01/27/26 20:44:22.891
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:44:22.907
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:44:22.917
  STEP: Creating a ResourceQuota @ 01/27/26 20:44:22.92
  STEP: Getting a ResourceQuota @ 01/27/26 20:44:22.927
  STEP: Updating a ResourceQuota @ 01/27/26 20:44:22.929
  STEP: Verifying a ResourceQuota was modified @ 01/27/26 20:44:22.954
  STEP: Deleting a ResourceQuota @ 01/27/26 20:44:22.957
  STEP: Verifying the deleted ResourceQuota @ 01/27/26 20:44:22.98
  I0127 20:44:22.982003 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2362" for this suite. @ 01/27/26 20:44:22.984
• [0.101 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:98
  STEP: Creating a kubernetes client @ 01/27/26 20:44:22.991
  I0127 20:44:22.991958 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename replication-controller @ 01/27/26 20:44:22.992
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:44:23.018
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:44:23.02
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 01/27/26 20:44:23.023
  E0127 20:44:23.510482      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:24.510700      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 01/27/26 20:44:25.039
  STEP: Then the orphan pod is adopted @ 01/27/26 20:44:25.047
  E0127 20:44:25.512039      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:26.052189 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-4942" for this suite. @ 01/27/26 20:44:26.054
• [3.076 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:114
  STEP: Creating a kubernetes client @ 01/27/26 20:44:26.068
  I0127 20:44:26.068268 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename replicaset @ 01/27/26 20:44:26.068
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:44:26.091
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:44:26.093
  I0127 20:44:26.096010 26 replica_set.go:194] Creating ReplicaSet my-hostname-basic-e6156d8c-09db-4a7d-ba86-27c8954e6682
  I0127 20:44:26.111251 26 resource.go:64] Pod name my-hostname-basic-e6156d8c-09db-4a7d-ba86-27c8954e6682: Found 0 pods out of 1
  E0127 20:44:26.512860      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:27.512894      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:28.513177      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:29.513300      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:30.513812      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:31.113759 26 resource.go:64] Pod name my-hostname-basic-e6156d8c-09db-4a7d-ba86-27c8954e6682: Found 1 pods out of 1
  I0127 20:44:31.113792 26 replica_set.go:207] Ensuring a pod for ReplicaSet "my-hostname-basic-e6156d8c-09db-4a7d-ba86-27c8954e6682" is running
  I0127 20:44:31.115454 26 replica_set.go:223] Pod "my-hostname-basic-e6156d8c-09db-4a7d-ba86-27c8954e6682-wtzkq" is running (conditions: [{Type:PodReadyToStartContainers ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2026-01-27 20:44:28 +0000 UTC Reason: Message:} {Type:Initialized ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2026-01-27 20:44:26 +0000 UTC Reason: Message:} {Type:Ready ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2026-01-27 20:44:28 +0000 UTC Reason: Message:} {Type:ContainersReady ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2026-01-27 20:44:28 +0000 UTC Reason: Message:} {Type:PodScheduled ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2026-01-27 20:44:26 +0000 UTC Reason: Message:}])
  I0127 20:44:31.115488 26 replica_set.go:231] Trying to dial the pod
  STEP: trying to dial each unique pod @ 01/27/26 20:44:31.115
  I0127 20:44:31.123926 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-48" for this suite. @ 01/27/26 20:44:31.125
• [5.075 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 01/27/26 20:44:31.142
  I0127 20:44:31.142972 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename events @ 01/27/26 20:44:31.143
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:44:31.169
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:44:31.172
  STEP: Create set of events @ 01/27/26 20:44:31.174
  I0127 20:44:31.182083 26 core_events.go:198] created test-event-1
  I0127 20:44:31.190771 26 core_events.go:198] created test-event-2
  I0127 20:44:31.198473 26 core_events.go:198] created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 01/27/26 20:44:31.198
  STEP: delete collection of events @ 01/27/26 20:44:31.2
  I0127 20:44:31.200555 26 core_events.go:213] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 01/27/26 20:44:31.223
  I0127 20:44:31.223106 26 core_events.go:230] requesting list of events to confirm quantity
  I0127 20:44:31.225048 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-3237" for this suite. @ 01/27/26 20:44:31.228
• [0.106 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:256
  STEP: Creating a kubernetes client @ 01/27/26 20:44:31.249
  I0127 20:44:31.249525 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename limitrange @ 01/27/26 20:44:31.25
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:44:31.266
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:44:31.271
  STEP: Creating LimitRange "e2e-limitrange-52b7r" in namespace "limitrange-5794" @ 01/27/26 20:44:31.273
  STEP: Creating another limitRange in another namespace @ 01/27/26 20:44:31.287
  I0127 20:44:31.303010 26 limit_range.go:303] Namespace "e2e-limitrange-52b7r-6572" created
  I0127 20:44:31.303042 26 limit_range.go:304] Creating LimitRange "e2e-limitrange-52b7r" in namespace "e2e-limitrange-52b7r-6572"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-52b7r" @ 01/27/26 20:44:31.311
  I0127 20:44:31.313637 26 limit_range.go:313] Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-52b7r" in "limitrange-5794" namespace @ 01/27/26 20:44:31.313
  I0127 20:44:31.331153 26 limit_range.go:339] LimitRange "e2e-limitrange-52b7r" has been patched
  STEP: Delete LimitRange "e2e-limitrange-52b7r" by Collection with labelSelector: "e2e-limitrange-52b7r=patched" @ 01/27/26 20:44:31.331
  STEP: Confirm that the limitRange "e2e-limitrange-52b7r" has been deleted @ 01/27/26 20:44:31.36
  I0127 20:44:31.360161 26 limit_range.go:448] Requesting list of LimitRange to confirm quantity
  I0127 20:44:31.362072 26 limit_range.go:458] Found 0 LimitRange with label "e2e-limitrange-52b7r=patched"
  I0127 20:44:31.362103 26 limit_range.go:349] LimitRange "e2e-limitrange-52b7r" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-52b7r" @ 01/27/26 20:44:31.362
  I0127 20:44:31.363422 26 limit_range.go:355] Found 1 limitRange
  I0127 20:44:31.363523 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-5794" for this suite. @ 01/27/26 20:44:31.365
  STEP: Destroying namespace "e2e-limitrange-52b7r-6572" for this suite. @ 01/27/26 20:44:31.373
• [0.132 seconds]
------------------------------
[sig-node] Pods Extended (pod generation) Pod Generation issue 500 podspec updates and verify generation and observedGeneration eventually converge [MinimumKubeletVersion:1.34] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:583
  STEP: Creating a kubernetes client @ 01/27/26 20:44:31.381
  I0127 20:44:31.381371 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pods @ 01/27/26 20:44:31.381
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:44:31.396
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:44:31.407
  STEP: creating the pod @ 01/27/26 20:44:31.409
  STEP: submitting the pod to kubernetes @ 01/27/26 20:44:31.409
  E0127 20:44:31.513880      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:32.514095      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:44:33.514671      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:33.946516 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:34.457687 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:34.515730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:34.975390 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:35.493551 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:35.516281      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:36.005443 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:36.517269      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:36.529097 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:37.049116 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:37.517974      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:37.566820 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:38.080193 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:38.518356      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:38.600730 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:39.118948 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:39.519458      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:39.638031 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:40.156694 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:40.519761      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:40.675397 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:41.193686 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:41.520393      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:41.712797 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:42.231427 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:42.520713      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:42.749392 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:43.268160 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:43.522031      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:43.785252 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:44.304426 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:44.522921      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:44.821697 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:45.340465 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:45.523541      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:45.858664 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:46.375687 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:46.524067      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:46.894789 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:47.407954 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:47.524117      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:47.921224 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:48.439493 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:48.524996      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:48.958030 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:49.476209 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:49.525307      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:50.001029 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:50.522329 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:50.525535      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:51.040502 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:51.525706      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:51.557636 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:52.075228 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:52.525744      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:52.594790 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:53.112478 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:53.526017      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:53.630237 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:54.154721 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:54.526356      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:54.674077 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:55.192492 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:55.527146      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:55.711852 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:56.231411 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:56.527851      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:56.748710 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:57.267379 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:57.528763      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:57.780903 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:58.293117 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:58.529638      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:58.811587 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:44:59.330222 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:44:59.530590      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:44:59.843288 26 pod_client.go:191] Conflicting update to pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8", re-get and re-update: Operation cannot be fulfilled on pods "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8": the object has been modified; please apply your changes to the latest version and try again
  I0127 20:45:00.347976 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:00.531372      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:00.870742 26 pod_client.go:191] Conflicting update to pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8", re-get and re-update: Operation cannot be fulfilled on pods "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8": the object has been modified; please apply your changes to the latest version and try again
  I0127 20:45:01.363566 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:01.531987      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:01.881153 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:02.400570 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:02.532893      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:02.918771 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:03.437466 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:03.533706      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:03.955192 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:04.474422 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:04.534675      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:04.994542 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:05.514812 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:05.534941      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:06.032470 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:06.535342      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:06.544754 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:07.062834 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:07.536385      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:07.586805 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:08.104942 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:08.536424      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:08.623036 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:09.141120 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:09.536589      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:09.660203 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:10.180455 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:10.537487      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:10.698575 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:11.210559 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:11.538531      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:11.728106 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:12.257249 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:12.538598      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:12.770870 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:13.289337 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:13.539753      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:13.808003 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:14.325480 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:14.539803      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:14.842771 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:15.362072 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:15.540376      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:15.878592 26 pod_client.go:191] Conflicting update to pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8", re-get and re-update: Operation cannot be fulfilled on pods "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8": the object has been modified; please apply your changes to the latest version and try again
  I0127 20:45:16.380529 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:16.540840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:16.892681 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:17.410307 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:17.541691      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:17.929189 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:18.448264 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:18.542134      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:18.968994 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:19.487530 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:19.542806      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:20.006687 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:20.524298 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:20.543494      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:21.042185 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:21.544118      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:21.554131 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:22.072236 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:22.544855      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:22.589732 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:23.103243 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:23.545920      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:23.615333 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:24.134445 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:24.546316      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:24.653225 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:25.170546 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:25.546363      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:25.683646 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:26.202179 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:26.546642      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:26.724819 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:27.237010 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:27.547466      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:27.749667 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:28.270163 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:28.547497      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:28.783708 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:29.301686 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:29.548126      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:29.821248 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:30.339886 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:30.548690      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:30.858338 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:31.376249 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:31.549755      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:31.893958 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:32.412596 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:32.549799      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:32.925758 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:33.443678 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:33.549857      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:33.961632 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:34.480599 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:34.550806      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:34.992018 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:35.509367 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:35.551612      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:36.028717 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:36.546290 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:36.552798      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:37.060792 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:37.553319      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:37.578618 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:38.096671 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:38.554456      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:38.614711 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:39.132703 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:39.555338      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:39.650386 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:40.173104 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:40.555760      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:40.692410 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:41.209807 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:41.556238      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:41.726993 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:42.240226 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:42.556550      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:42.758004 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:43.275332 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:43.556676      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:43.787849 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:44.306998 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:44.557387      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:44.825601 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:45.343495 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:45.557845      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:45.856254 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:46.368836 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:46.558162      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:46.881689 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:47.393862 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:47.558618      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:47.911874 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:48.433403 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:48.559696      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:48.952697 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:49.471775 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:49.560093      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:49.990361 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:50.507729 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:50.560904      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:51.026359 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:51.546189 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:51.561357      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:52.058809 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:52.561572      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:52.576341 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:53.088790 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:53.562555      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:53.606703 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:54.124648 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:54.563412      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:54.639627 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:55.152119 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:55.563936      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:55.669273 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:56.188118 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:56.564837      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:56.703393 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:57.221681 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:57.565082      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:57.740634 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:58.260720 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:58.566105      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:58.772869 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:45:59.292448 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:45:59.566854      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:45:59.810489 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:00.336671 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:00.567393      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:00.857363 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:01.376098 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:01.568427      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:01.895482 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:02.413585 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:02.569309      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:02.935207 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:03.447208 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:03.569606      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:03.958663 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:04.483243 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:04.570487      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:05.001620 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:05.513520 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:05.570760      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:06.031788 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:06.551397 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:06.572106      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:07.063669 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:07.572549      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:07.582130 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:08.099717 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:08.572840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:08.611572 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:09.124043 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:09.573611      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:09.642384 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:10.160399 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:10.573957      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:10.678593 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:11.197054 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:11.574541      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:11.716715 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:12.234411 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:12.574875      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:12.752034 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:13.269525 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:13.576004      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:13.781944 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:14.295283 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:14.576356      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:14.812589 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:15.330359 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:15.576631      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:15.842790 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:16.368099 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:16.577451      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:16.886567 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:17.399486 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:17.578295      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:17.917272 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:18.430067 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:18.578770      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:18.947755 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:19.466095 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:19.579898      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:19.983375 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:20.502111 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:20.580270      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:21.021647 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:21.538678 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:21.580860      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:22.056724 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:22.574681 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:22.580898      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:23.093136 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:23.581868      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:23.611875 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:24.124194 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:24.582777      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:24.642086 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:25.162000 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:25.583901      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:25.679644 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:26.197997 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:26.584094      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:26.716032 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:27.234132 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:27.584629      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:27.746711 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:28.259399 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:28.584752      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:28.777392 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:29.288748 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:29.585274      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:29.806082 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:30.324217 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:30.585413      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:30.842538 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:31.359712 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:31.586098      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:31.878611 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:32.397433 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:32.587051      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:32.918386 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:33.436417 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:33.588058      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:33.954212 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:34.466942 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:34.588248      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:34.994450 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:35.513574 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:35.588907      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:36.033271 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:36.551581 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:36.589756      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:37.073733 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:37.590190      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:37.591880 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:38.103803 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:38.590353      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:38.621328 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:39.139756 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:39.591306      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:39.652204 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:40.169877 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:40.591463      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:40.682138 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:41.199013 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:41.591722      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:41.717946 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:42.236118 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:42.591892      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:42.755158 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:43.272975 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:43.592410      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:43.791167 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:44.303794 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:44.593061      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:44.820951 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:45.340011 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:45.593329      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:45.858068 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:46.371045 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:46.594413      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:46.889232 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:47.407459 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:47.594647      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:47.925639 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:48.443430 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:48.595757      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:48.960999 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:49.477818 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:49.596079      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:49.990414 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:50.511372 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:50.596939      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:51.029186 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:51.547006 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:51.597181      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:52.066811 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:52.584332 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:52.597715      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:53.101744 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:53.598262      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:53.619608 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:54.142214 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:54.598696      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:54.664067 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:55.182265 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:55.599083      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:55.712631 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:56.231171 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:56.599748      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:56.748899 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:57.268383 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:57.600789      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:57.785655 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:58.297877 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:58.601544      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:58.816820 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:46:59.336101 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:46:59.602516      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:46:59.855421 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:00.367761 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:00.603317      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:00.886296 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:01.398322 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:01.603621      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:01.916326 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:02.433898 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:02.604636      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:02.953071 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:03.471010 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:03.605360      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:03.988628 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:04.508498 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:04.606355      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:05.025963 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:05.546894 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:05.607143      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:06.065147 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:06.585528 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:06.607726      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:07.113059 26 pod_client.go:191] Conflicting update to pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8", re-get and re-update: Operation cannot be fulfilled on pods "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8": the object has been modified; please apply your changes to the latest version and try again
  I0127 20:47:07.605903 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:07.608003      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:08.116662 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:08.608336      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:08.639866 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:09.158039 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:09.608542      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:09.676161 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:10.193705 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:10.609250      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:10.716222 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:11.236847 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:11.609313      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:11.750163 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:12.267992 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:12.609965      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:12.784897 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:13.302597 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:13.611053      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:13.821419 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:14.340001 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:14.611630      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:14.859319 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:15.377707 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:15.612037      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:15.895695 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:16.414320 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:16.613048      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:16.933590 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:17.453413 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:17.613813      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:17.975232 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:18.492385 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:18.614618      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:19.011132 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:19.530012 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:19.615195      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:20.048311 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:20.560876 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:20.616517      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:21.080457 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:21.599113 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:21.617523      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:22.111287 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:22.618434      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:22.629787 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:23.148138 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:23.618637      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:23.666131 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:24.184736 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:24.618955      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:24.701016 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:25.224320 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:25.619882      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:25.749933 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:26.270517 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:26.620817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:26.797262 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:27.315378 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:27.621763      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:27.833331 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:28.352155 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:28.622595      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:28.869797 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:29.388415 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:29.622860      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:29.907145 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:30.426432 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:30.623896      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:30.953197 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:31.471473 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:31.625048      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:31.983965 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:32.502173 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:32.625769      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:33.015068 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:33.533194 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:33.626468      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:34.051415 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:34.569699 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:34.626926      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:35.086741 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:35.604876 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:35.626968      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:36.122203 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:36.628066      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:36.639848 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:37.158132 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:37.628576      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:37.676677 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:38.193099 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:38.628671      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:38.706061 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:39.218210 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:39.628855      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:39.746662 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:40.258689 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:40.628991      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:40.771344 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:41.283946 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:41.629357      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:41.796229 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:42.314351 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:42.630751      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:42.843933 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:43.374654 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:43.630908      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:43.893049 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:44.412100 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:44.631564      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:44.930431 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:45.448683 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:45.632185      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:45.967375 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:46.485875 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:46.633231      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:47.004528 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:47.522559 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:47.633904      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:48.041114 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:48.559768 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:48.635384      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:49.078323 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:49.595488 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:49.635896      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:50.113339 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:50.624959 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:50.636263      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:51.144971 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:51.636477      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:51.663354 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:52.176099 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:52.637347      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:52.695239 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:53.212758 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:53.638289      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:53.731693 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:54.251562 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:54.639037      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:54.769515 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:55.289003 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:55.639333      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:55.806222 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:56.324377 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:56.639936      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:56.841553 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:57.359351 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:57.641078      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:57.877274 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:58.390778 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:58.641587      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:58.909741 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:47:59.428314 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:47:59.641779      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:47:59.945924 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:00.472812 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:00.642180      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:00.997010 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:01.514092 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:01.642382      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:02.033114 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:02.545755 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:02.643002      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:03.058143 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:03.571745 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:03.644017      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:04.090686 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:04.608595 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:04.644662      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:05.132898 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:05.645092      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:05.649754 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:06.167711 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:06.645721      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:06.686910 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:07.205119 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:07.646827      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:07.722313 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:08.238926 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:08.647162      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:08.756762 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:09.275189 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:09.647632      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:09.792837 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:10.308610 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:10.648116      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:10.828241 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:11.347265 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:11.649099      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:11.865237 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:12.377203 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:12.650122      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:12.894595 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:13.413992 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:13.650233      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:13.925861 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:14.443476 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:14.650813      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:14.960939 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:15.479581 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:15.651901      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:15.997030 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:16.514200 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:16.652450      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:17.031991 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:17.549435 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:17.652513      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:18.067643 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:18.593664 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:18.653182      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:19.112096 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:19.629347 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:19.653513      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:20.147139 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:20.654118      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:20.665132 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:21.183104 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:21.654618      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:21.707532 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:22.226203 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:22.654905      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:22.738995 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:23.254525 26 pod_client.go:191] Conflicting update to pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8", re-get and re-update: Operation cannot be fulfilled on pods "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8": the object has been modified; please apply your changes to the latest version and try again
  E0127 20:48:23.655112      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:23.758565 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:24.271151 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:24.655258      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:24.783389 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:25.295089 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:25.655530      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:25.807326 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:26.326042 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:26.656457      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:26.845482 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:27.369760 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:27.657157      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:27.881165 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:28.400049 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:28.658271      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:28.918582 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:29.438197 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:29.658444      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:29.955724 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:30.473862 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:30.659313      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:30.991683 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:31.513122 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:31.659449      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:32.029977 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:32.548491 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:32.659723      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:33.066985 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:33.595445 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:33.660881      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:34.112976 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:34.631054 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:34.661215      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:35.148336 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:35.661816      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:35.666802 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:36.178841 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:36.662462      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:36.696550 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:37.214348 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:37.662856      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:37.736140 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:38.255435 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:38.663182      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:38.774303 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:39.281492 26 pod_client.go:191] Conflicting update to pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8", re-get and re-update: Operation cannot be fulfilled on pods "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8": the object has been modified; please apply your changes to the latest version and try again
  E0127 20:48:39.664040      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:39.793102 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:40.311085 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:40.664368      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:40.828954 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:41.340983 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:41.665368      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:41.853796 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:42.381124 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:42.666472      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:42.900323 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:43.418677 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:43.667097      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:43.936679 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:44.453415 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:44.667730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:44.970322 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:45.489031 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:45.668591      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:46.005939 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:46.518729 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:46.669084      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:47.031063 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:47.543091 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:47.669587      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:48.061263 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:48.578086 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:48.670610      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:49.098030 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:49.610266 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:49.671573      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:50.127519 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:50.644535 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:50.671659      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:51.159139 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:51.671732      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:51.683945 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:52.197043 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:52.672687      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:52.714524 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:53.232580 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:53.673298      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:53.749891 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  I0127 20:48:54.268131 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:54.673578      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:48:54.788364 26 pod_client.go:187] Successfully updated pod "pod-generation-0d12d12d-91a0-47a4-a273-49b2c09d20e8"
  E0127 20:48:55.674197      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:48:56.674814      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 01/27/26 20:48:56.796
  I0127 20:48:56.823364 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7627" for this suite. @ 01/27/26 20:48:56.826
• [265.459 seconds]
------------------------------
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:135
  STEP: Creating a kubernetes client @ 01/27/26 20:48:56.841
  I0127 20:48:56.841017 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubelet-test @ 01/27/26 20:48:56.841
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:48:56.869
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:48:56.87
  I0127 20:48:56.938635 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-426" for this suite. @ 01/27/26 20:48:56.941
• [0.113 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Endpoints should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpoints.go:58
  STEP: Creating a kubernetes client @ 01/27/26 20:48:56.957
  I0127 20:48:56.957601 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename endpoints @ 01/27/26 20:48:56.958
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:48:56.979
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:48:56.981
  I0127 20:48:57.025195      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: creating an Endpoint @ 01/27/26 20:48:57.025
  I0127 20:48:57.033558      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: waiting for available Endpoint @ 01/27/26 20:48:57.033
  I0127 20:48:57.034930      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: listing all Endpoints @ 01/27/26 20:48:57.035
  I0127 20:48:57.036963      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: updating the Endpoint @ 01/27/26 20:48:57.037
  I0127 20:48:57.044689      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0127 20:48:57.045648      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: fetching the Endpoint @ 01/27/26 20:48:57.045
  I0127 20:48:57.047002      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: patching the Endpoint @ 01/27/26 20:48:57.047
  I0127 20:48:57.062708      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0127 20:48:57.063697      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: fetching the Endpoint @ 01/27/26 20:48:57.063
  I0127 20:48:57.065247      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: deleting the Endpoint by Collection @ 01/27/26 20:48:57.065
  I0127 20:48:57.073589      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: waiting for Endpoint deletion @ 01/27/26 20:48:57.073
  I0127 20:48:57.074478      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: fetching the Endpoint @ 01/27/26 20:48:57.074
  I0127 20:48:57.075812      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0127 20:48:57.075949 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpoints-3291" for this suite. @ 01/27/26 20:48:57.077
• [0.138 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 01/27/26 20:48:57.095
  I0127 20:48:57.095906 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename container-probe @ 01/27/26 20:48:57.096
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:48:57.122
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:48:57.125
  STEP: Creating pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113 @ 01/27/26 20:48:57.126
  E0127 20:48:57.675639      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:48:58.675734      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 01/27/26 20:48:59.141
  I0127 20:48:59.144106 26 container_probe.go:1746] Initial restart count of pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 is 0
  I0127 20:48:59.145557 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:48:59.676876      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:00.677083      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:01.149267 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:01.677372      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:02.677576      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:03.152389 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:03.677730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:04.677950      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:05.155561 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:05.678712      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:06.679063      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:07.159808 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:07.679334      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:08.679532      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:09.162288 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:09.679746      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:10.680747      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:11.165951 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:11.681742      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:12.682282      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:13.169351 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:13.682985      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:14.683448      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:15.171868 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:15.684024      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:16.684381      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:17.175915 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:17.685136      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:18.685380      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:19.179667 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:19.686196      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:20.686704      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:21.182011 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:21.687654      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:22.687870      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:23.184469 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:23.687983      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:24.688803      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:25.187966 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:25.689045      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:26.689162      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:27.191355 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:27.689477      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:28.689658      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:29.194690 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:29.690543      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:30.691577      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:31.197640 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:31.692334      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:32.692835      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:33.200528 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:33.693115      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:34.693586      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:35.203311 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:35.693901      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:36.694080      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:37.206356 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:37.694902      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:38.695057      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:39.209540 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:39.695084      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:40.695223      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:41.211878 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:41.695567      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:42.695850      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:43.215004 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:43.696625      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:44.696744      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:45.217781 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:45.697280      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:46.698286      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:47.223355 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:47.699315      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:48.699444      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:49.231550 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:49.700127      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:50.700263      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:51.235213 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:51.700704      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:52.700908      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:53.237641 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:53.701063      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:54.701167      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:55.239852 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:55.701294      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:56.701424      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:57.242896 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:57.702189      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:49:58.702325      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:49:59.246525 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:49:59.703787      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:00.704025      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:01.249932 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:01.704380      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:02.704596      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:03.252742 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:03.705700      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:04.705896      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:05.255849 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:05.706295      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:06.707153      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:07.259709 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:07.708185      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:08.708311      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:09.262773 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:09.709339      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:10.709487      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:11.265973 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:11.710515      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:12.710951      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:13.269057 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:13.711573      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:14.711743      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:15.271906 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:15.712418      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:16.712952      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:17.276028 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:17.713441      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:18.714376      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:19.279019 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:19.715034      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:20.715253      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:21.282640 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:21.715725      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:22.715732      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:23.285712 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:23.715891      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:24.716193      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:25.288795 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:25.716663      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:26.717248      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:27.291670 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:27.717402      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:28.717594      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:29.295710 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:29.718236      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:30.718426      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:31.298013 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:31.718927      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:32.719146      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:33.300916 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:33.719416      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:34.720192      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:35.303683 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:35.720835      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:36.721040      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:37.316812 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:37.721232      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:38.721457      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:39.319432 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:39.721616      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:40.721672      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:41.322506 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:41.721943      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:42.722740      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:43.327059 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:43.723551      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:44.723904      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:45.329838 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:45.724003      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:46.724848      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:47.332757 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:47.725171      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:48.725384      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:49.335773 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:49.726260      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:50.726403      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:51.338887 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:51.727392      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:52.727618      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:53.341396 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:53.727784      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:54.727979      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:55.344690 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:55.728843      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:56.729067      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:57.349266 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:57.729792      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:50:58.729984      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:50:59.352202 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:50:59.730835      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:00.731135      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:01.355334 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:01.731729      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:02.731738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:03.359455 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:03.731922      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:04.732987      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:05.362014 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:05.733607      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:06.734018      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:07.365507 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:07.734955      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:08.735201      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:09.371898 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:09.735312      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:10.735557      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:11.374036 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:11.735744      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:12.736801      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:13.376920 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:13.737386      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:14.738434      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:15.380213 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:15.737718      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:16.737908      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:17.383888 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:17.739123      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:18.739243      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:19.387295 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:19.739497      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:20.739686      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:21.390939 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:21.740446      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:22.741031      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:23.394105 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:23.741496      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:24.742664      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:25.397214 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:25.743728      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:26.744837      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:27.400242 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:27.745716      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:28.746016      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:29.403736 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:29.746056      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:30.746344      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:31.407313 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:31.746667      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:32.746988      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:33.410310 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:33.747730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:34.748804      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:35.413206 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:35.750102      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:36.750305      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:37.416493 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:37.750926      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:38.751121      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:39.419558 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:39.752126      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:40.752453      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:41.422530 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:41.752975      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:42.753036      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:43.424920 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:43.753285      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:44.753869      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:45.428475 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:45.754275      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:46.754473      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:47.431877 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:47.755754      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:48.756013      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:49.435901 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:49.756245      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:50.756732      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:51.439137 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:51.757583      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:52.757695      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:53.441729 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:53.758311      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:54.758552      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:55.444492 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:55.758708      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:56.758982      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:57.447297 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:57.759719      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:51:58.760050      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:51:59.449983 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:51:59.760692      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:00.760920      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:01.453124 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:01.761561      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:02.761773      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:03.455418 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:03.762857      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:04.762903      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:05.458020 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:05.763412      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:06.764044      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:07.460746 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:07.764410      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:08.764791      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:09.463569 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:09.764965      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:10.765181      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:11.466299 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:11.765682      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:12.765901      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:13.469264 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:13.765969      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:14.766799      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:15.472136 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:15.767630      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:16.767756      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:17.474876 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:17.768264      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:18.768899      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:19.478569 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:19.769944      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:20.770068      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:21.480988 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:21.770295      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:22.771058      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:23.483894 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:23.771180      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:24.771380      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:25.486398 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:25.771725      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:26.771733      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:27.490579 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:27.772809      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:28.773006      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:29.493360 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:29.773718      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:30.773889      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:31.495894 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:31.774135      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:32.775137      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:33.498881 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:33.775178      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:34.775297      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:35.501443 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:35.775696      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:36.775918      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:37.504756 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:37.777001      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:38.777319      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:39.509043 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:39.778340      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:40.778451      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:41.511393 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:41.778662      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:42.778881      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:43.513877 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:43.779241      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:44.779377      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:45.516386 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:45.779541      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:46.779867      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:47.519872 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:47.780123      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:48.780848      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:49.522959 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:49.781499      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:50.781661      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:51.525849 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:51.782243      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:52.782714      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:53.530288 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:53.783981      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:54.784812      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:55.533829 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:55.785866      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:56.786257      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:52:57.536487 26 container_probe.go:1756] Get pod liveness-63056773-73c1-4f48-8f34-deebdfb1ec11 in namespace container-probe-3113
  E0127 20:52:57.786856      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:52:58.787468      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 01/27/26 20:52:59.537
  I0127 20:52:59.568095 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-3113" for this suite. @ 01/27/26 20:52:59.586
• [242.499 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:76
  STEP: Creating a kubernetes client @ 01/27/26 20:52:59.594
  I0127 20:52:59.594744 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename containers @ 01/27/26 20:52:59.595
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:52:59.622
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:52:59.625
  STEP: Creating a pod to test override command @ 01/27/26 20:52:59.627
  E0127 20:52:59.787951      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:00.788270      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:01.788333      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:02.788804      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 20:53:03.646
  I0127 20:53:03.648034 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod client-containers-d08cbc36-1939-411a-8356-e3c56043b7ad container agnhost-container: <nil>
  STEP: delete the pod @ 01/27/26 20:53:03.663
  I0127 20:53:03.692939 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-2103" for this suite. @ 01/27/26 20:53:03.696
• [4.117 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:679
  STEP: Creating a kubernetes client @ 01/27/26 20:53:03.712
  I0127 20:53:03.712268 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename svcaccounts @ 01/27/26 20:53:03.712
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:53:03.728
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:53:03.732
  STEP: creating a ServiceAccount @ 01/27/26 20:53:03.734
  STEP: watching for the ServiceAccount to be added @ 01/27/26 20:53:03.744
  STEP: patching the ServiceAccount @ 01/27/26 20:53:03.746
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 01/27/26 20:53:03.755
  STEP: deleting the ServiceAccount @ 01/27/26 20:53:03.757
  I0127 20:53:03.781192 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0127 20:53:03.789706      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Destroying namespace "svcaccounts-2310" for this suite. @ 01/27/26 20:53:03.796
• [0.100 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:856
  STEP: Creating a kubernetes client @ 01/27/26 20:53:03.812
  I0127 20:53:03.812383 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename daemonsets @ 01/27/26 20:53:03.812
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:53:03.865
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:53:03.868
  STEP: Creating simple DaemonSet "daemon-set" @ 01/27/26 20:53:03.899
  STEP: Check that daemon pods launch on every node of the cluster. @ 01/27/26 20:53:03.908
  I0127 20:53:03.998208 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 20:53:03.998247 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 20:53:04.791777      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:53:04.923487 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 20:53:04.923535 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 20:53:05.792876      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:53:05.916690 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0127 20:53:05.916729 26 fixtures.go:138] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: listing all DaemonSets @ 01/27/26 20:53:05.918
  STEP: DeleteCollection of the DaemonSets @ 01/27/26 20:53:05.92
  STEP: Verify that ReplicaSets have been deleted @ 01/27/26 20:53:05.929
  I0127 20:53:05.934456 26 daemon_set.go:137] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23148"},"items":null}

  I0127 20:53:05.956555 26 daemon_set.go:142] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23151"},"items":[{"metadata":{"name":"daemon-set-kqq59","generateName":"daemon-set-","namespace":"daemonsets-617","uid":"cac85f94-6384-4532-bd9a-d063a38de1d6","resourceVersion":"23150","generation":2,"creationTimestamp":"2026-01-27T20:53:03Z","deletionTimestamp":"2026-01-27T20:53:35Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"cdc9497f8","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"1bab0817-a176-4079-8128-7cb8c97ec70f","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"k3s","operation":"Update","apiVersion":"v1","time":"2026-01-27T20:53:03Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1bab0817-a176-4079-8128-7cb8c97ec70f\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"k3s","operation":"Update","apiVersion":"v1","time":"2026-01-27T20:53:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodScheduled\"}":{"f:observedGeneration":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:observedGeneration":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.52.1.198\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-xd2sq","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/agnhost:2.59","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-xd2sq","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"observedGeneration":1,"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2026-01-27T20:53:05Z"},{"type":"Initialized","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2026-01-27T20:53:03Z"},{"type":"Ready","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2026-01-27T20:53:05Z"},{"type":"ContainersReady","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2026-01-27T20:53:05Z"},{"type":"PodScheduled","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2026-01-27T20:53:03Z"}],"hostIP":"10.42.0.10","hostIPs":[{"ip":"10.42.0.10"}],"podIP":"10.52.1.198","podIPs":[{"ip":"10.52.1.198"}],"startTime":"2026-01-27T20:53:03Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2026-01-27T20:53:04Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/agnhost:2.59","imageID":"registry.k8s.io/e2e-test-images/agnhost@sha256:10ed98804c877e505e17bced991682b6fd50ab1da9cddcd19935b48d645da40a","containerID":"containerd://25b45ceda455a8e228311418f52706d65a90d5e16d4209faa6cc4c1a60a0847e","started":true,"resources":{},"volumeMounts":[{"name":"kube-api-access-xd2sq","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}],"user":{"linux":{"uid":0,"gid":0,"supplementalGroups":[0,1,2,3,4,6,10,11,20,26,27]}}}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-q5m5f","generateName":"daemon-set-","namespace":"daemonsets-617","uid":"a7567d7d-0505-48d7-a11d-e7d8957576b5","resourceVersion":"23151","generation":2,"creationTimestamp":"2026-01-27T20:53:03Z","deletionTimestamp":"2026-01-27T20:53:35Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"cdc9497f8","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"1bab0817-a176-4079-8128-7cb8c97ec70f","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"k3s","operation":"Update","apiVersion":"v1","time":"2026-01-27T20:53:03Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1bab0817-a176-4079-8128-7cb8c97ec70f\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"k3s","operation":"Update","apiVersion":"v1","time":"2026-01-27T20:53:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodScheduled\"}":{"f:observedGeneration":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:observedGeneration":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.52.0.110\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-xb4t6","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/agnhost:2.59","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-xb4t6","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"k3k-k3kcluster-server-0","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["k3k-k3kcluster-server-0"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"observedGeneration":1,"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2026-01-27T20:53:05Z"},{"type":"Initialized","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2026-01-27T20:53:03Z"},{"type":"Ready","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2026-01-27T20:53:05Z"},{"type":"ContainersReady","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2026-01-27T20:53:05Z"},{"type":"PodScheduled","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2026-01-27T20:53:03Z"}],"hostIP":"10.42.0.12","hostIPs":[{"ip":"10.42.0.12"}],"podIP":"10.52.0.110","podIPs":[{"ip":"10.52.0.110"}],"startTime":"2026-01-27T20:53:03Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2026-01-27T20:53:04Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/agnhost:2.59","imageID":"registry.k8s.io/e2e-test-images/agnhost@sha256:10ed98804c877e505e17bced991682b6fd50ab1da9cddcd19935b48d645da40a","containerID":"containerd://1fae606df187396b6d145e8c353188df13ddfb4dc77441a985921cd5dbef50a0","started":true,"resources":{},"volumeMounts":[{"name":"kube-api-access-xb4t6","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}],"user":{"linux":{"uid":0,"gid":0,"supplementalGroups":[0,1,2,3,4,6,10,11,20,26,27]}}}],"qosClass":"BestEffort"}}]}

  I0127 20:53:06.028192 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-617" for this suite. @ 01/27/26 20:53:06.029
• [2.225 seconds]
------------------------------
S
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:338
  STEP: Creating a kubernetes client @ 01/27/26 20:53:06.037
  I0127 20:53:06.037512 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename proxy @ 01/27/26 20:53:06.038
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:53:06.064
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:53:06.067
  I0127 20:53:06.070114 26 proxy.go:345] Creating pod...
  E0127 20:53:06.792938      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:07.793717      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:53:08.086789 26 proxy.go:369] Creating service...
  I0127 20:53:08.108952 26 proxy.go:406] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-3784/pods/agnhost/proxy/some/path/with/DELETE
  I0127 20:53:08.119750 26 proxy.go:582] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0127 20:53:08.119792 26 proxy.go:406] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-3784/pods/agnhost/proxy/some/path/with/GET
  I0127 20:53:08.122957 26 proxy.go:582] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0127 20:53:08.122995 26 proxy.go:406] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-3784/pods/agnhost/proxy/some/path/with/HEAD
  I0127 20:53:08.124824 26 proxy.go:569] http.Client request:HEAD | StatusCode:200
  I0127 20:53:08.124852 26 proxy.go:406] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-3784/pods/agnhost/proxy/some/path/with/OPTIONS
  I0127 20:53:08.126331 26 proxy.go:582] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0127 20:53:08.126360 26 proxy.go:406] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-3784/pods/agnhost/proxy/some/path/with/PATCH
  I0127 20:53:08.127977 26 proxy.go:582] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0127 20:53:08.128006 26 proxy.go:406] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-3784/pods/agnhost/proxy/some/path/with/POST
  I0127 20:53:08.129792 26 proxy.go:582] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0127 20:53:08.129817 26 proxy.go:406] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-3784/pods/agnhost/proxy/some/path/with/PUT
  I0127 20:53:08.131070 26 proxy.go:582] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0127 20:53:08.131097 26 proxy.go:417] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-3784/services/test-service/proxy/some/path/with/DELETE
  I0127 20:53:08.133052 26 proxy.go:582] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0127 20:53:08.133075 26 proxy.go:417] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-3784/services/test-service/proxy/some/path/with/GET
  I0127 20:53:08.134996 26 proxy.go:582] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0127 20:53:08.135021 26 proxy.go:417] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-3784/services/test-service/proxy/some/path/with/HEAD
  I0127 20:53:08.136721 26 proxy.go:569] http.Client request:HEAD | StatusCode:200
  I0127 20:53:08.136743 26 proxy.go:417] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-3784/services/test-service/proxy/some/path/with/OPTIONS
  I0127 20:53:08.139495 26 proxy.go:582] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0127 20:53:08.139523 26 proxy.go:417] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-3784/services/test-service/proxy/some/path/with/PATCH
  I0127 20:53:08.141880 26 proxy.go:582] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0127 20:53:08.141909 26 proxy.go:417] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-3784/services/test-service/proxy/some/path/with/POST
  I0127 20:53:08.144157 26 proxy.go:582] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0127 20:53:08.144189 26 proxy.go:417] Starting http.Client for https://10.53.0.1:443/api/v1/namespaces/proxy-3784/services/test-service/proxy/some/path/with/PUT
  I0127 20:53:08.146886 26 proxy.go:582] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0127 20:53:08.146996 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-3784" for this suite. @ 01/27/26 20:53:08.149
• [2.120 seconds]
------------------------------
S
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csistoragecapacity.go:52
  STEP: Creating a kubernetes client @ 01/27/26 20:53:08.157
  I0127 20:53:08.157497 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename csistoragecapacity @ 01/27/26 20:53:08.158
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:53:08.188
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:53:08.192
  STEP: getting /apis @ 01/27/26 20:53:08.194
  STEP: getting /apis/storage.k8s.io @ 01/27/26 20:53:08.197
  STEP: getting /apis/storage.k8s.io/v1 @ 01/27/26 20:53:08.198
  STEP: creating @ 01/27/26 20:53:08.199
  STEP: watching @ 01/27/26 20:53:08.223
  I0127 20:53:08.223871 26 csistoragecapacity.go:145] starting watch
  STEP: getting @ 01/27/26 20:53:08.239
  STEP: listing in namespace @ 01/27/26 20:53:08.241
  STEP: listing across namespaces @ 01/27/26 20:53:08.242
  STEP: patching @ 01/27/26 20:53:08.244
  STEP: updating @ 01/27/26 20:53:08.252
  I0127 20:53:08.260292 26 csistoragecapacity.go:185] waiting for watch events with expected annotations in namespace
  I0127 20:53:08.260360 26 csistoragecapacity.go:185] waiting for watch events with expected annotations across namespace
  STEP: deleting @ 01/27/26 20:53:08.26
  STEP: deleting a collection @ 01/27/26 20:53:08.271
  I0127 20:53:08.294082 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-3248" for this suite. @ 01/27/26 20:53:08.296
• [0.146 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:166
  STEP: Creating a kubernetes client @ 01/27/26 20:53:08.303
  I0127 20:53:08.303874 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename field-validation @ 01/27/26 20:53:08.304
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:53:08.325
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:53:08.329
  I0127 20:53:08.331719 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  E0127 20:53:08.794780      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:09.795042      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:10.795544      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:53:10.874271      26 warnings.go:107] "Warning: unknown field \"alpha\""
  I0127 20:53:10.874300      26 warnings.go:107] "Warning: unknown field \"beta\""
  I0127 20:53:10.874307      26 warnings.go:107] "Warning: unknown field \"delta\""
  I0127 20:53:10.874314      26 warnings.go:107] "Warning: unknown field \"epsilon\""
  I0127 20:53:10.874322      26 warnings.go:107] "Warning: unknown field \"gamma\""
  I0127 20:53:11.417433 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6573" for this suite. @ 01/27/26 20:53:11.419
• [3.124 seconds]
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:307
  STEP: Creating a kubernetes client @ 01/27/26 20:53:11.427
  I0127 20:53:11.427914 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename daemonsets @ 01/27/26 20:53:11.428
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:53:11.449
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:53:11.455
  STEP: Creating a simple DaemonSet "daemon-set" @ 01/27/26 20:53:11.524
  STEP: Check that daemon pods launch on every node of the cluster. @ 01/27/26 20:53:11.532
  I0127 20:53:11.623180 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 20:53:11.623215 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 20:53:11.796496      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:53:12.682736 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 20:53:12.682773 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 20:53:12.796853      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:13.797923      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:53:13.815362 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 20:53:13.815399 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  I0127 20:53:14.537885 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0127 20:53:14.537920 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 20:53:14.798191      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:53:15.539410 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0127 20:53:15.539440 26 fixtures.go:138] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 01/27/26 20:53:15.541
  I0127 20:53:15.644738 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0127 20:53:15.644774 26 fixtures.go:133] Node k3k-k3kcluster-server-0 is running 0 daemon pod, expected 1
  E0127 20:53:15.799285      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:53:16.564476 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0127 20:53:16.564511 26 fixtures.go:133] Node k3k-k3kcluster-server-0 is running 0 daemon pod, expected 1
  E0127 20:53:16.799930      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:53:17.565862 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0127 20:53:17.565902 26 fixtures.go:138] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 01/27/26 20:53:17.565
  STEP: Deleting DaemonSet "daemon-set" @ 01/27/26 20:53:17.569
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8410, will wait for the garbage collector to delete the pods @ 01/27/26 20:53:17.569
  I0127 20:53:17.630561 26 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 8.219971ms
  I0127 20:53:17.731381 26 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.822256ms
  E0127 20:53:17.800766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:18.801755      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:53:19.234108 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 20:53:19.234145 26 fixtures.go:138] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0127 20:53:19.240692 26 daemon_set.go:137] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23357"},"items":null}

  I0127 20:53:19.242123 26 daemon_set.go:142] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23357"},"items":null}

  I0127 20:53:19.245954 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8410" for this suite. @ 01/27/26 20:53:19.247
• [7.829 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:124
  STEP: Creating a kubernetes client @ 01/27/26 20:53:19.256
  I0127 20:53:19.256893 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 20:53:19.257
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:53:19.289
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:53:19.292
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-60fee672-a841-489a-9900-793007cb3efd @ 01/27/26 20:53:19.344
  STEP: Creating the pod @ 01/27/26 20:53:19.353
  E0127 20:53:19.802115      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:20.802374      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-60fee672-a841-489a-9900-793007cb3efd @ 01/27/26 20:53:21.379
  STEP: waiting to observe update in volume @ 01/27/26 20:53:21.387
  E0127 20:53:21.803041      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:22.803163      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:23.803353      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:24.803586      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:25.804643      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:26.804890      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:27.805868      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:28.806125      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:29.807148      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:30.807500      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:31.808088      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:32.808832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:33.809231      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:34.809435      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:35.809943      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:36.810102      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:37.811477      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:38.811771      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:39.812706      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:40.813239      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:41.814534      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:42.814805      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:43.815674      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:44.815858      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:45.816840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:46.817052      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:47.817263      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:48.818224      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:49.819242      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:50.819862      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:51.820855      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:52.821179      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:53.821840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:54.822089      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:55.822948      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:56.823149      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:57.823969      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:58.824852      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:53:59.825355      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:00.825524      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:01.826545      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:02.827094      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:03.827872      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:04.828893      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:05.829671      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:06.830154      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:07.830817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:08.831464      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:09.831687      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:10.831749      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:11.832461      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:12.832837      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:13.833513      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:14.834274      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:15.834916      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:16.835152      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:17.836174      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:18.836935      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:19.837851      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:20.838115      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:21.838329      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:22.839017      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:23.840014      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:24.840246      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:25.840516      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:26.840744      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:27.841818      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:28.842043      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:29.842921      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:30.843245      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:31.844128      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:32.844705      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:33.845121      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:34.845356      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:35.846265      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:36.846469      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:37.847233      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:38.847684      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:39.848300      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:40.848433      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:41.849003      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:42.849223      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:54:43.658827 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9631" for this suite. @ 01/27/26 20:54:43.661
• [84.412 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 01/27/26 20:54:43.669
  I0127 20:54:43.669706 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename container-probe @ 01/27/26 20:54:43.67
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:54:43.696
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:54:43.699
  STEP: Creating pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695 @ 01/27/26 20:54:43.703
  E0127 20:54:43.850349      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:44.850584      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 01/27/26 20:54:45.725
  I0127 20:54:45.727989 26 container_probe.go:1746] Initial restart count of pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 is 0
  I0127 20:54:45.730097 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:54:45.851410      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:46.851793      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:54:47.733118 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:54:47.852325      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:48.852908      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:54:49.737774 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:54:49.853660      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:50.853856      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:54:51.740118 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:54:51.854329      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:52.854794      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:54:53.743014 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:54:53.855316      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:54.855522      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:54:55.746714 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:54:55.855960      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:56.856850      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:54:57.750181 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:54:57.857373      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:54:58.857577      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:54:59.762272 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:54:59.858529      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:00.858569      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:01.764703 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:01.858914      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:02.859562      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:03.771154 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:03.860725      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:04.860935      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:05.773615 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  I0127 20:55:05.773657 26 container_probe.go:1760] Restart count of pod container-probe-4695/liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 is now 1 (20.045635268s elapsed)
  E0127 20:55:05.861846      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:06.862314      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:07.776485 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:07.862421      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:08.862700      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:09.779788 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:09.863017      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:10.863471      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:11.786295 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:11.864534      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:12.864791      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:13.788483 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:13.865694      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:14.866030      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:15.797192 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:15.866452      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:16.866581      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:17.802348 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:17.867203      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:18.867415      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:19.805969 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:19.868193      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:20.868334      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:21.814677 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:21.868859      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:22.868991      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:23.817483 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:23.869627      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:24.869837      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:25.820755 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  I0127 20:55:25.820797 26 container_probe.go:1760] Restart count of pod container-probe-4695/liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 is now 2 (40.092774255s elapsed)
  E0127 20:55:25.870041      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:26.870694      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:27.823885 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:27.871010      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:28.871237      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:29.829130 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:29.871445      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:30.871562      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:31.831771 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:31.871854      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:32.872838      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:33.835149 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:33.873315      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:34.873517      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:35.838577 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:35.873588      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:36.874046      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:37.841227 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:37.874355      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:38.874566      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:39.845040 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:39.875203      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:40.876161      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:41.848607 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:41.876518      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:42.876839      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:43.851643 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:43.877109      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:44.877330      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:45.855086 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  I0127 20:55:45.855134 26 container_probe.go:1760] Restart count of pod container-probe-4695/liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 is now 3 (1m0.127112009s elapsed)
  E0127 20:55:45.878313      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:46.878542      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:47.871662 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:47.878784      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:48.878984      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:49.875191 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:49.879343      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:50.879433      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:51.877781 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:51.879886      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:52.881081      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:53.880309 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:53.881467      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:54.881699      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:55.881966      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:55.882788 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:56.882817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:57.883061      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:57.885165 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:55:58.883524      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:55:59.883805      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:55:59.888294 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:00.884060      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:01.884987      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:01.891936 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:02.886250      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:03.886473      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:03.895147 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:04.887032      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:05.887291      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:05.897718 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  I0127 20:56:05.897761 26 container_probe.go:1760] Restart count of pod container-probe-4695/liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 is now 4 (1m20.169738414s elapsed)
  E0127 20:56:06.887763      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:07.887887      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:07.900061 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:08.888830      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:09.888830      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:09.904100 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:10.889724      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:11.889861      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:11.907536 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:12.890543      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:13.890658      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:13.910213 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:14.891122      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:15.891374      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:15.912716 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:16.891682      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:17.891932      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:17.915762 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:18.892705      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:19.892960      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:19.918784 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:20.893038      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:21.893254      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:21.921860 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:22.894314      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:23.894782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:23.926078 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:24.895256      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:25.895505      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:25.929233 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:26.895725      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:27.895968      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:27.933139 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:28.896821      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:29.897438      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:29.936152 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:30.898094      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:31.898288      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:31.938689 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:32.899079      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:33.899285      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:33.942293 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:34.899768      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:35.899880      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:35.945450 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:36.899918      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:37.900166      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:37.948524 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:38.901472      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:39.901489      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:39.951326 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:40.902571      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:41.902812      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:41.954030 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:42.903161      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:43.903436      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:43.956616 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:44.903732      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:45.904864      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:45.959189 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:46.905119      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:47.905756      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:47.962906 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:48.905856      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:49.906066      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:49.966493 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:50.906427      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:51.906633      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:51.969230 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:52.907247      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:53.907444      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:53.972093 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:54.908062      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:55.908512      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:55.974620 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:56.908650      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:57.908879      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:57.977606 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:56:58.909579      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:56:59.909804      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:56:59.980903 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:57:00.910389      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:01.910594      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:57:01.984289 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:57:02.911420      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:03.912068      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:57:03.987891 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:57:04.912801      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:05.913075      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:57:05.991147 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:57:06.913099      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:07.913313      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:57:07.993793 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:57:08.913792      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:09.914005      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:57:09.996671 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:57:10.914720      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:11.914974      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:57:11.999109 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:57:12.915041      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:13.915268      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:57:14.001505 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:57:14.915899      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:15.915771      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:57:16.004024 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:57:16.915807      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:17.916827      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:57:18.007518 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:57:18.917428      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:19.917651      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:57:20.010381 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:57:20.917854      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:21.918089      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:57:22.013963 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  E0127 20:57:22.918829      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:23.919063      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:57:24.016262 26 container_probe.go:1756] Get pod liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 in namespace container-probe-4695
  I0127 20:57:24.016301 26 container_probe.go:1760] Restart count of pod container-probe-4695/liveness-3c94b4cb-383a-42d9-9d10-04734eae1e80 is now 5 (2m38.288279122s elapsed)
  STEP: deleting the pod @ 01/27/26 20:57:24.016
  I0127 20:57:24.060270 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4695" for this suite. @ 01/27/26 20:57:24.065
• [160.403 seconds]
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:249
  STEP: Creating a kubernetes client @ 01/27/26 20:57:24.072
  I0127 20:57:24.072962 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename container-runtime @ 01/27/26 20:57:24.073
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:57:24.102
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:57:24.105
  STEP: create the container @ 01/27/26 20:57:24.107
  I0127 20:57:24.118829      26 warnings.go:107] "Warning: metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]"
  STEP: wait for the container to reach Succeeded @ 01/27/26 20:57:24.118
  E0127 20:57:24.919358      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:25.919559      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:26.919874      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: get the container status @ 01/27/26 20:57:27.129
  STEP: the container should be terminated @ 01/27/26 20:57:27.131
  STEP: the termination message should be set @ 01/27/26 20:57:27.131
  I0127 20:57:27.131728 26 runtime.go:168] Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 01/27/26 20:57:27.131
  I0127 20:57:27.159177 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-9078" for this suite. @ 01/27/26 20:57:27.161
• [3.096 seconds]
------------------------------
SS
------------------------------
[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaim [Conformance] [sig-node, DRA, Conformance]
k8s.io/kubernetes/test/e2e/dra/dra.go:115
  STEP: Creating a kubernetes client @ 01/27/26 20:57:27.169
  I0127 20:57:27.169090 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename dra @ 01/27/26 20:57:27.169
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:57:27.202
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:57:27.204
  STEP: Get resource.k8s.io/v1 @ 01/27/26 20:57:27.206
  I0127 20:57:27.208224      26 shared_informer.go:370] "Waiting for caches to sync"
  I0127 20:57:27.309808      26 shared_informer.go:377] "Caches are synced"
  STEP: Creating:
      <*unstructured.Unstructured | 0xc00061c908>: 
          metadata:
            labels:
              e2e-test.kubernetes.io: dra-4961
            name: test
            namespace: dra-4961
          spec:
            devices:
              requests:
              - exactly:
                  deviceClassName: dra.example.com
                name: req-0
          status: {} @ 01/27/26 20:57:27.31
  E0127 20:57:27.920027      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:28.920876      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Getting dra-4961/test @ 01/27/26 20:57:29.319
  STEP: Updating:
      <*unstructured.Unstructured | 0xc00070c198>: 
          apiVersion: resource.k8s.io/v1
          kind: ResourceClaim
          metadata:
            creationTimestamp: "2026-01-27T20:57:27Z"
            labels:
              e2e-test.kubernetes.io: dra-4961
              test.dra.example.com: test
            managedFields:
            - apiVersion: resource.k8s.io/v1
              fieldsType: FieldsV1
              fieldsV1:
                f:metadata:
                  f:labels:
                    .: {}
                    f:e2e-test.kubernetes.io: {}
                f:spec:
                  f:devices:
                    f:requests: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:57:27Z"
            name: test
            namespace: dra-4961
            resourceVersion: "24194"
            uid: c4f881c6-81f2-4662-8119-7147836f1c38
          spec:
            devices:
              requests:
              - exactly:
                  allocationMode: ExactCount
                  count: 1
                  deviceClassName: dra.example.com
                name: req-0
          status: {} @ 01/27/26 20:57:29.322
  E0127 20:57:29.921895      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:30.922128      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Updating status:
      <*unstructured.Unstructured | 0xc0008be200>: 
          apiVersion: resource.k8s.io/v1
          kind: ResourceClaim
          metadata:
            creationTimestamp: "2026-01-27T20:57:27Z"
            labels:
              e2e-test.kubernetes.io: dra-4961
              test.dra.example.com: test
            managedFields:
            - apiVersion: resource.k8s.io/v1
              fieldsType: FieldsV1
              fieldsV1:
                f:metadata:
                  f:labels:
                    .: {}
                    f:e2e-test.kubernetes.io: {}
                    f:test.dra.example.com: {}
                f:spec:
                  f:devices:
                    f:requests: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:57:29Z"
            name: test
            namespace: dra-4961
            resourceVersion: "24211"
            uid: c4f881c6-81f2-4662-8119-7147836f1c38
          spec:
            devices:
              requests:
              - exactly:
                  allocationMode: ExactCount
                  count: 1
                  deviceClassName: dra.example.com
                name: req-0
          status:
            allocation:
              devices: {} @ 01/27/26 20:57:31.332
  STEP: Getting dra-4961/test status @ 01/27/26 20:57:31.341
  STEP: Deleting dra-4961/test @ 01/27/26 20:57:31.343
  STEP: Checking for existence @ 01/27/26 20:57:31.351
  STEP: Creating again:
      <*unstructured.Unstructured | 0xc00061c908>: 
          metadata:
            labels:
              e2e-test.kubernetes.io: dra-4961
            name: test
            namespace: dra-4961
          spec:
            devices:
              requests:
              - exactly:
                  deviceClassName: dra.example.com
                name: req-0
          status: {} @ 01/27/26 20:57:31.353
  STEP: Patching with application/strategic-merge-patch+json:
  {"apiVersion":"resource.k8s.io/v1","kind":"ResourceClaim","metadata":{"labels":{"test.dra.example.com":"test"},"name":"test","namespace":"dra-4961","uid":"4f4da18f-5cd9-438c-82f5-44f1dfd65ab4"}}
   @ 01/27/26 20:57:31.361
  STEP: Deleting dra-4961/test @ 01/27/26 20:57:31.373
  STEP: Checking for existence @ 01/27/26 20:57:31.39
  STEP: Creating again:
      <*unstructured.Unstructured | 0xc00061c908>: 
          metadata:
            labels:
              e2e-test.kubernetes.io: dra-4961
            name: test
            namespace: dra-4961
          spec:
            devices:
              requests:
              - exactly:
                  deviceClassName: dra.example.com
                name: req-0
          status: {} @ 01/27/26 20:57:31.392
  STEP: Patching with application/apply-patch+yaml:
  {"apiVersion":"resource.k8s.io/v1","kind":"ResourceClaim","metadata":{"labels":{"test.dra.example.com":"test"},"name":"test","namespace":"dra-4961","uid":"f809dc63-6ac4-43fe-a9cf-48dc0fde559c"}}
   @ 01/27/26 20:57:31.405
  STEP: Deleting dra-4961/test @ 01/27/26 20:57:31.413
  STEP: Checking for existence @ 01/27/26 20:57:31.424
  STEP: Creating again:
      <*unstructured.Unstructured | 0xc00061c908>: 
          metadata:
            labels:
              e2e-test.kubernetes.io: dra-4961
            name: test
            namespace: dra-4961
          spec:
            devices:
              requests:
              - exactly:
                  deviceClassName: dra.example.com
                name: req-0
          status: {} @ 01/27/26 20:57:31.43
  STEP: Patching with application/merge-patch+json:
  {"apiVersion":"resource.k8s.io/v1","kind":"ResourceClaim","metadata":{"labels":{"test.dra.example.com":"test"},"name":"test","namespace":"dra-4961","uid":"5d178aa4-b533-4acc-96fa-92b243a4a5b3"}}
   @ 01/27/26 20:57:31.438
  STEP: Deleting dra-4961/test @ 01/27/26 20:57:31.446
  STEP: Checking for existence @ 01/27/26 20:57:31.454
  STEP: Creating again:
      <*unstructured.Unstructured | 0xc00061c908>: 
          metadata:
            labels:
              e2e-test.kubernetes.io: dra-4961
            name: test
            namespace: dra-4961
          spec:
            devices:
              requests:
              - exactly:
                  deviceClassName: dra.example.com
                name: req-0
          status: {} @ 01/27/26 20:57:31.456
  STEP: Patching with application/json-patch+json:
  [{"op": "add", "path": "/metadata/labels/test.dra.example.com", "value": "test"}] @ 01/27/26 20:57:31.47
  STEP: Deleting dra-4961/test @ 01/27/26 20:57:31.478
  STEP: Checking for existence @ 01/27/26 20:57:31.486
  STEP: Creating again:
      <*unstructured.Unstructured | 0xc00061c908>: 
          metadata:
            labels:
              e2e-test.kubernetes.io: dra-4961
            name: test
            namespace: dra-4961
          spec:
            devices:
              requests:
              - exactly:
                  deviceClassName: dra.example.com
                name: req-0
          status: {} @ 01/27/26 20:57:31.49
  STEP: Updating:
      <*unstructured.Unstructured | 0xc0006e4460>: 
          apiVersion: resource.k8s.io/v1
          kind: ResourceClaim
          metadata:
            creationTimestamp: "2026-01-27T20:57:31Z"
            labels:
              e2e-test.kubernetes.io: dra-4961
              test.dra.example.com: test
            managedFields:
            - apiVersion: resource.k8s.io/v1
              fieldsType: FieldsV1
              fieldsV1:
                f:metadata:
                  f:labels:
                    .: {}
                    f:e2e-test.kubernetes.io: {}
                f:spec:
                  f:devices:
                    f:requests: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:57:31Z"
            name: test
            namespace: dra-4961
            resourceVersion: "24235"
            uid: 94f8b9cd-cccf-4e73-bd57-799d7a3159bd
          spec:
            devices:
              requests:
              - exactly:
                  allocationMode: ExactCount
                  count: 1
                  deviceClassName: dra.example.com
                name: req-0
          status: {} @ 01/27/26 20:57:31.5
  STEP: Patching status with application/strategic-merge-patch+json:
  {"apiVersion":"resource.k8s.io/v1","kind":"ResourceClaim","metadata":{"name":"test","namespace":"dra-4961","uid":"94f8b9cd-cccf-4e73-bd57-799d7a3159bd"},"status":{"allocation":{}}}
   @ 01/27/26 20:57:31.508
  STEP: Deleting dra-4961/test @ 01/27/26 20:57:31.516
  STEP: Checking for existence @ 01/27/26 20:57:31.524
  STEP: Creating again:
      <*unstructured.Unstructured | 0xc00061c908>: 
          metadata:
            labels:
              e2e-test.kubernetes.io: dra-4961
            name: test
            namespace: dra-4961
          spec:
            devices:
              requests:
              - exactly:
                  deviceClassName: dra.example.com
                name: req-0
          status: {} @ 01/27/26 20:57:31.526
  STEP: Updating:
      <*unstructured.Unstructured | 0xc00070c448>: 
          apiVersion: resource.k8s.io/v1
          kind: ResourceClaim
          metadata:
            creationTimestamp: "2026-01-27T20:57:31Z"
            labels:
              e2e-test.kubernetes.io: dra-4961
              test.dra.example.com: test
            managedFields:
            - apiVersion: resource.k8s.io/v1
              fieldsType: FieldsV1
              fieldsV1:
                f:metadata:
                  f:labels:
                    .: {}
                    f:e2e-test.kubernetes.io: {}
                f:spec:
                  f:devices:
                    f:requests: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:57:31Z"
            name: test
            namespace: dra-4961
            resourceVersion: "24239"
            uid: 9cbed49f-0a17-4da6-801b-e39aeca49ac1
          spec:
            devices:
              requests:
              - exactly:
                  allocationMode: ExactCount
                  count: 1
                  deviceClassName: dra.example.com
                name: req-0
          status: {} @ 01/27/26 20:57:31.535
  STEP: Patching status with application/apply-patch+yaml:
  {"apiVersion":"resource.k8s.io/v1","kind":"ResourceClaim","metadata":{"name":"test","namespace":"dra-4961","uid":"9cbed49f-0a17-4da6-801b-e39aeca49ac1"},"status":{"allocation":{}}}
   @ 01/27/26 20:57:31.549
  STEP: Deleting dra-4961/test @ 01/27/26 20:57:31.558
  STEP: Checking for existence @ 01/27/26 20:57:31.567
  STEP: Creating again:
      <*unstructured.Unstructured | 0xc00061c908>: 
          metadata:
            labels:
              e2e-test.kubernetes.io: dra-4961
            name: test
            namespace: dra-4961
          spec:
            devices:
              requests:
              - exactly:
                  deviceClassName: dra.example.com
                name: req-0
          status: {} @ 01/27/26 20:57:31.569
  STEP: Updating:
      <*unstructured.Unstructured | 0xc00008f028>: 
          apiVersion: resource.k8s.io/v1
          kind: ResourceClaim
          metadata:
            creationTimestamp: "2026-01-27T20:57:31Z"
            labels:
              e2e-test.kubernetes.io: dra-4961
              test.dra.example.com: test
            managedFields:
            - apiVersion: resource.k8s.io/v1
              fieldsType: FieldsV1
              fieldsV1:
                f:metadata:
                  f:labels:
                    .: {}
                    f:e2e-test.kubernetes.io: {}
                f:spec:
                  f:devices:
                    f:requests: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:57:31Z"
            name: test
            namespace: dra-4961
            resourceVersion: "24243"
            uid: 5d7957f4-d009-4867-8f25-f34bfa5e655c
          spec:
            devices:
              requests:
              - exactly:
                  allocationMode: ExactCount
                  count: 1
                  deviceClassName: dra.example.com
                name: req-0
          status: {} @ 01/27/26 20:57:31.579
  STEP: Patching status with application/merge-patch+json:
  {"apiVersion":"resource.k8s.io/v1","kind":"ResourceClaim","metadata":{"name":"test","namespace":"dra-4961","uid":"5d7957f4-d009-4867-8f25-f34bfa5e655c"},"status":{"allocation":{}}}
   @ 01/27/26 20:57:31.588
  STEP: Deleting dra-4961/test @ 01/27/26 20:57:31.597
  STEP: Checking for existence @ 01/27/26 20:57:31.61
  STEP: Creating again:
      <*unstructured.Unstructured | 0xc00061c908>: 
          metadata:
            labels:
              e2e-test.kubernetes.io: dra-4961
            name: test
            namespace: dra-4961
          spec:
            devices:
              requests:
              - exactly:
                  deviceClassName: dra.example.com
                name: req-0
          status: {} @ 01/27/26 20:57:31.612
  STEP: Updating:
      <*unstructured.Unstructured | 0xc00008f0d8>: 
          apiVersion: resource.k8s.io/v1
          kind: ResourceClaim
          metadata:
            creationTimestamp: "2026-01-27T20:57:31Z"
            labels:
              e2e-test.kubernetes.io: dra-4961
              test.dra.example.com: test
            managedFields:
            - apiVersion: resource.k8s.io/v1
              fieldsType: FieldsV1
              fieldsV1:
                f:metadata:
                  f:labels:
                    .: {}
                    f:e2e-test.kubernetes.io: {}
                f:spec:
                  f:devices:
                    f:requests: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T20:57:31Z"
            name: test
            namespace: dra-4961
            resourceVersion: "24247"
            uid: 191157bb-cde0-4dbc-a6fe-b7db49e43c76
          spec:
            devices:
              requests:
              - exactly:
                  allocationMode: ExactCount
                  count: 1
                  deviceClassName: dra.example.com
                name: req-0
          status: {} @ 01/27/26 20:57:31.626
  STEP: Patching status with application/json-patch+json:
  [{"op": "add", "path": "/status/allocation", "value": {}}] @ 01/27/26 20:57:31.634
  STEP: Listing resource.k8s.io/v1, Resource=resourceclaims collection with label selector e2e-test.kubernetes.io=dra-4961 @ 01/27/26 20:57:31.643
  STEP: Listing resource.k8s.io/v1, Resource=resourceclaims without namespace and with label selector e2e-test.kubernetes.io=dra-4961 @ 01/27/26 20:57:31.645
  STEP: Deleting resource.k8s.io/v1, Resource=resourceclaims collection with label selector e2e-test.kubernetes.io=dra-4961 @ 01/27/26 20:57:31.646
  STEP: Checking for existence @ 01/27/26 20:57:31.654
  I0127 20:57:31.658355 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dra-4961" for this suite. @ 01/27/26 20:57:31.661
• [4.500 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:130
  STEP: Creating a kubernetes client @ 01/27/26 20:57:31.668
  I0127 20:57:31.668894 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename dns @ 01/27/26 20:57:31.669
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:57:31.695
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:57:31.705
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7286.svc.cluster.local)" && echo OK > /results/agnhost_hosts@dns-querier-1.dns-test-service.dns-7286.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/agnhost_hosts@dns-querier-1;sleep 1; done
   @ 01/27/26 20:57:31.71
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7286.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-7286.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 01/27/26 20:57:31.71
  STEP: creating a pod to probe /etc/hosts @ 01/27/26 20:57:31.71
  STEP: submitting the pod to kubernetes @ 01/27/26 20:57:31.71
  E0127 20:57:31.922580      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:32.922893      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:33.923107      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:34.923505      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 01/27/26 20:57:35.759
  STEP: looking for the results for each expected name from probers @ 01/27/26 20:57:35.76
  I0127 20:57:35.770530 26 dns_common.go:546] DNS probes using dns-7286/dns-test-3dcb3bea-0eb4-4fe8-92c6-f54fa50a1bcf succeeded

  STEP: deleting the pod @ 01/27/26 20:57:35.77
  I0127 20:57:35.791210 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-7286" for this suite. @ 01/27/26 20:57:35.796
• [4.142 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:800
  STEP: Creating a kubernetes client @ 01/27/26 20:57:35.811
  I0127 20:57:35.811066 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename job @ 01/27/26 20:57:35.811
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:57:35.846
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:57:35.848
  STEP: Creating a job @ 01/27/26 20:57:35.85
  STEP: Ensuring job reaches completions @ 01/27/26 20:57:35.867
  E0127 20:57:35.924041      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:36.925023      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:37.925465      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:38.925659      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:39.926231      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:40.926618      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:41.927021      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:42.927567      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:43.927896      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:44.928506      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:57:45.889481 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7812" for this suite. @ 01/27/26 20:57:45.891
• [10.094 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:309
  STEP: Creating a kubernetes client @ 01/27/26 20:57:45.905
  I0127 20:57:45.905636 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename namespaces @ 01/27/26 20:57:45.906
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:57:45.926
  E0127 20:57:45.928841      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:57:45.928
  STEP: Read namespace status @ 01/27/26 20:57:45.931
  I0127 20:57:45.933466 26 namespace.go:322] Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 01/27/26 20:57:45.933
  I0127 20:57:45.946944 26 namespace.go:342] Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 01/27/26 20:57:45.946
  I0127 20:57:45.957618 26 namespace.go:367] Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  I0127 20:57:45.957731 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-4549" for this suite. @ 01/27/26 20:57:45.992
• [0.095 seconds]
------------------------------
SS
------------------------------
[sig-network] EndpointSlice should create and delete EndpointSlices for a Service with a selector that matches no pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:67
  STEP: Creating a kubernetes client @ 01/27/26 20:57:46
  I0127 20:57:46.000888 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename endpointslice @ 01/27/26 20:57:46.001
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:57:46.033
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:57:46.035
  E0127 20:57:46.929176      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:47.929377      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:57:48.102546 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-4451" for this suite. @ 01/27/26 20:57:48.105
• [2.112 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:362
  STEP: Creating a kubernetes client @ 01/27/26 20:57:48.113
  I0127 20:57:48.113112 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename crd-publish-openapi @ 01/27/26 20:57:48.113
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:57:48.134
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:57:48.139
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 01/27/26 20:57:48.142
  I0127 20:57:48.142597 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  E0127 20:57:48.929989      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:57:49.501536 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  E0127 20:57:49.931215      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:50.932073      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:51.932857      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:52.933809      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:53.934168      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:54.935867      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:57:54.946660 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3443" for this suite. @ 01/27/26 20:57:54.95
• [6.846 seconds]
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 01/27/26 20:57:54.959
  I0127 20:57:54.959227 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename init-container @ 01/27/26 20:57:54.959
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:57:54.981
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:57:54.994
  STEP: creating the pod @ 01/27/26 20:57:54.997
  I0127 20:57:54.997070 26 init_container.go:374] PodSpec: initContainers in spec.initContainers
  E0127 20:57:55.936640      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:56.936791      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:57.936917      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:58.937189      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:57:59.937770      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:00.938159      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:01.938402      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:02.938594      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:03.938809      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:04.938993      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:05.939530      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:06.939732      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:07.940838      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:08.941245      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:09.941428      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:10.942475      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:11.943372      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:12.943644      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:13.943735      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:14.944813      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:15.945348      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:16.945515      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:17.945805      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:18.945997      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:19.946551      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:20.947434      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:21.947521      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:22.948532      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:23.949436      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:24.949759      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:25.950837      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:26.951262      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:27.951489      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:28.952172      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:29.952412      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:30.952927      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:31.953144      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:32.953327      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:33.953523      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:34.953643      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:35.953896      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:36.954087      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:37.954348      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:38.954553      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:39.955431      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:58:40.611527 26 init_container.go:432] init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-cf4762c7-cb04-4fb3-a110-203e2f62bcbd", GenerateName:"", Namespace:"init-container-9681", SelfLink:"", UID:"6b8b53f6-830e-4154-a4a1-50842482722b", ResourceVersion:"24688", Generation:1, CreationTimestamp:time.Date(2026, time.January, 27, 20, 57, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"997062487"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 57, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0017ee6c0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"k3s", Operation:"Update", APIVersion:"v1", Time:time.Date(2026, time.January, 27, 20, 58, 40, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0017ee6f0), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-k8thd", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc003bd6040), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil), Image:(*v1.ImageVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.37.0-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), RestartPolicyRules:[]v1.ContainerRestartRule(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-k8thd", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.37.0-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), RestartPolicyRules:[]v1.ContainerRestartRule(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-k8thd", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.10.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), RestartPolicyRules:[]v1.ContainerRestartRule(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-k8thd", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0020c84f0), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00687dcb0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0020c8570)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0020c8590)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0020c8598), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0020c859c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc004935e60), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil), Resources:(*v1.ResourceRequirements)(nil), HostnameOverride:(*string)(nil), WorkloadRef:(*v1.WorkloadReference)(nil)}, Status:v1.PodStatus{ObservedGeneration:1, Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", ObservedGeneration:1, Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2026, time.January, 27, 20, 57, 56, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", ObservedGeneration:1, Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2026, time.January, 27, 20, 57, 55, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", ObservedGeneration:1, Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2026, time.January, 27, 20, 57, 55, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", ObservedGeneration:1, Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2026, time.January, 27, 20, 57, 55, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", ObservedGeneration:1, Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2026, time.January, 27, 20, 57, 55, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.42.0.10", HostIPs:[]v1.HostIP{v1.HostIP{IP:"10.42.0.10"}}, PodIP:"10.52.1.208", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.52.1.208"}}, StartTime:time.Date(2026, time.January, 27, 20, 57, 55, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003efd0a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003efd110)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.37.0-1", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:0ffbe172f8d245c83f285c6992b452c53d085661e03ddfd3b484332026e6c8bb", ContainerID:"containerd://549b6f0052d62036700ad0238062d5f9ca9afe0b132d509de6458e59f7ef40ad", Started:(*bool)(0xc0020c864a), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(0xc0067f98c0), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-k8thd", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc004935e80)}}, User:(*v1.ContainerUser)(0xc00061c600), AllocatedResourcesStatus:[]v1.ResourceStatus(nil), StopSignal:(*v1.Signal)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003bd60a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.37.0-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0020c8675), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-k8thd", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc004935e90)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil), StopSignal:(*v1.Signal)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003bd6080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.10.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0020c861f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-k8thd", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc004935e70)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil), StopSignal:(*v1.Signal)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil), ExtendedResourceClaimStatus:(*v1.PodExtendedResourceClaimStatus)(nil), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}
  I0127 20:58:40.611705 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-9681" for this suite. @ 01/27/26 20:58:40.615
• [45.669 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:281
  STEP: Creating a kubernetes client @ 01/27/26 20:58:40.629
  I0127 20:58:40.629040 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename crd-publish-openapi @ 01/27/26 20:58:40.629
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:58:40.654
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:58:40.656
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 01/27/26 20:58:40.67
  I0127 20:58:40.670906 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  E0127 20:58:40.955705      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:41.956518      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:58:42.062981 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  E0127 20:58:42.956901      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:43.957662      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:44.957788      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:45.958804      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:46.959683      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:58:47.484176 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4386" for this suite. @ 01/27/26 20:58:47.488
• [6.874 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 01/27/26 20:58:47.503
  I0127 20:58:47.503246 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename hostport @ 01/27/26 20:58:47.504
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:58:47.526
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:58:47.531
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 01/27/26 20:58:47.589
  E0127 20:58:47.960647      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:48.960714      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.42.0.10 on the node which pod1 resides and expect scheduled @ 01/27/26 20:58:49.609
  E0127 20:58:49.961199      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:50.961467      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:51.961806      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:52.962644      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.42.0.10 but use UDP protocol on the node which pod2 resides @ 01/27/26 20:58:53.625
  E0127 20:58:53.963260      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:54.963453      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:55.964351      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:56.964821      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 01/27/26 20:58:57.658
  I0127 20:58:57.658912 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.42.0.10 http://127.0.0.1:54323/hostname] Namespace:hostport-3985 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:58:57.658927 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:58:57.658964 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/hostport-3985/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.42.0.10+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.42.0.10, port: 54323 @ 01/27/26 20:58:57.721
  I0127 20:58:57.721382 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.42.0.10:54323/hostname] Namespace:hostport-3985 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:58:57.721397 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:58:57.721443 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/hostport-3985/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.42.0.10%3A54323%2Fhostname&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.42.0.10, port: 54323 UDP @ 01/27/26 20:58:57.769
  I0127 20:58:57.769567 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.42.0.10 54323] Namespace:hostport-3985 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 20:58:57.769584 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 20:58:57.769650 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/hostport-3985/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.42.0.10+54323&container=e2e-host-exec&stderr=true&stdout=true)
  E0127 20:58:57.965564      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:58.965942      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:58:59.966156      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:00.967156      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:01.967617      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:59:02.824490 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-3985" for this suite. @ 01/27/26 20:59:02.827
• [15.333 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:370
  STEP: Creating a kubernetes client @ 01/27/26 20:59:02.836
  I0127 20:59:02.836525 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 20:59:02.837
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:59:02.852
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:59:02.864
  STEP: Setting up server cert @ 01/27/26 20:59:02.907
  E0127 20:59:02.968336      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 20:59:03.14
  STEP: Deploying the webhook pod @ 01/27/26 20:59:03.15
  STEP: Wait for the deployment to be ready @ 01/27/26 20:59:03.172
  I0127 20:59:03.186579 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0127 20:59:03.968817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:04.969036      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/27/26 20:59:05.193
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 20:59:05.208
  I0127 20:59:05.208575 26 wait.go:65] Waiting for amount of service webhook-6141/e2e-test-webhook endpoints to be 1
  I0127 20:59:05.210184 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  E0127 20:59:05.969254      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 01/27/26 20:59:06.213
  STEP: Registering slow webhook via the AdmissionRegistration API @ 01/27/26 20:59:06.213
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 01/27/26 20:59:06.237
  E0127 20:59:06.969294      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 01/27/26 20:59:07.256
  STEP: Registering slow webhook via the AdmissionRegistration API @ 01/27/26 20:59:07.256
  E0127 20:59:07.970234      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 01/27/26 20:59:08.307
  STEP: Registering slow webhook via the AdmissionRegistration API @ 01/27/26 20:59:08.307
  E0127 20:59:08.970619      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:09.970820      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:10.971071      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:11.971398      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:12.971555      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 01/27/26 20:59:13.375
  STEP: Registering slow webhook via the AdmissionRegistration API @ 01/27/26 20:59:13.375
  E0127 20:59:13.972155      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:14.973119      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:15.973372      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:16.973974      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:17.974689      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:59:18.514086 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6141" for this suite. @ 01/27/26 20:59:18.516
  STEP: Destroying namespace "webhook-markers-9208" for this suite. @ 01/27/26 20:59:18.524
• [15.705 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 01/27/26 20:59:18.541
  I0127 20:59:18.541742 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename watch @ 01/27/26 20:59:18.542
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:59:18.559
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:59:18.57
  STEP: getting a starting resourceVersion @ 01/27/26 20:59:18.574
  STEP: starting a background goroutine to produce watch events @ 01/27/26 20:59:18.576
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 01/27/26 20:59:18.576
  E0127 20:59:18.975245      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:19.975705      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:20.976050      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:59:21.238296 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3457" for this suite. @ 01/27/26 20:59:21.245
• [2.763 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:159
  STEP: Creating a kubernetes client @ 01/27/26 20:59:21.304
  I0127 20:59:21.304388 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename emptydir @ 01/27/26 20:59:21.304
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:59:21.322
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:59:21.324
  STEP: Creating a pod to test emptydir volume type on node default medium @ 01/27/26 20:59:21.325
  E0127 20:59:21.976877      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:22.977309      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:23.977377      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:24.977573      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 20:59:25.346
  I0127 20:59:25.347706 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-f298ef55-1762-48e0-b261-e02d6ba6902f container test-container: <nil>
  STEP: delete the pod @ 01/27/26 20:59:25.359
  I0127 20:59:25.389002 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1163" for this suite. @ 01/27/26 20:59:25.392
• [4.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Serial] [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:647
  STEP: Creating a kubernetes client @ 01/27/26 20:59:25.412
  I0127 20:59:25.412488 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename gc @ 01/27/26 20:59:25.413
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:59:25.433
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:59:25.435
  STEP: create the rc @ 01/27/26 20:59:25.492
  I0127 20:59:25.507059      26 warnings.go:107] "Warning: metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]"
  E0127 20:59:25.978303      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:26.978493      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:27.979649      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:28.979724      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:29.980829      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:30.981524      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the rc @ 01/27/26 20:59:31.953
  E0127 20:59:31.982794      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: wait for the rc to be deleted @ 01/27/26 20:59:32.182
  E0127 20:59:32.982982      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:59:33.689579 26 garbage_collector.go:678] 97 pods remaining
  I0127 20:59:33.689615 26 garbage_collector.go:685] 80 pods has nil DeletionTimestamp
  I0127 20:59:33.689623 26 garbage_collector.go:686] 
  E0127 20:59:33.983223      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:59:34.505452 26 garbage_collector.go:678] 80 pods remaining
  I0127 20:59:34.505495 26 garbage_collector.go:685] 77 pods has nil DeletionTimestamp
  I0127 20:59:34.505502 26 garbage_collector.go:686] 
  E0127 20:59:34.984074      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:59:35.604313 26 garbage_collector.go:678] 61 pods remaining
  I0127 20:59:35.604350 26 garbage_collector.go:685] 60 pods has nil DeletionTimestamp
  I0127 20:59:35.604357 26 garbage_collector.go:686] 
  E0127 20:59:35.985431      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:59:36.635700 26 garbage_collector.go:678] 56 pods remaining
  I0127 20:59:36.635736 26 garbage_collector.go:685] 43 pods has nil DeletionTimestamp
  I0127 20:59:36.635743 26 garbage_collector.go:686] 
  E0127 20:59:36.985597      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:59:37.486704 26 garbage_collector.go:678] 37 pods remaining
  I0127 20:59:37.486744 26 garbage_collector.go:685] 36 pods has nil DeletionTimestamp
  I0127 20:59:37.486752 26 garbage_collector.go:686] 
  E0127 20:59:37.986513      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:59:38.603508 26 garbage_collector.go:678] 26 pods remaining
  I0127 20:59:38.603545 26 garbage_collector.go:685] 22 pods has nil DeletionTimestamp
  I0127 20:59:38.603552 26 garbage_collector.go:686] 
  E0127 20:59:38.987204      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:59:39.502992 26 garbage_collector.go:678] 15 pods remaining
  I0127 20:59:39.503119 26 garbage_collector.go:685] 9 pods has nil DeletionTimestamp
  I0127 20:59:39.503158 26 garbage_collector.go:686] 
  E0127 20:59:39.987349      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:59:40.602891 26 garbage_collector.go:678] 2 pods remaining
  I0127 20:59:40.602927 26 garbage_collector.go:685] 0 pods has nil DeletionTimestamp
  I0127 20:59:40.602934 26 garbage_collector.go:686] 
  E0127 20:59:40.988081      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 01/27/26 20:59:41.224
  W0127 20:59:41.226484      26 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I0127 20:59:41.226515 26 garbage_collector.go:273] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0127 20:59:41.226663 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-42" for this suite. @ 01/27/26 20:59:41.229
• [15.840 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:445
  STEP: Creating a kubernetes client @ 01/27/26 20:59:41.252
  I0127 20:59:41.252758 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename sched-pred @ 01/27/26 20:59:41.254
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:59:41.558
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:59:41.561
  I0127 20:59:41.564383 26 helper.go:125] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0127 20:59:41.568162 26 util.go:389] Waiting for terminating namespaces to be deleted...
  I0127 20:59:41.569955 26 predicates.go:120] 
  Logging pods the apiserver thinks is on node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 before test
  I0127 20:59:41.572064 26 predicates.go:958] svclb-traefik-4c5baeff-vbqt2 from kube-system started at 2026-01-27 19:41:22 +0000 UTC (2 container statuses recorded)
  I0127 20:59:41.572085 26 predicates.go:960] 	Container lb-tcp-443 ready: true, restart count 0
  I0127 20:59:41.572093 26 predicates.go:960] 	Container lb-tcp-80 ready: true, restart count 0
  I0127 20:59:41.572102 26 predicates.go:958] sonobuoy from sonobuoy started at 2026-01-27 19:52:38 +0000 UTC (1 container statuses recorded)
  I0127 20:59:41.572109 26 predicates.go:960] 	Container kube-sonobuoy ready: true, restart count 0
  I0127 20:59:41.572116 26 predicates.go:958] sonobuoy-e2e-job-211431d51fbc478c from sonobuoy started at 2026-01-27 19:52:42 +0000 UTC (2 container statuses recorded)
  I0127 20:59:41.572125 26 predicates.go:960] 	Container e2e ready: true, restart count 0
  I0127 20:59:41.572131 26 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0127 20:59:41.572139 26 predicates.go:958] sonobuoy-systemd-logs-daemon-set-7c9a66bc53524567-gzwrw from sonobuoy started at 2026-01-27 19:52:42 +0000 UTC (2 container statuses recorded)
  I0127 20:59:41.572146 26 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0127 20:59:41.572151 26 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  I0127 20:59:41.572158 26 predicates.go:120] 
  Logging pods the apiserver thinks is on node k3k-k3kcluster-server-0 before test
  I0127 20:59:41.574382 26 predicates.go:958] coredns-54bf7cdff9-hvd6n from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 20:59:41.574407 26 predicates.go:960] 	Container coredns ready: true, restart count 0
  I0127 20:59:41.574415 26 predicates.go:958] helm-install-traefik-ck8zv from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 20:59:41.574421 26 predicates.go:960] 	Container helm ready: false, restart count 1
  I0127 20:59:41.574429 26 predicates.go:958] helm-install-traefik-crd-kw4dk from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 20:59:41.574436 26 predicates.go:960] 	Container helm ready: false, restart count 0
  I0127 20:59:41.574443 26 predicates.go:958] local-path-provisioner-69879d7dd7-xrhgn from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 20:59:41.574449 26 predicates.go:960] 	Container local-path-provisioner ready: true, restart count 0
  I0127 20:59:41.574455 26 predicates.go:958] metrics-server-77dbbf84b-fkr5h from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 20:59:41.574461 26 predicates.go:960] 	Container metrics-server ready: true, restart count 0
  I0127 20:59:41.574468 26 predicates.go:958] svclb-traefik-4c5baeff-dqplp from kube-system started at 2026-01-27 19:41:06 +0000 UTC (2 container statuses recorded)
  I0127 20:59:41.574475 26 predicates.go:960] 	Container lb-tcp-443 ready: true, restart count 0
  I0127 20:59:41.574480 26 predicates.go:960] 	Container lb-tcp-80 ready: true, restart count 0
  I0127 20:59:41.574487 26 predicates.go:958] traefik-6d98778dfc-p2jdc from kube-system started at 2026-01-27 19:41:06 +0000 UTC (1 container statuses recorded)
  I0127 20:59:41.574493 26 predicates.go:960] 	Container traefik ready: true, restart count 0
  I0127 20:59:41.574500 26 predicates.go:958] sonobuoy-systemd-logs-daemon-set-7c9a66bc53524567-h78hs from sonobuoy started at 2026-01-27 19:52:42 +0000 UTC (2 container statuses recorded)
  I0127 20:59:41.574514 26 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0127 20:59:41.574520 26 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 01/27/26 20:59:41.574
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.188eb22667320826], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match Pod's node affinity/selector. no new claims to deallocate, preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling.] @ 01/27/26 20:59:41.783
  E0127 20:59:41.988670      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 20:59:42.738129 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-8845" for this suite. @ 01/27/26 20:59:42.74
• [1.590 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:376
  STEP: Creating a kubernetes client @ 01/27/26 20:59:42.842
  I0127 20:59:42.842911 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename namespaces @ 01/27/26 20:59:42.843
  E0127 20:59:42.989648      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:59:43.108
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:59:43.127
  STEP: Updating Namespace "namespaces-1411" @ 01/27/26 20:59:43.248
  I0127 20:59:43.322847 26 namespace.go:393] Namespace "namespaces-1411" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"9363327e-b7dc-40b5-856e-73161be656f5", "kubernetes.io/metadata.name":"namespaces-1411", "namespaces-1411":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  I0127 20:59:43.322977 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1411" for this suite. @ 01/27/26 20:59:43.428
• [0.615 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:208
  STEP: Creating a kubernetes client @ 01/27/26 20:59:43.457
  I0127 20:59:43.457757 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename dns @ 01/27/26 20:59:43.458
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 20:59:43.702
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 20:59:43.706
  STEP: Creating a test headless service @ 01/27/26 20:59:43.709
  E0127 20:59:43.990778      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2756 A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service.dns-2756;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2756 A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service.dns-2756;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2756.svc A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service.dns-2756.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2756.svc A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service.dns-2756.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2756.svc SRV)" && test -n "$$check" && echo OK > /results/agnhost_udp@_http._tcp.dns-test-service.dns-2756.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2756.svc SRV)" && test -n "$$check" && echo OK > /results/agnhost_tcp@_http._tcp.dns-test-service.dns-2756.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2756.svc SRV)" && test -n "$$check" && echo OK > /results/agnhost_udp@_http._tcp.test-service-2.dns-2756.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2756.svc SRV)" && test -n "$$check" && echo OK > /results/agnhost_tcp@_http._tcp.test-service-2.dns-2756.svc;check="$$(dig +notcp +noall +answer +search 42.74.53.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.53.74.42_udp@PTR;check="$$(dig +tcp +noall +answer +search 42.74.53.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.53.74.42_tcp@PTR;sleep 1; done
   @ 01/27/26 20:59:44.083
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2756 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2756;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2756 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2756;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2756.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2756.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2756.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2756.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2756.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2756.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2756.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2756.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2756.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2756.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2756.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2756.svc;check="$$(dig +notcp +noall +answer +search 42.74.53.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.53.74.42_udp@PTR;check="$$(dig +tcp +noall +answer +search 42.74.53.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.53.74.42_tcp@PTR;sleep 1; done
   @ 01/27/26 20:59:44.083
  STEP: creating a pod to probe DNS @ 01/27/26 20:59:44.083
  STEP: submitting the pod to kubernetes @ 01/27/26 20:59:44.083
  E0127 20:59:44.991069      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:45.991648      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:46.991689      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:47.991757      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:48.992475      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:49.992915      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:50.993779      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:51.994035      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:52.994122      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:53.995175      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:54.995384      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:55.995467      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:56.995710      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:57.995757      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:58.996798      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 20:59:59.997205      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:00.997682      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:01.998132      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:02.998344      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:03.998876      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:04.999177      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:05.999809      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:07.000562      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:08.001165      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:09.001786      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:10.001986      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:11.002096      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:12.002837      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:13.003532      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:14.003734      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:15.004276      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:16.004852      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:17.005702      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:18.006088      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:19.006831      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:20.007039      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:21.007240      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:22.007571      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:23.008395      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:24.008515      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:25.008751      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:26.009213      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:27.009441      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:28.010486      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:29.010780      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:30.011570      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:31.011761      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:32.012817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:33.013295      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:34.014041      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:35.014376      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:36.015191      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:37.015427      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:38.015733      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:39.015765      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:40.016834      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:41.017018      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:42.017168      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:43.017610      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:44.018259      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:45.018393      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:46.019429      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:47.019733      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:48.020552      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:49.021095      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:50.021759      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:51.022010      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:52.023092      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:53.024088      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:54.024105      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:55.024903      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:56.025618      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:57.026552      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:58.027625      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:00:59.028544      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:00.028776      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:01.029177      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:02.029367      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:03.030379      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:04.030575      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:05.031490      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:06.031724      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:07.031751      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:08.032834      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:09.032958      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:10.033339      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 01/27/26 21:01:10.774
  STEP: looking for the results for each expected name from probers @ 01/27/26 21:01:10.776
  I0127 21:01:10.781260 26 dns_common.go:495] Unable to read agnhost_udp@dns-test-service from pod dns-2756/dns-test-7874265c-d14e-4651-9126-69a58f2816c4: the server could not find the requested resource (get pods dns-test-7874265c-d14e-4651-9126-69a58f2816c4)
  I0127 21:01:10.782829 26 dns_common.go:495] Unable to read agnhost_tcp@dns-test-service from pod dns-2756/dns-test-7874265c-d14e-4651-9126-69a58f2816c4: the server could not find the requested resource (get pods dns-test-7874265c-d14e-4651-9126-69a58f2816c4)
  I0127 21:01:10.784696 26 dns_common.go:495] Unable to read agnhost_udp@dns-test-service.dns-2756 from pod dns-2756/dns-test-7874265c-d14e-4651-9126-69a58f2816c4: the server could not find the requested resource (get pods dns-test-7874265c-d14e-4651-9126-69a58f2816c4)
  I0127 21:01:10.786329 26 dns_common.go:495] Unable to read agnhost_tcp@dns-test-service.dns-2756 from pod dns-2756/dns-test-7874265c-d14e-4651-9126-69a58f2816c4: the server could not find the requested resource (get pods dns-test-7874265c-d14e-4651-9126-69a58f2816c4)
  I0127 21:01:10.787796 26 dns_common.go:495] Unable to read agnhost_udp@dns-test-service.dns-2756.svc from pod dns-2756/dns-test-7874265c-d14e-4651-9126-69a58f2816c4: the server could not find the requested resource (get pods dns-test-7874265c-d14e-4651-9126-69a58f2816c4)
  I0127 21:01:10.789496 26 dns_common.go:495] Unable to read agnhost_tcp@dns-test-service.dns-2756.svc from pod dns-2756/dns-test-7874265c-d14e-4651-9126-69a58f2816c4: the server could not find the requested resource (get pods dns-test-7874265c-d14e-4651-9126-69a58f2816c4)
  I0127 21:01:10.792144 26 dns_common.go:495] Unable to read agnhost_udp@_http._tcp.dns-test-service.dns-2756.svc from pod dns-2756/dns-test-7874265c-d14e-4651-9126-69a58f2816c4: the server could not find the requested resource (get pods dns-test-7874265c-d14e-4651-9126-69a58f2816c4)
  I0127 21:01:10.794870 26 dns_common.go:495] Unable to read agnhost_tcp@_http._tcp.dns-test-service.dns-2756.svc from pod dns-2756/dns-test-7874265c-d14e-4651-9126-69a58f2816c4: the server could not find the requested resource (get pods dns-test-7874265c-d14e-4651-9126-69a58f2816c4)
  I0127 21:01:10.805611 26 dns_common.go:495] Unable to read jessie_udp@dns-test-service from pod dns-2756/dns-test-7874265c-d14e-4651-9126-69a58f2816c4: the server could not find the requested resource (get pods dns-test-7874265c-d14e-4651-9126-69a58f2816c4)
  I0127 21:01:10.807182 26 dns_common.go:495] Unable to read jessie_tcp@dns-test-service from pod dns-2756/dns-test-7874265c-d14e-4651-9126-69a58f2816c4: the server could not find the requested resource (get pods dns-test-7874265c-d14e-4651-9126-69a58f2816c4)
  I0127 21:01:10.808715 26 dns_common.go:495] Unable to read jessie_udp@dns-test-service.dns-2756 from pod dns-2756/dns-test-7874265c-d14e-4651-9126-69a58f2816c4: the server could not find the requested resource (get pods dns-test-7874265c-d14e-4651-9126-69a58f2816c4)
  I0127 21:01:10.810180 26 dns_common.go:495] Unable to read jessie_tcp@dns-test-service.dns-2756 from pod dns-2756/dns-test-7874265c-d14e-4651-9126-69a58f2816c4: the server could not find the requested resource (get pods dns-test-7874265c-d14e-4651-9126-69a58f2816c4)
  I0127 21:01:10.811609 26 dns_common.go:495] Unable to read jessie_udp@dns-test-service.dns-2756.svc from pod dns-2756/dns-test-7874265c-d14e-4651-9126-69a58f2816c4: the server could not find the requested resource (get pods dns-test-7874265c-d14e-4651-9126-69a58f2816c4)
  I0127 21:01:10.813588 26 dns_common.go:495] Unable to read jessie_tcp@dns-test-service.dns-2756.svc from pod dns-2756/dns-test-7874265c-d14e-4651-9126-69a58f2816c4: the server could not find the requested resource (get pods dns-test-7874265c-d14e-4651-9126-69a58f2816c4)
  I0127 21:01:10.815036 26 dns_common.go:495] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2756.svc from pod dns-2756/dns-test-7874265c-d14e-4651-9126-69a58f2816c4: the server could not find the requested resource (get pods dns-test-7874265c-d14e-4651-9126-69a58f2816c4)
  I0127 21:01:10.816489 26 dns_common.go:495] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2756.svc from pod dns-2756/dns-test-7874265c-d14e-4651-9126-69a58f2816c4: the server could not find the requested resource (get pods dns-test-7874265c-d14e-4651-9126-69a58f2816c4)
  I0127 21:01:10.822857 26 dns_common.go:506] Lookups using dns-2756/dns-test-7874265c-d14e-4651-9126-69a58f2816c4 failed for: [agnhost_udp@dns-test-service agnhost_tcp@dns-test-service agnhost_udp@dns-test-service.dns-2756 agnhost_tcp@dns-test-service.dns-2756 agnhost_udp@dns-test-service.dns-2756.svc agnhost_tcp@dns-test-service.dns-2756.svc agnhost_udp@_http._tcp.dns-test-service.dns-2756.svc agnhost_tcp@_http._tcp.dns-test-service.dns-2756.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-2756 jessie_tcp@dns-test-service.dns-2756 jessie_udp@dns-test-service.dns-2756.svc jessie_tcp@dns-test-service.dns-2756.svc jessie_udp@_http._tcp.dns-test-service.dns-2756.svc jessie_tcp@_http._tcp.dns-test-service.dns-2756.svc]

  I0127 21:01:10.832526 26 dns_common.go:514] Pod client logs for webserver: 
  I0127 21:01:10.836369 26 dns_common.go:514] Pod client logs for agnhost-querier: 
  I0127 21:01:10.839642 26 dns_common.go:514] Pod client logs for jessie-querier: 
  E0127 21:01:11.034096      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:12.034277      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:13.034413      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:14.034539      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:15.034756      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:01:15.824697 26 dns_common.go:546] DNS probes using dns-2756/dns-test-7874265c-d14e-4651-9126-69a58f2816c4 succeeded

  STEP: deleting the pod @ 01/27/26 21:01:15.824
  STEP: deleting the test service @ 01/27/26 21:01:15.862
  STEP: deleting the test headless service @ 01/27/26 21:01:15.915
  I0127 21:01:15.930290 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2756" for this suite. @ 01/27/26 21:01:15.932
• [92.488 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:287
  STEP: Creating a kubernetes client @ 01/27/26 21:01:15.945
  I0127 21:01:15.945967 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename field-validation @ 01/27/26 21:01:15.946
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:01:15.968
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:01:15.975
  I0127 21:01:15.977123 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  E0127 21:01:16.035881      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:17.037597      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:18.037798      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:19.038284      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:01:19.050724 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-882" for this suite. @ 01/27/26 21:01:19.052
• [3.115 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2228
  STEP: Creating a kubernetes client @ 01/27/26 21:01:19.061
  I0127 21:01:19.061190 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename services @ 01/27/26 21:01:19.061
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:01:19.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:01:19.095
  STEP: creating service in namespace services-6943 @ 01/27/26 21:01:19.097
  STEP: creating service affinity-clusterip in namespace services-6943 @ 01/27/26 21:01:19.097
  I0127 21:01:19.133122 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0127 21:01:20.038674      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:21.039577      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:01:21.140346 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:3, TerminatingReplicas:(*int32)(0xc001dfc110), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 21, 1, 19, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 1, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 1, 19, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 1, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-clusterip-76bb56bdb7\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:01:22.039762      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:23.039910      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:01:23.193925 26 resource.go:344] Creating new exec pod
  E0127 21:01:24.040825      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:25.041268      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:26.042138      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:27.042345      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:28.042953      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:29.043177      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:01:29.777833 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-6943 exec execpod-affinity2qxbc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  I0127 21:01:29.922005 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip (10.53.90.215) 80 port [tcp/http] succeeded!\n"
  I0127 21:01:29.922064 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 21:01:29.922125 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-6943 exec execpod-affinity2qxbc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.90.215 80'
  E0127 21:01:30.043564      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:01:30.151476 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.53.90.215 80\nConnection to 10.53.90.215 80 port [tcp/http] succeeded!\n"
  I0127 21:01:30.151522 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 21:01:30.151580 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-6943 exec execpod-affinity2qxbc -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://10.53.90.215:80/ ; done'
  I0127 21:01:30.317738 26 builder.go:156] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.90.215:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.90.215:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.90.215:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.90.215:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.90.215:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.90.215:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.90.215:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.90.215:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.90.215:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.90.215:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.90.215:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.90.215:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.90.215:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.90.215:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.90.215:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.53.90.215:80/\n"
  I0127 21:01:30.317794 26 builder.go:157] stdout: "\naffinity-clusterip-76bb56bdb7-6l99w\naffinity-clusterip-76bb56bdb7-6l99w\naffinity-clusterip-76bb56bdb7-6l99w\naffinity-clusterip-76bb56bdb7-6l99w\naffinity-clusterip-76bb56bdb7-6l99w\naffinity-clusterip-76bb56bdb7-6l99w\naffinity-clusterip-76bb56bdb7-6l99w\naffinity-clusterip-76bb56bdb7-6l99w\naffinity-clusterip-76bb56bdb7-6l99w\naffinity-clusterip-76bb56bdb7-6l99w\naffinity-clusterip-76bb56bdb7-6l99w\naffinity-clusterip-76bb56bdb7-6l99w\naffinity-clusterip-76bb56bdb7-6l99w\naffinity-clusterip-76bb56bdb7-6l99w\naffinity-clusterip-76bb56bdb7-6l99w\naffinity-clusterip-76bb56bdb7-6l99w"
  I0127 21:01:30.317809 26 service.go:227] Received response from host: affinity-clusterip-76bb56bdb7-6l99w
  I0127 21:01:30.317819 26 service.go:227] Received response from host: affinity-clusterip-76bb56bdb7-6l99w
  I0127 21:01:30.317826 26 service.go:227] Received response from host: affinity-clusterip-76bb56bdb7-6l99w
  I0127 21:01:30.317834 26 service.go:227] Received response from host: affinity-clusterip-76bb56bdb7-6l99w
  I0127 21:01:30.317842 26 service.go:227] Received response from host: affinity-clusterip-76bb56bdb7-6l99w
  I0127 21:01:30.317849 26 service.go:227] Received response from host: affinity-clusterip-76bb56bdb7-6l99w
  I0127 21:01:30.317856 26 service.go:227] Received response from host: affinity-clusterip-76bb56bdb7-6l99w
  I0127 21:01:30.317863 26 service.go:227] Received response from host: affinity-clusterip-76bb56bdb7-6l99w
  I0127 21:01:30.317871 26 service.go:227] Received response from host: affinity-clusterip-76bb56bdb7-6l99w
  I0127 21:01:30.317878 26 service.go:227] Received response from host: affinity-clusterip-76bb56bdb7-6l99w
  I0127 21:01:30.317890 26 service.go:227] Received response from host: affinity-clusterip-76bb56bdb7-6l99w
  I0127 21:01:30.317897 26 service.go:227] Received response from host: affinity-clusterip-76bb56bdb7-6l99w
  I0127 21:01:30.317904 26 service.go:227] Received response from host: affinity-clusterip-76bb56bdb7-6l99w
  I0127 21:01:30.317911 26 service.go:227] Received response from host: affinity-clusterip-76bb56bdb7-6l99w
  I0127 21:01:30.317918 26 service.go:227] Received response from host: affinity-clusterip-76bb56bdb7-6l99w
  I0127 21:01:30.317926 26 service.go:227] Received response from host: affinity-clusterip-76bb56bdb7-6l99w
  I0127 21:01:30.317996 26 service.go:4286] Cleaning up the exec pod
  I0127 21:01:30.696604 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0127 21:01:31.043932      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-6943" for this suite. @ 01/27/26 21:01:31.221
• [12.370 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:47
  STEP: Creating a kubernetes client @ 01/27/26 21:01:31.431
  I0127 21:01:31.431481 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename configmap @ 01/27/26 21:01:31.432
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:01:31.515
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:01:31.517
  STEP: Creating configMap with name configmap-test-volume-7dba18d0-aae9-44d3-9d95-cbea7b8b163b @ 01/27/26 21:01:31.519
  STEP: Creating a pod to test consume configMaps @ 01/27/26 21:01:31.531
  E0127 21:01:32.044426      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:33.044641      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:34.046040      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:35.046156      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:36.046728      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:37.047354      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:01:37.727
  I0127 21:01:37.729443 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-configmaps-e411d184-0ca3-44fe-bbc6-2f281b751bc6 container agnhost-container: <nil>
  STEP: delete the pod @ 01/27/26 21:01:37.738
  I0127 21:01:37.920221 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2651" for this suite. @ 01/27/26 21:01:37.922
• [6.554 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:57
  STEP: Creating a kubernetes client @ 01/27/26 21:01:37.986
  I0127 21:01:37.986079 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 21:01:37.986
  E0127 21:01:38.047438      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:01:38.05
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:01:38.14
  STEP: Creating configMap with name projected-configmap-test-volume-cb490df7-7c5f-4bc3-b7be-e0194d21709e @ 01/27/26 21:01:38.142
  STEP: Creating a pod to test consume configMaps @ 01/27/26 21:01:38.15
  E0127 21:01:39.047461      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:40.047692      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:41.047781      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:42.047815      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:43.048443      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:44.048678      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:01:44.201
  I0127 21:01:44.204210 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-projected-configmaps-efd2ac6e-4ec6-4b8a-b082-7182979044ec container agnhost-container: <nil>
  STEP: delete the pod @ 01/27/26 21:01:44.209
  I0127 21:01:44.233051 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8556" for this suite. @ 01/27/26 21:01:44.235
• [6.268 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 01/27/26 21:01:44.254
  I0127 21:01:44.254666 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename subpath @ 01/27/26 21:01:44.255
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:01:44.276
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:01:44.281
  STEP: Setting up data @ 01/27/26 21:01:44.284
  STEP: Creating pod pod-subpath-test-downwardapi-n59q @ 01/27/26 21:01:44.3
  STEP: Creating a pod to test atomic-volume-subpath @ 01/27/26 21:01:44.3
  E0127 21:01:45.049262      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:46.049489      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:47.050004      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:48.050245      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:49.050680      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:50.050883      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:51.051545      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:52.051748      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:53.052858      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:54.053423      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:55.053772      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:56.054413      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:57.054553      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:58.054766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:01:59.054898      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:00.055096      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:01.055575      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:02.055783      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:03.056848      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:04.057213      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:05.057830      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:06.058219      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:07.059100      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:08.059735      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:02:08.365
  I0127 21:02:08.367921 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-subpath-test-downwardapi-n59q container test-container-subpath-downwardapi-n59q: <nil>
  STEP: delete the pod @ 01/27/26 21:02:08.373
  STEP: Deleting pod pod-subpath-test-downwardapi-n59q @ 01/27/26 21:02:08.542
  I0127 21:02:08.542866 26 delete.go:78] Deleting pod "pod-subpath-test-downwardapi-n59q" in namespace "subpath-3032"
  I0127 21:02:08.544611 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3032" for this suite. @ 01/27/26 21:02:08.547
• [24.310 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:754
  STEP: Creating a kubernetes client @ 01/27/26 21:02:08.565
  I0127 21:02:08.565295 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename resourcequota @ 01/27/26 21:02:08.566
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:02:08.695
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:02:08.698
  STEP: Creating a ResourceQuota with terminating scope @ 01/27/26 21:02:08.7
  STEP: Ensuring ResourceQuota status is calculated @ 01/27/26 21:02:08.72
  E0127 21:02:09.060089      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:10.060903      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:02:10.733405 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001fda640>: 
          metadata:
            creationTimestamp: "2026-01-27T21:02:08Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:02:08Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:used:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T21:02:08Z"
            name: quota-terminating
            namespace: resourcequota-9933
            resourceVersion: "26630"
            uid: 449cfa03-7833-4342-83f5-74321d18855d
          spec:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            scopes:
            - Terminating
          status:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            used:
              limits.cpu: "0"
              limits.memory: "0"
              pods: "0"
              requests.cpu: "0"
              requests.memory: "0"
  STEP: Creating a ResourceQuota with not terminating scope @ 01/27/26 21:02:10.733
  STEP: Ensuring ResourceQuota status is calculated @ 01/27/26 21:02:10.765
  E0127 21:02:11.061965      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:12.062214      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:02:12.770764 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc00563af00>: 
          metadata:
            creationTimestamp: "2026-01-27T21:02:10Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:02:10Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:used:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T21:02:10Z"
            name: quota-not-terminating
            namespace: resourcequota-9933
            resourceVersion: "26638"
            uid: 16c235ed-66c2-40b6-bb42-88b66b551226
          spec:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            scopes:
            - NotTerminating
          status:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            used:
              limits.cpu: "0"
              limits.memory: "0"
              pods: "0"
              requests.cpu: "0"
              requests.memory: "0"
  STEP: Creating a long running pod @ 01/27/26 21:02:12.77
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 01/27/26 21:02:12.783
  I0127 21:02:12.785666 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc00563ba40>: 
          metadata:
            creationTimestamp: "2026-01-27T21:02:10Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:02:10Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:used:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T21:02:12Z"
            name: quota-not-terminating
            namespace: resourcequota-9933
            resourceVersion: "26644"
            uid: 16c235ed-66c2-40b6-bb42-88b66b551226
          spec:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            scopes:
            - NotTerminating
          status:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            used:
              limits.cpu: "1"
              limits.memory: 400Mi
              pods: "1"
              requests.cpu: 500m
              requests.memory: 200Mi
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 01/27/26 21:02:12.785
  E0127 21:02:13.062480      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:14.062676      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:15.062899      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:16.063096      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:17.063561      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:18.063746      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:19.064504      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:20.064873      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:21.065561      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:22.065751      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 01/27/26 21:02:22.786
  STEP: Ensuring resource quota status released the pod usage @ 01/27/26 21:02:22.819
  I0127 21:02:22.821452 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc00101aa00>: 
          metadata:
            creationTimestamp: "2026-01-27T21:02:10Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:02:10Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:used:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T21:02:22Z"
            name: quota-not-terminating
            namespace: resourcequota-9933
            resourceVersion: "26688"
            uid: 16c235ed-66c2-40b6-bb42-88b66b551226
          spec:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            scopes:
            - NotTerminating
          status:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            used:
              limits.cpu: "0"
              limits.memory: "0"
              pods: "0"
              requests.cpu: "0"
              requests.memory: "0"
  STEP: Creating a terminating pod @ 01/27/26 21:02:22.821
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 01/27/26 21:02:22.844
  I0127 21:02:22.846815 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001012280>: 
          metadata:
            creationTimestamp: "2026-01-27T21:02:08Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:02:08Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:used:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T21:02:22Z"
            name: quota-terminating
            namespace: resourcequota-9933
            resourceVersion: "26690"
            uid: 449cfa03-7833-4342-83f5-74321d18855d
          spec:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            scopes:
            - Terminating
          status:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            used:
              limits.cpu: "1"
              limits.memory: 400Mi
              pods: "1"
              requests.cpu: 500m
              requests.memory: 200Mi
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 01/27/26 21:02:22.846
  I0127 21:02:22.852650 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc00101b400>: 
          metadata:
            creationTimestamp: "2026-01-27T21:02:10Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:02:10Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:used:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T21:02:22Z"
            name: quota-not-terminating
            namespace: resourcequota-9933
            resourceVersion: "26688"
            uid: 16c235ed-66c2-40b6-bb42-88b66b551226
          spec:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            scopes:
            - NotTerminating
          status:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            used:
              limits.cpu: "0"
              limits.memory: "0"
              pods: "0"
              requests.cpu: "0"
              requests.memory: "0"
  E0127 21:02:23.066319      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:24.066520      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:25.066677      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:26.066831      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:27.067195      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:28.067427      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:29.068433      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:30.068632      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:31.069762      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:32.070060      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 01/27/26 21:02:32.853
  STEP: Ensuring resource quota status released the pod usage @ 01/27/26 21:02:32.88
  I0127 21:02:32.882912 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001696f00>: 
          metadata:
            creationTimestamp: "2026-01-27T21:02:08Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:02:08Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:used:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T21:02:32Z"
            name: quota-terminating
            namespace: resourcequota-9933
            resourceVersion: "26724"
            uid: 449cfa03-7833-4342-83f5-74321d18855d
          spec:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            scopes:
            - Terminating
          status:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            used:
              limits.cpu: "0"
              limits.memory: "0"
              pods: "0"
              requests.cpu: "0"
              requests.memory: "0"
  I0127 21:02:32.883182 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9933" for this suite. @ 01/27/26 21:02:32.894
• [24.342 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:118
  STEP: Creating a kubernetes client @ 01/27/26 21:02:32.907
  I0127 21:02:32.907928 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 21:02:32.908
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:02:32.93
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:02:32.932
  STEP: Setting up server cert @ 01/27/26 21:02:32.969
  E0127 21:02:33.070946      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 21:02:33.154
  STEP: Deploying the webhook pod @ 01/27/26 21:02:33.164
  STEP: Wait for the deployment to be ready @ 01/27/26 21:02:33.192
  I0127 21:02:33.201866 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0127 21:02:34.071773      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:35.072003      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/27/26 21:02:35.208
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 21:02:35.223
  I0127 21:02:35.223993 26 wait.go:65] Waiting for amount of service webhook-1467/e2e-test-webhook endpoints to be 1
  I0127 21:02:35.227101 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  E0127 21:02:36.072144      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: fetching the /apis discovery document @ 01/27/26 21:02:36.227
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 01/27/26 21:02:36.228
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 01/27/26 21:02:36.228
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 01/27/26 21:02:36.228
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 01/27/26 21:02:36.229
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 01/27/26 21:02:36.229
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 01/27/26 21:02:36.23
  I0127 21:02:36.291423 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1467" for this suite. @ 01/27/26 21:02:36.293
  STEP: Destroying namespace "webhook-markers-7458" for this suite. @ 01/27/26 21:02:36.31
• [3.420 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 01/27/26 21:02:36.327
  I0127 21:02:36.327807 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename secrets @ 01/27/26 21:02:36.328
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:02:36.343
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:02:36.349
  STEP: Creating secret with name secret-test-dd69e957-aff8-4092-91a4-1adafb929a90 @ 01/27/26 21:02:36.351
  STEP: Creating a pod to test consume secrets @ 01/27/26 21:02:36.368
  E0127 21:02:37.072564      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:38.073240      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:39.073932      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:40.074164      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:02:40.392
  I0127 21:02:40.394270 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-secrets-de547e96-1e23-49ae-97e6-f56265d3f987 container secret-volume-test: <nil>
  STEP: delete the pod @ 01/27/26 21:02:40.398
  I0127 21:02:40.423205 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1726" for this suite. @ 01/27/26 21:02:40.425
• [4.116 seconds]
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:368
  STEP: Creating a kubernetes client @ 01/27/26 21:02:40.444
  I0127 21:02:40.444189 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename cronjob @ 01/27/26 21:02:40.444
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:02:40.459
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:02:40.469
  STEP: Creating a cronjob @ 01/27/26 21:02:40.471
  STEP: creating @ 01/27/26 21:02:40.471
  STEP: getting @ 01/27/26 21:02:40.48
  STEP: listing @ 01/27/26 21:02:40.481
  STEP: watching @ 01/27/26 21:02:40.483
  I0127 21:02:40.483260 26 cronjob.go:398] starting watch
  STEP: cluster-wide listing @ 01/27/26 21:02:40.484
  STEP: cluster-wide watching @ 01/27/26 21:02:40.485
  I0127 21:02:40.485980 26 cronjob.go:410] starting watch
  STEP: patching @ 01/27/26 21:02:40.486
  STEP: updating @ 01/27/26 21:02:40.495
  I0127 21:02:40.511200 26 cronjob.go:435] waiting for watch events with expected annotations
  I0127 21:02:40.511254 26 cronjob.go:449] saw patched and updated annotations
  STEP: patching /status @ 01/27/26 21:02:40.511
  STEP: updating /status @ 01/27/26 21:02:40.52
  STEP: get /status @ 01/27/26 21:02:40.53
  STEP: deleting @ 01/27/26 21:02:40.532
  STEP: deleting a collection @ 01/27/26 21:02:40.558
  I0127 21:02:40.568488 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-2199" for this suite. @ 01/27/26 21:02:40.57
• [0.134 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:348
  STEP: Creating a kubernetes client @ 01/27/26 21:02:40.577
  I0127 21:02:40.577837 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename field-validation @ 01/27/26 21:02:40.578
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:02:40.593
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:02:40.604
  I0127 21:02:40.606895 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  W0127 21:02:40.607365      26 field_validation.go:421] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc0009c1ac0 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E0127 21:02:41.075231      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:42.075760      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:43.076874      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:02:43.137279      26 warnings.go:107] "Warning: unknown field \"alpha\""
  I0127 21:02:43.137300      26 warnings.go:107] "Warning: unknown field \"beta\""
  I0127 21:02:43.137307      26 warnings.go:107] "Warning: unknown field \"delta\""
  I0127 21:02:43.137314      26 warnings.go:107] "Warning: unknown field \"epsilon\""
  I0127 21:02:43.137323      26 warnings.go:107] "Warning: unknown field \"gamma\""
  I0127 21:02:43.672149 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4324" for this suite. @ 01/27/26 21:02:43.674
• [3.104 seconds]
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:100
  STEP: Creating a kubernetes client @ 01/27/26 21:02:43.681
  I0127 21:02:43.681749 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename events @ 01/27/26 21:02:43.682
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:02:43.755
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:02:43.76
  STEP: creating a test event @ 01/27/26 21:02:43.761
  STEP: listing events in all namespaces @ 01/27/26 21:02:43.769
  STEP: listing events in test namespace @ 01/27/26 21:02:43.772
  STEP: listing events with field selection filtering on source @ 01/27/26 21:02:43.773
  STEP: listing events with field selection filtering on reportingController @ 01/27/26 21:02:43.774
  STEP: getting the test event @ 01/27/26 21:02:43.777
  STEP: patching the test event @ 01/27/26 21:02:43.778
  STEP: getting the test event @ 01/27/26 21:02:43.786
  STEP: updating the test event @ 01/27/26 21:02:43.788
  STEP: getting the test event @ 01/27/26 21:02:43.804
  STEP: deleting the test event @ 01/27/26 21:02:43.806
  STEP: listing events in all namespaces @ 01/27/26 21:02:43.834
  STEP: listing events in test namespace @ 01/27/26 21:02:43.836
  I0127 21:02:43.839063 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-4583" for this suite. @ 01/27/26 21:02:43.841
• [0.169 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/volume_attachment.go:61
  STEP: Creating a kubernetes client @ 01/27/26 21:02:43.85
  I0127 21:02:43.850865 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename volumeattachment @ 01/27/26 21:02:43.851
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:02:43.871
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:02:43.873
  STEP: Create VolumeAttachment "va-e2e-lbv2p" on node "k3k-k3kcluster-server-0" @ 01/27/26 21:02:43.946
  STEP: Get VolumeAttachment "va-e2e-lbv2p" on node "k3k-k3kcluster-server-0" @ 01/27/26 21:02:43.954
  STEP: Patch VolumeAttachment "va-e2e-lbv2p" on node "k3k-k3kcluster-server-0" @ 01/27/26 21:02:43.956
  STEP: List VolumeAttachments with "va-e2e-lbv2p=patched" label @ 01/27/26 21:02:43.964
  STEP: Delete VolumeAttachment "va-e2e-lbv2p" on node "k3k-k3kcluster-server-0" @ 01/27/26 21:02:43.966
  STEP: Confirm deletion of VolumeAttachment "va-e2e-lbv2p" on node "k3k-k3kcluster-server-0" @ 01/27/26 21:02:43.974
  STEP: Create VolumeAttachment "va-e2e-ppx9p" on node "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2" @ 01/27/26 21:02:44.043
  STEP: Update the VolumeAttachment "va-e2e-ppx9p" on node "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2" with label "va-e2e=updated" @ 01/27/26 21:02:44.059
  E0127 21:02:44.077841      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create VolumeAttachment "va-e2e-xtcx2" on node "k3k-k3kcluster-server-0" @ 01/27/26 21:02:44.144
  STEP: Update the VolumeAttachment "va-e2e-xtcx2" on node "k3k-k3kcluster-server-0" with label "va-e2e=updated" @ 01/27/26 21:02:44.158
  STEP: DeleteCollection of VolumeAttachments with "va-e2e=updated" label @ 01/27/26 21:02:44.179
  STEP: Confirm deleteCollection of VolumeAttachments with "va-e2e=updated" label @ 01/27/26 21:02:44.196
  I0127 21:02:44.199251 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "volumeattachment-1171" for this suite. @ 01/27/26 21:02:44.245
• [0.404 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:89
  STEP: Creating a kubernetes client @ 01/27/26 21:02:44.255
  I0127 21:02:44.255138 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 21:02:44.255
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:02:44.283
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:02:44.285
  STEP: Creating configMap with name projected-configmap-test-volume-map-490c80ea-978a-46dd-aa01-c902d453bf46 @ 01/27/26 21:02:44.286
  STEP: Creating a pod to test consume configMaps @ 01/27/26 21:02:44.294
  E0127 21:02:45.079432      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:46.079809      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:47.080929      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:48.081125      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:02:48.319
  I0127 21:02:48.321380 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-projected-configmaps-792b3c48-e755-4268-90ea-5e4f1d65d3ea container agnhost-container: <nil>
  STEP: delete the pod @ 01/27/26 21:02:48.325
  I0127 21:02:48.349076 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8604" for this suite. @ 01/27/26 21:02:48.351
• [4.110 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:135
  STEP: Creating a kubernetes client @ 01/27/26 21:02:48.365
  I0127 21:02:48.365724 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename runtimeclass @ 01/27/26 21:02:48.366
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:02:48.389
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:02:48.392
  E0127 21:02:49.081699      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:50.081856      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:02:50.436648 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-4737" for this suite. @ 01/27/26 21:02:50.438
• [2.081 seconds]
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 01/27/26 21:02:50.446
  I0127 21:02:50.446691 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename secrets @ 01/27/26 21:02:50.447
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:02:50.469
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:02:50.471
  STEP: Creating secret with name secret-test-map-e2deb186-691a-4e37-8f09-10cec2b45649 @ 01/27/26 21:02:50.484
  STEP: Creating a pod to test consume secrets @ 01/27/26 21:02:50.492
  E0127 21:02:51.082071      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:52.082321      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:53.082926      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:54.083231      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:02:54.515
  I0127 21:02:54.518261 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-secrets-14a5c88f-1130-466a-b9b1-63d7108c0dee container secret-volume-test: <nil>
  STEP: delete the pod @ 01/27/26 21:02:54.534
  I0127 21:02:54.561555 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-417" for this suite. @ 01/27/26 21:02:54.564
• [4.135 seconds]
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:98
  STEP: Creating a kubernetes client @ 01/27/26 21:02:54.581
  I0127 21:02:54.581504 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename secrets @ 01/27/26 21:02:54.582
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:02:54.602
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:02:54.607
  STEP: creating secret secrets-722/secret-test-d8b0c0e7-3cca-4f96-b50f-263411075e93 @ 01/27/26 21:02:54.613
  STEP: Creating a pod to test consume secrets @ 01/27/26 21:02:54.62
  E0127 21:02:55.083271      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:56.083328      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:57.084094      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:02:58.084855      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:02:58.645
  I0127 21:02:58.648107 26 output.go:207] Trying to get logs from node k3k-k3kcluster-server-0 pod pod-configmaps-a393995c-1566-4626-a352-afce5c43f042 container env-test: <nil>
  STEP: delete the pod @ 01/27/26 21:02:58.657
  I0127 21:02:58.680259 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-722" for this suite. @ 01/27/26 21:02:58.682
• [4.110 seconds]
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:944
  STEP: Creating a kubernetes client @ 01/27/26 21:02:58.691
  I0127 21:02:58.691580 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename sched-preemption @ 01/27/26 21:02:58.692
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:02:58.72
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:02:58.81
  I0127 21:02:58.835334 26 wait.go:53] Waiting up to 1m0s for all nodes to be ready
  E0127 21:02:59.085951      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:00.086109      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:01.086713      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:02.086978      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:03.087524      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:04.088041      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:05.088221      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:06.089009      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:07.089113      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:08.089333      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:09.089940      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:10.090005      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:11.090750      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:12.090960      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:13.091952      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:14.092176      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:15.092647      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:16.093453      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:17.093781      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:18.093984      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:19.094404      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:20.094901      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:21.095694      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:22.095750      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:23.096439      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:24.096667      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:25.096777      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:26.097018      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:27.097284      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:28.097517      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:29.097629      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:30.098107      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:31.099018      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:32.099771      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:33.100830      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:34.100945      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:35.101942      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:36.103035      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:37.104056      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:38.104269      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:39.104445      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:40.105043      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:41.105953      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:42.106163      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:43.106381      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:44.106587      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:45.106908      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:46.107529      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:47.108123      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:48.108804      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:49.109228      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:50.109615      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:51.110190      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:52.110384      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:53.111388      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:54.111581      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:55.112110      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:56.112314      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:57.113032      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:03:58.113787      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:03:58.838119 26 util.go:389] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 01/27/26 21:03:58.839
  I0127 21:03:58.840857 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename sched-preemption-path @ 01/27/26 21:03:58.841
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:03:58.862
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:03:58.864
  I0127 21:03:58.890059 26 preemption.go:950] PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  I0127 21:03:58.891680 26 preemption.go:956] PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  STEP: Removing a custom resource @ 01/27/26 21:03:58.96
  STEP: Removing a custom resource @ 01/27/26 21:03:58.966
  I0127 21:03:58.970942 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-2609" for this suite. @ 01/27/26 21:03:58.973
  I0127 21:03:58.988424 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-5334" for this suite. @ 01/27/26 21:03:59.074
• [60.391 seconds]
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:42
  STEP: Creating a kubernetes client @ 01/27/26 21:03:59.082
  I0127 21:03:59.082874 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename containers @ 01/27/26 21:03:59.083
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:03:59.099
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:03:59.106
  E0127 21:03:59.114664      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:00.115579      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:01.116406      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:04:01.133186 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-5587" for this suite. @ 01/27/26 21:04:01.135
• [2.061 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:92
  STEP: Creating a kubernetes client @ 01/27/26 21:04:01.143
  I0127 21:04:01.143532 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename disruption @ 01/27/26 21:04:01.144
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:04:01.173
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:04:01.176
  STEP: Creating a kubernetes client @ 01/27/26 21:04:01.178
  I0127 21:04:01.178657 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename disruption-2 @ 01/27/26 21:04:01.179
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:04:01.193
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:04:01.204
  STEP: Waiting for the pdb to be processed @ 01/27/26 21:04:01.294
  E0127 21:04:02.116875      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:03.116985      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 01/27/26 21:04:03.31
  E0127 21:04:04.118088      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:05.118264      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 01/27/26 21:04:05.321
  E0127 21:04:06.119255      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:07.120325      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: listing a collection of PDBs across all namespaces @ 01/27/26 21:04:07.325
  STEP: listing a collection of PDBs in namespace disruption-4648 @ 01/27/26 21:04:07.328
  STEP: deleting a collection of PDBs @ 01/27/26 21:04:07.33
  STEP: Waiting for the PDB collection to be deleted @ 01/27/26 21:04:07.356
  I0127 21:04:07.358920 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-4047" for this suite. @ 01/27/26 21:04:07.361
  I0127 21:04:07.368818 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-4648" for this suite. @ 01/27/26 21:04:07.468
• [6.334 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:547
  STEP: Creating a kubernetes client @ 01/27/26 21:04:07.477
  I0127 21:04:07.477346 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename gc @ 01/27/26 21:04:07.477
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:04:07.502
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:04:07.504
  STEP: create the deployment @ 01/27/26 21:04:07.506
  I0127 21:04:07.516827      26 warnings.go:107] "Warning: metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]"
  STEP: Wait for the Deployment to create new ReplicaSet @ 01/27/26 21:04:07.516
  STEP: delete the deployment @ 01/27/26 21:04:08.027
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 01/27/26 21:04:08.035
  E0127 21:04:08.120893      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 01/27/26 21:04:08.544
  W0127 21:04:08.546626      26 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I0127 21:04:08.546654 26 garbage_collector.go:273] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0127 21:04:08.546822 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-7985" for this suite. @ 01/27/26 21:04:08.548
• [1.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:849
  STEP: Creating a kubernetes client @ 01/27/26 21:04:08.556
  I0127 21:04:08.556626 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 21:04:08.557
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:04:08.572
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:04:08.581
  STEP: Setting up server cert @ 01/27/26 21:04:08.622
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 21:04:08.847
  STEP: Deploying the webhook pod @ 01/27/26 21:04:08.856
  STEP: Wait for the deployment to be ready @ 01/27/26 21:04:08.88
  I0127 21:04:08.893569 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0127 21:04:09.121496      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:10.121709      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/27/26 21:04:10.9
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 21:04:10.921
  I0127 21:04:10.921918 26 wait.go:65] Waiting for amount of service webhook-3698/e2e-test-webhook endpoints to be 1
  I0127 21:04:10.928522 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  E0127 21:04:11.121852      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: creating a mutating webhook with match conditions @ 01/27/26 21:04:11.924
  I0127 21:04:11.984449 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3698" for this suite. @ 01/27/26 21:04:11.986
  STEP: Destroying namespace "webhook-markers-1284" for this suite. @ 01/27/26 21:04:12.018
• [3.474 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:107
  STEP: Creating a kubernetes client @ 01/27/26 21:04:12.03
  I0127 21:04:12.030273 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename replication-controller @ 01/27/26 21:04:12.03
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:04:12.047
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:04:12.056
  STEP: Given a ReplicationController is created @ 01/27/26 21:04:12.059
  STEP: When the matched label of one of its pods change @ 01/27/26 21:04:12.068
  I0127 21:04:12.070753 26 resource.go:64] Pod name pod-release: Found 0 pods out of 1
  E0127 21:04:12.121921      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:13.122461      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:14.122791      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:15.123844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:16.124081      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:17.125067      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:04:17.125524 26 resource.go:64] Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 01/27/26 21:04:17.143
  E0127 21:04:18.126014      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:04:18.148529 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-8498" for this suite. @ 01/27/26 21:04:18.151
• [6.129 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 01/27/26 21:04:18.159
  I0127 21:04:18.159656 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename watch @ 01/27/26 21:04:18.16
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:04:18.181
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:04:18.185
  STEP: creating a watch on configmaps @ 01/27/26 21:04:18.187
  STEP: creating a new configmap @ 01/27/26 21:04:18.19
  STEP: modifying the configmap once @ 01/27/26 21:04:18.198
  STEP: closing the watch once it receives two notifications @ 01/27/26 21:04:18.208
  I0127 21:04:18.208667 26 watch.go:426] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5692  e64ab2d0-e39d-414d-a6e8-52fde43157ea 27523 0 2026-01-27 21:04:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2026-01-27 21:04:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0127 21:04:18.208824 26 watch.go:426] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5692  e64ab2d0-e39d-414d-a6e8-52fde43157ea 27524 0 2026-01-27 21:04:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2026-01-27 21:04:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 01/27/26 21:04:18.208
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 01/27/26 21:04:18.219
  STEP: deleting the configmap @ 01/27/26 21:04:18.221
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 01/27/26 21:04:18.239
  I0127 21:04:18.239573 26 watch.go:426] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5692  e64ab2d0-e39d-414d-a6e8-52fde43157ea 27525 0 2026-01-27 21:04:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2026-01-27 21:04:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0127 21:04:18.239719 26 watch.go:426] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5692  e64ab2d0-e39d-414d-a6e8-52fde43157ea 27526 0 2026-01-27 21:04:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2026-01-27 21:04:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0127 21:04:18.239874 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-5692" for this suite. @ 01/27/26 21:04:18.252
• [0.107 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Pod InPlace Resize Container burstable pods - extended resize with equivalents [MinimumKubeletVersion:1.34] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pod_resize.go:350
  STEP: Creating a kubernetes client @ 01/27/26 21:04:18.266
  I0127 21:04:18.266922 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pod-resize-tests @ 01/27/26 21:04:18.267
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:04:18.283
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:04:18.285
  STEP: creating and verifying pod @ 01/27/26 21:04:18.352
  E0127 21:04:19.126738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:20.126958      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:21.127586      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:22.127765      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:23.128942      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:24.129159      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:25.129689      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:26.130494      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:04:26.388405 26 cgroups.go:379] Namespace pod-resize-tests-6342 Pod resize-test-qvr6z Container c1 - looking for one of the expected cgroup values [max] in path /sys/fs/cgroup/memory.max
  I0127 21:04:26.388441 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-6342 PodName:resize-test-qvr6z ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:04:26.388451 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:04:26.388499 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-6342/pods/resize-test-qvr6z/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c1&stderr=true&stdout=true)
  E0127 21:04:27.130986      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:28.131183      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:29.131397      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:04:30.022836 26 cgroups.go:379] Namespace pod-resize-tests-6342 Pod resize-test-qvr6z Container c1 - looking for one of the expected cgroup values [1000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:04:30.022880 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-6342 PodName:resize-test-qvr6z ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:04:30.022891 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:04:30.022936 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-6342/pods/resize-test-qvr6z/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c1&stderr=true&stdout=true)
  E0127 21:04:30.132414      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:31.132639      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:32.132850      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:33.133199      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:04:33.521365 26 cgroups.go:379] Namespace pod-resize-tests-6342 Pod resize-test-qvr6z Container c1 - looking for one of the expected cgroup values [1 1] in path /sys/fs/cgroup/cpu.weight
  I0127 21:04:33.521409 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-6342 PodName:resize-test-qvr6z ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:04:33.521419 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:04:33.521463 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-6342/pods/resize-test-qvr6z/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c1&stderr=true&stdout=true)
  E0127 21:04:34.133872      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:35.134138      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:36.134349      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: patching and verifying pod for resize @ 01/27/26 21:04:37.021
  E0127 21:04:37.135285      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:38.135498      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:04:39.044815 26 cgroups.go:379] Namespace pod-resize-tests-6342 Pod resize-test-qvr6z Container c1 - looking for one of the expected cgroup values [max] in path /sys/fs/cgroup/memory.max
  I0127 21:04:39.044853 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-6342 PodName:resize-test-qvr6z ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:04:39.044865 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:04:39.044900 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-6342/pods/resize-test-qvr6z/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c1&stderr=true&stdout=true)
  E0127 21:04:39.136541      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:40.136779      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:41.137471      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:42.138096      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:04:42.529265 26 cgroups.go:379] Namespace pod-resize-tests-6342 Pod resize-test-qvr6z Container c1 - looking for one of the expected cgroup values [1000 100000 1000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:04:42.529313 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-6342 PodName:resize-test-qvr6z ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:04:42.529326 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:04:42.529368 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-6342/pods/resize-test-qvr6z/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c1&stderr=true&stdout=true)
  E0127 21:04:43.138945      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:44.139148      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:45.139284      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:46.139483      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:04:46.227158 26 cgroups.go:379] Namespace pod-resize-tests-6342 Pod resize-test-qvr6z Container c1 - looking for one of the expected cgroup values [1 1] in path /sys/fs/cgroup/cpu.weight
  I0127 21:04:46.227208 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-6342 PodName:resize-test-qvr6z ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:04:46.227225 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:04:46.227281 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-6342/pods/resize-test-qvr6z/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c1&stderr=true&stdout=true)
  E0127 21:04:47.139812      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:48.140861      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:49.141104      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: patching and verifying pod for rollback @ 01/27/26 21:04:49.527
  E0127 21:04:50.141776      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:51.141959      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:04:51.554065 26 cgroups.go:379] Namespace pod-resize-tests-6342 Pod resize-test-qvr6z Container c1 - looking for one of the expected cgroup values [max] in path /sys/fs/cgroup/memory.max
  I0127 21:04:51.554103 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-6342 PodName:resize-test-qvr6z ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:04:51.554114 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:04:51.554159 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-6342/pods/resize-test-qvr6z/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c1&stderr=true&stdout=true)
  E0127 21:04:52.142487      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:53.143293      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:54.143550      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:55.143756      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:04:55.322933 26 cgroups.go:379] Namespace pod-resize-tests-6342 Pod resize-test-qvr6z Container c1 - looking for one of the expected cgroup values [1000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:04:55.322975 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-6342 PodName:resize-test-qvr6z ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:04:55.322985 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:04:55.323030 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-6342/pods/resize-test-qvr6z/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c1&stderr=true&stdout=true)
  E0127 21:04:56.143917      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:57.144807      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:04:58.145522      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:04:58.721520 26 cgroups.go:379] Namespace pod-resize-tests-6342 Pod resize-test-qvr6z Container c1 - looking for one of the expected cgroup values [1 1] in path /sys/fs/cgroup/cpu.weight
  I0127 21:04:58.721562 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-6342 PodName:resize-test-qvr6z ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:04:58.721573 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:04:58.721625 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-6342/pods/resize-test-qvr6z/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c1&stderr=true&stdout=true)
  E0127 21:04:59.145867      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:00.146198      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:01.146396      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting pod @ 01/27/26 21:05:02.028
  I0127 21:05:02.070072 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-resize-tests-6342" for this suite. @ 01/27/26 21:05:02.072
• [43.814 seconds]
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet_etc_hosts.go:65
  STEP: Creating a kubernetes client @ 01/27/26 21:05:02.081
  I0127 21:05:02.081125 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 01/27/26 21:05:02.081
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:05:02.106
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:05:02.108
  STEP: Setting up the test @ 01/27/26 21:05:02.111
  STEP: Creating hostNetwork=false pod @ 01/27/26 21:05:02.111
  E0127 21:05:02.147073      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:03.147363      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating hostNetwork=true pod @ 01/27/26 21:05:04.133
  E0127 21:05:04.148436      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:05.149728      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Running the test @ 01/27/26 21:05:06.149
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 01/27/26 21:05:06.149
  I0127 21:05:06.149195 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3193 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:05:06.149211 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:05:06.149247 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3193/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&stderr=true&stdout=true)
  E0127 21:05:06.150247      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:05:06.205781 26 exec_util.go:112] Exec stderr: ""
  I0127 21:05:06.205825 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3193 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:05:06.205840 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:05:06.205884 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3193/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&stderr=true&stdout=true)
  I0127 21:05:06.255566 26 exec_util.go:112] Exec stderr: ""
  I0127 21:05:06.255638 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3193 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:05:06.255648 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:05:06.255698 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3193/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&stderr=true&stdout=true)
  I0127 21:05:06.307661 26 exec_util.go:112] Exec stderr: ""
  I0127 21:05:06.307709 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3193 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:05:06.307724 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:05:06.307769 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3193/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&stderr=true&stdout=true)
  I0127 21:05:06.357812 26 exec_util.go:112] Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 01/27/26 21:05:06.357
  I0127 21:05:06.357880 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3193 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:05:06.357890 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:05:06.357935 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3193/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&stderr=true&stdout=true)
  I0127 21:05:06.403346 26 exec_util.go:112] Exec stderr: ""
  I0127 21:05:06.403388 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3193 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:05:06.403398 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:05:06.403446 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3193/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&stderr=true&stdout=true)
  I0127 21:05:06.450617 26 exec_util.go:112] Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 01/27/26 21:05:06.45
  I0127 21:05:06.450687 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3193 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:05:06.450696 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:05:06.450741 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3193/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&stderr=true&stdout=true)
  I0127 21:05:06.494461 26 exec_util.go:112] Exec stderr: ""
  I0127 21:05:06.494506 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3193 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:05:06.494515 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:05:06.494562 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3193/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&stderr=true&stdout=true)
  I0127 21:05:06.538739 26 exec_util.go:112] Exec stderr: ""
  I0127 21:05:06.538782 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3193 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:05:06.538791 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:05:06.538835 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3193/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&stderr=true&stdout=true)
  I0127 21:05:06.582811 26 exec_util.go:112] Exec stderr: ""
  I0127 21:05:06.582856 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3193 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:05:06.582865 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:05:06.582911 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3193/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&stderr=true&stdout=true)
  I0127 21:05:06.626698 26 exec_util.go:112] Exec stderr: ""
  I0127 21:05:06.626822 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-3193" for this suite. @ 01/27/26 21:05:06.629
• [4.561 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 01/27/26 21:05:06.642
  I0127 21:05:06.642454 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename secrets @ 01/27/26 21:05:06.643
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:05:06.664
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:05:06.666
  STEP: Creating secret with name secret-test-86f71402-ca7d-46b0-b694-e69b24c3f5fa @ 01/27/26 21:05:06.669
  STEP: Creating a pod to test consume secrets @ 01/27/26 21:05:06.682
  E0127 21:05:07.151093      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:08.151294      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:09.152322      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:10.152854      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:05:10.709
  I0127 21:05:10.711235 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-secrets-ac36c344-64b8-439b-a15d-059d1a0dd589 container secret-volume-test: <nil>
  STEP: delete the pod @ 01/27/26 21:05:10.716
  I0127 21:05:10.750655 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9530" for this suite. @ 01/27/26 21:05:10.763
• [4.130 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support a Service with multiple endpoint IPs specified in multiple EndpointSlices [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:570
  STEP: Creating a kubernetes client @ 01/27/26 21:05:10.772
  I0127 21:05:10.772358 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename endpointslice @ 01/27/26 21:05:10.773
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:05:10.798
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:05:10.8
  E0127 21:05:11.152917      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:12.153892      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:13.154761      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:14.154964      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: creating @ 01/27/26 21:05:14.867
  STEP: Creating a pause pods that will try to connect to the webserver @ 01/27/26 21:05:14.889
  E0127 21:05:15.155518      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:16.155768      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:05:16.930764 26 util.go:162] Waiting up to 2m0s to get response from 10.53.176.237:80
  I0127 21:05:16.930833 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=endpointslice-5416 exec pause-pod-0 -- /bin/sh -x -c curl -q -s --max-time 30 10.53.176.237:80/hostname'
  I0127 21:05:17.038218 26 builder.go:156] stderr: "+ curl -q -s --max-time 30 10.53.176.237:80/hostname\n"
  I0127 21:05:17.038262 26 builder.go:157] stdout: "pod1-handle-http-request"
  I0127 21:05:17.038284 26 util.go:162] Waiting up to 2m0s to get response from 10.53.176.237:81
  I0127 21:05:17.038323 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=endpointslice-5416 exec pause-pod-0 -- /bin/sh -x -c curl -q -s --max-time 30 10.53.176.237:81/hostname'
  I0127 21:05:17.144319 26 builder.go:156] stderr: "+ curl -q -s --max-time 30 10.53.176.237:81/hostname\n"
  I0127 21:05:17.144370 26 builder.go:157] stdout: "pod2-handle-http-request"
  I0127 21:05:17.144511 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-5416" for this suite. @ 01/27/26 21:05:17.146
• [6.383 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:87
  STEP: Creating a kubernetes client @ 01/27/26 21:05:17.155
  I0127 21:05:17.155429 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  E0127 21:05:17.156259      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Building a namespace api object, basename resourcequota @ 01/27/26 21:05:17.156
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:05:17.182
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:05:17.185
  STEP: Counting existing ResourceQuota @ 01/27/26 21:05:17.189
  E0127 21:05:18.157265      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:19.158255      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:20.158574      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:21.158959      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:22.159690      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 01/27/26 21:05:22.219
  STEP: Ensuring resource quota status is calculated @ 01/27/26 21:05:22.231
  E0127 21:05:23.160458      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:24.160529      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:05:24.240668 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc000f8b540>: 
          metadata:
            creationTimestamp: "2026-01-27T21:05:22Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:05:22Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T21:05:22Z"
            name: test-quota
            namespace: resourcequota-8666
            resourceVersion: "27903"
            uid: 27732641-0df6-493d-bbdc-9e8fd6972b6f
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  I0127 21:05:24.241250 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8666" for this suite. @ 01/27/26 21:05:24.244
• [7.103 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:157
  STEP: Creating a kubernetes client @ 01/27/26 21:05:24.259
  I0127 21:05:24.259022 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 01/27/26 21:05:24.259
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:05:24.279
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:05:24.281
  STEP: create the container to handle the HTTPGet hook request. @ 01/27/26 21:05:24.344
  E0127 21:05:25.160604      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:26.160777      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 01/27/26 21:05:26.366
  E0127 21:05:27.161398      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:28.161535      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 01/27/26 21:05:28.387
  E0127 21:05:29.162081      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:30.162318      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 01/27/26 21:05:30.399
  I0127 21:05:30.407901 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-5188" for this suite. @ 01/27/26 21:05:30.411
• [6.177 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [LinuxOnly] [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:102
  STEP: Creating a kubernetes client @ 01/27/26 21:05:30.435
  I0127 21:05:30.435953 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename aggregator @ 01/27/26 21:05:30.436
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:05:30.458
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:05:30.468
  I0127 21:05:30.470345 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Registering the sample API server. @ 01/27/26 21:05:30.471
  I0127 21:05:30.645567 26 helpers.go:191] Found ClusterRoles; assuming RBAC is enabled.
  I0127 21:05:30.683655 26 deployment.go:223] new replicaset for deployment "sample-apiserver-deployment" is yet to be created
  E0127 21:05:31.163344      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:32.163570      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:05:32.741378 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc006059070), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-776485db45\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:05:33.163718      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:34.163788      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:05:34.744853 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc0060593d0), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-776485db45\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:05:35.163931      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:36.164818      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:05:36.773242 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc003714220), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-776485db45\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:05:37.166092      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:38.166274      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:05:38.744459 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc003714490), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-776485db45\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:05:39.167108      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:40.167306      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:05:40.743991 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc0030bb070), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-776485db45\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:05:41.168328      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:42.169275      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:05:42.744011 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc003714720), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-776485db45\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:05:43.169577      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:44.170153      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:05:44.744031 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc003714990), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-776485db45\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:05:45.170522      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:46.171185      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:05:46.744220 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc0030bb2e0), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-776485db45\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:05:47.171637      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:48.171771      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:05:48.743427 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc0030bb550), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-776485db45\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:05:49.173128      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:50.173324      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:05:50.745142 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc003714be0), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-776485db45\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:05:51.173779      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:52.174012      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:05:52.744327 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc0060596d0), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-776485db45\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:05:53.174861      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:54.175122      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:05:54.867098 26 aggregator.go:762] Waited 108.821586ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 01/27/26 21:05:54.918
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 01/27/26 21:05:54.919
  STEP: List APIServices @ 01/27/26 21:05:54.935
  I0127 21:05:54.938851 26 aggregator.go:563] Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 01/27/26 21:05:54.938
  I0127 21:05:54.957447 26 aggregator.go:588] APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 01/27/26 21:05:54.957
  I0127 21:05:54.972947 26 aggregator.go:614] updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 54, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 01/27/26 21:05:54.972
  I0127 21:05:54.974585 26 aggregator.go:632] Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2026-01-27 21:05:54 +0000 UTC Passed all checks passed}
  I0127 21:05:54.974617 26 aggregator.go:628] Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0127 21:05:54.974628 26 aggregator.go:638] Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 01/27/26 21:05:54.974
  I0127 21:05:54.989943 26 aggregator.go:654] Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-424353644" @ 01/27/26 21:05:54.989
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 01/27/26 21:05:55.004
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 01/27/26 21:05:55.017
  STEP: Patch APIService Status @ 01/27/26 21:05:55.019
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 01/27/26 21:05:55.038
  I0127 21:05:55.040909 26 aggregator.go:732] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2026-01-27 21:05:54 +0000 UTC Passed all checks passed}
  I0127 21:05:55.040950 26 aggregator.go:732] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0127 21:05:55.040962 26 aggregator.go:728] Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  I0127 21:05:55.040973 26 aggregator.go:738] Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 01/27/26 21:05:55.04
  STEP: Confirm that the generated APIService has been deleted @ 01/27/26 21:05:55.049
  I0127 21:05:55.049547 26 aggregator.go:799] Requesting list of APIServices to confirm quantity
  I0127 21:05:55.051440 26 aggregator.go:809] Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  I0127 21:05:55.051481 26 aggregator.go:751] APIService v1alpha1.wardle.example.com has been deleted.
  E0127 21:05:55.175128      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:05:55.183329 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-9604" for this suite. @ 01/27/26 21:05:55.186
• [24.759 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:693
  STEP: Creating a kubernetes client @ 01/27/26 21:05:55.194
  I0127 21:05:55.194820 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pv @ 01/27/26 21:05:55.195
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:05:55.221
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:05:55.227
  STEP: Creating initial PV and PVC @ 01/27/26 21:05:55.23
  I0127 21:05:55.230424 26 pv.go:394] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-3323" @ 01/27/26 21:05:55.267
  STEP: Listing PVCs in namespace "pv-3323" @ 01/27/26 21:05:55.269
  STEP: Reading "pvc-dvdrf" Status @ 01/27/26 21:05:55.276
  STEP: Reading "pv-3323-zztds" Status @ 01/27/26 21:05:55.278
  STEP: Patching "pvc-dvdrf" Status @ 01/27/26 21:05:55.291
  STEP: Patching "pv-3323-zztds" Status @ 01/27/26 21:05:55.325
  STEP: Updating "pvc-dvdrf" Status @ 01/27/26 21:05:55.334
  STEP: Updating "pv-3323-zztds" Status @ 01/27/26 21:05:55.35
  I0127 21:05:55.361271 26 persistent_volumes.go:427] AfterEach: deleting 1 PVCs and 1 PVs...
  I0127 21:05:55.361692 26 pv.go:205] Deleting PersistentVolumeClaim "pvc-dvdrf"
  I0127 21:05:55.385234 26 pv.go:193] Deleting PersistentVolume "pv-3323-zztds"
  I0127 21:05:55.394066 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-3323" for this suite. @ 01/27/26 21:05:55.401
• [0.225 seconds]
------------------------------
SS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:134
  STEP: Creating a kubernetes client @ 01/27/26 21:05:55.419
  I0127 21:05:55.419767 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename deployment @ 01/27/26 21:05:55.42
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:05:55.437
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:05:55.443
  I0127 21:05:55.469800 26 resource.go:64] Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 01/27/26 21:05:55.469
  E0127 21:05:56.176266      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:57.176480      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:05:57.474304 26 deployment.go:934] Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E0127 21:05:58.176841      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:05:59.177065      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:05:59.476835 26 deployment.go:944] Creating deployment "test-rollover-deployment"
  I0127 21:05:59.492229 26 deployment.go:957] Make sure deployment "test-rollover-deployment" performs scaling operations
  E0127 21:06:00.177507      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:01.177710      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:06:01.496502 26 deployment.go:962] Check revision of new replica set for deployment "test-rollover-deployment"
  I0127 21:06:01.500228 26 deployment.go:966] Ensure that both replica sets have 1 created replica
  I0127 21:06:01.503421 26 deployment.go:975] Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  I0127 21:06:01.524971 26 deployment.go:314] Updating deployment test-rollover-deployment
  I0127 21:06:01.525015 26 deployment.go:984] Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E0127 21:06:02.178824      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:03.179025      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:06:03.530219 26 deployment.go:989] Wait for revision update of deployment "test-rollover-deployment" to 2
  I0127 21:06:03.533915 26 deployment.go:993] Make sure deployment "test-rollover-deployment" is complete
  I0127 21:06:03.635358 26 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0127 21:06:03.635414 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc002d6d124), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 59, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 59, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 6, 2, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7c87fbb999\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:06:04.179690      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:05.179938      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:06:05.642343 26 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0127 21:06:05.642402 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc002d6d8d4), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 59, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 59, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 6, 2, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7c87fbb999\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:06:06.180834      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:07.181059      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:06:07.639811 26 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0127 21:06:07.639912 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc002d6daa4), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 59, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 59, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 6, 2, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7c87fbb999\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:06:08.181219      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:09.181886      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:06:09.640161 26 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0127 21:06:09.640219 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc0025f47b4), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 59, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 59, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 6, 2, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7c87fbb999\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:06:10.182495      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:11.182751      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:06:11.645048 26 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0127 21:06:11.645101 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc0025ad184), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 5, 59, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 59, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 6, 2, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 5, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7c87fbb999\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:06:12.183677      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:13.183761      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:06:13.640909 26 deployment.go:95] 
  I0127 21:06:13.640970 26 deployment.go:997] Ensure that both old replica sets have no replicas
  I0127 21:06:13.663454 26 deployment.go:636] Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6969",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f544b8ed-7aee-4c80-af34-68b569a02761",
      ResourceVersion: (string) (len=5) "28310",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905144759,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144761,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144772,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 74 65 72  |licas":{},"f:ter|
              000001f0  6d 69 6e 61 74 69 6e 67  52 65 70 6c 69 63 61 73  |minatingReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(0),
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144759,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144759,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144772,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144759,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-7c87fbb999\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0127 21:06:13.742098 26 deployment.go:40] New ReplicaSet "test-rollover-deployment-7c87fbb999" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-7c87fbb999",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6969",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "10dfbb11-643a-424b-89a2-f1b57947c640",
      ResourceVersion: (string) (len=5) "28300",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905144761,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7c87fbb999"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "f544b8ed-7aee-4c80-af34-68b569a02761",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144761,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 66 35 34 34 62 38  65 64 2d 37 61 65 65 2d  |\"f544b8ed-7aee-|
              00000120  34 63 38 30 2d 61 66 33  34 2d 36 38 62 35 36 39  |4c80-af34-68b569|
              00000130  61 30 32 37 36 31 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |a02761\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144772,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=157) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6e 67 52  |,"f:terminatingR|
              00000090  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "7c87fbb999"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7c87fbb999"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      TerminatingReplicas: (*int32)(0),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0127 21:06:13.742845 26 deployment.go:45] All old ReplicaSets of Deployment "test-rollover-deployment":
  I0127 21:06:13.743301 26 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6969",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8188bc2a-62b0-4c9e-9635-e033f1a72f66",
      ResourceVersion: (string) (len=5) "28309",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905144755,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=7) "agnhost"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "f544b8ed-7aee-4c80-af34-68b569a02761",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144755,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=469) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 61 67  6e 68 6f 73 74 5c 22 7d  |e\":\"agnhost\"}|
              000000d0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              000000e0  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              000000f0  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000100  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000110  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000120  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000130  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000140  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000150  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              00000160  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              00000170  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              00000180  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              00000190  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001a0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001b0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              000001c0  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              000001d0  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144772,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  66 35 34 34 62 38 65 64  2d 37 61 65 65 2d 34 63  |f544b8ed-7aee-4c|
              000000c0  38 30 2d 61 66 33 34 2d  36 38 62 35 36 39 61 30  |80-af34-68b569a0|
              000000d0  32 37 36 31 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |2761\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144772,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=83) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |as":{},"f:termin|
              00000040  61 74 69 6e 67 52 65 70  6c 69 63 61 73 22 3a 7b  |atingReplicas":{|
              00000050  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=7) "agnhost"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=7) "agnhost"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(0),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0127 21:06:13.744224 26 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-5b8676cffc",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6969",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2268be94-cfb5-471b-aa40-7dcecb8d6ab3",
      ResourceVersion: (string) (len=5) "28258",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905144759,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5b8676cffc"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "f544b8ed-7aee-4c80-af34-68b569a02761",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144761,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 66 35 34 34 62 38  65 64 2d 37 61 65 65 2d  |\"f544b8ed-7aee-|
              00000120  34 63 38 30 2d 61 66 33  34 2d 36 38 62 35 36 39  |4c80-af34-68b569|
              00000130  61 30 32 37 36 31 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |a02761\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144761,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=83) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |as":{},"f:termin|
              00000040  61 74 69 6e 67 52 65 70  6c 69 63 61 73 22 3a 7b  |atingReplicas":{|
              00000050  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5b8676cffc"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5b8676cffc"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(0),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0127 21:06:13.747481 26 deployment.go:68] Pod "test-rollover-deployment-7c87fbb999-fdf9z" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-7c87fbb999-fdf9z",
      GenerateName: (string) (len=36) "test-rollover-deployment-7c87fbb999-",
      Namespace: (string) (len=15) "deployment-6969",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e9b33601-e31c-45cc-a5e9-51f48262a6f7",
      ResourceVersion: (string) (len=5) "28268",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905144761,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7c87fbb999"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-7c87fbb999",
          UID: (types.UID) (len=36) "10dfbb11-643a-424b-89a2-f1b57947c640",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144761,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  64 66 62 62 31 31 2d 36  |d\":\"10dfbb11-6|
              00000090  34 33 61 2d 34 32 34 62  2d 38 39 61 32 2d 66 31  |43a-424b-89a2-f1|
              000000a0  62 35 37 39 34 37 63 36  34 30 5c 22 7d 22 3a 7b  |b57947c640\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144762,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=850) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 35  |k:{\"ip\":\"10.5|
              00000320  32 2e 30 2e 31 37 31 5c  22 7d 22 3a 7b 22 2e 22  |2.0.171\"}":{"."|
              00000330  3a 7b 7d 2c 22 66 3a 69  70 22 3a 7b 7d 7d 7d 2c  |:{},"f:ip":{}}},|
              00000340  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              00000350  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-287p2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-287p2",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144762,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144761,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144762,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144762,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144761,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.12",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.12"
        }
      },
      PodIP: (string) (len=11) "10.52.0.171",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.52.0.171"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905144761,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63905144762,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:10ed98804c877e505e17bced991682b6fd50ab1da9cddcd19935b48d645da40a",
          ContainerID: (string) (len=77) "containerd://ffe7b202a8209db1db89b483e1debc518da6586a0176369f59574771577a1524",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-287p2",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:06:13.749545 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6969" for this suite. @ 01/27/26 21:06:13.752
• [18.354 seconds]
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:124
  STEP: Creating a kubernetes client @ 01/27/26 21:06:13.774
  I0127 21:06:13.774555 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename deployment @ 01/27/26 21:06:13.775
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:06:13.791
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:06:13.805
  I0127 21:06:13.833875 26 resource.go:64] Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 01/27/26 21:06:13.833
  E0127 21:06:14.184487      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:15.184906      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:06:15.839522 26 deployment.go:858] Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 01/27/26 21:06:15.856
  I0127 21:06:15.866941 26 deployment.go:636] Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a1a29b33-0eb7-4c6c-a1b8-7f0d24b7f75c",
      ResourceVersion: (string) (len=5) "28342",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905144775,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144775,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 0,
      Replicas: (int32) 0,
      UpdatedReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      Conditions: ([]v1.DeploymentCondition) <nil>,
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0127 21:06:15.881495 26 deployment.go:42] New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
  I0127 21:06:15.881533 26 deployment.go:45] All old ReplicaSets of Deployment "test-cleanup-deployment":
  I0127 21:06:15.881721 26 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b59029d5-4fc9-45dc-9e11-5f9d4b237e7a",
      ResourceVersion: (string) (len=5) "28343",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905144773,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=7) "agnhost"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "a1a29b33-0eb7-4c6c-a1b8-7f0d24b7f75c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144773,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=485) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000050  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000060  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000070  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000080  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000090  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              000000a0  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000b0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000c0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000d0  65 5c 22 3a 5c 22 61 67  6e 68 6f 73 74 5c 22 7d  |e\":\"agnhost\"}|
              000000e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              000000f0  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000100  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000110  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000120  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000130  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000140  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000160  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              00000170  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              00000180  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              00000190  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001a0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001b0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001c0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              000001d0  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              000001e0  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144775,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=103) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000020  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              00000030  22 75 69 64 5c 22 3a 5c  22 61 31 61 32 39 62 33  |"uid\":\"a1a29b3|
              00000040  33 2d 30 65 62 37 2d 34  63 36 63 2d 61 31 62 38  |3-0eb7-4c6c-a1b8|
              00000050  2d 37 66 30 64 32 34 62  37 66 37 35 63 5c 22 7d  |-7f0d24b7f75c\"}|
              00000060  22 3a 7b 7d 7d 7d 7d                              |":{}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144775,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=157) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6e 67 52  |,"f:terminatingR|
              00000090  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=3) "pod": (string) (len=7) "agnhost"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "pod": (string) (len=7) "agnhost",
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      TerminatingReplicas: (*int32)(0),
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0127 21:06:15.904181 26 deployment.go:68] Pod "test-cleanup-controller-7xktz" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=29) "test-cleanup-controller-7xktz",
      GenerateName: (string) (len=24) "test-cleanup-controller-",
      Namespace: (string) (len=15) "deployment-6205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e70f39d2-c3e2-45ea-80b9-c5b0ddc75686",
      ResourceVersion: (string) (len=5) "28340",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905144773,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=7) "agnhost"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=23) "test-cleanup-controller",
          UID: (types.UID) (len=36) "b59029d5-4fc9-45dc-9e11-5f9d4b237e7a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144773,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=502) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 2c 22 66  |},"f:pod":{}},"f|
              00000050  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000060  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000070  75 69 64 5c 22 3a 5c 22  62 35 39 30 32 39 64 35  |uid\":\"b59029d5|
              00000080  2d 34 66 63 39 2d 34 35  64 63 2d 39 65 31 31 2d  |-4fc9-45dc-9e11-|
              00000090  35 66 39 64 34 62 32 33  37 65 37 61 5c 22 7d 22  |5f9d4b237e7a\"}"|
              000000a0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000b0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000c0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 61  |"k:{\"name\":\"a|
              000000d0  67 6e 68 6f 73 74 5c 22  7d 22 3a 7b 22 2e 22 3a  |gnhost\"}":{".":|
              000000e0  7b 7d 2c 22 66 3a 69 6d  61 67 65 22 3a 7b 7d 2c  |{},"f:image":{},|
              000000f0  22 66 3a 69 6d 61 67 65  50 75 6c 6c 50 6f 6c 69  |"f:imagePullPoli|
              00000100  63 79 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |cy":{},"f:name":|
              00000110  7b 7d 2c 22 66 3a 72 65  73 6f 75 72 63 65 73 22  |{},"f:resources"|
              00000120  3a 7b 7d 2c 22 66 3a 74  65 72 6d 69 6e 61 74 69  |:{},"f:terminati|
              00000130  6f 6e 4d 65 73 73 61 67  65 50 61 74 68 22 3a 7b  |onMessagePath":{|
              00000140  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000150  4d 65 73 73 61 67 65 50  6f 6c 69 63 79 22 3a 7b  |MessagePolicy":{|
              00000160  7d 7d 7d 2c 22 66 3a 64  6e 73 50 6f 6c 69 63 79  |}}},"f:dnsPolicy|
              00000170  22 3a 7b 7d 2c 22 66 3a  65 6e 61 62 6c 65 53 65  |":{},"f:enableSe|
              00000180  72 76 69 63 65 4c 69 6e  6b 73 22 3a 7b 7d 2c 22  |rviceLinks":{},"|
              00000190  66 3a 72 65 73 74 61 72  74 50 6f 6c 69 63 79 22  |f:restartPolicy"|
              000001a0  3a 7b 7d 2c 22 66 3a 73  63 68 65 64 75 6c 65 72  |:{},"f:scheduler|
              000001b0  4e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |Name":{},"f:secu|
              000001c0  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              000001d0  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 47 72  |"f:terminationGr|
              000001e0  61 63 65 50 65 72 69 6f  64 53 65 63 6f 6e 64 73  |acePeriodSeconds|
              000001f0  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144775,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=849) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 35  |k:{\"ip\":\"10.5|
              00000320  32 2e 31 2e 33 33 5c 22  7d 22 3a 7b 22 2e 22 3a  |2.1.33\"}":{".":|
              00000330  7b 7d 2c 22 66 3a 69 70  22 3a 7b 7d 7d 7d 2c 22  |{},"f:ip":{}}},"|
              00000340  66 3a 73 74 61 72 74 54  69 6d 65 22 3a 7b 7d 7d  |f:startTime":{}}|
              00000350  7d                                                |}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-wrpb7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-wrpb7",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)(<nil>),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144775,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144773,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144775,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144775,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905144773,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.10",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.10"
        }
      },
      PodIP: (string) (len=10) "10.52.1.33",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.52.1.33"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905144773,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63905144774,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:10ed98804c877e505e17bced991682b6fd50ab1da9cddcd19935b48d645da40a",
          ContainerID: (string) (len=77) "containerd://02881e835935c8c7eba2daae042430f9f81b60b47b3f0f8ffb5b3867224feaba",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-wrpb7",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:06:15.905678 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6205" for this suite. @ 01/27/26 21:06:15.922
• [2.171 seconds]
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 01/27/26 21:06:15.944
  I0127 21:06:15.945007 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 21:06:15.945
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:06:15.991
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:06:15.993
  STEP: Creating projection with secret that has name projected-secret-test-map-684dca8f-4b87-4a61-9917-6b3253328818 @ 01/27/26 21:06:15.995
  STEP: Creating a pod to test consume secrets @ 01/27/26 21:06:16.01
  E0127 21:06:16.185312      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:17.185514      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:18.186435      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:19.186863      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:06:20.029
  I0127 21:06:20.031808 26 output.go:207] Trying to get logs from node k3k-k3kcluster-server-0 pod pod-projected-secrets-20f34025-cf9d-4b0f-a5d5-3518ff925f06 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 01/27/26 21:06:20.037
  I0127 21:06:20.082515 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4817" for this suite. @ 01/27/26 21:06:20.085
• [4.148 seconds]
------------------------------
S
------------------------------
[sig-network] EndpointsController should create and delete Endpoints for a Service with a selector that matches no pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpoints.go:254
  STEP: Creating a kubernetes client @ 01/27/26 21:06:20.092
  I0127 21:06:20.092606 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename endpoints @ 01/27/26 21:06:20.093
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:06:20.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:06:20.123
  I0127 21:06:20.144128      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  E0127 21:06:20.187406      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:21.187719      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:06:22.145379      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0127 21:06:22.188229      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0127 21:06:22.188370 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0127 21:06:22.188523      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Destroying namespace "endpoints-8440" for this suite. @ 01/27/26 21:06:22.191
• [2.107 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:402
  STEP: Creating a kubernetes client @ 01/27/26 21:06:22.199
  I0127 21:06:22.199265 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pods @ 01/27/26 21:06:22.2
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:06:22.221
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:06:22.222
  STEP: creating the pod @ 01/27/26 21:06:22.224
  STEP: submitting the pod to kubernetes @ 01/27/26 21:06:22.224
  I0127 21:06:22.240501      26 warnings.go:107] "Warning: metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]"
  E0127 21:06:23.188839      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:24.188950      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 01/27/26 21:06:24.247
  STEP: updating the pod @ 01/27/26 21:06:24.248
  I0127 21:06:24.762012 26 pod_client.go:187] Successfully updated pod "pod-update-activedeadlineseconds-a03f025a-f4cb-4ec4-a6a1-6041a3c5cce4"
  E0127 21:06:25.189641      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:26.189849      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:27.190869      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:28.191330      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:06:28.771211 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-893" for this suite. @ 01/27/26 21:06:28.773
• [6.588 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:194
  STEP: Creating a kubernetes client @ 01/27/26 21:06:28.787
  I0127 21:06:28.787803 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename aggregateddiscovery @ 01/27/26 21:06:28.788
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:06:28.808
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:06:28.811
  I0127 21:06:28.823684 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  E0127 21:06:29.191386      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:30.191754      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:31.192851      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:06:31.875001 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-2149" for this suite. @ 01/27/26 21:06:31.877
• [3.108 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:229
  STEP: Creating a kubernetes client @ 01/27/26 21:06:31.895
  I0127 21:06:31.895630 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename emptydir @ 01/27/26 21:06:31.896
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:06:31.918
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:06:31.922
  STEP: Creating Pod @ 01/27/26 21:06:31.924
  E0127 21:06:32.193056      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:33.193327      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 01/27/26 21:06:33.944
  I0127 21:06:33.944155 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-4338 PodName:pod-sharedvolume-b7458744-03e4-48e7-9644-2dfc78608286 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:06:33.944171 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:06:33.944211 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/emptydir-4338/pods/pod-sharedvolume-b7458744-03e4-48e7-9644-2dfc78608286/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&stderr=true&stdout=true)
  I0127 21:06:33.988184 26 exec_util.go:112] Exec stderr: ""
  I0127 21:06:33.988332 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4338" for this suite. @ 01/27/26 21:06:33.99
• [2.108 seconds]
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:307
  STEP: Creating a kubernetes client @ 01/27/26 21:06:34.003
  I0127 21:06:34.003929 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename svcaccounts @ 01/27/26 21:06:34.004
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:06:34.037
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:06:34.048
  STEP: Creating a pod to test service account token:  @ 01/27/26 21:06:34.065
  E0127 21:06:34.194098      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:35.194461      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:36.195362      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:37.196175      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:06:38.086
  I0127 21:06:38.089241 26 output.go:207] Trying to get logs from node k3k-k3kcluster-server-0 pod test-pod-00cf5401-ddc0-4b1f-a2ef-38fb251a5c95 container agnhost-container: <nil>
  STEP: delete the pod @ 01/27/26 21:06:38.094
  I0127 21:06:38.128838 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2461" for this suite. @ 01/27/26 21:06:38.131
• [4.136 seconds]
------------------------------
SS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 01/27/26 21:06:38.139
  I0127 21:06:38.139975 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename init-container @ 01/27/26 21:06:38.14
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:06:38.166
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:06:38.168
  STEP: creating the pod @ 01/27/26 21:06:38.17
  I0127 21:06:38.170620 26 init_container.go:499] PodSpec: initContainers in spec.initContainers
  E0127 21:06:38.196500      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:39.196633      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:40.197736      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:41.198591      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:06:41.844364 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-339" for this suite. @ 01/27/26 21:06:41.846
• [3.716 seconds]
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:81
  STEP: Creating a kubernetes client @ 01/27/26 21:06:41.856
  I0127 21:06:41.856459 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename svcaccounts @ 01/27/26 21:06:41.857
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:06:41.883
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:06:41.885
  E0127 21:06:42.198872      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:43.199263      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 01/27/26 21:06:43.925
  I0127 21:06:43.925538 26 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3115 pod-service-account-fbc34909-c1e8-416a-b63d-9182fa77d657 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 01/27/26 21:06:44.035
  I0127 21:06:44.035601 26 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3115 pod-service-account-fbc34909-c1e8-416a-b63d-9182fa77d657 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 01/27/26 21:06:44.136
  I0127 21:06:44.136937 26 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3115 pod-service-account-fbc34909-c1e8-416a-b63d-9182fa77d657 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  E0127 21:06:44.200316      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:06:44.242946 26 service_accounts.go:121] Got root ca configmap in namespace "svcaccounts-3115"
  I0127 21:06:44.245117 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-3115" for this suite. @ 01/27/26 21:06:44.247
• [2.399 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable as environment variable names with various prefixes [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:261
  STEP: Creating a kubernetes client @ 01/27/26 21:06:44.256
  I0127 21:06:44.256143 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename configmap @ 01/27/26 21:06:44.256
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:06:44.272
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:06:44.284
  STEP: Creating configMap configmap-8613/configmap-test-122af3e4-3766-4e85-8a41-a16944a412f4 @ 01/27/26 21:06:44.286
  STEP: Creating a pod to test consume configMaps @ 01/27/26 21:06:44.293
  E0127 21:06:45.201592      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:46.202533      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:47.203730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:48.204122      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:06:48.32
  I0127 21:06:48.322384 26 output.go:207] Trying to get logs from node k3k-k3kcluster-server-0 pod pod-configmaps-09648e6f-34de-4f7b-9c01-f26784c6f8ab container env-test: <nil>
  STEP: delete the pod @ 01/27/26 21:06:48.326
  I0127 21:06:48.348696 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8613" for this suite. @ 01/27/26 21:06:48.351
• [4.105 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:151
  STEP: Creating a kubernetes client @ 01/27/26 21:06:48.361
  I0127 21:06:48.361858 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename aggregateddiscovery @ 01/27/26 21:06:48.362
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:06:48.384
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:06:48.389
  I0127 21:06:48.394301 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-3259" for this suite. @ 01/27/26 21:06:48.452
• [0.099 seconds]
------------------------------
S
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingress.go:57
  STEP: Creating a kubernetes client @ 01/27/26 21:06:48.461
  I0127 21:06:48.461132 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename ingress @ 01/27/26 21:06:48.461
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:06:48.482
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:06:48.487
  STEP: getting /apis @ 01/27/26 21:06:48.489
  STEP: getting /apis/networking.k8s.io @ 01/27/26 21:06:48.493
  STEP: getting /apis/networking.k8s.iov1 @ 01/27/26 21:06:48.493
  STEP: creating @ 01/27/26 21:06:48.494
  STEP: getting @ 01/27/26 21:06:48.527
  STEP: listing @ 01/27/26 21:06:48.533
  STEP: watching @ 01/27/26 21:06:48.534
  I0127 21:06:48.534975 26 ingress.go:189] starting watch
  STEP: cluster-wide listing @ 01/27/26 21:06:48.535
  STEP: cluster-wide watching @ 01/27/26 21:06:48.541
  I0127 21:06:48.541549 26 ingress.go:201] starting watch
  STEP: patching @ 01/27/26 21:06:48.542
  STEP: updating @ 01/27/26 21:06:48.558
  I0127 21:06:48.568207 26 ingress.go:225] waiting for watch events with expected annotations
  I0127 21:06:48.568255 26 ingress.go:242] missing expected annotations, waiting: map[string]string(nil)
  I0127 21:06:48.568290 26 ingress.go:238] saw patched and updated annotations
  STEP: patching /status @ 01/27/26 21:06:48.568
  STEP: updating /status @ 01/27/26 21:06:48.576
  STEP: get /status @ 01/27/26 21:06:48.617
  STEP: deleting @ 01/27/26 21:06:48.619
  STEP: deleting a collection @ 01/27/26 21:06:48.641
  I0127 21:06:48.666997 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-9566" for this suite. @ 01/27/26 21:06:48.669
• [0.217 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 01/27/26 21:06:48.678
  I0127 21:06:48.678219 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename container-probe @ 01/27/26 21:06:48.678
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:06:48.693
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:06:48.698
  STEP: Creating pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751 @ 01/27/26 21:06:48.703
  E0127 21:06:49.204891      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:50.205111      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 01/27/26 21:06:50.725
  I0127 21:06:50.726668 26 container_probe.go:1746] Initial restart count of pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b is 0
  I0127 21:06:50.728091 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:06:51.205479      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:52.205935      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:06:52.731093 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:06:53.206650      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:54.206870      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:06:54.734434 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:06:55.206958      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:56.207246      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:06:56.737491 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:06:57.208179      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:06:58.208847      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:06:58.741087 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:06:59.209884      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:00.210137      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:00.744315 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:01.210206      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:02.210525      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:02.747373 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:03.210906      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:04.211685      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:04.749862 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:05.212606      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:06.212834      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:06.752683 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:07.213175      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:08.213839      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:08.756512 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:09.213983      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:10.214206      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:10.759478 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:11.215251      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:12.215453      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:12.762279 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:13.215756      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:14.216818      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:14.765161 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:15.217872      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:16.218100      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:16.767969 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:17.218386      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:18.218626      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:18.771493 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:19.219078      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:20.219308      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:20.774496 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:21.219369      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:22.219580      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:22.777917 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:23.220416      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:24.220835      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:24.781146 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:25.220898      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:26.221105      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:26.785071 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:27.221501      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:28.221707      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:28.787388 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:29.221856      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:30.222139      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:30.791335 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:31.222844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:32.223504      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:32.794446 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:33.223725      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:34.223910      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:34.797741 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:35.224421      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:36.225436      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:36.799956 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:37.226464      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:38.226639      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:38.802837 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:39.227506      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:40.227911      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:40.805783 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:41.228233      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:42.228447      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:42.808241 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:43.228815      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:44.228916      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:44.811045 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:45.229862      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:46.230170      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:46.813836 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:47.230301      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:48.230712      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:48.817002 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:49.231705      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:50.232830      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:50.820312 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:51.233605      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:52.234002      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:52.824498 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:53.234634      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:54.234863      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:54.827552 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:55.235559      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:56.235766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:56.832100 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:57.235989      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:07:58.236404      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:07:58.835092 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:07:59.236490      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:00.237035      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:00.837969 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:01.237432      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:02.237759      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:02.840859 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:03.238312      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:04.238530      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:04.843164 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:05.239104      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:06.239321      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:06.847016 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:07.239421      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:08.239678      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:08.849274 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:09.239726      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:10.240011      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:10.851620 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:11.241132      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:12.241399      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:12.855507 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:13.242014      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:14.242219      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:14.858594 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:15.243310      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:16.243515      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:16.861429 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:17.243754      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:18.244847      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:18.865368 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:19.245827      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:20.246175      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:20.868601 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:21.247048      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:22.247312      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:22.871165 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:23.247610      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:24.247740      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:24.874944 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:25.247946      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:26.248883      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:26.877854 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:27.249274      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:28.249553      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:28.880455 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:29.249963      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:30.250256      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:30.883150 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:31.250617      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:32.250818      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:32.886217 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:33.251723      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:34.252090      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:34.889558 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:35.252139      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:36.253272      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:36.891984 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:37.253394      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:38.253601      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:38.894738 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:39.254355      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:40.254546      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:40.897842 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:41.255569      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:42.255999      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:42.902026 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:43.256397      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:44.257280      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:44.905206 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:45.258278      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:46.258484      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:46.908457 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:47.258803      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:48.258997      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:48.910956 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:49.259086      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:50.259275      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:50.913752 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:51.259939      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:52.260809      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:52.918203 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:53.261260      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:54.262127      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:54.921332 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:55.262806      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:56.263388      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:56.923847 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:57.264315      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:08:58.265016      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:08:58.927015 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:08:59.265695      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:00.266084      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:00.929985 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:01.266574      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:02.267392      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:02.932380 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:03.268436      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:04.268878      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:04.935048 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:05.269199      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:06.269391      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:06.938291 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:07.269653      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:08.270065      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:08.941333 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:09.270341      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:10.270534      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:10.944436 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:11.270801      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:12.271018      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:12.947646 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:13.271294      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:14.271978      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:14.951435 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:15.272964      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:16.273496      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:16.954247 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:17.273740      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:18.273967      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:18.957129 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:19.275260      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:20.275280      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:20.960631 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:21.275993      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:22.276025      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:22.963740 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:23.276835      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:24.277427      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:24.966651 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:25.277773      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:26.278628      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:26.974497 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:27.278877      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:28.279047      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:28.978308 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:29.279729      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:30.280140      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:30.980578 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:31.280466      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:32.281651      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:32.983848 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:33.282409      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:34.282589      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:34.986686 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:35.283305      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:36.283528      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:36.989337 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:37.284520      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:38.285268      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:38.992501 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:39.286134      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:40.286585      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:40.995564 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:41.286912      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:42.288036      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:42.998212 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:43.288853      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:44.289184      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:45.001985 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:45.289847      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:46.290927      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:47.005400 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:47.291421      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:48.292373      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:49.008272 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:49.292543      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:50.292934      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:51.011875 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:51.293151      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:52.293365      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:53.015086 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:53.294353      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:54.294597      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:55.018450 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:55.295501      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:56.296383      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:57.021993 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:57.297311      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:09:58.297875      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:09:59.025067 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:09:59.298424      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:00.298788      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:01.027698 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:01.299269      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:02.299983      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:03.031192 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:03.300523      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:04.301448      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:05.034003 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:05.302747      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:06.302940      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:07.037504 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:07.303685      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:08.303745      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:09.041088 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:09.304481      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:10.304753      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:11.043873 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:11.305238      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:12.305453      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:13.046407 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:13.305695      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:14.305949      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:15.048868 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:15.306446      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:16.307482      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:17.051545 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:17.308282      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:18.308996      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:19.054196 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:19.309722      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:20.310049      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:21.057271 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:21.310665      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:22.310858      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:23.061336 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:23.312132      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:24.312875      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:25.065125 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:25.312952      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:26.313181      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:27.068199 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:27.313461      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:28.313690      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:29.070707 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:29.314013      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:30.314241      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:31.075892 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:31.315231      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:32.315661      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:33.083749 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:33.316285      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:34.316477      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:35.086564 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:35.317652      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:36.318094      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:37.091949 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:37.318172      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:38.318609      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:39.094608 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:39.318908      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:40.319044      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:41.096964 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:41.319248      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:42.320057      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:43.099549 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:43.320850      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:44.321419      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:45.103064 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:45.322507      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:46.322723      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:47.106091 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:47.323419      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:48.323646      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:49.109021 26 container_probe.go:1756] Get pod test-webserver-5f0042a0-5b11-4fff-a915-4877422a4d4b in namespace container-probe-2751
  E0127 21:10:49.324673      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:50.325656      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 01/27/26 21:10:51.109
  I0127 21:10:51.140661 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2751" for this suite. @ 01/27/26 21:10:51.146
• [242.479 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_latency.go:60
  STEP: Creating a kubernetes client @ 01/27/26 21:10:51.157
  I0127 21:10:51.157978 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename svc-latency @ 01/27/26 21:10:51.159
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:10:51.183
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:10:51.279
  I0127 21:10:51.282009 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  I0127 21:10:51.304634 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0127 21:10:51.325744      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:52.326280      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:10:53.326495      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:53.430693 26 service_latency.go:356] Created: latency-svc-q2rtg
  I0127 21:10:53.444555 26 service_latency.go:363] Got endpoints: latency-svc-q2rtg [36.895789ms]
  I0127 21:10:53.465236 26 service_latency.go:356] Created: latency-svc-pmpkb
  I0127 21:10:53.475592 26 service_latency.go:363] Got endpoints: latency-svc-pmpkb [30.902014ms]
  I0127 21:10:53.486286 26 service_latency.go:356] Created: latency-svc-vlrcv
  I0127 21:10:53.494180 26 service_latency.go:356] Created: latency-svc-vwhh9
  I0127 21:10:53.504591 26 service_latency.go:363] Got endpoints: latency-svc-vlrcv [59.817576ms]
  I0127 21:10:53.509172 26 service_latency.go:363] Got endpoints: latency-svc-vwhh9 [64.30967ms]
  I0127 21:10:53.520409 26 service_latency.go:356] Created: latency-svc-rbscp
  I0127 21:10:53.532603 26 service_latency.go:363] Got endpoints: latency-svc-rbscp [87.7679ms]
  I0127 21:10:53.532867 26 service_latency.go:356] Created: latency-svc-9gwqn
  I0127 21:10:53.544408 26 service_latency.go:356] Created: latency-svc-qw6b4
  I0127 21:10:53.549601 26 service_latency.go:363] Got endpoints: latency-svc-9gwqn [104.893354ms]
  I0127 21:10:53.560336 26 service_latency.go:363] Got endpoints: latency-svc-qw6b4 [115.506034ms]
  I0127 21:10:53.567014 26 service_latency.go:356] Created: latency-svc-rbgwj
  I0127 21:10:53.572540 26 service_latency.go:356] Created: latency-svc-dllhp
  I0127 21:10:53.583513 26 service_latency.go:363] Got endpoints: latency-svc-rbgwj [138.700135ms]
  I0127 21:10:53.594319 26 service_latency.go:363] Got endpoints: latency-svc-dllhp [149.428306ms]
  I0127 21:10:53.599438 26 service_latency.go:356] Created: latency-svc-svkn5
  I0127 21:10:53.606121 26 service_latency.go:356] Created: latency-svc-2nhlk
  I0127 21:10:53.616889 26 service_latency.go:363] Got endpoints: latency-svc-svkn5 [171.980711ms]
  I0127 21:10:53.622600 26 service_latency.go:363] Got endpoints: latency-svc-2nhlk [177.726916ms]
  I0127 21:10:53.644244 26 service_latency.go:356] Created: latency-svc-srjx2
  I0127 21:10:53.651188 26 service_latency.go:356] Created: latency-svc-2rd7n
  I0127 21:10:53.661661 26 service_latency.go:363] Got endpoints: latency-svc-srjx2 [216.751077ms]
  I0127 21:10:53.667074 26 service_latency.go:363] Got endpoints: latency-svc-2rd7n [222.170561ms]
  I0127 21:10:53.678093 26 service_latency.go:356] Created: latency-svc-q2grh
  I0127 21:10:53.685865 26 service_latency.go:363] Got endpoints: latency-svc-q2grh [240.947751ms]
  I0127 21:10:53.692582 26 service_latency.go:356] Created: latency-svc-l97g8
  I0127 21:10:53.708986 26 service_latency.go:356] Created: latency-svc-ppt5p
  I0127 21:10:53.713581 26 service_latency.go:363] Got endpoints: latency-svc-l97g8 [268.773848ms]
  I0127 21:10:53.723800 26 service_latency.go:363] Got endpoints: latency-svc-ppt5p [278.919341ms]
  I0127 21:10:53.728815 26 service_latency.go:356] Created: latency-svc-s2vkv
  I0127 21:10:53.735960 26 service_latency.go:356] Created: latency-svc-ppxhr
  I0127 21:10:53.755196 26 service_latency.go:363] Got endpoints: latency-svc-s2vkv [279.538654ms]
  I0127 21:10:53.758380 26 service_latency.go:363] Got endpoints: latency-svc-ppxhr [253.743179ms]
  I0127 21:10:53.763173 26 service_latency.go:356] Created: latency-svc-6sppq
  I0127 21:10:53.779513 26 service_latency.go:363] Got endpoints: latency-svc-6sppq [270.299786ms]
  I0127 21:10:53.784483 26 service_latency.go:356] Created: latency-svc-gfrqk
  I0127 21:10:53.792723 26 service_latency.go:356] Created: latency-svc-56jz9
  I0127 21:10:53.803009 26 service_latency.go:363] Got endpoints: latency-svc-gfrqk [270.362085ms]
  I0127 21:10:53.808487 26 service_latency.go:363] Got endpoints: latency-svc-56jz9 [258.847983ms]
  I0127 21:10:53.818119 26 service_latency.go:356] Created: latency-svc-64ckl
  I0127 21:10:53.825219 26 service_latency.go:356] Created: latency-svc-q7qfc
  I0127 21:10:53.836148 26 service_latency.go:363] Got endpoints: latency-svc-64ckl [275.763134ms]
  I0127 21:10:53.841086 26 service_latency.go:363] Got endpoints: latency-svc-q7qfc [257.532312ms]
  I0127 21:10:53.852179 26 service_latency.go:356] Created: latency-svc-7w69q
  I0127 21:10:53.867536 26 service_latency.go:356] Created: latency-svc-r7m9s
  I0127 21:10:53.867568 26 service_latency.go:363] Got endpoints: latency-svc-7w69q [273.210704ms]
  I0127 21:10:53.881167 26 service_latency.go:356] Created: latency-svc-vk6js
  I0127 21:10:53.885644 26 service_latency.go:363] Got endpoints: latency-svc-r7m9s [268.701967ms]
  I0127 21:10:53.896045 26 service_latency.go:363] Got endpoints: latency-svc-vk6js [273.399845ms]
  I0127 21:10:53.903073 26 service_latency.go:356] Created: latency-svc-p8jnl
  I0127 21:10:53.909518 26 service_latency.go:356] Created: latency-svc-xg4dm
  I0127 21:10:53.921441 26 service_latency.go:363] Got endpoints: latency-svc-p8jnl [259.731294ms]
  I0127 21:10:53.931899 26 service_latency.go:363] Got endpoints: latency-svc-xg4dm [264.783658ms]
  I0127 21:10:53.937117 26 service_latency.go:356] Created: latency-svc-5vnmk
  I0127 21:10:53.943598 26 service_latency.go:356] Created: latency-svc-78lmv
  I0127 21:10:53.954529 26 service_latency.go:363] Got endpoints: latency-svc-5vnmk [268.622276ms]
  I0127 21:10:53.959344 26 service_latency.go:363] Got endpoints: latency-svc-78lmv [245.719108ms]
  I0127 21:10:53.980785 26 service_latency.go:356] Created: latency-svc-2z9sn
  I0127 21:10:53.988667 26 service_latency.go:356] Created: latency-svc-mlqdr
  I0127 21:10:53.998388 26 service_latency.go:363] Got endpoints: latency-svc-2z9sn [274.505109ms]
  I0127 21:10:54.004057 26 service_latency.go:363] Got endpoints: latency-svc-mlqdr [248.814033ms]
  I0127 21:10:54.014410 26 service_latency.go:356] Created: latency-svc-qklj6
  I0127 21:10:54.020538 26 service_latency.go:356] Created: latency-svc-2l2q8
  I0127 21:10:54.031064 26 service_latency.go:363] Got endpoints: latency-svc-qklj6 [272.614769ms]
  I0127 21:10:54.036287 26 service_latency.go:363] Got endpoints: latency-svc-2l2q8 [256.721575ms]
  I0127 21:10:54.041228 26 service_latency.go:356] Created: latency-svc-zcbnr
  I0127 21:10:54.054466 26 service_latency.go:356] Created: latency-svc-54cfr
  I0127 21:10:54.058616 26 service_latency.go:363] Got endpoints: latency-svc-zcbnr [255.56576ms]
  I0127 21:10:54.069548 26 service_latency.go:363] Got endpoints: latency-svc-54cfr [261.014475ms]
  I0127 21:10:54.075453 26 service_latency.go:356] Created: latency-svc-6ffn2
  I0127 21:10:54.091060 26 service_latency.go:356] Created: latency-svc-l5plk
  I0127 21:10:54.091867 26 service_latency.go:363] Got endpoints: latency-svc-6ffn2 [255.679303ms]
  I0127 21:10:54.099120 26 service_latency.go:356] Created: latency-svc-dqwfw
  I0127 21:10:54.109231 26 service_latency.go:363] Got endpoints: latency-svc-l5plk [268.099171ms]
  I0127 21:10:54.120384 26 service_latency.go:363] Got endpoints: latency-svc-dqwfw [252.766764ms]
  I0127 21:10:54.125315 26 service_latency.go:356] Created: latency-svc-shbp5
  I0127 21:10:54.133386 26 service_latency.go:356] Created: latency-svc-6zhp4
  I0127 21:10:54.142528 26 service_latency.go:363] Got endpoints: latency-svc-shbp5 [256.838124ms]
  I0127 21:10:54.148587 26 service_latency.go:363] Got endpoints: latency-svc-6zhp4 [252.504685ms]
  I0127 21:10:54.159643 26 service_latency.go:356] Created: latency-svc-5whz4
  I0127 21:10:54.166116 26 service_latency.go:356] Created: latency-svc-x2mz4
  I0127 21:10:54.177348 26 service_latency.go:363] Got endpoints: latency-svc-5whz4 [255.863228ms]
  I0127 21:10:54.182204 26 service_latency.go:363] Got endpoints: latency-svc-x2mz4 [250.256038ms]
  I0127 21:10:54.204539 26 service_latency.go:356] Created: latency-svc-cfxhv
  I0127 21:10:54.211340 26 service_latency.go:356] Created: latency-svc-v5xmd
  I0127 21:10:54.216854 26 service_latency.go:363] Got endpoints: latency-svc-cfxhv [262.274848ms]
  I0127 21:10:54.227732 26 service_latency.go:363] Got endpoints: latency-svc-v5xmd [268.346411ms]
  I0127 21:10:54.233045 26 service_latency.go:356] Created: latency-svc-z55hz
  I0127 21:10:54.247625 26 service_latency.go:356] Created: latency-svc-svwbl
  I0127 21:10:54.252816 26 service_latency.go:363] Got endpoints: latency-svc-z55hz [254.381242ms]
  I0127 21:10:54.260045 26 service_latency.go:356] Created: latency-svc-q65dv
  I0127 21:10:54.277854 26 service_latency.go:356] Created: latency-svc-pqkrs
  I0127 21:10:54.300077 26 service_latency.go:356] Created: latency-svc-svtrl
  I0127 21:10:54.300099 26 service_latency.go:363] Got endpoints: latency-svc-svwbl [296.000671ms]
  I0127 21:10:54.315634 26 service_latency.go:356] Created: latency-svc-j4xfj
  I0127 21:10:54.323610 26 service_latency.go:356] Created: latency-svc-59wqr
  E0127 21:10:54.327201      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:54.340867 26 service_latency.go:363] Got endpoints: latency-svc-q65dv [309.759ms]
  I0127 21:10:54.353246 26 service_latency.go:356] Created: latency-svc-zmk85
  I0127 21:10:54.360977 26 service_latency.go:356] Created: latency-svc-88wlz
  I0127 21:10:54.373959 26 service_latency.go:356] Created: latency-svc-vrbjl
  I0127 21:10:54.401453 26 service_latency.go:363] Got endpoints: latency-svc-pqkrs [365.12492ms]
  I0127 21:10:54.407263 26 service_latency.go:356] Created: latency-svc-wcqgp
  I0127 21:10:54.414408 26 service_latency.go:356] Created: latency-svc-d5997
  I0127 21:10:54.435156 26 service_latency.go:356] Created: latency-svc-gqr7p
  I0127 21:10:54.439516 26 service_latency.go:363] Got endpoints: latency-svc-svtrl [380.843119ms]
  I0127 21:10:54.451930 26 service_latency.go:356] Created: latency-svc-4gtxc
  I0127 21:10:54.464582 26 service_latency.go:356] Created: latency-svc-w7bnb
  I0127 21:10:54.476158 26 service_latency.go:356] Created: latency-svc-l9kx6
  I0127 21:10:54.491779 26 service_latency.go:363] Got endpoints: latency-svc-j4xfj [422.190801ms]
  I0127 21:10:54.497368 26 service_latency.go:356] Created: latency-svc-567xv
  I0127 21:10:54.509775 26 service_latency.go:356] Created: latency-svc-nk9wf
  I0127 21:10:54.522286 26 service_latency.go:356] Created: latency-svc-sshhj
  I0127 21:10:54.545074 26 service_latency.go:363] Got endpoints: latency-svc-59wqr [453.16798ms]
  I0127 21:10:54.550597 26 service_latency.go:356] Created: latency-svc-gqjkb
  I0127 21:10:54.568534 26 service_latency.go:356] Created: latency-svc-xsvrv
  I0127 21:10:54.578861 26 service_latency.go:356] Created: latency-svc-knjqz
  I0127 21:10:54.588118 26 service_latency.go:363] Got endpoints: latency-svc-zmk85 [478.839141ms]
  I0127 21:10:54.610687 26 service_latency.go:356] Created: latency-svc-4mrvg
  I0127 21:10:54.650197 26 service_latency.go:363] Got endpoints: latency-svc-88wlz [529.768229ms]
  I0127 21:10:54.673908 26 service_latency.go:356] Created: latency-svc-wxxsv
  I0127 21:10:54.694818 26 service_latency.go:363] Got endpoints: latency-svc-vrbjl [552.24448ms]
  I0127 21:10:54.720570 26 service_latency.go:356] Created: latency-svc-qbm7m
  I0127 21:10:54.739130 26 service_latency.go:363] Got endpoints: latency-svc-wcqgp [590.491752ms]
  I0127 21:10:54.775248 26 service_latency.go:356] Created: latency-svc-hgkrs
  I0127 21:10:54.788691 26 service_latency.go:363] Got endpoints: latency-svc-d5997 [611.279005ms]
  I0127 21:10:54.812652 26 service_latency.go:356] Created: latency-svc-m5l2z
  I0127 21:10:54.844053 26 service_latency.go:363] Got endpoints: latency-svc-gqr7p [661.808522ms]
  I0127 21:10:54.872815 26 service_latency.go:356] Created: latency-svc-pkxs4
  I0127 21:10:54.893825 26 service_latency.go:363] Got endpoints: latency-svc-4gtxc [676.901626ms]
  I0127 21:10:54.918630 26 service_latency.go:356] Created: latency-svc-v2ml7
  I0127 21:10:54.944877 26 service_latency.go:363] Got endpoints: latency-svc-w7bnb [717.037482ms]
  I0127 21:10:54.966185 26 service_latency.go:356] Created: latency-svc-f2mn6
  I0127 21:10:54.994575 26 service_latency.go:363] Got endpoints: latency-svc-l9kx6 [741.720787ms]
  I0127 21:10:55.016501 26 service_latency.go:356] Created: latency-svc-8j7cj
  I0127 21:10:55.039397 26 service_latency.go:363] Got endpoints: latency-svc-567xv [739.264194ms]
  I0127 21:10:55.060616 26 service_latency.go:356] Created: latency-svc-rjfrf
  I0127 21:10:55.096420 26 service_latency.go:363] Got endpoints: latency-svc-nk9wf [755.487087ms]
  I0127 21:10:55.116951 26 service_latency.go:356] Created: latency-svc-xgspw
  I0127 21:10:55.139885 26 service_latency.go:363] Got endpoints: latency-svc-sshhj [738.365384ms]
  I0127 21:10:55.156922 26 service_latency.go:356] Created: latency-svc-2r9g5
  I0127 21:10:55.207736 26 service_latency.go:363] Got endpoints: latency-svc-gqjkb [768.181944ms]
  I0127 21:10:55.229655 26 service_latency.go:356] Created: latency-svc-56wcj
  I0127 21:10:55.238784 26 service_latency.go:363] Got endpoints: latency-svc-xsvrv [746.918717ms]
  I0127 21:10:55.254653 26 service_latency.go:356] Created: latency-svc-jlfsp
  I0127 21:10:55.295196 26 service_latency.go:363] Got endpoints: latency-svc-knjqz [750.078435ms]
  I0127 21:10:55.319265 26 service_latency.go:356] Created: latency-svc-n7b2r
  E0127 21:10:55.327580      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:55.346087 26 service_latency.go:363] Got endpoints: latency-svc-4mrvg [757.921107ms]
  I0127 21:10:55.362917 26 service_latency.go:356] Created: latency-svc-d9b4t
  I0127 21:10:55.399113 26 service_latency.go:363] Got endpoints: latency-svc-wxxsv [748.869951ms]
  I0127 21:10:55.417336 26 service_latency.go:356] Created: latency-svc-5zbqq
  I0127 21:10:55.450518 26 service_latency.go:363] Got endpoints: latency-svc-qbm7m [755.646773ms]
  I0127 21:10:55.465944 26 service_latency.go:356] Created: latency-svc-8mxnw
  I0127 21:10:55.495139 26 service_latency.go:363] Got endpoints: latency-svc-hgkrs [755.952816ms]
  I0127 21:10:55.511471 26 service_latency.go:356] Created: latency-svc-f2j2q
  I0127 21:10:55.540745 26 service_latency.go:363] Got endpoints: latency-svc-m5l2z [752.007619ms]
  I0127 21:10:55.562390 26 service_latency.go:356] Created: latency-svc-gqx5r
  I0127 21:10:55.590586 26 service_latency.go:363] Got endpoints: latency-svc-pkxs4 [746.483358ms]
  I0127 21:10:55.613237 26 service_latency.go:356] Created: latency-svc-t4fzb
  I0127 21:10:55.640160 26 service_latency.go:363] Got endpoints: latency-svc-v2ml7 [746.284054ms]
  I0127 21:10:55.661929 26 service_latency.go:356] Created: latency-svc-hksk5
  I0127 21:10:55.688489 26 service_latency.go:363] Got endpoints: latency-svc-f2mn6 [743.531505ms]
  I0127 21:10:55.712311 26 service_latency.go:356] Created: latency-svc-4g6rx
  I0127 21:10:55.739006 26 service_latency.go:363] Got endpoints: latency-svc-8j7cj [744.386696ms]
  I0127 21:10:55.763539 26 service_latency.go:356] Created: latency-svc-rd2bj
  I0127 21:10:55.795584 26 service_latency.go:363] Got endpoints: latency-svc-rjfrf [756.129259ms]
  I0127 21:10:55.821906 26 service_latency.go:356] Created: latency-svc-cs78l
  I0127 21:10:55.844807 26 service_latency.go:363] Got endpoints: latency-svc-xgspw [748.344341ms]
  I0127 21:10:55.860857 26 service_latency.go:356] Created: latency-svc-fdxzm
  I0127 21:10:55.899409 26 service_latency.go:363] Got endpoints: latency-svc-2r9g5 [759.476155ms]
  I0127 21:10:55.916295 26 service_latency.go:356] Created: latency-svc-bn9d5
  I0127 21:10:55.946530 26 service_latency.go:363] Got endpoints: latency-svc-56wcj [738.749115ms]
  I0127 21:10:55.963396 26 service_latency.go:356] Created: latency-svc-sjq4z
  I0127 21:10:56.000614 26 service_latency.go:363] Got endpoints: latency-svc-jlfsp [761.782084ms]
  I0127 21:10:56.016400 26 service_latency.go:356] Created: latency-svc-nvgc8
  I0127 21:10:56.049990 26 service_latency.go:363] Got endpoints: latency-svc-n7b2r [754.740085ms]
  I0127 21:10:56.065936 26 service_latency.go:356] Created: latency-svc-kg8cd
  I0127 21:10:56.099987 26 service_latency.go:363] Got endpoints: latency-svc-d9b4t [753.850597ms]
  I0127 21:10:56.115352 26 service_latency.go:356] Created: latency-svc-snfwm
  I0127 21:10:56.151862 26 service_latency.go:363] Got endpoints: latency-svc-5zbqq [752.702824ms]
  I0127 21:10:56.166199 26 service_latency.go:356] Created: latency-svc-ldppq
  I0127 21:10:56.198532 26 service_latency.go:363] Got endpoints: latency-svc-8mxnw [747.961085ms]
  I0127 21:10:56.218659 26 service_latency.go:356] Created: latency-svc-kdwc5
  I0127 21:10:56.237989 26 service_latency.go:363] Got endpoints: latency-svc-f2j2q [742.797431ms]
  I0127 21:10:56.260294 26 service_latency.go:356] Created: latency-svc-wnk85
  I0127 21:10:56.288050 26 service_latency.go:363] Got endpoints: latency-svc-gqx5r [747.254112ms]
  I0127 21:10:56.323026 26 service_latency.go:356] Created: latency-svc-n2nvv
  E0127 21:10:56.328443      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:56.344336 26 service_latency.go:363] Got endpoints: latency-svc-t4fzb [753.708502ms]
  I0127 21:10:56.365188 26 service_latency.go:356] Created: latency-svc-b2rjr
  I0127 21:10:56.392817 26 service_latency.go:363] Got endpoints: latency-svc-hksk5 [752.611313ms]
  I0127 21:10:56.422482 26 service_latency.go:356] Created: latency-svc-jd2sq
  I0127 21:10:56.445104 26 service_latency.go:363] Got endpoints: latency-svc-4g6rx [756.571344ms]
  I0127 21:10:56.474058 26 service_latency.go:356] Created: latency-svc-cfbmd
  I0127 21:10:56.500262 26 service_latency.go:363] Got endpoints: latency-svc-rd2bj [761.20772ms]
  I0127 21:10:56.515793 26 service_latency.go:356] Created: latency-svc-c4k5x
  I0127 21:10:56.545614 26 service_latency.go:363] Got endpoints: latency-svc-cs78l [749.972057ms]
  I0127 21:10:56.560740 26 service_latency.go:356] Created: latency-svc-gjtl4
  I0127 21:10:56.595617 26 service_latency.go:363] Got endpoints: latency-svc-fdxzm [750.766649ms]
  I0127 21:10:56.616487 26 service_latency.go:356] Created: latency-svc-2mrmw
  I0127 21:10:56.639166 26 service_latency.go:363] Got endpoints: latency-svc-bn9d5 [739.714395ms]
  I0127 21:10:56.662988 26 service_latency.go:356] Created: latency-svc-x7wbl
  I0127 21:10:56.699756 26 service_latency.go:363] Got endpoints: latency-svc-sjq4z [753.165748ms]
  I0127 21:10:56.716210 26 service_latency.go:356] Created: latency-svc-q2ncp
  I0127 21:10:56.749900 26 service_latency.go:363] Got endpoints: latency-svc-nvgc8 [749.24211ms]
  I0127 21:10:56.774909 26 service_latency.go:356] Created: latency-svc-h2trs
  I0127 21:10:56.798783 26 service_latency.go:363] Got endpoints: latency-svc-kg8cd [748.732666ms]
  I0127 21:10:56.815118 26 service_latency.go:356] Created: latency-svc-cghvp
  I0127 21:10:56.844461 26 service_latency.go:363] Got endpoints: latency-svc-snfwm [744.427753ms]
  I0127 21:10:56.861491 26 service_latency.go:356] Created: latency-svc-sz4j6
  I0127 21:10:56.894828 26 service_latency.go:363] Got endpoints: latency-svc-ldppq [742.912526ms]
  I0127 21:10:56.913147 26 service_latency.go:356] Created: latency-svc-f6xqk
  I0127 21:10:56.940736 26 service_latency.go:363] Got endpoints: latency-svc-kdwc5 [742.15234ms]
  I0127 21:10:56.962653 26 service_latency.go:356] Created: latency-svc-j25jl
  I0127 21:10:56.995792 26 service_latency.go:363] Got endpoints: latency-svc-wnk85 [757.75962ms]
  I0127 21:10:57.011366 26 service_latency.go:356] Created: latency-svc-97s2h
  I0127 21:10:57.044697 26 service_latency.go:363] Got endpoints: latency-svc-n2nvv [756.599514ms]
  I0127 21:10:57.062240 26 service_latency.go:356] Created: latency-svc-4gsdb
  I0127 21:10:57.101668 26 service_latency.go:363] Got endpoints: latency-svc-b2rjr [757.288848ms]
  I0127 21:10:57.117224 26 service_latency.go:356] Created: latency-svc-fsbl7
  I0127 21:10:57.145146 26 service_latency.go:363] Got endpoints: latency-svc-jd2sq [752.284323ms]
  I0127 21:10:57.162382 26 service_latency.go:356] Created: latency-svc-ggljk
  I0127 21:10:57.194794 26 service_latency.go:363] Got endpoints: latency-svc-cfbmd [749.642233ms]
  I0127 21:10:57.221686 26 service_latency.go:356] Created: latency-svc-sr8jh
  I0127 21:10:57.250483 26 service_latency.go:363] Got endpoints: latency-svc-c4k5x [750.169731ms]
  I0127 21:10:57.267252 26 service_latency.go:356] Created: latency-svc-cdwlj
  I0127 21:10:57.295230 26 service_latency.go:363] Got endpoints: latency-svc-gjtl4 [749.567559ms]
  I0127 21:10:57.312441 26 service_latency.go:356] Created: latency-svc-d2d8m
  E0127 21:10:57.328775      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:57.338659 26 service_latency.go:363] Got endpoints: latency-svc-2mrmw [742.995136ms]
  I0127 21:10:57.362366 26 service_latency.go:356] Created: latency-svc-d6fft
  I0127 21:10:57.389361 26 service_latency.go:363] Got endpoints: latency-svc-x7wbl [750.151337ms]
  I0127 21:10:57.411481 26 service_latency.go:356] Created: latency-svc-44tjn
  I0127 21:10:57.444668 26 service_latency.go:363] Got endpoints: latency-svc-q2ncp [744.867136ms]
  I0127 21:10:57.465333 26 service_latency.go:356] Created: latency-svc-bxh86
  I0127 21:10:57.489027 26 service_latency.go:363] Got endpoints: latency-svc-h2trs [739.08099ms]
  I0127 21:10:57.512165 26 service_latency.go:356] Created: latency-svc-6vjl9
  I0127 21:10:57.548192 26 service_latency.go:363] Got endpoints: latency-svc-cghvp [749.345015ms]
  I0127 21:10:57.568653 26 service_latency.go:356] Created: latency-svc-8dgsm
  I0127 21:10:57.589936 26 service_latency.go:363] Got endpoints: latency-svc-sz4j6 [745.427775ms]
  I0127 21:10:57.612782 26 service_latency.go:356] Created: latency-svc-d74qg
  I0127 21:10:57.639207 26 service_latency.go:363] Got endpoints: latency-svc-f6xqk [744.331735ms]
  I0127 21:10:57.671415 26 service_latency.go:356] Created: latency-svc-mgzsv
  I0127 21:10:57.694046 26 service_latency.go:363] Got endpoints: latency-svc-j25jl [753.253149ms]
  I0127 21:10:57.711564 26 service_latency.go:356] Created: latency-svc-6vdzw
  I0127 21:10:57.750987 26 service_latency.go:363] Got endpoints: latency-svc-97s2h [755.109332ms]
  I0127 21:10:57.777852 26 service_latency.go:356] Created: latency-svc-zscbt
  I0127 21:10:57.794268 26 service_latency.go:363] Got endpoints: latency-svc-4gsdb [749.518774ms]
  I0127 21:10:57.812026 26 service_latency.go:356] Created: latency-svc-spvzn
  I0127 21:10:57.844407 26 service_latency.go:363] Got endpoints: latency-svc-fsbl7 [742.690413ms]
  I0127 21:10:57.862121 26 service_latency.go:356] Created: latency-svc-brgw7
  I0127 21:10:57.899698 26 service_latency.go:363] Got endpoints: latency-svc-ggljk [754.503913ms]
  I0127 21:10:57.915290 26 service_latency.go:356] Created: latency-svc-29pjs
  I0127 21:10:57.940706 26 service_latency.go:363] Got endpoints: latency-svc-sr8jh [745.861177ms]
  I0127 21:10:57.962513 26 service_latency.go:356] Created: latency-svc-zjns7
  I0127 21:10:58.000694 26 service_latency.go:363] Got endpoints: latency-svc-cdwlj [750.163588ms]
  I0127 21:10:58.017159 26 service_latency.go:356] Created: latency-svc-j82d7
  I0127 21:10:58.043900 26 service_latency.go:363] Got endpoints: latency-svc-d2d8m [748.618546ms]
  I0127 21:10:58.064780 26 service_latency.go:356] Created: latency-svc-6bg8n
  I0127 21:10:58.089197 26 service_latency.go:363] Got endpoints: latency-svc-d6fft [750.493223ms]
  I0127 21:10:58.111323 26 service_latency.go:356] Created: latency-svc-x4lzb
  I0127 21:10:58.139889 26 service_latency.go:363] Got endpoints: latency-svc-44tjn [750.476391ms]
  I0127 21:10:58.162876 26 service_latency.go:356] Created: latency-svc-bc6rr
  I0127 21:10:58.190812 26 service_latency.go:363] Got endpoints: latency-svc-bxh86 [746.09651ms]
  I0127 21:10:58.215997 26 service_latency.go:356] Created: latency-svc-wnx7m
  I0127 21:10:58.244380 26 service_latency.go:363] Got endpoints: latency-svc-6vjl9 [755.300785ms]
  I0127 21:10:58.265272 26 service_latency.go:356] Created: latency-svc-5rpc4
  I0127 21:10:58.294943 26 service_latency.go:363] Got endpoints: latency-svc-8dgsm [746.706699ms]
  I0127 21:10:58.310062 26 service_latency.go:356] Created: latency-svc-kttpp
  E0127 21:10:58.329612      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:58.344979 26 service_latency.go:363] Got endpoints: latency-svc-d74qg [754.992258ms]
  I0127 21:10:58.362190 26 service_latency.go:356] Created: latency-svc-htjm7
  I0127 21:10:58.399237 26 service_latency.go:363] Got endpoints: latency-svc-mgzsv [759.983866ms]
  I0127 21:10:58.415261 26 service_latency.go:356] Created: latency-svc-zhgwp
  I0127 21:10:58.444896 26 service_latency.go:363] Got endpoints: latency-svc-6vdzw [750.792752ms]
  I0127 21:10:58.462400 26 service_latency.go:356] Created: latency-svc-gj8rh
  I0127 21:10:58.495443 26 service_latency.go:363] Got endpoints: latency-svc-zscbt [744.410057ms]
  I0127 21:10:58.513376 26 service_latency.go:356] Created: latency-svc-gnppx
  I0127 21:10:58.550581 26 service_latency.go:363] Got endpoints: latency-svc-spvzn [756.259016ms]
  I0127 21:10:58.566920 26 service_latency.go:356] Created: latency-svc-cgmzg
  I0127 21:10:58.589190 26 service_latency.go:363] Got endpoints: latency-svc-brgw7 [744.743068ms]
  I0127 21:10:58.612977 26 service_latency.go:356] Created: latency-svc-th4v2
  I0127 21:10:58.639959 26 service_latency.go:363] Got endpoints: latency-svc-29pjs [740.2057ms]
  I0127 21:10:58.670430 26 service_latency.go:356] Created: latency-svc-8xvgr
  I0127 21:10:58.694472 26 service_latency.go:363] Got endpoints: latency-svc-zjns7 [753.702432ms]
  I0127 21:10:58.716377 26 service_latency.go:356] Created: latency-svc-vhc25
  I0127 21:10:58.739500 26 service_latency.go:363] Got endpoints: latency-svc-j82d7 [738.752961ms]
  I0127 21:10:58.762436 26 service_latency.go:356] Created: latency-svc-zrvv5
  I0127 21:10:58.790026 26 service_latency.go:363] Got endpoints: latency-svc-6bg8n [746.063235ms]
  I0127 21:10:58.816824 26 service_latency.go:356] Created: latency-svc-cmswn
  I0127 21:10:58.839719 26 service_latency.go:363] Got endpoints: latency-svc-x4lzb [750.46957ms]
  I0127 21:10:58.863100 26 service_latency.go:356] Created: latency-svc-kvw4m
  I0127 21:10:58.893754 26 service_latency.go:363] Got endpoints: latency-svc-bc6rr [753.807439ms]
  I0127 21:10:58.918365 26 service_latency.go:356] Created: latency-svc-kj6f6
  I0127 21:10:58.948750 26 service_latency.go:363] Got endpoints: latency-svc-wnx7m [757.888404ms]
  I0127 21:10:58.963650 26 service_latency.go:356] Created: latency-svc-pks52
  I0127 21:10:58.995998 26 service_latency.go:363] Got endpoints: latency-svc-5rpc4 [751.567798ms]
  I0127 21:10:59.011673 26 service_latency.go:356] Created: latency-svc-5gmtd
  I0127 21:10:59.048125 26 service_latency.go:363] Got endpoints: latency-svc-kttpp [753.134161ms]
  I0127 21:10:59.064304 26 service_latency.go:356] Created: latency-svc-p5mv8
  I0127 21:10:59.107316 26 service_latency.go:363] Got endpoints: latency-svc-htjm7 [762.28499ms]
  I0127 21:10:59.123372 26 service_latency.go:356] Created: latency-svc-vr8tz
  I0127 21:10:59.150317 26 service_latency.go:363] Got endpoints: latency-svc-zhgwp [751.027776ms]
  I0127 21:10:59.165958 26 service_latency.go:356] Created: latency-svc-b2kr9
  I0127 21:10:59.194321 26 service_latency.go:363] Got endpoints: latency-svc-gj8rh [749.378498ms]
  I0127 21:10:59.219247 26 service_latency.go:356] Created: latency-svc-xmk4g
  I0127 21:10:59.238923 26 service_latency.go:363] Got endpoints: latency-svc-gnppx [743.436986ms]
  I0127 21:10:59.262299 26 service_latency.go:356] Created: latency-svc-25q6j
  I0127 21:10:59.299124 26 service_latency.go:363] Got endpoints: latency-svc-cgmzg [748.495473ms]
  I0127 21:10:59.314997 26 service_latency.go:356] Created: latency-svc-pb68s
  E0127 21:10:59.330218      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:10:59.350055 26 service_latency.go:363] Got endpoints: latency-svc-th4v2 [760.81567ms]
  I0127 21:10:59.365688 26 service_latency.go:356] Created: latency-svc-ljtjz
  I0127 21:10:59.394515 26 service_latency.go:363] Got endpoints: latency-svc-8xvgr [754.500308ms]
  I0127 21:10:59.415243 26 service_latency.go:356] Created: latency-svc-hdkp2
  I0127 21:10:59.444233 26 service_latency.go:363] Got endpoints: latency-svc-vhc25 [749.708041ms]
  I0127 21:10:59.469089 26 service_latency.go:356] Created: latency-svc-9zrkt
  I0127 21:10:59.490220 26 service_latency.go:363] Got endpoints: latency-svc-zrvv5 [750.664436ms]
  I0127 21:10:59.513235 26 service_latency.go:356] Created: latency-svc-c7btn
  I0127 21:10:59.538604 26 service_latency.go:363] Got endpoints: latency-svc-cmswn [748.515943ms]
  I0127 21:10:59.567367 26 service_latency.go:356] Created: latency-svc-fs9ws
  I0127 21:10:59.595292 26 service_latency.go:363] Got endpoints: latency-svc-kvw4m [755.524401ms]
  I0127 21:10:59.617035 26 service_latency.go:356] Created: latency-svc-r5cvw
  I0127 21:10:59.639118 26 service_latency.go:363] Got endpoints: latency-svc-kj6f6 [745.321019ms]
  I0127 21:10:59.666305 26 service_latency.go:356] Created: latency-svc-ln9jl
  I0127 21:10:59.695010 26 service_latency.go:363] Got endpoints: latency-svc-pks52 [746.207406ms]
  I0127 21:10:59.712635 26 service_latency.go:356] Created: latency-svc-dk6bt
  I0127 21:10:59.746307 26 service_latency.go:363] Got endpoints: latency-svc-5gmtd [750.251742ms]
  I0127 21:10:59.764172 26 service_latency.go:356] Created: latency-svc-rjds5
  I0127 21:10:59.796010 26 service_latency.go:363] Got endpoints: latency-svc-p5mv8 [747.82275ms]
  I0127 21:10:59.814630 26 service_latency.go:356] Created: latency-svc-cd452
  I0127 21:10:59.850870 26 service_latency.go:363] Got endpoints: latency-svc-vr8tz [743.505883ms]
  I0127 21:10:59.867563 26 service_latency.go:356] Created: latency-svc-qmt9t
  I0127 21:10:59.900370 26 service_latency.go:363] Got endpoints: latency-svc-b2kr9 [749.825342ms]
  I0127 21:10:59.916768 26 service_latency.go:356] Created: latency-svc-xw8w4
  I0127 21:10:59.949307 26 service_latency.go:363] Got endpoints: latency-svc-xmk4g [754.939461ms]
  I0127 21:10:59.964608 26 service_latency.go:356] Created: latency-svc-r5tdj
  I0127 21:11:00.001325 26 service_latency.go:363] Got endpoints: latency-svc-25q6j [762.356667ms]
  I0127 21:11:00.023219 26 service_latency.go:356] Created: latency-svc-hfjjw
  I0127 21:11:00.039039 26 service_latency.go:363] Got endpoints: latency-svc-pb68s [739.86405ms]
  I0127 21:11:00.061571 26 service_latency.go:356] Created: latency-svc-fsg6n
  I0127 21:11:00.089415 26 service_latency.go:363] Got endpoints: latency-svc-ljtjz [739.316265ms]
  I0127 21:11:00.119374 26 service_latency.go:356] Created: latency-svc-xtp28
  I0127 21:11:00.144910 26 service_latency.go:363] Got endpoints: latency-svc-hdkp2 [750.340885ms]
  I0127 21:11:00.165584 26 service_latency.go:356] Created: latency-svc-5xznm
  I0127 21:11:00.194292 26 service_latency.go:363] Got endpoints: latency-svc-9zrkt [750.01331ms]
  I0127 21:11:00.224830 26 service_latency.go:356] Created: latency-svc-2hz52
  I0127 21:11:00.240104 26 service_latency.go:363] Got endpoints: latency-svc-c7btn [749.841468ms]
  I0127 21:11:00.255029 26 service_latency.go:356] Created: latency-svc-p66b7
  I0127 21:11:00.294934 26 service_latency.go:363] Got endpoints: latency-svc-fs9ws [756.287078ms]
  I0127 21:11:00.316532 26 service_latency.go:356] Created: latency-svc-kjnc8
  E0127 21:11:00.330719      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:11:00.344323 26 service_latency.go:363] Got endpoints: latency-svc-r5cvw [748.981288ms]
  I0127 21:11:00.365882 26 service_latency.go:356] Created: latency-svc-dfx74
  I0127 21:11:00.388338 26 service_latency.go:363] Got endpoints: latency-svc-ln9jl [749.160103ms]
  I0127 21:11:00.407079 26 service_latency.go:356] Created: latency-svc-pb5ql
  I0127 21:11:00.450256 26 service_latency.go:363] Got endpoints: latency-svc-dk6bt [755.197161ms]
  I0127 21:11:00.466801 26 service_latency.go:356] Created: latency-svc-nr7kd
  I0127 21:11:00.496723 26 service_latency.go:363] Got endpoints: latency-svc-rjds5 [750.366454ms]
  I0127 21:11:00.513388 26 service_latency.go:356] Created: latency-svc-r6bpl
  I0127 21:11:00.560584 26 service_latency.go:363] Got endpoints: latency-svc-cd452 [764.531649ms]
  I0127 21:11:00.577631 26 service_latency.go:356] Created: latency-svc-5gxlg
  I0127 21:11:00.589894 26 service_latency.go:363] Got endpoints: latency-svc-qmt9t [738.978753ms]
  I0127 21:11:00.612216 26 service_latency.go:356] Created: latency-svc-zn9gh
  I0127 21:11:00.640242 26 service_latency.go:363] Got endpoints: latency-svc-xw8w4 [739.809618ms]
  I0127 21:11:00.671243 26 service_latency.go:356] Created: latency-svc-jgkcn
  I0127 21:11:00.700991 26 service_latency.go:363] Got endpoints: latency-svc-r5tdj [751.63779ms]
  I0127 21:11:00.716520 26 service_latency.go:356] Created: latency-svc-zlwhw
  I0127 21:11:00.739804 26 service_latency.go:363] Got endpoints: latency-svc-hfjjw [738.438278ms]
  I0127 21:11:00.762583 26 service_latency.go:356] Created: latency-svc-jtftz
  I0127 21:11:00.798858 26 service_latency.go:363] Got endpoints: latency-svc-fsg6n [759.77279ms]
  I0127 21:11:00.813640 26 service_latency.go:356] Created: latency-svc-88jj9
  I0127 21:11:00.839860 26 service_latency.go:363] Got endpoints: latency-svc-xtp28 [750.390865ms]
  I0127 21:11:00.862634 26 service_latency.go:356] Created: latency-svc-xrccc
  I0127 21:11:00.900391 26 service_latency.go:363] Got endpoints: latency-svc-5xznm [755.440173ms]
  I0127 21:11:00.915794 26 service_latency.go:356] Created: latency-svc-p6fr5
  I0127 21:11:00.950497 26 service_latency.go:363] Got endpoints: latency-svc-2hz52 [756.152324ms]
  I0127 21:11:00.967731 26 service_latency.go:356] Created: latency-svc-rdx74
  I0127 21:11:01.004166 26 service_latency.go:363] Got endpoints: latency-svc-p66b7 [764.016272ms]
  I0127 21:11:01.019697 26 service_latency.go:356] Created: latency-svc-8lkh8
  I0127 21:11:01.040384 26 service_latency.go:363] Got endpoints: latency-svc-kjnc8 [745.402149ms]
  I0127 21:11:01.063226 26 service_latency.go:356] Created: latency-svc-v75jm
  I0127 21:11:01.099708 26 service_latency.go:363] Got endpoints: latency-svc-dfx74 [755.340348ms]
  I0127 21:11:01.123112 26 service_latency.go:356] Created: latency-svc-w76xn
  I0127 21:11:01.138347 26 service_latency.go:363] Got endpoints: latency-svc-pb5ql [749.96795ms]
  I0127 21:11:01.161649 26 service_latency.go:356] Created: latency-svc-tsp4q
  I0127 21:11:01.189135 26 service_latency.go:363] Got endpoints: latency-svc-nr7kd [738.831436ms]
  I0127 21:11:01.212011 26 service_latency.go:356] Created: latency-svc-6ghpb
  I0127 21:11:01.239625 26 service_latency.go:363] Got endpoints: latency-svc-r6bpl [742.849855ms]
  I0127 21:11:01.261636 26 service_latency.go:356] Created: latency-svc-v86mm
  I0127 21:11:01.288923 26 service_latency.go:363] Got endpoints: latency-svc-5gxlg [728.279572ms]
  E0127 21:11:01.331136      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:11:01.351255 26 service_latency.go:363] Got endpoints: latency-svc-zn9gh [761.312799ms]
  I0127 21:11:01.394769 26 service_latency.go:363] Got endpoints: latency-svc-jgkcn [754.474353ms]
  I0127 21:11:01.451145 26 service_latency.go:363] Got endpoints: latency-svc-zlwhw [750.108656ms]
  I0127 21:11:01.494178 26 service_latency.go:363] Got endpoints: latency-svc-jtftz [754.273549ms]
  I0127 21:11:01.539926 26 service_latency.go:363] Got endpoints: latency-svc-88jj9 [741.021026ms]
  I0127 21:11:01.599731 26 service_latency.go:363] Got endpoints: latency-svc-xrccc [759.819672ms]
  I0127 21:11:01.639694 26 service_latency.go:363] Got endpoints: latency-svc-p6fr5 [739.251946ms]
  I0127 21:11:01.701393 26 service_latency.go:363] Got endpoints: latency-svc-rdx74 [750.837227ms]
  I0127 21:11:01.743449 26 service_latency.go:363] Got endpoints: latency-svc-8lkh8 [739.229027ms]
  I0127 21:11:01.801686 26 service_latency.go:363] Got endpoints: latency-svc-v75jm [761.257022ms]
  I0127 21:11:01.839758 26 service_latency.go:363] Got endpoints: latency-svc-w76xn [740.008325ms]
  I0127 21:11:01.897775 26 service_latency.go:363] Got endpoints: latency-svc-tsp4q [759.370884ms]
  I0127 21:11:01.947522 26 service_latency.go:363] Got endpoints: latency-svc-6ghpb [758.342184ms]
  I0127 21:11:01.994627 26 service_latency.go:363] Got endpoints: latency-svc-v86mm [754.957466ms]
  I0127 21:11:01.994724 26 service_latency.go:115] Latencies: [30.902014ms 59.817576ms 64.30967ms 87.7679ms 104.893354ms 115.506034ms 138.700135ms 149.428306ms 171.980711ms 177.726916ms 216.751077ms 222.170561ms 240.947751ms 245.719108ms 248.814033ms 250.256038ms 252.504685ms 252.766764ms 253.743179ms 254.381242ms 255.56576ms 255.679303ms 255.863228ms 256.721575ms 256.838124ms 257.532312ms 258.847983ms 259.731294ms 261.014475ms 262.274848ms 264.783658ms 268.099171ms 268.346411ms 268.622276ms 268.701967ms 268.773848ms 270.299786ms 270.362085ms 272.614769ms 273.210704ms 273.399845ms 274.505109ms 275.763134ms 278.919341ms 279.538654ms 296.000671ms 309.759ms 365.12492ms 380.843119ms 422.190801ms 453.16798ms 478.839141ms 529.768229ms 552.24448ms 590.491752ms 611.279005ms 661.808522ms 676.901626ms 717.037482ms 728.279572ms 738.365384ms 738.438278ms 738.749115ms 738.752961ms 738.831436ms 738.978753ms 739.08099ms 739.229027ms 739.251946ms 739.264194ms 739.316265ms 739.714395ms 739.809618ms 739.86405ms 740.008325ms 740.2057ms 741.021026ms 741.720787ms 742.15234ms 742.690413ms 742.797431ms 742.849855ms 742.912526ms 742.995136ms 743.436986ms 743.505883ms 743.531505ms 744.331735ms 744.386696ms 744.410057ms 744.427753ms 744.743068ms 744.867136ms 745.321019ms 745.402149ms 745.427775ms 745.861177ms 746.063235ms 746.09651ms 746.207406ms 746.284054ms 746.483358ms 746.706699ms 746.918717ms 747.254112ms 747.82275ms 747.961085ms 748.344341ms 748.495473ms 748.515943ms 748.618546ms 748.732666ms 748.869951ms 748.981288ms 749.160103ms 749.24211ms 749.345015ms 749.378498ms 749.518774ms 749.567559ms 749.642233ms 749.708041ms 749.825342ms 749.841468ms 749.96795ms 749.972057ms 750.01331ms 750.078435ms 750.108656ms 750.151337ms 750.163588ms 750.169731ms 750.251742ms 750.340885ms 750.366454ms 750.390865ms 750.46957ms 750.476391ms 750.493223ms 750.664436ms 750.766649ms 750.792752ms 750.837227ms 751.027776ms 751.567798ms 751.63779ms 752.007619ms 752.284323ms 752.611313ms 752.702824ms 753.134161ms 753.165748ms 753.253149ms 753.702432ms 753.708502ms 753.807439ms 753.850597ms 754.273549ms 754.474353ms 754.500308ms 754.503913ms 754.740085ms 754.939461ms 754.957466ms 754.992258ms 755.109332ms 755.197161ms 755.300785ms 755.340348ms 755.440173ms 755.487087ms 755.524401ms 755.646773ms 755.952816ms 756.129259ms 756.152324ms 756.259016ms 756.287078ms 756.571344ms 756.599514ms 757.288848ms 757.75962ms 757.888404ms 757.921107ms 758.342184ms 759.370884ms 759.476155ms 759.77279ms 759.819672ms 759.983866ms 760.81567ms 761.20772ms 761.257022ms 761.312799ms 761.782084ms 762.28499ms 762.356667ms 764.016272ms 764.531649ms 768.181944ms]
  I0127 21:11:01.994741 26 service_latency.go:119] 50 %ile: 746.284054ms
  I0127 21:11:01.994750 26 service_latency.go:120] 90 %ile: 757.288848ms
  I0127 21:11:01.994758 26 service_latency.go:121] 99 %ile: 764.531649ms
  I0127 21:11:01.994765 26 service_latency.go:122] Total sample count: 200
  I0127 21:11:01.994853 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-8396" for this suite. @ 01/27/26 21:11:02.009
• [10.861 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 01/27/26 21:11:02.018
  I0127 21:11:02.018656 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename init-container @ 01/27/26 21:11:02.019
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:11:02.035
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:11:02.045
  STEP: creating the pod @ 01/27/26 21:11:02.047
  I0127 21:11:02.047664 26 init_container.go:213] PodSpec: initContainers in spec.initContainers
  E0127 21:11:02.332065      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:03.332152      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:04.333222      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:05.334234      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:06.334426      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:11:06.412443 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-2897" for this suite. @ 01/27/26 21:11:06.415
• [4.405 seconds]
------------------------------
SS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:99
  STEP: Creating a kubernetes client @ 01/27/26 21:11:06.423
  I0127 21:11:06.423758 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename configmap @ 01/27/26 21:11:06.424
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:11:06.448
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:11:06.453
  STEP: Creating configMap with name configmap-test-volume-map-a67eef40-d082-4502-825f-7b92e0b15778 @ 01/27/26 21:11:06.455
  STEP: Creating a pod to test consume configMaps @ 01/27/26 21:11:06.463
  E0127 21:11:07.334993      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:08.335570      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:09.335723      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:10.335794      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:11:10.8
  I0127 21:11:10.804753 26 output.go:207] Trying to get logs from node k3k-k3kcluster-server-0 pod pod-configmaps-0d1839ca-fbde-48bf-8dfb-234f02a4dfcb container agnhost-container: <nil>
  STEP: delete the pod @ 01/27/26 21:11:10.822
  I0127 21:11:10.881004 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3868" for this suite. @ 01/27/26 21:11:10.949
• [4.555 seconds]
------------------------------
SSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:49
  STEP: Creating a kubernetes client @ 01/27/26 21:11:10.979
  I0127 21:11:10.979322 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename secrets @ 01/27/26 21:11:10.979
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:11:10.994
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:11:11.094
  STEP: Creating secret with name secret-test-f786899c-5644-4291-954b-94b7a5cf0afa @ 01/27/26 21:11:11.109
  STEP: Creating a pod to test consume secrets @ 01/27/26 21:11:11.115
  E0127 21:11:11.336805      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:12.337415      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:13.338292      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:14.339423      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:11:15.205
  I0127 21:11:15.208700 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-secrets-9b298a3e-a17a-4187-90ff-47bd0389cf44 container secret-env-test: <nil>
  STEP: delete the pod @ 01/27/26 21:11:15.258
  I0127 21:11:15.308700 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1647" for this suite. @ 01/27/26 21:11:15.31
• [4.340 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:256
  STEP: Creating a kubernetes client @ 01/27/26 21:11:15.319
  I0127 21:11:15.319673 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename namespaces @ 01/27/26 21:11:15.32
  E0127 21:11:15.340244      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:11:15.392
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:11:15.526
  STEP: Creating a test namespace @ 01/27/26 21:11:15.533
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:11:15.547
  STEP: Creating a service in the namespace @ 01/27/26 21:11:15.584
  STEP: Deleting the namespace @ 01/27/26 21:11:15.602
  STEP: Waiting for the namespace to be removed. @ 01/27/26 21:11:15.625
  E0127 21:11:16.340844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:17.340980      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:18.341646      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:19.342183      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:20.342299      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:21.342755      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 01/27/26 21:11:21.628
  STEP: Verifying there is no service in the namespace @ 01/27/26 21:11:21.648
  I0127 21:11:21.651213 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-5748" for this suite. @ 01/27/26 21:11:21.653
  STEP: Destroying namespace "nsdeletetest-5359" for this suite. @ 01/27/26 21:11:21.661
  I0127 21:11:21.662321 26 framework.go:370] Namespace nsdeletetest-5359 was already deleted
  STEP: Destroying namespace "nsdeletetest-1708" for this suite. @ 01/27/26 21:11:21.662
• [6.356 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:170
  STEP: Creating a kubernetes client @ 01/27/26 21:11:21.675
  I0127 21:11:21.675884 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename security-context @ 01/27/26 21:11:21.676
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:11:21.693
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:11:21.703
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 01/27/26 21:11:21.705
  E0127 21:11:22.343005      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:23.343490      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:24.343932      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:25.344025      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:11:25.73
  I0127 21:11:25.732419 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod security-context-46b5253d-2d01-49fa-91f8-857ab43f478b container test-container: <nil>
  STEP: delete the pod @ 01/27/26 21:11:25.736
  I0127 21:11:25.766685 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-8499" for this suite. @ 01/27/26 21:11:25.769
• [4.101 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Secrets should be consumable as environment variable names variable names with various prefixes [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:253
  STEP: Creating a kubernetes client @ 01/27/26 21:11:25.777
  I0127 21:11:25.777235 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename secrets @ 01/27/26 21:11:25.777
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:11:25.813
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:11:25.815
  STEP: creating secret secrets-6151/secret-test-3e3a8ad2-47a2-4de9-8944-0eb2dda9eb32 @ 01/27/26 21:11:25.819
  STEP: Creating a pod to test consume secrets @ 01/27/26 21:11:25.844
  E0127 21:11:26.344823      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:27.345943      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:28.346473      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:29.346678      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:11:29.875
  I0127 21:11:29.876794 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-secret-0b6fa95f-af8d-420f-8e91-475ea7e85d2a container env-test: <nil>
  STEP: delete the pod @ 01/27/26 21:11:29.882
  I0127 21:11:29.910603 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6151" for this suite. @ 01/27/26 21:11:29.912
• [4.143 seconds]
------------------------------
SSS
------------------------------
[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 DeviceClass [Conformance] [sig-node, DRA, Conformance]
k8s.io/kubernetes/test/e2e/dra/dra.go:87
  STEP: Creating a kubernetes client @ 01/27/26 21:11:29.92
  I0127 21:11:29.920795 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename dra @ 01/27/26 21:11:29.921
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:11:29.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:11:29.949
  STEP: Get resource.k8s.io/v1 @ 01/27/26 21:11:29.963
  I0127 21:11:29.965073      26 shared_informer.go:370] "Waiting for caches to sync"
  I0127 21:11:30.065500      26 shared_informer.go:377] "Caches are synced"
  STEP: Creating:
      <*unstructured.Unstructured | 0xc0006e42e8>: 
          metadata:
            labels:
              e2e-test.kubernetes.io: dra-1599
            name: test-dra-1599
          spec:
            selectors:
            - cel:
                expression: "false" @ 01/27/26 21:11:30.065
  STEP: Getting test-dra-1599 @ 01/27/26 21:11:30.074
  STEP: Updating:
      <*unstructured.Unstructured | 0xc000790c90>: 
          apiVersion: resource.k8s.io/v1
          kind: DeviceClass
          metadata:
            creationTimestamp: "2026-01-27T21:11:30Z"
            generation: 1
            labels:
              e2e-test.kubernetes.io: dra-1599
            managedFields:
            - apiVersion: resource.k8s.io/v1
              fieldsType: FieldsV1
              fieldsV1:
                f:metadata:
                  f:labels:
                    .: {}
                    f:e2e-test.kubernetes.io: {}
                f:spec:
                  f:selectors: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:11:30Z"
            name: test-dra-1599
            resourceVersion: "31740"
            uid: 080b3fd5-1fef-4dae-a2e7-a487332767ea
          spec:
            selectors:
            - cel:
                expression: 1 == 0 @ 01/27/26 21:11:30.076
  STEP: Deleting test-dra-1599 @ 01/27/26 21:11:30.084
  STEP: Checking for existence @ 01/27/26 21:11:30.092
  STEP: Creating again:
      <*unstructured.Unstructured | 0xc0006e42e8>: 
          metadata:
            labels:
              e2e-test.kubernetes.io: dra-1599
            name: test-dra-1599
          spec:
            selectors:
            - cel:
                expression: "false" @ 01/27/26 21:11:30.094
  STEP: Patching with application/strategic-merge-patch+json:
  {"apiVersion":"resource.k8s.io/v1","kind":"DeviceClass","metadata":{"name":"test-dra-1599","uid":"0bfad9c2-3bca-4199-b97a-b5ff5374f1b4"},"spec":{"selectors":[{"cel":{"expression":"1 == 0"}}]}}
   @ 01/27/26 21:11:30.106
  STEP: Listing resource.k8s.io/v1, Resource=deviceclasses collection with label selector e2e-test.kubernetes.io=dra-1599 @ 01/27/26 21:11:30.115
  STEP: Deleting resource.k8s.io/v1, Resource=deviceclasses collection with label selector e2e-test.kubernetes.io=dra-1599 @ 01/27/26 21:11:30.117
  STEP: Checking for existence @ 01/27/26 21:11:30.126
  I0127 21:11:30.129193 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dra-1599" for this suite. @ 01/27/26 21:11:30.131
• [0.226 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:144
  STEP: Creating a kubernetes client @ 01/27/26 21:11:30.146
  I0127 21:11:30.146854 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename endpointslice @ 01/27/26 21:11:30.148
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:11:30.175
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:11:30.26
  E0127 21:11:30.346880      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:31.347951      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:32.348925      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 01/27/26 21:11:32.366
  STEP: referencing matching pods with named port @ 01/27/26 21:11:32.369
  STEP: recreating EndpointSlices after they've been deleted @ 01/27/26 21:11:32.371
  I0127 21:11:32.396988 26 endpointslice.go:801] EndpointSlice for Service endpointslice-9939/example-named-port not found
  E0127 21:11:33.349007      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:34.349202      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:11:34.400103 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-9939" for this suite. @ 01/27/26 21:11:34.403
• [4.265 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Job with successPolicy succeededIndexes rule should succeeded even when some indexes remain pending [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:526
  STEP: Creating a kubernetes client @ 01/27/26 21:11:34.411
  I0127 21:11:34.411606 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename job @ 01/27/26 21:11:34.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:11:34.441
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:11:34.443
  STEP: Creating an indexed job with successPolicy succeededIndexes rule @ 01/27/26 21:11:34.447
  STEP: Awaiting for the job to have the interim SuccessCriteriaMet with SuccessPolicy reason condition @ 01/27/26 21:11:34.455
  E0127 21:11:35.349685      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:36.350198      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:37.350647      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:38.351068      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:39.351377      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:40.351712      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensure that the job reaches completions @ 01/27/26 21:11:40.466
  STEP: Verifying that the only appropriately index succeeded @ 01/27/26 21:11:40.469
  I0127 21:11:40.470857 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-848" for this suite. @ 01/27/26 21:11:40.472
• [6.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:52
  STEP: Creating a kubernetes client @ 01/27/26 21:11:40.482
  I0127 21:11:40.482296 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename csiinlinevolumes @ 01/27/26 21:11:40.482
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:11:40.504
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:11:40.509
  STEP: creating @ 01/27/26 21:11:40.511
  STEP: getting @ 01/27/26 21:11:40.557
  STEP: listing in namespace @ 01/27/26 21:11:40.558
  STEP: patching @ 01/27/26 21:11:40.56
  STEP: deleting @ 01/27/26 21:11:40.593
  I0127 21:11:40.608118 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-8063" for this suite. @ 01/27/26 21:11:40.61
• [0.136 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:59
  STEP: Creating a kubernetes client @ 01/27/26 21:11:40.618
  I0127 21:11:40.618685 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename runtimeclass @ 01/27/26 21:11:40.619
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:11:40.639
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:11:40.645
  I0127 21:11:40.651619 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-663" for this suite. @ 01/27/26 21:11:40.71
• [0.101 seconds]
------------------------------
SS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:165
  STEP: Creating a kubernetes client @ 01/27/26 21:11:40.719
  I0127 21:11:40.719729 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pods @ 01/27/26 21:11:40.72
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:11:40.736
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:11:40.748
  STEP: creating the pod @ 01/27/26 21:11:40.75
  STEP: submitting the pod to kubernetes @ 01/27/26 21:11:40.75
  STEP: verifying QOS class is set on the pod @ 01/27/26 21:11:40.759
  I0127 21:11:40.763488 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3593" for this suite. @ 01/27/26 21:11:40.813
• [0.112 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 01/27/26 21:11:40.831
  I0127 21:11:40.831779 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename container-probe @ 01/27/26 21:11:40.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:11:40.861
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:11:40.862
  STEP: Creating pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620 @ 01/27/26 21:11:40.901
  E0127 21:11:41.352718      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:42.352915      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 01/27/26 21:11:42.918
  I0127 21:11:42.919587 26 container_probe.go:1746] Initial restart count of pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 is 0
  I0127 21:11:42.921425 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:11:43.353647      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:44.354177      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:11:44.925927 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:11:45.354527      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:46.354868      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:11:46.930752 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:11:47.355234      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:48.355443      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:11:48.933574 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:11:49.356111      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:50.356634      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:11:50.937364 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:11:51.356778      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:52.357012      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:11:52.939728 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:11:53.357316      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:54.357511      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:11:54.943016 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:11:55.357597      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:56.357813      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:11:56.945738 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:11:57.358431      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:11:58.358636      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:11:58.948677 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:11:59.359219      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:00.360303      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:00.951448 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:01.362272      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:02.362504      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:02.953821 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:03.363584      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:04.363886      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:04.956701 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:05.364178      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:06.364366      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:06.960084 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:07.364612      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:08.364993      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:08.963037 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:09.365554      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:10.366395      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:10.965933 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:11.367442      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:12.367673      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:12.968349 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:13.367880      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:14.367980      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:14.971478 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:15.369143      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:16.369583      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:16.973724 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:17.370273      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:18.370506      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:18.976738 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:19.371295      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:20.371569      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:20.979535 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:21.371854      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:22.372094      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:22.981691 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:23.372279      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:24.372866      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:24.984842 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:25.373617      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:26.373844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:26.987587 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:27.373966      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:28.374977      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:28.990610 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:29.375083      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:30.375902      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:31.000775 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:31.376888      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:32.377119      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:33.004041 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:33.377425      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:34.377659      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:35.007099 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:35.377725      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:36.377934      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:37.009787 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:37.378184      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:38.378256      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:39.012979 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:39.379266      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:40.379433      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:41.015288 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:41.379727      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:42.379873      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:43.017697 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:43.380260      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:44.380820      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:45.021017 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:45.381098      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:46.381324      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:47.024264 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:47.381684      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:48.383885      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:49.027127 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:49.384620      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:50.385134      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:51.031044 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:51.385291      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:52.385532      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:53.033771 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:53.386288      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:54.387285      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:55.037060 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:55.387808      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:56.388053      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:57.040332 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:57.389093      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:12:58.390087      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:12:59.043265 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:12:59.391196      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:00.391390      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:01.046546 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:01.392185      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:02.392412      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:03.049352 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:03.392756      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:04.392909      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:05.051906 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:05.393824      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:06.394076      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:07.054876 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:07.394219      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:08.394393      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:09.057778 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:09.395220      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:10.396019      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:11.061070 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:11.396670      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:12.397608      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:13.063491 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:13.397841      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:14.398051      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:15.066544 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:15.398281      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:16.398502      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:17.070243 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:17.398621      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:18.398831      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:19.072990 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:19.399385      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:20.399742      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:21.076610 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:21.400868      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:22.401217      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:23.079468 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:23.401968      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:24.402179      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:25.083533 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:25.402443      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:26.402645      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:27.087388 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:27.402752      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:28.403049      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:29.089891 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:29.403288      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:30.403519      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:31.092292 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:31.403747      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:32.403935      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:33.095141 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:33.404518      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:34.405598      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:35.097523 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:35.406111      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:36.406325      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:37.101098 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:37.406604      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:38.406922      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:39.104546 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:39.407990      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:40.408150      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:41.107857 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:41.408191      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:42.408441      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:43.110968 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:43.409405      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:44.409610      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:45.113744 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:45.410671      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:46.410920      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:47.115989 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:47.411667      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:48.411755      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:49.119845 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:49.412193      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:50.412579      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:51.123057 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:51.413281      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:52.413518      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:53.128058 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:53.414607      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:54.414810      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:55.132175 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:55.415653      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:56.415741      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:57.134886 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:57.416268      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:13:58.416826      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:13:59.138383 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:13:59.416970      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:00.417115      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:01.141746 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:01.417168      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:02.417384      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:03.144316 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:03.417644      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:04.417967      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:05.146890 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:05.418565      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:06.418780      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:07.150434 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:07.419321      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:08.419531      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:09.153644 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:09.420182      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:10.420323      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:11.156563 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:11.420842      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:12.421045      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:13.159394 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:13.421791      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:14.422039      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:15.162015 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:15.423028      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:16.423248      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:17.165343 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:17.423742      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:18.423932      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:19.168694 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:19.423980      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:20.424148      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:21.171654 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:21.424840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:22.425277      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:23.174255 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:23.425596      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:24.425849      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:25.178205 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:25.426773      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:26.427018      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:27.181523 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:27.427893      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:28.428905      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:29.184742 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:29.429044      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:30.429233      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:31.187473 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:31.429387      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:32.429579      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:33.190490 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:33.429777      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:34.430014      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:35.192695 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:35.430539      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:36.430736      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:37.195964 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:37.430820      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:38.431062      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:39.200524 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:39.431868      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:40.432042      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:41.203409 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:41.432776      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:42.433308      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:43.205790 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:43.434073      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:44.434301      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:45.208111 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:45.434905      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:46.435113      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:47.212347 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:47.435939      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:48.436858      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:49.215434 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:49.437757      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:50.437948      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:51.218421 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:51.439382      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:52.439566      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:53.223338 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:53.440258      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:54.440498      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:55.226643 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:55.441169      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:56.441704      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:57.229695 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:57.441911      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:14:58.442459      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:14:59.233562 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:14:59.443014      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:00.443183      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:01.236100 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:01.443326      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:02.443526      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:03.238892 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:03.444190      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:04.444476      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:05.242751 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:05.445417      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:06.445647      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:07.245507 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:07.446214      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:08.446453      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:09.249189 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:09.447550      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:10.447970      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:11.252349 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:11.448785      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:12.449021      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:13.254785 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:13.450083      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:14.450346      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:15.258072 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:15.450459      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:16.450676      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:17.261249 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:17.451579      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:18.451798      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:19.264493 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:19.452746      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:20.453091      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:21.267813 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:21.453201      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:22.454650      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:23.271465 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:23.454696      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:24.454909      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:25.274817 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:25.455521      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:26.455735      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:27.278416 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:27.456711      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:28.456915      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:29.281632 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:29.458226      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:30.458578      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:31.284377 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:31.459254      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:32.460074      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:33.287460 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:33.460705      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:34.461039      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:35.290772 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:35.462077      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:36.462830      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:37.293188 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:37.463728      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:38.463953      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:39.297643 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:39.464937      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:40.465085      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:15:41.300630 26 container_probe.go:1756] Get pod busybox-49528017-c55a-48c7-818b-f43e5f7290b3 in namespace container-probe-7620
  E0127 21:15:41.465422      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:42.465516      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 01/27/26 21:15:43.301
  I0127 21:15:43.333419 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7620" for this suite. @ 01/27/26 21:15:43.341
• [242.518 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:53
  STEP: Creating a kubernetes client @ 01/27/26 21:15:43.35
  I0127 21:15:43.350149 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename container-runtime @ 01/27/26 21:15:43.351
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:15:43.37
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:15:43.378
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 01/27/26 21:15:43.388
  E0127 21:15:43.466765      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:44.466806      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:45.467783      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:46.468487      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:47.468649      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:48.469078      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:49.469721      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:50.470500      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:51.471232      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:52.471410      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:53.472336      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:54.472781      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:55.473125      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:56.473561      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:57.474358      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:15:58.474980      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 01/27/26 21:15:59.439
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 01/27/26 21:15:59.441
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 01/27/26 21:15:59.444
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 01/27/26 21:15:59.444
  E0127 21:15:59.474957      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 01/27/26 21:15:59.48
  E0127 21:16:00.475255      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:01.475856      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:02.476846      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 01/27/26 21:16:02.503
  E0127 21:16:03.477231      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 01/27/26 21:16:03.507
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 01/27/26 21:16:03.512
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 01/27/26 21:16:03.512
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 01/27/26 21:16:03.541
  E0127 21:16:04.477457      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 01/27/26 21:16:04.552
  E0127 21:16:05.478515      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:06.478709      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 01/27/26 21:16:06.56
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 01/27/26 21:16:06.562
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 01/27/26 21:16:06.562
  I0127 21:16:06.596383 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1611" for this suite. @ 01/27/26 21:16:06.598
• [23.256 seconds]
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1826
  STEP: Creating a kubernetes client @ 01/27/26 21:16:06.606
  I0127 21:16:06.606645 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubectl @ 01/27/26 21:16:06.607
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:16:06.628
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:16:06.641
  STEP: running the image registry.k8s.io/e2e-test-images/agnhost:2.59 @ 01/27/26 21:16:06.643
  I0127 21:16:06.644002 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9944 run e2e-test-agnhost-pod --image=registry.k8s.io/e2e-test-images/agnhost:2.59 --pod-running-timeout=2m0s --labels=run=e2e-test-agnhost-pod'
  I0127 21:16:06.723538 26 builder.go:156] stderr: ""
  I0127 21:16:06.723577 26 builder.go:157] stdout: "pod/e2e-test-agnhost-pod created\n"
  STEP: verifying the pod e2e-test-agnhost-pod is running @ 01/27/26 21:16:06.723
  E0127 21:16:07.479038      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:08.479636      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:09.479782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:10.480807      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:11.481746      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-agnhost-pod was created @ 01/27/26 21:16:11.775
  I0127 21:16:11.775211 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9944 get pod e2e-test-agnhost-pod -o json'
  I0127 21:16:11.834117 26 builder.go:156] stderr: ""
  I0127 21:16:11.834214 26 builder.go:157] stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2026-01-27T21:16:06Z\",\n        \"generation\": 1,\n        \"labels\": {\n            \"run\": \"e2e-test-agnhost-pod\"\n        },\n        \"name\": \"e2e-test-agnhost-pod\",\n        \"namespace\": \"kubectl-9944\",\n        \"resourceVersion\": \"32834\",\n        \"uid\": \"7aa939fd-6ab8-42ee-a046-313572a8d922\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/agnhost:2.59\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-agnhost-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-ds4x6\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-ds4x6\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2026-01-27T21:16:07Z\",\n                \"observedGeneration\": 1,\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2026-01-27T21:16:06Z\",\n                \"observedGeneration\": 1,\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2026-01-27T21:16:07Z\",\n                \"observedGeneration\": 1,\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2026-01-27T21:16:07Z\",\n                \"observedGeneration\": 1,\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2026-01-27T21:16:06Z\",\n                \"observedGeneration\": 1,\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://33d57ac15e30beb3adebab12d2f1f63c1f2551427d78606d219e98c514b4b192\",\n                \"image\": \"registry.k8s.io/e2e-test-images/agnhost:2.59\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/agnhost@sha256:10ed98804c877e505e17bced991682b6fd50ab1da9cddcd19935b48d645da40a\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-agnhost-pod\",\n                \"ready\": true,\n                \"resources\": {},\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2026-01-27T21:16:07Z\"\n                    }\n                },\n                \"user\": {\n                    \"linux\": {\n                        \"gid\": 0,\n                        \"supplementalGroups\": [\n                            0,\n                            1,\n                            2,\n                            3,\n                            4,\n                            6,\n                            10,\n                            11,\n                            20,\n                            26,\n                            27\n                        ],\n                        \"uid\": 0\n                    }\n                },\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-ds4x6\",\n                        \"readOnly\": true,\n                        \"recursiveReadOnly\": \"Disabled\"\n                    }\n                ]\n            }\n        ],\n        \"hostIP\": \"10.42.0.10\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"10.42.0.10\"\n            }\n        ],\n        \"observedGeneration\": 1,\n        \"phase\": \"Running\",\n        \"podIP\": \"10.52.1.46\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.52.1.46\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2026-01-27T21:16:06Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 01/27/26 21:16:11.834
  I0127 21:16:11.834301 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9944 replace -f -'
  I0127 21:16:11.983735 26 builder.go:156] stderr: ""
  I0127 21:16:11.983771 26 builder.go:157] stdout: "pod/e2e-test-agnhost-pod replaced\n"
  STEP: verifying the pod e2e-test-agnhost-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.37.0-1 @ 01/27/26 21:16:11.983
  I0127 21:16:12.000163 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9944 delete pods e2e-test-agnhost-pod'
  E0127 21:16:12.483147      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:13.483395      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:16:14.029854 26 builder.go:156] stderr: ""
  I0127 21:16:14.029895 26 builder.go:157] stdout: "pod \"e2e-test-agnhost-pod\" deleted from kubectl-9944 namespace\n"
  I0127 21:16:14.030011 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9944" for this suite. @ 01/27/26 21:16:14.033
• [7.436 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:236
  STEP: Creating a kubernetes client @ 01/27/26 21:16:14.042
  I0127 21:16:14.042500 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename downward-api @ 01/27/26 21:16:14.043
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:16:14.075
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:16:14.076
  STEP: Creating a pod to test downward API volume plugin @ 01/27/26 21:16:14.079
  E0127 21:16:14.483438      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:15.484050      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:16.484653      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:17.484862      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:16:18.148
  I0127 21:16:18.150284 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downwardapi-volume-0cb1b4d1-6c07-4be0-99a6-01b914c5ddef container client-container: <nil>
  STEP: delete the pod @ 01/27/26 21:16:18.161
  I0127 21:16:18.184649 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1059" for this suite. @ 01/27/26 21:16:18.187
• [4.154 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:99
  STEP: Creating a kubernetes client @ 01/27/26 21:16:18.196
  I0127 21:16:18.196877 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 21:16:18.197
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:16:18.213
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:16:18.314
  STEP: Creating configMap with name projected-configmap-test-volume-map-74a01ad5-6381-4217-8531-861446c58765 @ 01/27/26 21:16:18.316
  STEP: Creating a pod to test consume configMaps @ 01/27/26 21:16:18.324
  E0127 21:16:18.485483      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:19.485662      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:20.486406      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:21.486617      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:16:22.342
  I0127 21:16:22.344753 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-projected-configmaps-34aecf8e-0502-406f-82b4-4168adf9ce9f container agnhost-container: <nil>
  STEP: delete the pod @ 01/27/26 21:16:22.348
  I0127 21:16:22.378377 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4789" for this suite. @ 01/27/26 21:16:22.38
• [4.191 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 01/27/26 21:16:22.387
  I0127 21:16:22.387770 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename secrets @ 01/27/26 21:16:22.388
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:16:22.403
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:16:22.416
  STEP: Creating secret with name secret-test-8ba79f1e-af73-4f73-a5d3-6a8a271164a0 @ 01/27/26 21:16:22.417
  STEP: Creating a pod to test consume secrets @ 01/27/26 21:16:22.433
  E0127 21:16:22.486966      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:23.487170      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:24.487657      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:25.488438      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:16:26.457
  I0127 21:16:26.459811 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-secrets-d032c6f6-7f72-4acb-9eb0-f2151aca0f2d container secret-volume-test: <nil>
  STEP: delete the pod @ 01/27/26 21:16:26.463
  E0127 21:16:26.489065      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:16:26.506738 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-461" for this suite. @ 01/27/26 21:16:26.509
• [4.131 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:330
  STEP: Creating a kubernetes client @ 01/27/26 21:16:26.519
  I0127 21:16:26.519241 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename gc @ 01/27/26 21:16:26.52
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:16:26.54
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:16:26.543
  STEP: create the rc @ 01/27/26 21:16:26.545
  I0127 21:16:26.558381      26 warnings.go:107] "Warning: metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]"
  E0127 21:16:27.489114      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:28.489303      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:29.489532      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:30.489673      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:31.489940      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the rc @ 01/27/26 21:16:31.628
  STEP: wait for all pods to be garbage collected @ 01/27/26 21:16:31.642
  E0127 21:16:32.490265      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:33.490507      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:34.490725      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:35.491625      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:36.491763      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 01/27/26 21:16:36.647
  W0127 21:16:36.650488      26 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I0127 21:16:36.650532 26 garbage_collector.go:273] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0127 21:16:36.650678 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1930" for this suite. @ 01/27/26 21:16:36.653
• [10.142 seconds]
------------------------------
S
------------------------------
[sig-network] EndpointSlice should support a Service with multiple ports specified in multiple EndpointSlices [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:458
  STEP: Creating a kubernetes client @ 01/27/26 21:16:36.661
  I0127 21:16:36.661489 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename endpointslice @ 01/27/26 21:16:36.662
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:16:36.682
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:16:36.684
  E0127 21:16:37.492023      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:38.492276      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: creating @ 01/27/26 21:16:38.731
  STEP: Creating a pause pods that will try to connect to the webserver @ 01/27/26 21:16:38.746
  E0127 21:16:39.492444      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:40.492570      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:16:40.768238 26 util.go:162] Waiting up to 2m0s to get response from 10.53.218.146:80
  I0127 21:16:40.768295 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=endpointslice-7831 exec pause-pod-0 -- /bin/sh -x -c curl -q -s --max-time 30 10.53.218.146:80/hostname'
  I0127 21:16:40.874191 26 builder.go:156] stderr: "+ curl -q -s --max-time 30 10.53.218.146:80/hostname\n"
  I0127 21:16:40.874240 26 builder.go:157] stdout: "pod-handle-http-request"
  I0127 21:16:40.874258 26 util.go:162] Waiting up to 2m0s to get response from 10.53.218.146:81
  I0127 21:16:40.874294 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=endpointslice-7831 exec pause-pod-0 -- /bin/sh -x -c curl -q -s --max-time 30 10.53.218.146:81/hostname'
  I0127 21:16:40.974478 26 builder.go:156] stderr: "+ curl -q -s --max-time 30 10.53.218.146:81/hostname\n"
  I0127 21:16:40.974538 26 builder.go:157] stdout: "pod-handle-http-request"
  I0127 21:16:40.974656 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-7831" for this suite. @ 01/27/26 21:16:40.976
• [4.329 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:250
  STEP: Creating a kubernetes client @ 01/27/26 21:16:40.99
  I0127 21:16:40.990980 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename downward-api @ 01/27/26 21:16:40.991
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:16:41.007
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:16:41.012
  STEP: Creating a pod to test downward API volume plugin @ 01/27/26 21:16:41.014
  E0127 21:16:41.492809      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:42.493028      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:43.493079      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:44.493278      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:16:45.046
  I0127 21:16:45.048520 26 output.go:207] Trying to get logs from node k3k-k3kcluster-server-0 pod downwardapi-volume-edfd5fb7-68d1-4d64-9ec7-74b676670909 container client-container: <nil>
  STEP: delete the pod @ 01/27/26 21:16:45.058
  I0127 21:16:45.089753 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5590" for this suite. @ 01/27/26 21:16:45.091
• [4.109 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 01/27/26 21:16:45.1
  I0127 21:16:45.100183 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename sysctl @ 01/27/26 21:16:45.1
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:16:45.135
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:16:45.137
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 01/27/26 21:16:45.139
  STEP: Watching for error events or started pod @ 01/27/26 21:16:45.148
  E0127 21:16:45.493629      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:46.493866      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:47.494596      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:48.494630      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 01/27/26 21:16:49.151
  E0127 21:16:49.495173      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:50.495291      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 01/27/26 21:16:51.157
  STEP: Getting logs from the pod @ 01/27/26 21:16:51.157
  STEP: Checking that the sysctl is actually updated @ 01/27/26 21:16:51.16
  I0127 21:16:51.161129 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-7382" for this suite. @ 01/27/26 21:16:51.163
• [6.086 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:370
  STEP: Creating a kubernetes client @ 01/27/26 21:16:51.186
  I0127 21:16:51.186261 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubectl @ 01/27/26 21:16:51.186
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:16:51.203
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:16:51.208
  STEP: creating a replication controller @ 01/27/26 21:16:51.21
  I0127 21:16:51.210595 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 create -f -'
  I0127 21:16:51.332951 26 builder.go:156] stderr: ""
  I0127 21:16:51.332993 26 builder.go:157] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 01/27/26 21:16:51.333
  I0127 21:16:51.333064 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0127 21:16:51.398995 26 builder.go:156] stderr: ""
  I0127 21:16:51.399032 26 builder.go:157] stdout: "update-demo-nautilus-885l6 update-demo-nautilus-vg2gv "
  I0127 21:16:51.399071 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 get pods update-demo-nautilus-885l6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0127 21:16:51.456076 26 builder.go:156] stderr: ""
  I0127 21:16:51.456114 26 builder.go:157] stdout: ""
  I0127 21:16:51.456124 26 kubectl.go:2537] update-demo-nautilus-885l6 is created but not running
  E0127 21:16:51.496440      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:52.496523      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:53.496700      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:54.496935      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:16:55.498320      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:16:56.456760 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0127 21:16:56.499180      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:16:56.518743 26 builder.go:156] stderr: ""
  I0127 21:16:56.518781 26 builder.go:157] stdout: "update-demo-nautilus-885l6 update-demo-nautilus-vg2gv "
  I0127 21:16:56.518818 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 get pods update-demo-nautilus-885l6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0127 21:16:56.575641 26 builder.go:156] stderr: ""
  I0127 21:16:56.575684 26 builder.go:157] stdout: "true"
  I0127 21:16:56.575724 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 get pods update-demo-nautilus-885l6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0127 21:16:56.643048 26 builder.go:156] stderr: ""
  I0127 21:16:56.643090 26 builder.go:157] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0127 21:16:56.643101 26 kubectl.go:2428] validating pod update-demo-nautilus-885l6
  I0127 21:16:56.648231 26 kubectl.go:2448] got data: {
    "image": "nautilus.jpg"
  }

  I0127 21:16:56.648720 26 kubectl.go:2453] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0127 21:16:56.648756 26 kubectl.go:2555] update-demo-nautilus-885l6 is verified up and running
  I0127 21:16:56.648793 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 get pods update-demo-nautilus-vg2gv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0127 21:16:56.707662 26 builder.go:156] stderr: ""
  I0127 21:16:56.707697 26 builder.go:157] stdout: "true"
  I0127 21:16:56.707734 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 get pods update-demo-nautilus-vg2gv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0127 21:16:56.767679 26 builder.go:156] stderr: ""
  I0127 21:16:56.767716 26 builder.go:157] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0127 21:16:56.767740 26 kubectl.go:2428] validating pod update-demo-nautilus-vg2gv
  I0127 21:16:56.772121 26 kubectl.go:2448] got data: {
    "image": "nautilus.jpg"
  }

  I0127 21:16:56.772170 26 kubectl.go:2453] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0127 21:16:56.772192 26 kubectl.go:2555] update-demo-nautilus-vg2gv is verified up and running
  STEP: scaling down the replication controller @ 01/27/26 21:16:56.772
  I0127 21:16:56.773303 26 kubectl.go:339] scanned /root for discovery docs: <nil>
  I0127 21:16:56.773362 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E0127 21:16:57.499343      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:16:57.857408 26 builder.go:156] stderr: ""
  I0127 21:16:57.857448 26 builder.go:157] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 01/27/26 21:16:57.857
  I0127 21:16:57.857530 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0127 21:16:57.918657 26 builder.go:156] stderr: ""
  I0127 21:16:57.918697 26 builder.go:157] stdout: "update-demo-nautilus-885l6 "
  I0127 21:16:57.918739 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 get pods update-demo-nautilus-885l6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0127 21:16:57.980672 26 builder.go:156] stderr: ""
  I0127 21:16:57.980727 26 builder.go:157] stdout: "true"
  I0127 21:16:57.980771 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 get pods update-demo-nautilus-885l6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0127 21:16:58.038144 26 builder.go:156] stderr: ""
  I0127 21:16:58.038184 26 builder.go:157] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0127 21:16:58.038197 26 kubectl.go:2428] validating pod update-demo-nautilus-885l6
  I0127 21:16:58.042575 26 kubectl.go:2448] got data: {
    "image": "nautilus.jpg"
  }

  I0127 21:16:58.042632 26 kubectl.go:2453] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0127 21:16:58.042644 26 kubectl.go:2555] update-demo-nautilus-885l6 is verified up and running
  STEP: scaling up the replication controller @ 01/27/26 21:16:58.042
  I0127 21:16:58.044126 26 kubectl.go:339] scanned /root for discovery docs: <nil>
  I0127 21:16:58.044175 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E0127 21:16:58.499960      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:16:59.116244 26 builder.go:156] stderr: ""
  I0127 21:16:59.116281 26 builder.go:157] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 01/27/26 21:16:59.116
  I0127 21:16:59.116348 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0127 21:16:59.210822 26 builder.go:156] stderr: ""
  I0127 21:16:59.210863 26 builder.go:157] stdout: "update-demo-nautilus-885l6 update-demo-nautilus-xmnxn "
  I0127 21:16:59.210907 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 get pods update-demo-nautilus-885l6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0127 21:16:59.269192 26 builder.go:156] stderr: ""
  I0127 21:16:59.269231 26 builder.go:157] stdout: "true"
  I0127 21:16:59.269276 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 get pods update-demo-nautilus-885l6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0127 21:16:59.327918 26 builder.go:156] stderr: ""
  I0127 21:16:59.327956 26 builder.go:157] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0127 21:16:59.327972 26 kubectl.go:2428] validating pod update-demo-nautilus-885l6
  I0127 21:16:59.330064 26 kubectl.go:2448] got data: {
    "image": "nautilus.jpg"
  }

  I0127 21:16:59.330113 26 kubectl.go:2453] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0127 21:16:59.330124 26 kubectl.go:2555] update-demo-nautilus-885l6 is verified up and running
  I0127 21:16:59.330156 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 get pods update-demo-nautilus-xmnxn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0127 21:16:59.387360 26 builder.go:156] stderr: ""
  I0127 21:16:59.387399 26 builder.go:157] stdout: "true"
  I0127 21:16:59.387441 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 get pods update-demo-nautilus-xmnxn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0127 21:16:59.442403 26 builder.go:156] stderr: ""
  I0127 21:16:59.442444 26 builder.go:157] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0127 21:16:59.442457 26 kubectl.go:2428] validating pod update-demo-nautilus-xmnxn
  I0127 21:16:59.447155 26 kubectl.go:2448] got data: {
    "image": "nautilus.jpg"
  }

  I0127 21:16:59.447209 26 kubectl.go:2453] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0127 21:16:59.447230 26 kubectl.go:2555] update-demo-nautilus-xmnxn is verified up and running
  STEP: using delete to clean up resources @ 01/27/26 21:16:59.447
  I0127 21:16:59.447314 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 delete --grace-period=0 --force -f -'
  E0127 21:16:59.500586      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:16:59.509513 26 builder.go:156] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0127 21:16:59.509550 26 builder.go:157] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted from kubectl-9603 namespace\n"
  I0127 21:16:59.509599 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 get rc,svc -l name=update-demo --no-headers'
  I0127 21:16:59.577105 26 builder.go:156] stderr: "No resources found in kubectl-9603 namespace.\n"
  I0127 21:16:59.577144 26 builder.go:157] stdout: ""
  I0127 21:16:59.577181 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9603 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0127 21:16:59.639755 26 builder.go:156] stderr: ""
  I0127 21:16:59.639795 26 builder.go:157] stdout: ""
  I0127 21:16:59.639930 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9603" for this suite. @ 01/27/26 21:16:59.642
• [8.465 seconds]
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:207
  STEP: Creating a kubernetes client @ 01/27/26 21:16:59.651
  I0127 21:16:59.651662 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename daemonsets @ 01/27/26 21:16:59.652
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:16:59.672
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:16:59.675
  I0127 21:16:59.757172 26 daemon_set.go:210] Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 01/27/26 21:16:59.765
  I0127 21:16:59.766782 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:16:59.766825 26 fixtures.go:138] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 01/27/26 21:16:59.766
  I0127 21:16:59.867327 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:16:59.867371 26 fixtures.go:133] Node k3k-k3kcluster-server-0 is running 0 daemon pod, expected 1
  E0127 21:17:00.500932      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:17:00.862495 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:17:00.862529 26 fixtures.go:133] Node k3k-k3kcluster-server-0 is running 0 daemon pod, expected 1
  E0127 21:17:01.502007      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:17:01.862951 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0127 21:17:01.862985 26 fixtures.go:138] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 01/27/26 21:17:01.864
  I0127 21:17:01.896961 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:17:01.896998 26 fixtures.go:138] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 01/27/26 21:17:01.897
  I0127 21:17:01.969522 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:17:01.969571 26 fixtures.go:133] Node k3k-k3kcluster-server-0 is running 0 daemon pod, expected 1
  E0127 21:17:02.502060      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:17:02.935347 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:17:02.935380 26 fixtures.go:133] Node k3k-k3kcluster-server-0 is running 0 daemon pod, expected 1
  E0127 21:17:03.502165      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:17:03.936820 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:17:03.936856 26 fixtures.go:133] Node k3k-k3kcluster-server-0 is running 0 daemon pod, expected 1
  E0127 21:17:04.502550      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:17:05.008131 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0127 21:17:05.008170 26 fixtures.go:138] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 01/27/26 21:17:05.012
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6674, will wait for the garbage collector to delete the pods @ 01/27/26 21:17:05.012
  I0127 21:17:05.073296 26 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 8.233187ms
  I0127 21:17:05.174238 26 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.936773ms
  E0127 21:17:05.503728      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:06.504223      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:17:07.176548 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:17:07.176582 26 fixtures.go:138] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0127 21:17:07.179068 26 daemon_set.go:137] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"33399"},"items":null}

  I0127 21:17:07.180529 26 daemon_set.go:142] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"33399"},"items":null}

  I0127 21:17:07.202123 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6674" for this suite. @ 01/27/26 21:17:07.204
• [7.561 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:209
  STEP: Creating a kubernetes client @ 01/27/26 21:17:07.212
  I0127 21:17:07.213006 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename emptydir @ 01/27/26 21:17:07.213
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:17:07.23
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:17:07.242
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 01/27/26 21:17:07.244
  E0127 21:17:07.504839      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:08.504944      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:09.505392      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:10.505921      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:17:11.272
  I0127 21:17:11.274672 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-02de25f0-86c4-4f39-9e47-77a316f8a827 container test-container: <nil>
  STEP: delete the pod @ 01/27/26 21:17:11.278
  I0127 21:17:11.301016 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5581" for this suite. @ 01/27/26 21:17:11.302
• [4.103 seconds]
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 01/27/26 21:17:11.316
  I0127 21:17:11.316373 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename subpath @ 01/27/26 21:17:11.317
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:17:11.332
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:17:11.337
  STEP: Setting up data @ 01/27/26 21:17:11.339
  STEP: Creating pod pod-subpath-test-projected-dlxj @ 01/27/26 21:17:11.354
  STEP: Creating a pod to test atomic-volume-subpath @ 01/27/26 21:17:11.354
  E0127 21:17:11.506367      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:12.507337      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:13.508393      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:14.508499      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:15.509017      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:16.509356      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:17.509851      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:18.510058      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:19.510761      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:20.511173      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:21.511164      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:22.511406      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:23.511855      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:24.513181      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:25.513323      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:26.513540      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:27.513919      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:28.514478      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:29.515550      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:30.515685      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:31.516474      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:32.516798      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:33.517488      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:34.517632      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:17:35.424
  I0127 21:17:35.426529 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-subpath-test-projected-dlxj container test-container-subpath-projected-dlxj: <nil>
  STEP: delete the pod @ 01/27/26 21:17:35.43
  STEP: Deleting pod pod-subpath-test-projected-dlxj @ 01/27/26 21:17:35.458
  I0127 21:17:35.458752 26 delete.go:78] Deleting pod "pod-subpath-test-projected-dlxj" in namespace "subpath-9626"
  I0127 21:17:35.460597 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-9626" for this suite. @ 01/27/26 21:17:35.464
• [24.162 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:298
  STEP: Creating a kubernetes client @ 01/27/26 21:17:35.477
  I0127 21:17:35.477604 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename downward-api @ 01/27/26 21:17:35.479
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:17:35.511
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:17:35.513
  STEP: Creating a pod to test downward api env vars @ 01/27/26 21:17:35.515
  E0127 21:17:35.518641      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:36.519429      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:37.519656      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:38.519739      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:39.519994      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:17:39.539
  I0127 21:17:39.541087 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downward-api-86d03ad6-ff34-4117-b480-cfe398977595 container dapi-container: <nil>
  STEP: delete the pod @ 01/27/26 21:17:39.545
  I0127 21:17:39.573973 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-135" for this suite. @ 01/27/26 21:17:39.576
• [4.115 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1868
  STEP: Creating a kubernetes client @ 01/27/26 21:17:39.592
  I0127 21:17:39.592699 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubectl @ 01/27/26 21:17:39.593
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:17:39.611
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:17:39.616
  STEP: starting the proxy server @ 01/27/26 21:17:39.618
  I0127 21:17:39.618778 26 util.go:502] Asynchronously running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-9019 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 01/27/26 21:17:39.661
  I0127 21:17:39.666683 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  I0127 21:17:39.668784 26 kubectl.go:2259] kubectl proxy stdout: Starting to serve on 127.0.0.1:40079

  I0127 21:17:39.669137 26 kubectl.go:2264] kubectl proxy stderr: W0127 21:17:39.660611    1506 proxy.go:177] Request filter disabled, your proxy is vulnerable to XSRF attacks, please be cautious

  STEP: Destroying namespace "kubectl-9019" for this suite. @ 01/27/26 21:17:39.676
• [0.098 seconds]
------------------------------
SSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:48
  STEP: Creating a kubernetes client @ 01/27/26 21:17:39.69
  I0127 21:17:39.690847 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename configmap @ 01/27/26 21:17:39.691
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:17:39.714
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:17:39.72
  STEP: Creating configMap configmap-1588/configmap-test-fec795d3-1d3e-48fa-8ca7-61302b96bbc8 @ 01/27/26 21:17:39.731
  STEP: Creating a pod to test consume configMaps @ 01/27/26 21:17:39.74
  E0127 21:17:40.520838      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:41.521055      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:42.521258      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:43.521484      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:17:43.764
  I0127 21:17:43.766645 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-configmaps-89db759b-6638-438f-830a-fbb0bdf2b551 container env-test: <nil>
  STEP: delete the pod @ 01/27/26 21:17:43.771
  I0127 21:17:43.806088 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1588" for this suite. @ 01/27/26 21:17:43.808
• [4.128 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:96
  STEP: Creating a kubernetes client @ 01/27/26 21:17:43.818
  I0127 21:17:43.818492 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename configmap @ 01/27/26 21:17:43.819
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:17:43.834
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:17:43.845
  STEP: Creating configMap configmap-2819/configmap-test-eed1069b-5391-49bf-b798-67c4a53f267d @ 01/27/26 21:17:43.847
  STEP: Creating a pod to test consume configMaps @ 01/27/26 21:17:43.854
  E0127 21:17:44.522062      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:45.522710      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:46.522918      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:47.523120      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:17:47.877
  I0127 21:17:47.879943 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-configmaps-06dffa42-949a-42b8-8533-26f78041a4ae container env-test: <nil>
  STEP: delete the pod @ 01/27/26 21:17:47.885
  I0127 21:17:47.911502 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2819" for this suite. @ 01/27/26 21:17:47.914
• [4.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:223
  STEP: Creating a kubernetes client @ 01/27/26 21:17:47.923
  I0127 21:17:47.923466 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename validating-admission-policy @ 01/27/26 21:17:47.924
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:17:47.945
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:17:47.958
  STEP: creating a policy with variables @ 01/27/26 21:17:47.969
  STEP: waiting until the marker is denied @ 01/27/26 21:17:47.994
  STEP: testing a replicated Deployment to be allowed @ 01/27/26 21:17:48.308
  STEP: testing a non-replicated ReplicaSet not to be denied @ 01/27/26 21:17:48.342
  I0127 21:17:48.457146 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-3605" for this suite. @ 01/27/26 21:17:48.469
• [0.553 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2265
  STEP: Creating a kubernetes client @ 01/27/26 21:17:48.476
  I0127 21:17:48.476790 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename services @ 01/27/26 21:17:48.477
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:17:48.514
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:17:48.517
  STEP: creating service in namespace services-1641 @ 01/27/26 21:17:48.519
  STEP: creating service affinity-nodeport in namespace services-1641 @ 01/27/26 21:17:48.519
  E0127 21:17:48.523878      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:17:48.560604 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0127 21:17:49.524916      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:50.526435      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:17:50.612207 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:3, TerminatingReplicas:(*int32)(0xc0056e02c0), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 21, 17, 48, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 17, 48, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 17, 48, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 17, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-5fd47c4cd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:17:51.527165      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:52.527304      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:17:52.572948 26 resource.go:344] Creating new exec pod
  E0127 21:17:53.527627      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:54.527751      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:17:54.594082 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1641 exec execpod-affinitywjbkx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  I0127 21:17:54.697929 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport (10.53.98.255) 80 port [tcp/http] succeeded!\n"
  I0127 21:17:54.697972 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 21:17:54.698045 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1641 exec execpod-affinitywjbkx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.98.255 80'
  I0127 21:17:54.808749 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.53.98.255 80\nConnection to 10.53.98.255 80 port [tcp/http] succeeded!\n"
  I0127 21:17:54.808790 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 21:17:54.808850 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1641 exec execpod-affinitywjbkx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.42.0.10 31343'
  I0127 21:17:54.915046 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.42.0.10 31343\nConnection to 10.42.0.10 31343 port [tcp/*] succeeded!\n"
  I0127 21:17:54.915092 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 21:17:54.915154 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1641 exec execpod-affinitywjbkx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.42.0.12 31343'
  I0127 21:17:55.018345 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.42.0.12 31343\nConnection to 10.42.0.12 31343 port [tcp/*] succeeded!\n"
  I0127 21:17:55.018388 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 21:17:55.018442 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1641 exec execpod-affinitywjbkx -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31343/ ; done'
  I0127 21:17:55.181293 26 builder.go:156] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31343/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31343/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31343/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31343/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31343/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31343/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31343/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31343/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31343/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31343/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31343/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31343/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31343/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31343/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31343/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31343/\n"
  I0127 21:17:55.181349 26 builder.go:157] stdout: "\naffinity-nodeport-5fd47c4cd5-rbhl4\naffinity-nodeport-5fd47c4cd5-rbhl4\naffinity-nodeport-5fd47c4cd5-rbhl4\naffinity-nodeport-5fd47c4cd5-rbhl4\naffinity-nodeport-5fd47c4cd5-rbhl4\naffinity-nodeport-5fd47c4cd5-rbhl4\naffinity-nodeport-5fd47c4cd5-rbhl4\naffinity-nodeport-5fd47c4cd5-rbhl4\naffinity-nodeport-5fd47c4cd5-rbhl4\naffinity-nodeport-5fd47c4cd5-rbhl4\naffinity-nodeport-5fd47c4cd5-rbhl4\naffinity-nodeport-5fd47c4cd5-rbhl4\naffinity-nodeport-5fd47c4cd5-rbhl4\naffinity-nodeport-5fd47c4cd5-rbhl4\naffinity-nodeport-5fd47c4cd5-rbhl4\naffinity-nodeport-5fd47c4cd5-rbhl4"
  I0127 21:17:55.181365 26 service.go:227] Received response from host: affinity-nodeport-5fd47c4cd5-rbhl4
  I0127 21:17:55.181375 26 service.go:227] Received response from host: affinity-nodeport-5fd47c4cd5-rbhl4
  I0127 21:17:55.181382 26 service.go:227] Received response from host: affinity-nodeport-5fd47c4cd5-rbhl4
  I0127 21:17:55.181389 26 service.go:227] Received response from host: affinity-nodeport-5fd47c4cd5-rbhl4
  I0127 21:17:55.181397 26 service.go:227] Received response from host: affinity-nodeport-5fd47c4cd5-rbhl4
  I0127 21:17:55.181404 26 service.go:227] Received response from host: affinity-nodeport-5fd47c4cd5-rbhl4
  I0127 21:17:55.181411 26 service.go:227] Received response from host: affinity-nodeport-5fd47c4cd5-rbhl4
  I0127 21:17:55.181419 26 service.go:227] Received response from host: affinity-nodeport-5fd47c4cd5-rbhl4
  I0127 21:17:55.181427 26 service.go:227] Received response from host: affinity-nodeport-5fd47c4cd5-rbhl4
  I0127 21:17:55.181437 26 service.go:227] Received response from host: affinity-nodeport-5fd47c4cd5-rbhl4
  I0127 21:17:55.181444 26 service.go:227] Received response from host: affinity-nodeport-5fd47c4cd5-rbhl4
  I0127 21:17:55.181451 26 service.go:227] Received response from host: affinity-nodeport-5fd47c4cd5-rbhl4
  I0127 21:17:55.181458 26 service.go:227] Received response from host: affinity-nodeport-5fd47c4cd5-rbhl4
  I0127 21:17:55.181465 26 service.go:227] Received response from host: affinity-nodeport-5fd47c4cd5-rbhl4
  I0127 21:17:55.181472 26 service.go:227] Received response from host: affinity-nodeport-5fd47c4cd5-rbhl4
  I0127 21:17:55.181478 26 service.go:227] Received response from host: affinity-nodeport-5fd47c4cd5-rbhl4
  I0127 21:17:55.181551 26 service.go:4286] Cleaning up the exec pod
  I0127 21:17:55.278149 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1641" for this suite. @ 01/27/26 21:17:55.289
• [6.831 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:771
  STEP: Creating a kubernetes client @ 01/27/26 21:17:55.308
  I0127 21:17:55.308106 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 21:17:55.308
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:17:55.335
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:17:55.337
  STEP: Setting up server cert @ 01/27/26 21:17:55.373
  E0127 21:17:55.528592      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 21:17:55.608
  STEP: Deploying the webhook pod @ 01/27/26 21:17:55.616
  STEP: Wait for the deployment to be ready @ 01/27/26 21:17:55.643
  I0127 21:17:55.652378 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0127 21:17:56.529288      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:17:57.529783      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/27/26 21:17:57.658
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 21:17:57.675
  I0127 21:17:57.675397 26 wait.go:65] Waiting for amount of service webhook-8861/e2e-test-webhook endpoints to be 1
  I0127 21:17:57.692322 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  E0127 21:17:58.529923      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: creating a mutating webhook with match conditions @ 01/27/26 21:17:58.678
  STEP: verifying the mutating webhook match conditions @ 01/27/26 21:17:58.694
  STEP: updating the mutating webhook match conditions @ 01/27/26 21:17:58.696
  STEP: verifying the mutating webhook match conditions @ 01/27/26 21:17:58.714
  I0127 21:17:58.794392 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8861" for this suite. @ 01/27/26 21:17:58.796
  STEP: Destroying namespace "webhook-markers-9784" for this suite. @ 01/27/26 21:17:58.813
• [3.518 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:52
  STEP: Creating a kubernetes client @ 01/27/26 21:17:58.826
  I0127 21:17:58.826552 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename crd-watch @ 01/27/26 21:17:58.827
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:17:58.854
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:17:58.856
  I0127 21:17:58.858843 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  E0127 21:17:59.530649      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:00.531298      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 01/27/26 21:18:01.402
  I0127 21:18:01.411245 26 watch.go:426] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2026-01-27T21:18:01Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2026-01-27T21:18:01Z]] name:name1 resourceVersion:34001 uid:362d01d9-9314-4821-85a0-fa8595b024c1] num:map[num1:9223372036854775807 num2:1000000]]}
  E0127 21:18:01.531425      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:02.531799      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:03.532886      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:04.533574      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:05.534345      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:06.534559      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:07.535266      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:08.535491      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:09.535694      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:10.535891      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 01/27/26 21:18:11.411
  I0127 21:18:11.419777 26 watch.go:426] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2026-01-27T21:18:11Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2026-01-27T21:18:11Z]] name:name2 resourceVersion:34046 uid:4e9869ae-23ff-4aaf-9e03-8f3be18bd94e] num:map[num1:9223372036854775807 num2:1000000]]}
  E0127 21:18:11.536921      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:12.537138      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:13.537787      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:14.538541      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:15.538713      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:16.538926      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:17.539374      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:18.539644      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:19.539742      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:20.540832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 01/27/26 21:18:21.42
  I0127 21:18:21.429373 26 watch.go:426] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2026-01-27T21:18:01Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2026-01-27T21:18:21Z]] name:name1 resourceVersion:34076 uid:362d01d9-9314-4821-85a0-fa8595b024c1] num:map[num1:9223372036854775807 num2:1000000]]}
  E0127 21:18:21.541720      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:22.543086      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:23.543288      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:24.543511      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:25.544309      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:26.544426      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:27.545139      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:28.545349      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:29.545529      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:30.545567      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 01/27/26 21:18:31.43
  I0127 21:18:31.440840 26 watch.go:426] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2026-01-27T21:18:11Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2026-01-27T21:18:31Z]] name:name2 resourceVersion:34106 uid:4e9869ae-23ff-4aaf-9e03-8f3be18bd94e] num:map[num1:9223372036854775807 num2:1000000]]}
  E0127 21:18:31.546132      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:32.546578      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:33.546801      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:34.547013      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:35.547677      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:36.547758      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:37.547979      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:38.548894      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:39.549087      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:40.549273      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 01/27/26 21:18:41.441
  I0127 21:18:41.451001 26 watch.go:426] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2026-01-27T21:18:01Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2026-01-27T21:18:21Z]] name:name1 resourceVersion:34136 uid:362d01d9-9314-4821-85a0-fa8595b024c1] num:map[num1:9223372036854775807 num2:1000000]]}
  E0127 21:18:41.550261      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:42.550464      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:43.551474      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:44.551725      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:45.552560      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:46.552818      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:47.553208      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:48.553390      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:49.554430      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:50.554452      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 01/27/26 21:18:51.451
  I0127 21:18:51.461355 26 watch.go:426] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2026-01-27T21:18:11Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2026-01-27T21:18:31Z]] name:name2 resourceVersion:34166 uid:4e9869ae-23ff-4aaf-9e03-8f3be18bd94e] num:map[num1:9223372036854775807 num2:1000000]]}
  E0127 21:18:51.554551      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:52.555625      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:53.556290      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:54.556853      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:55.557019      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:56.557684      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:57.557891      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:58.558144      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:18:59.558897      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:00.559470      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:01.560097      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:19:01.978812 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-6161" for this suite. @ 01/27/26 21:19:01.981
• [63.163 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:162
  STEP: Creating a kubernetes client @ 01/27/26 21:19:01.99
  I0127 21:19:01.990118 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename runtimeclass @ 01/27/26 21:19:01.99
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:19:02.005
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:19:02.018
  STEP: Deleting RuntimeClass runtimeclass-7156-delete-me @ 01/27/26 21:19:02.037
  STEP: Waiting for the RuntimeClass to disappear @ 01/27/26 21:19:02.044
  I0127 21:19:02.051274 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-7156" for this suite. @ 01/27/26 21:19:02.081
• [0.099 seconds]
------------------------------
SS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:110
  STEP: Creating a kubernetes client @ 01/27/26 21:19:02.089
  I0127 21:19:02.089249 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubelet-test @ 01/27/26 21:19:02.089
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:19:02.111
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:19:02.117
  E0127 21:19:02.560759      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:03.561172      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:04.561490      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:05.562306      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:19:06.161038 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-9176" for this suite. @ 01/27/26 21:19:06.162
• [4.082 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:199
  STEP: Creating a kubernetes client @ 01/27/26 21:19:06.17
  I0127 21:19:06.170970 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename crd-publish-openapi @ 01/27/26 21:19:06.171
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:19:06.192
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:19:06.197
  I0127 21:19:06.199668 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  E0127 21:19:06.562429      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:07.562843      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 01/27/26 21:19:07.563
  I0127 21:19:07.563324 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-5871 --namespace=crd-publish-openapi-5871 create -f -'
  E0127 21:19:08.563663      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:09.563774      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:19:09.640672 26 builder.go:156] stderr: ""
  I0127 21:19:09.640724 26 builder.go:157] stdout: "e2e-test-crd-publish-openapi-5871-9074-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0127 21:19:09.640791 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-5871 --namespace=crd-publish-openapi-5871 delete e2e-test-crd-publish-openapi-5871-9074-crds test-cr'
  I0127 21:19:09.708752 26 builder.go:156] stderr: ""
  I0127 21:19:09.708793 26 builder.go:157] stdout: "e2e-test-crd-publish-openapi-5871-9074-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted from crd-publish-openapi-5871 namespace\n"
  I0127 21:19:09.708830 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-5871 --namespace=crd-publish-openapi-5871 apply -f -'
  I0127 21:19:09.780396 26 builder.go:156] stderr: ""
  I0127 21:19:09.780447 26 builder.go:157] stdout: "e2e-test-crd-publish-openapi-5871-9074-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0127 21:19:09.780486 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-5871 --namespace=crd-publish-openapi-5871 delete e2e-test-crd-publish-openapi-5871-9074-crds test-cr'
  I0127 21:19:09.848490 26 builder.go:156] stderr: ""
  I0127 21:19:09.848529 26 builder.go:157] stdout: "e2e-test-crd-publish-openapi-5871-9074-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted from crd-publish-openapi-5871 namespace\n"
  STEP: kubectl explain works to explain CR @ 01/27/26 21:19:09.848
  I0127 21:19:09.848591 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=crd-publish-openapi-5871 explain e2e-test-crd-publish-openapi-5871-9074-crds'
  I0127 21:19:09.904974 26 builder.go:156] stderr: ""
  I0127 21:19:09.905027 26 builder.go:157] stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-5871-9074-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0127 21:19:10.564816      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:19:11.292283 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5871" for this suite. @ 01/27/26 21:19:11.299
• [5.137 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3220
  STEP: Creating a kubernetes client @ 01/27/26 21:19:11.308
  I0127 21:19:11.308259 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename services @ 01/27/26 21:19:11.308
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:19:11.323
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:19:11.417
  STEP: fetching services @ 01/27/26 21:19:11.419
  I0127 21:19:11.423027 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9877" for this suite. @ 01/27/26 21:19:11.424
• [0.126 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:825
  STEP: Creating a kubernetes client @ 01/27/26 21:19:11.433
  I0127 21:19:11.433965 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 21:19:11.434
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:19:11.451
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:19:11.521
  STEP: Setting up server cert @ 01/27/26 21:19:11.551
  E0127 21:19:11.565490      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 21:19:11.742
  STEP: Deploying the webhook pod @ 01/27/26 21:19:11.757
  STEP: Wait for the deployment to be ready @ 01/27/26 21:19:11.779
  I0127 21:19:11.793793 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0127 21:19:12.565711      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:13.565863      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/27/26 21:19:13.811
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 21:19:13.827
  I0127 21:19:13.828261 26 wait.go:65] Waiting for amount of service webhook-7033/e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 01/27/26 21:19:13.842
  I0127 21:19:13.924716 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7033" for this suite. @ 01/27/26 21:19:13.928
  STEP: Destroying namespace "webhook-markers-2927" for this suite. @ 01/27/26 21:19:13.944
• [2.527 seconds]
------------------------------
S
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3246
  STEP: Creating a kubernetes client @ 01/27/26 21:19:13.96
  I0127 21:19:13.960655 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename services @ 01/27/26 21:19:13.961
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:19:13.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:19:13.993
  STEP: creating a Service @ 01/27/26 21:19:13.997
  STEP: watching for the Service to be added @ 01/27/26 21:19:14.024
  I0127 21:19:14.025715 26 service.go:3298] Found Service test-service-sb2vv in namespace services-8492 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 31535}]
  I0127 21:19:14.025750 26 service.go:3305] Service test-service-sb2vv created
  STEP: Getting /status @ 01/27/26 21:19:14.025
  I0127 21:19:14.027967 26 service.go:3316] Service test-service-sb2vv has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 01/27/26 21:19:14.027
  STEP: watching for the Service to be patched @ 01/27/26 21:19:14.035
  I0127 21:19:14.036694 26 service.go:3339] observed Service test-service-sb2vv in namespace services-8492 with annotations: map[] & LoadBalancer: {[]}
  I0127 21:19:14.036726 26 service.go:3342] Found Service test-service-sb2vv in namespace services-8492 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  0xc00184b610 []}]}
  I0127 21:19:14.036737 26 service.go:3349] Service test-service-sb2vv has service status patched
  STEP: updating the ServiceStatus @ 01/27/26 21:19:14.036
  I0127 21:19:14.047631 26 service.go:3369] updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 01/27/26 21:19:14.047
  I0127 21:19:14.048609 26 service.go:3380] Observed Service test-service-sb2vv in namespace services-8492 with annotations: map[] & Conditions: []
  I0127 21:19:14.048635 26 service.go:3391] Observed Service test-service-sb2vv in namespace services-8492 with annotations: map[patchedstatus:true] & Conditions: []
  I0127 21:19:14.048684 26 service.go:3387] Found Service test-service-sb2vv in namespace services-8492 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0127 21:19:14.048695 26 service.go:3398] Service test-service-sb2vv has service status updated
  STEP: patching the service @ 01/27/26 21:19:14.048
  STEP: watching for the Service to be patched @ 01/27/26 21:19:14.064
  I0127 21:19:14.065261 26 service.go:3421] observed Service test-service-sb2vv in namespace services-8492 with labels: map[test-service-static:true]
  I0127 21:19:14.065316 26 service.go:3421] observed Service test-service-sb2vv in namespace services-8492 with labels: map[test-service-static:true]
  I0127 21:19:14.065396 26 service.go:3421] observed Service test-service-sb2vv in namespace services-8492 with labels: map[test-service-static:true]
  I0127 21:19:14.065425 26 service.go:3424] Found Service test-service-sb2vv in namespace services-8492 with labels: map[test-service:patched test-service-static:true]
  I0127 21:19:14.065439 26 service.go:3431] Service test-service-sb2vv patched
  STEP: deleting the service @ 01/27/26 21:19:14.065
  STEP: watching for the Service to be deleted @ 01/27/26 21:19:14.097
  I0127 21:19:14.098559 26 service.go:3455] Observed event: ADDED
  I0127 21:19:14.098583 26 service.go:3455] Observed event: MODIFIED
  I0127 21:19:14.098639 26 service.go:3455] Observed event: MODIFIED
  I0127 21:19:14.098659 26 service.go:3455] Observed event: MODIFIED
  I0127 21:19:14.098728 26 service.go:3451] Found Service test-service-sb2vv in namespace services-8492 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  I0127 21:19:14.098741 26 service.go:3460] Service test-service-sb2vv deleted
  I0127 21:19:14.098833 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8492" for this suite. @ 01/27/26 21:19:14.101
• [0.150 seconds]
------------------------------
S
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:152
  STEP: Creating a kubernetes client @ 01/27/26 21:19:14.11
  I0127 21:19:14.110321 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename deployment @ 01/27/26 21:19:14.11
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:19:14.132
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:19:14.137
  I0127 21:19:14.139981 26 deployment.go:1668] Creating simple deployment test-new-deployment
  I0127 21:19:14.162542 26 deployment.go:223] deployment "test-new-deployment" doesn't have the required revision set
  E0127 21:19:14.566636      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:15.566742      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 01/27/26 21:19:16.171
  STEP: updating a scale subresource @ 01/27/26 21:19:16.172
  STEP: verifying the deployment Spec.Replicas was modified @ 01/27/26 21:19:16.186
  STEP: Patch a scale subresource @ 01/27/26 21:19:16.188
  I0127 21:19:16.223706 26 deployment.go:636] Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7862",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0a0decb1-02f3-47ac-95ec-752908c3ce57",
      ResourceVersion: (string) (len=5) "34382",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905145554,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=7) "agnhost"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905145554,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=621) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000150  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000170  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000180  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000190  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001a0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001b0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001c0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001d0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001e0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001f0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000200  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000210  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000220  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000230  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000240  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000250  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000260  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905145555,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 74 65 72  |licas":{},"f:ter|
              000001f0  6d 69 6e 61 74 69 6e 67  52 65 70 6c 69 63 61 73  |minatingReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=7) "agnhost"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=7) "agnhost"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(0),
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905145555,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905145555,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905145555,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905145554,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-79f99d89dd\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0127 21:19:16.234165 26 deployment.go:40] New ReplicaSet "test-new-deployment-79f99d89dd" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-79f99d89dd",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7862",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ca52027d-87fa-413b-b3c9-6ff0a6bab8fc",
      ResourceVersion: (string) (len=5) "34386",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905145554,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "0a0decb1-02f3-47ac-95ec-752908c3ce57",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905145556,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 30 61 30 64 65 63  62 31 2d 30 32 66 33 2d  |\"0a0decb1-02f3-|
              00000120  34 37 61 63 2d 39 35 65  63 2d 37 35 32 39 30 38  |47ac-95ec-752908|
              00000130  63 33 63 65 35 37 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |c3ce57\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905145556,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=157) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6e 67 52  |,"f:terminatingR|
              00000090  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=7) "agnhost",
          (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=7) "agnhost",
            (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      TerminatingReplicas: (*int32)(0),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0127 21:19:16.241229 26 deployment.go:68] Pod "test-new-deployment-79f99d89dd-hg4fn" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-79f99d89dd-hg4fn",
      GenerateName: (string) (len=31) "test-new-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-7862",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a1a5b937-6c2a-4612-8f0a-7917a1440f48",
      ResourceVersion: (string) (len=5) "34375",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905145554,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "ca52027d-87fa-413b-b3c9-6ff0a6bab8fc",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905145554,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 61  35 32 30 32 37 64 2d 38  |d\":\"ca52027d-8|
              00000090  37 66 61 2d 34 31 33 62  2d 62 33 63 39 2d 36 66  |7fa-413b-b3c9-6f|
              000000a0  66 30 61 36 62 61 62 38  66 63 5c 22 7d 22 3a 7b  |f0a6bab8fc\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905145555,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=849) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 35  |k:{\"ip\":\"10.5|
              00000320  32 2e 31 2e 36 34 5c 22  7d 22 3a 7b 22 2e 22 3a  |2.1.64\"}":{".":|
              00000330  7b 7d 2c 22 66 3a 69 70  22 3a 7b 7d 7d 7d 2c 22  |{},"f:ip":{}}},"|
              00000340  66 3a 73 74 61 72 74 54  69 6d 65 22 3a 7b 7d 7d  |f:startTime":{}}|
              00000350  7d                                                |}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xtdtf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xtdtf",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905145555,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905145554,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905145555,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905145555,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905145554,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.10",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.10"
        }
      },
      PodIP: (string) (len=10) "10.52.1.64",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.52.1.64"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905145554,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63905145554,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:10ed98804c877e505e17bced991682b6fd50ab1da9cddcd19935b48d645da40a",
          ContainerID: (string) (len=77) "containerd://dec8c73f9476881df985c618b58ccbaec9a6ea12e4b4ac0b24d5d3c43161396c",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-xtdtf",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:19:16.243495 26 deployment.go:68] Pod "test-new-deployment-79f99d89dd-pc65f" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-79f99d89dd-pc65f",
      GenerateName: (string) (len=31) "test-new-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-7862",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fd273edc-a06c-49ed-9d77-ff78ec4ab577",
      ResourceVersion: (string) (len=5) "34387",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905145556,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "ca52027d-87fa-413b-b3c9-6ff0a6bab8fc",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905145556,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 61  35 32 30 32 37 64 2d 38  |d\":\"ca52027d-8|
              00000090  37 66 61 2d 34 31 33 62  2d 62 33 63 39 2d 36 66  |7fa-413b-b3c9-6f|
              000000a0  66 30 61 36 62 61 62 38  66 63 5c 22 7d 22 3a 7b  |f0a6bab8fc\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-cjk6n",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-cjk6n",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905145556,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:19:16.244488 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7862" for this suite. @ 01/27/26 21:19:16.252
• [2.162 seconds]
------------------------------
SS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:211
  STEP: Creating a kubernetes client @ 01/27/26 21:19:16.272
  I0127 21:19:16.272456 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename events @ 01/27/26 21:19:16.272
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:19:16.32
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:19:16.4
  STEP: Create set of events @ 01/27/26 21:19:16.401
  STEP: get a list of Events with a label in the current namespace @ 01/27/26 21:19:16.431
  STEP: delete a list of events @ 01/27/26 21:19:16.433
  I0127 21:19:16.433208 26 events.go:228] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 01/27/26 21:19:16.455
  I0127 21:19:16.460447 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-3606" for this suite. @ 01/27/26 21:19:16.462
• [0.199 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:61
  STEP: Creating a kubernetes client @ 01/27/26 21:19:16.471
  I0127 21:19:16.471323 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename custom-resource-definition @ 01/27/26 21:19:16.472
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:19:16.498
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:19:16.5
  I0127 21:19:16.507009 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  E0127 21:19:16.567869      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:19:17.532289 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-3962" for this suite. @ 01/27/26 21:19:17.534
• [1.073 seconds]
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:240
  STEP: Creating a kubernetes client @ 01/27/26 21:19:17.544
  I0127 21:19:17.544706 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename configmap @ 01/27/26 21:19:17.545
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:19:17.561
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:19:17.563
  E0127 21:19:17.568129      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating configMap with name cm-test-opt-del-003a32ae-6ab1-4dd5-81ad-8f2a6924c3a0 @ 01/27/26 21:19:17.634
  STEP: Creating configMap with name cm-test-opt-upd-f8c96e2a-e80d-480b-8f2b-fe9550cf3181 @ 01/27/26 21:19:17.648
  STEP: Creating the pod @ 01/27/26 21:19:17.656
  E0127 21:19:18.568814      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:19.569373      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:20.569430      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:21.569646      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-003a32ae-6ab1-4dd5-81ad-8f2a6924c3a0 @ 01/27/26 21:19:22.406
  STEP: Updating configmap cm-test-opt-upd-f8c96e2a-e80d-480b-8f2b-fe9550cf3181 @ 01/27/26 21:19:22.415
  STEP: Creating configMap with name cm-test-opt-create-bd3b9c58-01de-4fef-bda8-90ebaeda29b9 @ 01/27/26 21:19:22.423
  STEP: waiting to observe update in volume @ 01/27/26 21:19:22.431
  E0127 21:19:22.570059      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:23.570394      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:24.571217      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:25.571418      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:26.571555      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:27.571782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:28.572185      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:29.572291      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:30.573274      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:31.573498      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:32.573787      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:33.573995      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:34.574672      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:35.575877      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:36.576303      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:37.577314      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:38.578193      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:39.578427      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:40.579155      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:41.579342      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:42.579755      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:43.579802      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:44.580499      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:45.580643      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:46.581765      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:47.581981      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:48.582356      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:49.583663      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:50.584512      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:51.585302      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:52.586331      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:53.586542      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:54.586628      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:55.586752      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:56.587077      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:57.587307      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:58.587967      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:19:59.588860      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:00.589385      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:01.589729      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:02.590168      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:03.591041      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:04.592001      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:05.592036      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:06.592954      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:07.593447      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:08.594296      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:09.594525      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:10.594998      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:11.595181      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:12.595746      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:13.596830      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:14.597300      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:15.597730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:16.598765      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:17.599027      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:18.599737      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:19.600844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:20.601191      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:21.602252      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:22.602634      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:23.602928      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:24.602983      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:25.603578      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:26.603746      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:27.603967      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:28.604869      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:29.605716      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:30.606465      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:31.606533      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:32.606588      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:33.607061      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:34.607278      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:35.607741      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:36.607972      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:37.608871      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:38.609094      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:39.609457      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:40.609462      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:41.610413      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:42.610610      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:20:42.674386 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9912" for this suite. @ 01/27/26 21:20:42.676
• [85.146 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:682
  STEP: Creating a kubernetes client @ 01/27/26 21:20:42.694
  I0127 21:20:42.694795 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename validating-admission-policy @ 01/27/26 21:20:42.695
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:20:42.716
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:20:42.719
  STEP: getting /apis @ 01/27/26 21:20:42.737
  STEP: getting /apis/admissionregistration.k8s.io @ 01/27/26 21:20:42.742
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 01/27/26 21:20:42.743
  STEP: creating @ 01/27/26 21:20:42.745
  STEP: getting @ 01/27/26 21:20:42.776
  STEP: listing @ 01/27/26 21:20:42.778
  STEP: watching @ 01/27/26 21:20:42.78
  I0127 21:20:42.780686 26 validatingadmissionpolicy.go:778] starting watch
  STEP: patching @ 01/27/26 21:20:42.781
  STEP: updating @ 01/27/26 21:20:42.789
  I0127 21:20:42.806981 26 validatingadmissionpolicy.go:807] waiting for watch events with expected annotations
  STEP: deleting @ 01/27/26 21:20:42.807
  STEP: deleting a collection @ 01/27/26 21:20:42.818
  I0127 21:20:42.837071 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-9075" for this suite. @ 01/27/26 21:20:42.839
• [0.153 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 01/27/26 21:20:42.848
  I0127 21:20:42.848077 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename subpath @ 01/27/26 21:20:42.848
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:20:42.879
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:20:42.883
  STEP: Setting up data @ 01/27/26 21:20:42.885
  STEP: Creating pod pod-subpath-test-configmap-rbgt @ 01/27/26 21:20:42.901
  STEP: Creating a pod to test atomic-volume-subpath @ 01/27/26 21:20:42.901
  E0127 21:20:43.611237      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:44.611484      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:45.612237      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:46.612847      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:47.612933      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:48.613151      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:49.613317      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:50.613449      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:51.613860      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:52.614097      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:53.614474      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:54.614912      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:55.615484      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:56.615735      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:57.615786      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:58.616842      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:20:59.617136      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:00.617280      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:01.617633      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:02.618278      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:03.619370      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:04.619579      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:05.620119      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:06.620367      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:21:06.947
  I0127 21:21:06.949087 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-subpath-test-configmap-rbgt container test-container-subpath-configmap-rbgt: <nil>
  STEP: delete the pod @ 01/27/26 21:21:06.959
  STEP: Deleting pod pod-subpath-test-configmap-rbgt @ 01/27/26 21:21:06.983
  I0127 21:21:06.983087 26 delete.go:78] Deleting pod "pod-subpath-test-configmap-rbgt" in namespace "subpath-6206"
  I0127 21:21:06.984871 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-6206" for this suite. @ 01/27/26 21:21:06.987
• [24.147 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:69
  STEP: Creating a kubernetes client @ 01/27/26 21:21:06.995
  I0127 21:21:06.995178 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 21:21:06.996
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:21:07.018
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:21:07.023
  STEP: Creating a pod to test downward API volume plugin @ 01/27/26 21:21:07.025
  E0127 21:21:07.620435      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:08.621607      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:09.621930      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:10.622698      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:21:11.053
  I0127 21:21:11.055556 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downwardapi-volume-9eac5480-1e3c-43f3-bab6-a5b42d2f533f container client-container: <nil>
  STEP: delete the pod @ 01/27/26 21:21:11.059
  I0127 21:21:11.096937 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4623" for this suite. @ 01/27/26 21:21:11.099
• [4.124 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should execute all indexes despite some failing when using backoffLimitPerIndex [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:607
  STEP: Creating a kubernetes client @ 01/27/26 21:21:11.119
  I0127 21:21:11.119930 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename job @ 01/27/26 21:21:11.12
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:21:11.146
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:21:11.148
  STEP: Creating an indexed job with backoffLimit per index and failing pods @ 01/27/26 21:21:11.15
  STEP: Awaiting for the job to fail as there are failed indexes @ 01/27/26 21:21:11.168
  E0127 21:21:11.623516      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:12.623900      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:13.624956      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:14.625143      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:15.626264      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:16.626489      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:17.627274      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:18.627507      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:19.628328      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:20.628475      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:21.629358      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:22.629730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:23.629917      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:24.630119      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:25.631075      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:26.631270      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:27.631781      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:28.632858      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:29.633308      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:30.633763      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:31.633955      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:32.634195      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Verifying the Job status fields to ensure all indexes were executed @ 01/27/26 21:21:33.226
  I0127 21:21:33.228092 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-5419" for this suite. @ 01/27/26 21:21:33.23
• [22.125 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:260
  STEP: Creating a kubernetes client @ 01/27/26 21:21:33.244
  I0127 21:21:33.244740 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 21:21:33.245
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:21:33.27
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:21:33.361
  STEP: Setting up server cert @ 01/27/26 21:21:33.401
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 21:21:33.551
  STEP: Deploying the webhook pod @ 01/27/26 21:21:33.559
  STEP: Wait for the deployment to be ready @ 01/27/26 21:21:33.59
  I0127 21:21:33.594269 26 deployment.go:223] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0127 21:21:33.634519      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:34.634741      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/27/26 21:21:35.6
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 21:21:35.617
  I0127 21:21:35.617138 26 wait.go:65] Waiting for amount of service webhook-9005/e2e-test-webhook endpoints to be 1
  I0127 21:21:35.619191 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  E0127 21:21:35.635447      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 01/27/26 21:21:36.619
  E0127 21:21:36.636110      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: create a pod that should be updated by the webhook @ 01/27/26 21:21:36.644
  I0127 21:21:36.771562 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9005" for this suite. @ 01/27/26 21:21:36.778
  STEP: Destroying namespace "webhook-markers-4474" for this suite. @ 01/27/26 21:21:36.788
• [3.552 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:218
  STEP: Creating a kubernetes client @ 01/27/26 21:21:36.796
  I0127 21:21:36.796961 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 01/27/26 21:21:36.797
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:21:36.82
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:21:36.825
  STEP: create the container to handle the HTTPGet hook request. @ 01/27/26 21:21:36.882
  E0127 21:21:37.636841      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:38.637280      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 01/27/26 21:21:38.9
  E0127 21:21:39.637344      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:40.637486      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 01/27/26 21:21:40.924
  E0127 21:21:41.637683      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:42.637900      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 01/27/26 21:21:42.936
  I0127 21:21:42.940586 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-7337" for this suite. @ 01/27/26 21:21:42.942
• [6.161 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:52
  STEP: Creating a kubernetes client @ 01/27/26 21:21:42.957
  I0127 21:21:42.957724 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubelet-test @ 01/27/26 21:21:42.958
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:21:42.979
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:21:42.981
  E0127 21:21:43.638939      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:44.639637      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:21:45.012539 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-3008" for this suite. @ 01/27/26 21:21:45.015
• [2.066 seconds]
------------------------------
S
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:124
  STEP: Creating a kubernetes client @ 01/27/26 21:21:45.023
  I0127 21:21:45.023675 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename configmap @ 01/27/26 21:21:45.024
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:21:45.046
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:21:45.059
  STEP: Creating configMap with name configmap-test-upd-bd48a9dc-755a-42a3-995e-7e7c47ef01dd @ 01/27/26 21:21:45.116
  STEP: Creating the pod @ 01/27/26 21:21:45.124
  E0127 21:21:45.640486      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:46.640914      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Updating configmap configmap-test-upd-bd48a9dc-755a-42a3-995e-7e7c47ef01dd @ 01/27/26 21:21:47.151
  STEP: waiting to observe update in volume @ 01/27/26 21:21:47.162
  E0127 21:21:47.641644      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:48.642473      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:49.643517      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:50.644429      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:21:51.177884 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1035" for this suite. @ 01/27/26 21:21:51.18
• [6.165 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 01/27/26 21:21:51.188
  I0127 21:21:51.188873 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename subpath @ 01/27/26 21:21:51.189
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:21:51.212
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:21:51.216
  STEP: Setting up data @ 01/27/26 21:21:51.219
  STEP: Creating pod pod-subpath-test-configmap-mgvs @ 01/27/26 21:21:51.235
  STEP: Creating a pod to test atomic-volume-subpath @ 01/27/26 21:21:51.235
  E0127 21:21:51.645237      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:52.645471      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:53.646003      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:54.646753      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:55.647340      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:56.647583      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:57.648427      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:58.648836      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:21:59.648845      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:00.649626      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:01.650261      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:02.650720      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:03.650791      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:04.650914      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:05.651611      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:06.651772      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:07.652334      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:08.652728      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:09.652801      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:10.653223      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:11.653864      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:12.653988      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:13.654584      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:14.654788      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:22:15.304
  I0127 21:22:15.306316 26 output.go:207] Trying to get logs from node k3k-k3kcluster-server-0 pod pod-subpath-test-configmap-mgvs container test-container-subpath-configmap-mgvs: <nil>
  STEP: delete the pod @ 01/27/26 21:22:15.312
  STEP: Deleting pod pod-subpath-test-configmap-mgvs @ 01/27/26 21:22:15.345
  I0127 21:22:15.345814 26 delete.go:78] Deleting pod "pod-subpath-test-configmap-mgvs" in namespace "subpath-4941"
  I0127 21:22:15.347527 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-4941" for this suite. @ 01/27/26 21:22:15.349
• [24.170 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:527
  STEP: Creating a kubernetes client @ 01/27/26 21:22:15.359
  I0127 21:22:15.359284 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename container-probe @ 01/27/26 21:22:15.359
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:22:15.381
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:22:15.386
  STEP: Creating pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328 @ 01/27/26 21:22:15.389
  E0127 21:22:15.655287      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:16.656424      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 01/27/26 21:22:17.417
  I0127 21:22:17.419064 26 container_probe.go:1746] Initial restart count of pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 is 0
  I0127 21:22:17.420477 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:17.656647      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:18.656865      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:19.424051 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:19.657438      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:20.657850      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:21.426301 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:21.658765      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:22.658968      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:23.430111 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:23.659559      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:24.659753      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:25.432828 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:25.660136      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:26.660803      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:27.436354 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:27.661874      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:28.662063      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:29.438817 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:29.663137      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:30.663269      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:31.441174 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:31.663444      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:32.663677      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:33.443725 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:33.664220      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:34.664422      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:35.446833 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:35.665177      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:36.665386      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:37.449743 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:37.666053      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:38.666178      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:39.452268 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:39.666718      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:40.667098      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:41.454997 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:41.667719      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:42.667942      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:43.457994 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:43.668211      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:44.668745      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:45.461310 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:45.669631      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:46.670076      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:47.464669 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:47.670966      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:48.671498      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:49.468072 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:49.672367      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:50.672477      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:51.471355 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:51.672834      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:52.673025      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:53.474013 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:53.674147      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:54.674343      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:55.476642 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:55.675028      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:56.676091      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:57.479495 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:57.676777      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:22:58.676992      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:22:59.483419 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:22:59.678154      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:00.678365      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:01.486736 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:01.679209      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:02.679993      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:03.490600 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:03.680810      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:04.681045      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:05.494265 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:05.681511      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:06.682112      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:07.496904 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:07.683154      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:08.684201      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:09.499206 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:09.684401      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:10.684860      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:11.502516 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:11.685174      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:12.685210      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:13.505938 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:13.686162      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:14.686815      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:15.508304 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:15.687733      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:16.687864      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:17.511412 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:17.688893      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:18.689236      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:19.514008 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:19.690641      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:20.691550      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:21.516930 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:21.692333      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:22.692514      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:23.519777 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:23.693110      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:24.693205      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:25.522443 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:25.693796      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:26.693936      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:27.524927 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:27.694609      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:28.694727      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:29.528117 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:29.695425      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:30.696920      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:31.531061 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:31.697355      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:32.698024      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:33.535592 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:33.698430      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:34.698625      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:35.537909 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:35.699292      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:36.699487      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:37.540670 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:37.699931      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:38.700006      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:39.543097 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:39.700719      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:40.700976      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:41.546236 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:41.701427      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:42.701599      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:43.550104 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:43.701834      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:44.702073      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:45.552646 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:45.702821      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:46.703479      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:47.556393 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:47.703567      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:48.703768      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:49.559242 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:49.703813      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:50.704023      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:51.562938 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:51.704471      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:52.704806      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:53.566842 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:53.706396      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:54.706632      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:55.570939 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:55.707236      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:56.707361      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:57.573842 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:57.708051      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:23:58.708835      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:23:59.577436 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:23:59.710040      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:00.710559      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:01.579694 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:01.710998      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:02.711155      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:03.583304 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:03.712119      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:04.712817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:05.586257 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:05.713426      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:06.713630      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:07.589856 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:07.714075      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:08.714253      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:09.593168 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:09.714313      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:10.714960      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:11.596183 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:11.715602      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:12.715734      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:13.599690 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:13.716854      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:14.717436      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:15.602775 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:15.718009      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:16.718217      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:17.605674 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:17.718836      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:18.719027      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:19.608641 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:19.719880      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:20.720903      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:21.610989 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:21.721184      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:22.721431      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:23.614310 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:23.721485      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:24.721699      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:25.617164 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:25.722750      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:26.722421      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:27.620593 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:27.722836      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:28.723053      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:29.623542 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:29.723721      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:30.723738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:31.625745 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:31.723921      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:32.724807      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:33.629887 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:33.725082      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:34.725284      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:35.632423 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:35.725623      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:36.726247      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:37.636651 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:37.727122      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:38.727343      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:39.639373 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:39.727656      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:40.728301      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:41.642242 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:41.729005      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:42.729222      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:43.646410 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:43.729737      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:44.729949      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:45.649943 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:45.730098      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:46.730322      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:47.653390 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:47.730655      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:48.730985      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:49.657001 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:49.731085      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:50.731659      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:51.659827 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:51.732488      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:52.733334      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:53.662885 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:53.734218      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:54.735222      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:55.666102 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:55.736274      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:56.736814      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:57.668769 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:57.737113      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:24:58.737365      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:24:59.671645 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:24:59.737754      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:00.738292      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:01.675486 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:01.738625      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:02.739166      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:03.678301 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:03.739511      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:04.740061      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:05.681272 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:05.740761      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:06.740995      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:07.684433 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:07.741539      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:08.741884      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:09.686956 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:09.742359      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:10.742488      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:11.691080 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:11.742858      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:12.742899      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:13.705390 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:13.742869      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:14.743121      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:15.709545 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:15.743702      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:16.743748      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:17.713321 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:17.744968      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:18.745205      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:19.723100 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:19.745754      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:20.746473      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:21.725414 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:21.747534      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:22.747734      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:23.728214 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:23.748728      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:24.749305      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:25.731122 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:25.750446      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:26.750681      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:27.734485 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:27.750787      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:28.750986      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:29.738080 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:29.751198      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:30.751368      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:31.741935 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:31.752045      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:32.752845      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:33.745253 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:33.753411      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:34.753601      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:35.748961 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:35.754121      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:36.754328      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:37.751956 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:37.754984      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:38.756686      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:39.755167 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:39.757253      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:40.757605      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:41.758165      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:41.758206 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:42.758358      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:43.758881      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:43.761440 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:44.759535      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:45.759695      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:45.764032 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:46.759738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:47.760093      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:47.766821 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:48.760292      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:49.761129      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:49.770203 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:50.761421      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:51.762088      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:51.772603 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:52.762903      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:53.763092      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:53.776404 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:54.763432      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:55.763610      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:55.779531 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:56.763765      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:57.765088      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:57.783210 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:25:58.765808      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:25:59.766082      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:25:59.785705 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:26:00.766158      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:01.766341      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:26:01.788919 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:26:02.766766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:03.766965      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:26:03.792244 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:26:04.767857      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:05.767624      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:26:05.794773 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:26:06.767766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:07.768806      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:26:07.806038 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:26:08.768972      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:09.769174      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:26:09.808464 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:26:10.769504      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:11.769699      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:26:11.816187 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:26:12.769846      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:13.770136      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:26:13.820186 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:26:14.770206      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:15.770410      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:26:15.822827 26 container_probe.go:1756] Get pod test-grpc-cae760e5-b999-4f6a-979d-0f55e32a2785 in namespace container-probe-4328
  E0127 21:26:16.770997      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:17.771686      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 01/27/26 21:26:17.823
  I0127 21:26:17.845732 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4328" for this suite. @ 01/27/26 21:26:17.852
• [242.510 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:196
  STEP: Creating a kubernetes client @ 01/27/26 21:26:17.869
  I0127 21:26:17.869382 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename container-runtime @ 01/27/26 21:26:17.869
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:26:17.887
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:26:17.898
  STEP: create the container @ 01/27/26 21:26:17.9
  I0127 21:26:17.911354      26 warnings.go:107] "Warning: metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]"
  STEP: wait for the container to reach Succeeded @ 01/27/26 21:26:17.911
  E0127 21:26:18.772293      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:19.771966      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:20.772903      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: get the container status @ 01/27/26 21:26:20.929
  STEP: the container should be terminated @ 01/27/26 21:26:20.932
  STEP: the termination message should be set @ 01/27/26 21:26:20.932
  I0127 21:26:20.932578 26 runtime.go:168] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 01/27/26 21:26:20.932
  I0127 21:26:20.961183 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-8083" for this suite. @ 01/27/26 21:26:20.963
• [3.102 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:220
  STEP: Creating a kubernetes client @ 01/27/26 21:26:20.971
  I0127 21:26:20.971468 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 21:26:20.972
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:26:20.998
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:26:21.003
  STEP: Setting up server cert @ 01/27/26 21:26:21.046
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 21:26:21.282
  STEP: Deploying the webhook pod @ 01/27/26 21:26:21.29
  STEP: Wait for the deployment to be ready @ 01/27/26 21:26:21.317
  I0127 21:26:21.325883 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0127 21:26:21.773341      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:22.773553      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/27/26 21:26:23.332
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 21:26:23.363
  I0127 21:26:23.363438 26 wait.go:65] Waiting for amount of service webhook-780/e2e-test-webhook endpoints to be 1
  I0127 21:26:23.365342 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  E0127 21:26:23.773846      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:26:24.367501 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  E0127 21:26:24.774658      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 01/27/26 21:26:24.878
  STEP: Creating a custom resource that should be denied by the webhook @ 01/27/26 21:26:24.901
  E0127 21:26:25.774875      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:26.775948      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 01/27/26 21:26:26.916
  STEP: Updating the custom resource with disallowed data should be denied @ 01/27/26 21:26:26.939
  STEP: Deleting the custom resource should be denied @ 01/27/26 21:26:26.944
  STEP: Remove the offending key and value from the custom resource data @ 01/27/26 21:26:26.947
  STEP: Deleting the updated custom resource should be successful @ 01/27/26 21:26:26.962
  I0127 21:26:27.585038 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-780" for this suite. @ 01/27/26 21:26:27.587
  STEP: Destroying namespace "webhook-markers-127" for this suite. @ 01/27/26 21:26:27.595
• [6.640 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:100
  STEP: Creating a kubernetes client @ 01/27/26 21:26:27.612
  I0127 21:26:27.612126 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename proxy @ 01/27/26 21:26:27.612
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:26:27.633
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:26:27.635
  STEP: starting an echo server on multiple ports @ 01/27/26 21:26:27.658
  I0127 21:26:27.686790 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0127 21:26:27.776056      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:28.777170      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:26:29.705006 26 wait.go:65] Waiting for amount of service proxy-7690/proxy-service-th4t9 endpoints to be 1
  I0127 21:26:29.712030 26 proxy.go:610] (0) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 5.157128ms)
  I0127 21:26:29.712067 26 proxy.go:282] setup took 2.074793908s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 01/27/26 21:26:29.712
  I0127 21:26:29.714802 26 proxy.go:610] (0) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 2.587916ms)
  I0127 21:26:29.718078 26 proxy.go:610] (0) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 5.927359ms)
  I0127 21:26:29.718593 26 proxy.go:610] (0) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 6.312907ms)
  I0127 21:26:29.719037 26 proxy.go:610] (0) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 6.601608ms)
  I0127 21:26:29.719083 26 proxy.go:610] (0) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 6.63006ms)
  I0127 21:26:29.719750 26 proxy.go:610] (0) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 7.604867ms)
  I0127 21:26:29.719789 26 proxy.go:610] (0) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 7.532474ms)
  I0127 21:26:29.719859 26 proxy.go:610] (0) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 7.367763ms)
  I0127 21:26:29.722043 26 proxy.go:610] (0) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 9.732232ms)
  I0127 21:26:29.722076 26 proxy.go:610] (0) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 9.842808ms)
  I0127 21:26:29.724960 26 proxy.go:610] (0) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 12.483702ms)
  I0127 21:26:29.725169 26 proxy.go:610] (0) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 12.79422ms)
  I0127 21:26:29.732787 26 proxy.go:610] (0) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 20.368656ms)
  I0127 21:26:29.733358 26 proxy.go:610] (0) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 21.025015ms)
  I0127 21:26:29.733381 26 proxy.go:610] (0) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 21.027808ms)
  I0127 21:26:29.734390 26 proxy.go:610] (0) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 21.994281ms)
  I0127 21:26:29.736284 26 proxy.go:610] (1) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 1.843736ms)
  I0127 21:26:29.737915 26 proxy.go:610] (1) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 3.307081ms)
  I0127 21:26:29.738091 26 proxy.go:610] (1) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 3.504722ms)
  I0127 21:26:29.738402 26 proxy.go:610] (1) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 3.902706ms)
  I0127 21:26:29.738428 26 proxy.go:610] (1) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 3.837216ms)
  I0127 21:26:29.738431 26 proxy.go:610] (1) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 3.861034ms)
  I0127 21:26:29.739272 26 proxy.go:610] (1) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 4.655831ms)
  I0127 21:26:29.739299 26 proxy.go:610] (1) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 4.843429ms)
  I0127 21:26:29.739407 26 proxy.go:610] (1) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 4.861185ms)
  I0127 21:26:29.739421 26 proxy.go:610] (1) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 4.856238ms)
  I0127 21:26:29.739437 26 proxy.go:610] (1) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 4.913253ms)
  I0127 21:26:29.739478 26 proxy.go:610] (1) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 4.85067ms)
  I0127 21:26:29.739493 26 proxy.go:610] (1) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 4.965377ms)
  I0127 21:26:29.739505 26 proxy.go:610] (1) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 5.000341ms)
  I0127 21:26:29.739527 26 proxy.go:610] (1) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 4.978923ms)
  I0127 21:26:29.739841 26 proxy.go:610] (1) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 5.401626ms)
  I0127 21:26:29.742064 26 proxy.go:610] (2) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 2.170345ms)
  I0127 21:26:29.742097 26 proxy.go:610] (2) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 2.055989ms)
  I0127 21:26:29.742113 26 proxy.go:610] (2) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 2.032716ms)
  I0127 21:26:29.742637 26 proxy.go:610] (2) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 2.630259ms)
  I0127 21:26:29.743146 26 proxy.go:610] (2) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 3.11022ms)
  I0127 21:26:29.743253 26 proxy.go:610] (2) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 3.216049ms)
  I0127 21:26:29.743270 26 proxy.go:610] (2) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 3.289413ms)
  I0127 21:26:29.743898 26 proxy.go:610] (2) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 3.987563ms)
  I0127 21:26:29.743914 26 proxy.go:610] (2) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 3.952957ms)
  I0127 21:26:29.743939 26 proxy.go:610] (2) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 3.9808ms)
  I0127 21:26:29.743992 26 proxy.go:610] (2) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 3.998931ms)
  I0127 21:26:29.744014 26 proxy.go:610] (2) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 3.996365ms)
  I0127 21:26:29.744043 26 proxy.go:610] (2) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 4.152053ms)
  I0127 21:26:29.744292 26 proxy.go:610] (2) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 4.273121ms)
  I0127 21:26:29.744518 26 proxy.go:610] (2) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 4.584554ms)
  I0127 21:26:29.745197 26 proxy.go:610] (2) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 5.212726ms)
  I0127 21:26:29.747891 26 proxy.go:610] (3) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 2.309814ms)
  I0127 21:26:29.747932 26 proxy.go:610] (3) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 2.67166ms)
  I0127 21:26:29.748110 26 proxy.go:610] (3) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 2.511202ms)
  I0127 21:26:29.748132 26 proxy.go:610] (3) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 2.874742ms)
  I0127 21:26:29.748178 26 proxy.go:610] (3) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 2.805042ms)
  I0127 21:26:29.749455 26 proxy.go:610] (3) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 4.143226ms)
  I0127 21:26:29.749465 26 proxy.go:610] (3) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 4.044031ms)
  I0127 21:26:29.749485 26 proxy.go:610] (3) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 4.041701ms)
  I0127 21:26:29.749482 26 proxy.go:610] (3) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 4.147123ms)
  I0127 21:26:29.749656 26 proxy.go:610] (3) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 4.259376ms)
  I0127 21:26:29.749718 26 proxy.go:610] (3) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 4.159788ms)
  I0127 21:26:29.749883 26 proxy.go:610] (3) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 4.528881ms)
  I0127 21:26:29.749906 26 proxy.go:610] (3) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 4.419441ms)
  I0127 21:26:29.749949 26 proxy.go:610] (3) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 4.485071ms)
  I0127 21:26:29.750337 26 proxy.go:610] (3) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 4.799448ms)
  I0127 21:26:29.750634 26 proxy.go:610] (3) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 5.121404ms)
  I0127 21:26:29.752758 26 proxy.go:610] (4) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 1.681625ms)
  I0127 21:26:29.752785 26 proxy.go:610] (4) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 2.082785ms)
  I0127 21:26:29.754469 26 proxy.go:610] (4) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 3.612261ms)
  I0127 21:26:29.754472 26 proxy.go:610] (4) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 3.354679ms)
  I0127 21:26:29.754493 26 proxy.go:610] (4) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 3.458315ms)
  I0127 21:26:29.754503 26 proxy.go:610] (4) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 3.487356ms)
  I0127 21:26:29.754510 26 proxy.go:610] (4) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 3.417149ms)
  I0127 21:26:29.754517 26 proxy.go:610] (4) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 3.572558ms)
  I0127 21:26:29.754724 26 proxy.go:610] (4) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 3.721989ms)
  I0127 21:26:29.754747 26 proxy.go:610] (4) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 3.935703ms)
  I0127 21:26:29.754812 26 proxy.go:610] (4) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 3.828094ms)
  I0127 21:26:29.754816 26 proxy.go:610] (4) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 3.964787ms)
  I0127 21:26:29.754916 26 proxy.go:610] (4) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 3.952599ms)
  I0127 21:26:29.754936 26 proxy.go:610] (4) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 4.03841ms)
  I0127 21:26:29.754962 26 proxy.go:610] (4) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 4.038888ms)
  I0127 21:26:29.754992 26 proxy.go:610] (4) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 3.939391ms)
  I0127 21:26:29.756608 26 proxy.go:610] (5) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 1.585163ms)
  I0127 21:26:29.756885 26 proxy.go:610] (5) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 1.814674ms)
  I0127 21:26:29.757266 26 proxy.go:610] (5) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 2.153332ms)
  I0127 21:26:29.758163 26 proxy.go:610] (5) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 3.003342ms)
  I0127 21:26:29.758167 26 proxy.go:610] (5) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 3.024763ms)
  I0127 21:26:29.758917 26 proxy.go:610] (5) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 3.728874ms)
  I0127 21:26:29.758927 26 proxy.go:610] (5) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 3.789973ms)
  I0127 21:26:29.758930 26 proxy.go:610] (5) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 3.728136ms)
  I0127 21:26:29.758938 26 proxy.go:610] (5) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 3.755113ms)
  I0127 21:26:29.758963 26 proxy.go:610] (5) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 3.764635ms)
  I0127 21:26:29.759268 26 proxy.go:610] (5) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 4.060172ms)
  I0127 21:26:29.760372 26 proxy.go:610] (5) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 5.212491ms)
  I0127 21:26:29.760385 26 proxy.go:610] (5) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 5.195865ms)
  I0127 21:26:29.760439 26 proxy.go:610] (5) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 5.166846ms)
  I0127 21:26:29.760691 26 proxy.go:610] (5) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 5.570744ms)
  I0127 21:26:29.760703 26 proxy.go:610] (5) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 5.527343ms)
  I0127 21:26:29.763863 26 proxy.go:610] (6) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 3.113452ms)
  I0127 21:26:29.763888 26 proxy.go:610] (6) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 3.103978ms)
  I0127 21:26:29.763901 26 proxy.go:610] (6) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 3.092904ms)
  I0127 21:26:29.763913 26 proxy.go:610] (6) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 3.062279ms)
  I0127 21:26:29.763926 26 proxy.go:610] (6) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 3.053227ms)
  I0127 21:26:29.763937 26 proxy.go:610] (6) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 3.046605ms)
  I0127 21:26:29.763949 26 proxy.go:610] (6) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 3.024828ms)
  I0127 21:26:29.763961 26 proxy.go:610] (6) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 3.001887ms)
  I0127 21:26:29.763990 26 proxy.go:610] (6) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 3.008412ms)
  I0127 21:26:29.764761 26 proxy.go:610] (6) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 3.926692ms)
  I0127 21:26:29.764779 26 proxy.go:610] (6) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 3.756768ms)
  I0127 21:26:29.764793 26 proxy.go:610] (6) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 3.74282ms)
  I0127 21:26:29.765488 26 proxy.go:610] (6) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 4.489025ms)
  I0127 21:26:29.765574 26 proxy.go:610] (6) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 4.496319ms)
  I0127 21:26:29.765951 26 proxy.go:610] (6) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 5.20414ms)
  I0127 21:26:29.766637 26 proxy.go:610] (6) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 5.540958ms)
  I0127 21:26:29.767992 26 proxy.go:610] (7) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 1.297676ms)
  I0127 21:26:29.768258 26 proxy.go:610] (7) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 1.572353ms)
  I0127 21:26:29.769739 26 proxy.go:610] (7) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 2.888806ms)
  I0127 21:26:29.769883 26 proxy.go:610] (7) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 3.073989ms)
  I0127 21:26:29.769890 26 proxy.go:610] (7) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 3.060215ms)
  I0127 21:26:29.769919 26 proxy.go:610] (7) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 3.149205ms)
  I0127 21:26:29.769923 26 proxy.go:610] (7) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 3.136265ms)
  I0127 21:26:29.769956 26 proxy.go:610] (7) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 3.192711ms)
  I0127 21:26:29.769979 26 proxy.go:610] (7) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 3.26453ms)
  I0127 21:26:29.769975 26 proxy.go:610] (7) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 3.214409ms)
  I0127 21:26:29.770321 26 proxy.go:610] (7) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 3.580876ms)
  I0127 21:26:29.770350 26 proxy.go:610] (7) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 3.610156ms)
  I0127 21:26:29.770364 26 proxy.go:610] (7) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 3.576294ms)
  I0127 21:26:29.770611 26 proxy.go:610] (7) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 3.780985ms)
  I0127 21:26:29.770612 26 proxy.go:610] (7) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 3.740953ms)
  I0127 21:26:29.771594 26 proxy.go:610] (7) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 4.798865ms)
  I0127 21:26:29.774433 26 proxy.go:610] (8) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 2.679576ms)
  I0127 21:26:29.775055 26 proxy.go:610] (8) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 3.283185ms)
  I0127 21:26:29.775083 26 proxy.go:610] (8) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 3.339009ms)
  I0127 21:26:29.775099 26 proxy.go:610] (8) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 3.36671ms)
  I0127 21:26:29.775133 26 proxy.go:610] (8) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 3.358762ms)
  I0127 21:26:29.775184 26 proxy.go:610] (8) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 3.485008ms)
  I0127 21:26:29.775217 26 proxy.go:610] (8) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 3.418784ms)
  I0127 21:26:29.776212 26 proxy.go:610] (8) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 4.444012ms)
  I0127 21:26:29.776228 26 proxy.go:610] (8) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 4.502683ms)
  I0127 21:26:29.776234 26 proxy.go:610] (8) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 4.529389ms)
  I0127 21:26:29.776241 26 proxy.go:610] (8) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 4.454024ms)
  I0127 21:26:29.776259 26 proxy.go:610] (8) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 4.485554ms)
  I0127 21:26:29.776261 26 proxy.go:610] (8) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 4.622304ms)
  I0127 21:26:29.776269 26 proxy.go:610] (8) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 4.621496ms)
  I0127 21:26:29.777218 26 proxy.go:610] (8) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 5.43203ms)
  E0127 21:26:29.777280      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:26:29.777995 26 proxy.go:610] (8) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 6.268079ms)
  I0127 21:26:29.780212 26 proxy.go:610] (9) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 2.034398ms)
  I0127 21:26:29.780500 26 proxy.go:610] (9) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 2.331423ms)
  I0127 21:26:29.780612 26 proxy.go:610] (9) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 2.455022ms)
  I0127 21:26:29.780635 26 proxy.go:610] (9) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 2.569346ms)
  I0127 21:26:29.780979 26 proxy.go:610] (9) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 2.825291ms)
  I0127 21:26:29.781149 26 proxy.go:610] (9) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 3.054126ms)
  I0127 21:26:29.781187 26 proxy.go:610] (9) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 2.995798ms)
  I0127 21:26:29.781186 26 proxy.go:610] (9) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 3.046209ms)
  I0127 21:26:29.781307 26 proxy.go:610] (9) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 3.137763ms)
  I0127 21:26:29.781420 26 proxy.go:610] (9) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 3.279698ms)
  I0127 21:26:29.781806 26 proxy.go:610] (9) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 3.754454ms)
  I0127 21:26:29.781810 26 proxy.go:610] (9) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 3.692383ms)
  I0127 21:26:29.781830 26 proxy.go:610] (9) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 3.701806ms)
  I0127 21:26:29.782472 26 proxy.go:610] (9) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 4.420246ms)
  I0127 21:26:29.782543 26 proxy.go:610] (9) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 4.367694ms)
  I0127 21:26:29.783295 26 proxy.go:610] (9) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 5.173527ms)
  I0127 21:26:29.784969 26 proxy.go:610] (10) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 1.51202ms)
  I0127 21:26:29.785132 26 proxy.go:610] (10) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 1.69814ms)
  I0127 21:26:29.785185 26 proxy.go:610] (10) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 1.851249ms)
  I0127 21:26:29.785387 26 proxy.go:610] (10) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 1.997385ms)
  I0127 21:26:29.785832 26 proxy.go:610] (10) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 2.319716ms)
  I0127 21:26:29.785853 26 proxy.go:610] (10) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 2.163273ms)
  I0127 21:26:29.785926 26 proxy.go:610] (10) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 2.208595ms)
  I0127 21:26:29.786180 26 proxy.go:610] (10) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 2.48535ms)
  I0127 21:26:29.786184 26 proxy.go:610] (10) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 2.472915ms)
  I0127 21:26:29.786386 26 proxy.go:610] (10) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 2.800574ms)
  I0127 21:26:29.786488 26 proxy.go:610] (10) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 2.832357ms)
  I0127 21:26:29.786496 26 proxy.go:610] (10) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 3.018472ms)
  I0127 21:26:29.786823 26 proxy.go:610] (10) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 3.148147ms)
  I0127 21:26:29.787107 26 proxy.go:610] (10) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 3.548344ms)
  I0127 21:26:29.787253 26 proxy.go:610] (10) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 3.718311ms)
  I0127 21:26:29.787526 26 proxy.go:610] (10) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 3.90224ms)
  I0127 21:26:29.789598 26 proxy.go:610] (11) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 2.026807ms)
  I0127 21:26:29.789716 26 proxy.go:610] (11) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 1.85538ms)
  I0127 21:26:29.789719 26 proxy.go:610] (11) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 1.931117ms)
  I0127 21:26:29.791068 26 proxy.go:610] (11) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 3.046581ms)
  I0127 21:26:29.791099 26 proxy.go:610] (11) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 3.159392ms)
  I0127 21:26:29.791116 26 proxy.go:610] (11) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 2.946084ms)
  I0127 21:26:29.791113 26 proxy.go:610] (11) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 2.867182ms)
  I0127 21:26:29.791332 26 proxy.go:610] (11) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 3.646157ms)
  I0127 21:26:29.791369 26 proxy.go:610] (11) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 3.391352ms)
  I0127 21:26:29.791610 26 proxy.go:610] (11) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 3.401056ms)
  I0127 21:26:29.791962 26 proxy.go:610] (11) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 3.905342ms)
  I0127 21:26:29.792035 26 proxy.go:610] (11) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 3.7592ms)
  I0127 21:26:29.792042 26 proxy.go:610] (11) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 4.138138ms)
  I0127 21:26:29.792055 26 proxy.go:610] (11) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 3.962888ms)
  I0127 21:26:29.792069 26 proxy.go:610] (11) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 3.934404ms)
  I0127 21:26:29.792865 26 proxy.go:610] (11) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 5.116243ms)
  I0127 21:26:29.796258 26 proxy.go:610] (12) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 3.214909ms)
  I0127 21:26:29.798340 26 proxy.go:610] (12) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 5.133265ms)
  I0127 21:26:29.798340 26 proxy.go:610] (12) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 5.208082ms)
  I0127 21:26:29.798365 26 proxy.go:610] (12) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 5.181551ms)
  I0127 21:26:29.798401 26 proxy.go:610] (12) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 5.145714ms)
  I0127 21:26:29.798404 26 proxy.go:610] (12) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 5.178732ms)
  I0127 21:26:29.798545 26 proxy.go:610] (12) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 5.272753ms)
  I0127 21:26:29.799378 26 proxy.go:610] (12) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 6.381965ms)
  I0127 21:26:29.799586 26 proxy.go:610] (12) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 6.375751ms)
  I0127 21:26:29.799619 26 proxy.go:610] (12) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 6.518332ms)
  I0127 21:26:29.799977 26 proxy.go:610] (12) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 6.889065ms)
  I0127 21:26:29.801188 26 proxy.go:610] (12) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 7.960363ms)
  I0127 21:26:29.802628 26 proxy.go:610] (12) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 9.463146ms)
  I0127 21:26:29.802614 26 proxy.go:610] (12) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 9.36293ms)
  I0127 21:26:29.802745 26 proxy.go:610] (12) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 9.472153ms)
  I0127 21:26:29.802861 26 proxy.go:610] (12) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 9.958417ms)
  I0127 21:26:29.808622 26 proxy.go:610] (13) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 5.5759ms)
  I0127 21:26:29.811941 26 proxy.go:610] (13) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 8.638322ms)
  I0127 21:26:29.811959 26 proxy.go:610] (13) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 8.406239ms)
  I0127 21:26:29.811968 26 proxy.go:610] (13) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 8.383867ms)
  I0127 21:26:29.811970 26 proxy.go:610] (13) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 8.635128ms)
  I0127 21:26:29.811982 26 proxy.go:610] (13) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 8.544049ms)
  I0127 21:26:29.811989 26 proxy.go:610] (13) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 8.33549ms)
  I0127 21:26:29.811997 26 proxy.go:610] (13) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 8.527058ms)
  I0127 21:26:29.811997 26 proxy.go:610] (13) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 8.629186ms)
  I0127 21:26:29.812004 26 proxy.go:610] (13) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 9.090468ms)
  I0127 21:26:29.812011 26 proxy.go:610] (13) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 8.499204ms)
  I0127 21:26:29.812018 26 proxy.go:610] (13) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 8.75511ms)
  I0127 21:26:29.812019 26 proxy.go:610] (13) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 8.912515ms)
  I0127 21:26:29.812057 26 proxy.go:610] (13) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 8.89514ms)
  I0127 21:26:29.812198 26 proxy.go:610] (13) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 8.791629ms)
  I0127 21:26:29.815065 26 proxy.go:610] (13) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 11.847205ms)
  I0127 21:26:29.817435 26 proxy.go:610] (14) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 2.310317ms)
  I0127 21:26:29.817467 26 proxy.go:610] (14) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 2.331578ms)
  I0127 21:26:29.817545 26 proxy.go:610] (14) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 2.427416ms)
  I0127 21:26:29.818038 26 proxy.go:610] (14) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 2.841966ms)
  I0127 21:26:29.818058 26 proxy.go:610] (14) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 2.793178ms)
  I0127 21:26:29.818087 26 proxy.go:610] (14) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 2.868753ms)
  I0127 21:26:29.818647 26 proxy.go:610] (14) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 3.425506ms)
  I0127 21:26:29.818672 26 proxy.go:610] (14) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 3.475489ms)
  I0127 21:26:29.818686 26 proxy.go:610] (14) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 3.446181ms)
  I0127 21:26:29.818701 26 proxy.go:610] (14) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 3.455495ms)
  I0127 21:26:29.818625 26 proxy.go:610] (14) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 3.306686ms)
  I0127 21:26:29.818850 26 proxy.go:610] (14) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 3.322473ms)
  I0127 21:26:29.818874 26 proxy.go:610] (14) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 3.594586ms)
  I0127 21:26:29.819821 26 proxy.go:610] (14) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 4.484743ms)
  I0127 21:26:29.819844 26 proxy.go:610] (14) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 4.57814ms)
  I0127 21:26:29.819994 26 proxy.go:610] (14) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 4.639912ms)
  I0127 21:26:29.821949 26 proxy.go:610] (15) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 1.86016ms)
  I0127 21:26:29.822285 26 proxy.go:610] (15) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 2.199255ms)
  I0127 21:26:29.822520 26 proxy.go:610] (15) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 2.473991ms)
  I0127 21:26:29.822558 26 proxy.go:610] (15) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 2.492048ms)
  I0127 21:26:29.822681 26 proxy.go:610] (15) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 2.633843ms)
  I0127 21:26:29.822714 26 proxy.go:610] (15) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 2.549237ms)
  I0127 21:26:29.822818 26 proxy.go:610] (15) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 2.70788ms)
  I0127 21:26:29.823037 26 proxy.go:610] (15) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 2.881868ms)
  I0127 21:26:29.823079 26 proxy.go:610] (15) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 2.96814ms)
  I0127 21:26:29.823076 26 proxy.go:610] (15) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 2.893498ms)
  I0127 21:26:29.823085 26 proxy.go:610] (15) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 2.911613ms)
  I0127 21:26:29.823081 26 proxy.go:610] (15) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 2.925913ms)
  I0127 21:26:29.823262 26 proxy.go:610] (15) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 3.109386ms)
  I0127 21:26:29.823431 26 proxy.go:610] (15) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 3.288031ms)
  I0127 21:26:29.823440 26 proxy.go:610] (15) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 3.320607ms)
  I0127 21:26:29.823630 26 proxy.go:610] (15) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 3.488446ms)
  I0127 21:26:29.827271 26 proxy.go:610] (16) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 3.464479ms)
  I0127 21:26:29.827278 26 proxy.go:610] (16) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 3.475312ms)
  I0127 21:26:29.827345 26 proxy.go:610] (16) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 3.633754ms)
  I0127 21:26:29.827379 26 proxy.go:610] (16) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 3.65261ms)
  I0127 21:26:29.827397 26 proxy.go:610] (16) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 3.629006ms)
  I0127 21:26:29.827415 26 proxy.go:610] (16) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 3.6778ms)
  I0127 21:26:29.827432 26 proxy.go:610] (16) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 3.643206ms)
  I0127 21:26:29.827445 26 proxy.go:610] (16) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 3.593958ms)
  I0127 21:26:29.827744 26 proxy.go:610] (16) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 3.881536ms)
  I0127 21:26:29.827789 26 proxy.go:610] (16) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 4.054465ms)
  I0127 21:26:29.827797 26 proxy.go:610] (16) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 4.100543ms)
  I0127 21:26:29.827804 26 proxy.go:610] (16) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 4.025747ms)
  I0127 21:26:29.827860 26 proxy.go:610] (16) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 4.179323ms)
  I0127 21:26:29.827874 26 proxy.go:610] (16) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 4.146676ms)
  I0127 21:26:29.830582 26 proxy.go:610] (16) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 6.767165ms)
  I0127 21:26:29.830599 26 proxy.go:610] (16) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 6.912026ms)
  I0127 21:26:29.832658 26 proxy.go:610] (17) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 2.012286ms)
  I0127 21:26:29.832939 26 proxy.go:610] (17) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 2.294736ms)
  I0127 21:26:29.832973 26 proxy.go:610] (17) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 2.233028ms)
  I0127 21:26:29.833044 26 proxy.go:610] (17) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 2.319715ms)
  I0127 21:26:29.833069 26 proxy.go:610] (17) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 2.31863ms)
  I0127 21:26:29.833821 26 proxy.go:610] (17) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 3.117253ms)
  I0127 21:26:29.834019 26 proxy.go:610] (17) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 3.320819ms)
  I0127 21:26:29.834022 26 proxy.go:610] (17) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 3.259782ms)
  I0127 21:26:29.834303 26 proxy.go:610] (17) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 3.554085ms)
  I0127 21:26:29.834318 26 proxy.go:610] (17) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 3.576864ms)
  I0127 21:26:29.836490 26 proxy.go:610] (17) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 5.823354ms)
  I0127 21:26:29.836523 26 proxy.go:610] (17) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 5.763663ms)
  I0127 21:26:29.836539 26 proxy.go:610] (17) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 5.822357ms)
  I0127 21:26:29.836553 26 proxy.go:610] (17) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 5.833593ms)
  I0127 21:26:29.836872 26 proxy.go:610] (17) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 6.142099ms)
  I0127 21:26:29.837050 26 proxy.go:610] (17) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 6.258207ms)
  I0127 21:26:29.842579 26 proxy.go:610] (18) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 5.362418ms)
  I0127 21:26:29.842999 26 proxy.go:610] (18) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 5.801238ms)
  I0127 21:26:29.845026 26 proxy.go:610] (18) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 7.738266ms)
  I0127 21:26:29.846727 26 proxy.go:610] (18) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 9.40133ms)
  I0127 21:26:29.847311 26 proxy.go:610] (18) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 10.208809ms)
  I0127 21:26:29.847338 26 proxy.go:610] (18) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 10.113948ms)
  I0127 21:26:29.847356 26 proxy.go:610] (18) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 10.089436ms)
  I0127 21:26:29.847368 26 proxy.go:610] (18) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 10.09416ms)
  I0127 21:26:29.847555 26 proxy.go:610] (18) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 10.263216ms)
  I0127 21:26:29.847580 26 proxy.go:610] (18) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 10.371592ms)
  I0127 21:26:29.847616 26 proxy.go:610] (18) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 10.363121ms)
  I0127 21:26:29.847764 26 proxy.go:610] (18) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 10.461373ms)
  I0127 21:26:29.847784 26 proxy.go:610] (18) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 10.540427ms)
  I0127 21:26:29.847984 26 proxy.go:610] (18) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 10.667887ms)
  I0127 21:26:29.848095 26 proxy.go:610] (18) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 10.789695ms)
  I0127 21:26:29.850099 26 proxy.go:610] (18) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 12.829148ms)
  I0127 21:26:29.854507 26 proxy.go:610] (19) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 4.249712ms)
  I0127 21:26:29.854550 26 proxy.go:610] (19) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname1/proxy/: foo (200; 4.288121ms)
  I0127 21:26:29.854621 26 proxy.go:610] (19) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:462/proxy/: tls qux (200; 4.391438ms)
  I0127 21:26:29.855095 26 proxy.go:610] (19) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/... (200; 4.953404ms)
  I0127 21:26:29.855152 26 proxy.go:610] (19) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:460/proxy/: tls baz (200; 4.864081ms)
  I0127 21:26:29.855648 26 proxy.go:610] (19) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt/proxy/rewriteme"... (200; 5.244957ms)
  I0127 21:26:29.855662 26 proxy.go:610] (19) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname1/proxy/: tls baz (200; 5.34455ms)
  I0127 21:26:29.856948 26 proxy.go:610] (19) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:1080/proxy/rewri... (200; 6.599797ms)
  I0127 21:26:29.857238 26 proxy.go:610] (19) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 6.871471ms)
  I0127 21:26:29.857707 26 proxy.go:610] (19) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname2/proxy/: bar (200; 7.345842ms)
  I0127 21:26:29.857718 26 proxy.go:610] (19) /api/v1/namespaces/proxy-7690/services/http:proxy-service-th4t9:portname1/proxy/: foo (200; 7.41972ms)
  I0127 21:26:29.857728 26 proxy.go:610] (19) /api/v1/namespaces/proxy-7690/pods/proxy-service-th4t9-5dd5f76bf8-j2hxt:162/proxy/: bar (200; 7.397867ms)
  I0127 21:26:29.857973 26 proxy.go:610] (19) /api/v1/namespaces/proxy-7690/services/https:proxy-service-th4t9:tlsportname2/proxy/: tls qux (200; 7.588957ms)
  I0127 21:26:29.857977 26 proxy.go:610] (19) /api/v1/namespaces/proxy-7690/pods/http:proxy-service-th4t9-5dd5f76bf8-j2hxt:160/proxy/: foo (200; 7.576964ms)
  I0127 21:26:29.858134 26 proxy.go:610] (19) /api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/: <a href="/api/v1/namespaces/proxy-7690/pods/https:proxy-service-th4t9-5dd5f76bf8-j2hxt:443/proxy/... (200; 7.749592ms)
  I0127 21:26:29.858721 26 proxy.go:610] (19) /api/v1/namespaces/proxy-7690/services/proxy-service-th4t9:portname2/proxy/: bar (200; 8.411549ms)
  I0127 21:26:29.872014 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-7690" for this suite. @ 01/27/26 21:26:29.875
• [2.275 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:717
  STEP: Creating a kubernetes client @ 01/27/26 21:26:29.887
  I0127 21:26:29.887790 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename security-context-test @ 01/27/26 21:26:29.888
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:26:29.92
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:26:29.93
  E0127 21:26:30.777706      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:31.779271      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:32.779363      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:33.779557      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:26:33.972870 26 security_context.go:724] Got logs for pod "busybox-privileged-false-28a2b0ad-b0ba-4e55-99b3-04783c7ab0de": "ip: RTNETLINK answers: Operation not permitted\n"
  I0127 21:26:33.973006 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-8415" for this suite. @ 01/27/26 21:26:33.975
• [4.096 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Job should terminate job execution when the number of failed indexes exceeds maxFailedIndexes [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:641
  STEP: Creating a kubernetes client @ 01/27/26 21:26:33.983
  I0127 21:26:33.983769 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename job @ 01/27/26 21:26:33.984
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:26:34.006
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:26:34.01
  STEP: Creating an indexed job with backoffLimit per index and maxFailedIndexes @ 01/27/26 21:26:34.012
  STEP: Awaiting for the job to fail as the number of max failed indexes is exceeded @ 01/27/26 21:26:34.021
  E0127 21:26:34.779753      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:35.780832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:36.781898      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:37.782593      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Verifying the Job status fields to ensure early termination of the job @ 01/27/26 21:26:38.031
  I0127 21:26:38.032677 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-6626" for this suite. @ 01/27/26 21:26:38.034
• [4.066 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:95
  STEP: Creating a kubernetes client @ 01/27/26 21:26:38.049
  I0127 21:26:38.049601 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename downward-api @ 01/27/26 21:26:38.05
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:26:38.071
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:26:38.073
  STEP: Creating a pod to test downward api env vars @ 01/27/26 21:26:38.075
  E0127 21:26:38.782851      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:39.783047      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:40.783097      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:41.783528      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:26:42.108
  I0127 21:26:42.110201 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downward-api-2bf80bca-73da-40d0-a3ea-e08661fe8402 container dapi-container: <nil>
  STEP: delete the pod @ 01/27/26 21:26:42.114
  I0127 21:26:42.142671 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-541" for this suite. @ 01/27/26 21:26:42.145
• [4.105 seconds]
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 01/27/26 21:26:42.155
  I0127 21:26:42.155145 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pod-network-test @ 01/27/26 21:26:42.155
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:26:42.172
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:26:42.182
  STEP: Performing setup for networking test in namespace pod-network-test-4416 @ 01/27/26 21:26:42.184
  STEP: creating a selector @ 01/27/26 21:26:42.184
  STEP: Creating the service pods in kubernetes @ 01/27/26 21:26:42.184
  I0127 21:26:42.184710 26 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0127 21:26:42.783707      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:43.783757      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:44.784779      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:45.785681      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:46.786056      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:47.786245      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:48.786773      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:49.786967      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:50.787239      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:51.787464      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:52.788281      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:53.788422      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:54.788846      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:55.789167      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 01/27/26 21:26:56.301
  E0127 21:26:56.790068      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:57.790268      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:26:58.327621 26 utils.go:803] Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  I0127 21:26:58.327655 26 networking.go:42] Breadth first check of 10.52.1.81 on host 10.42.0.10...
  I0127 21:26:58.329049 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.52.1.82:9080/dial?request=hostname&protocol=http&host=10.52.1.81&port=8083&tries=1'] Namespace:pod-network-test-4416 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:26:58.329079 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:26:58.329117 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-network-test-4416/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.52.1.82%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.52.1.81%26port%3D8083%26tries%3D1%27&container=webserver&stderr=true&stdout=true)
  I0127 21:26:58.378333 26 utils.go:356] Waiting for responses: map[]
  I0127 21:26:58.378366 26 utils.go:360] reached 10.52.1.81 after 0/1 tries
  I0127 21:26:58.378376 26 networking.go:42] Breadth first check of 10.52.0.197 on host 10.42.0.12...
  I0127 21:26:58.381161 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.52.1.82:9080/dial?request=hostname&protocol=http&host=10.52.0.197&port=8083&tries=1'] Namespace:pod-network-test-4416 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:26:58.381203 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:26:58.381246 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-network-test-4416/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.52.1.82%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.52.0.197%26port%3D8083%26tries%3D1%27&container=webserver&stderr=true&stdout=true)
  I0127 21:26:58.424952 26 utils.go:356] Waiting for responses: map[]
  I0127 21:26:58.424998 26 utils.go:360] reached 10.52.0.197 after 0/1 tries
  I0127 21:26:58.425008 26 networking.go:53] Going to retry 0 out of 2 pods....
  I0127 21:26:58.425118 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-4416" for this suite. @ 01/27/26 21:26:58.428
• [16.287 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Serial] [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:388
  STEP: Creating a kubernetes client @ 01/27/26 21:26:58.442
  I0127 21:26:58.442702 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename gc @ 01/27/26 21:26:58.443
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:26:58.464
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:26:58.475
  STEP: create the rc @ 01/27/26 21:26:58.529
  I0127 21:26:58.542452      26 warnings.go:107] "Warning: metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]"
  E0127 21:26:58.790900      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:26:59.791119      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:00.792081      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:01.793223      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:02.793873      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:03.794657      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:04.794745      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the rc @ 01/27/26 21:27:04.813
  STEP: wait for the rc to be deleted @ 01/27/26 21:27:05.367
  E0127 21:27:05.795459      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:06.795621      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:07.795764      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:08.796838      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:09.797557      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 01/27/26 21:27:10.387
  E0127 21:27:10.797663      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:11.798052      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:12.798217      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:13.798431      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:14.798523      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:15.798749      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:16.798860      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:17.798999      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:18.799758      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:19.800811      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:20.801189      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:21.801909      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:22.802056      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:23.802271      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:24.802465      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:25.803068      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:26.803739      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:27.804809      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:28.805390      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:29.806599      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:30.807651      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:31.807734      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:32.808819      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:33.809605      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:34.809826      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:35.810557      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:36.810742      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:37.810949      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:38.811168      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:39.811360      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 01/27/26 21:27:40.395
  W0127 21:27:40.397506      26 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I0127 21:27:40.397533 26 garbage_collector.go:273] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0127 21:27:40.397597 26 delete.go:111] Deleting pod "simpletest.rc-27mk2" in namespace "gc-1919"
  E0127 21:27:40.812149      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:27:40.897250 26 delete.go:111] Deleting pod "simpletest.rc-49wm6" in namespace "gc-1919"
  I0127 21:27:41.252447 26 delete.go:111] Deleting pod "simpletest.rc-6hntx" in namespace "gc-1919"
  I0127 21:27:41.742791 26 delete.go:111] Deleting pod "simpletest.rc-6jzhl" in namespace "gc-1919"
  E0127 21:27:41.811957      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:27:42.207872 26 delete.go:111] Deleting pod "simpletest.rc-6lzvk" in namespace "gc-1919"
  I0127 21:27:42.423265 26 delete.go:111] Deleting pod "simpletest.rc-6qnxb" in namespace "gc-1919"
  I0127 21:27:42.672437 26 delete.go:111] Deleting pod "simpletest.rc-6qqrs" in namespace "gc-1919"
  E0127 21:27:42.812854      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:27:43.013030 26 delete.go:111] Deleting pod "simpletest.rc-6t8dv" in namespace "gc-1919"
  I0127 21:27:43.257104 26 delete.go:111] Deleting pod "simpletest.rc-6wk2l" in namespace "gc-1919"
  I0127 21:27:43.677720 26 delete.go:111] Deleting pod "simpletest.rc-6zjfq" in namespace "gc-1919"
  E0127 21:27:43.813256      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:27:43.892871 26 delete.go:111] Deleting pod "simpletest.rc-7ksd8" in namespace "gc-1919"
  I0127 21:27:43.972426 26 delete.go:111] Deleting pod "simpletest.rc-82gv4" in namespace "gc-1919"
  I0127 21:27:44.313113 26 delete.go:111] Deleting pod "simpletest.rc-85v27" in namespace "gc-1919"
  I0127 21:27:44.452323 26 delete.go:111] Deleting pod "simpletest.rc-8gxqp" in namespace "gc-1919"
  E0127 21:27:44.813897      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:27:44.877720 26 delete.go:111] Deleting pod "simpletest.rc-8llxt" in namespace "gc-1919"
  I0127 21:27:45.247581 26 delete.go:111] Deleting pod "simpletest.rc-9496q" in namespace "gc-1919"
  I0127 21:27:45.397167 26 delete.go:111] Deleting pod "simpletest.rc-95prs" in namespace "gc-1919"
  I0127 21:27:45.637278 26 delete.go:111] Deleting pod "simpletest.rc-bmbmx" in namespace "gc-1919"
  E0127 21:27:45.814517      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:27:46.663181 26 delete.go:111] Deleting pod "simpletest.rc-cjxbt" in namespace "gc-1919"
  E0127 21:27:46.815539      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:27:46.957582 26 delete.go:111] Deleting pod "simpletest.rc-crvdr" in namespace "gc-1919"
  I0127 21:27:47.587875 26 delete.go:111] Deleting pod "simpletest.rc-cxfhm" in namespace "gc-1919"
  E0127 21:27:47.816303      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:27:48.008149 26 delete.go:111] Deleting pod "simpletest.rc-cxk9f" in namespace "gc-1919"
  I0127 21:27:48.437558 26 delete.go:111] Deleting pod "simpletest.rc-d4zlt" in namespace "gc-1919"
  E0127 21:27:48.816973      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:27:48.892285 26 delete.go:111] Deleting pod "simpletest.rc-d59jr" in namespace "gc-1919"
  I0127 21:27:49.129006 26 delete.go:111] Deleting pod "simpletest.rc-dkrhw" in namespace "gc-1919"
  I0127 21:27:49.572750 26 delete.go:111] Deleting pod "simpletest.rc-dwzqq" in namespace "gc-1919"
  E0127 21:27:49.817138      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:27:50.092763 26 delete.go:111] Deleting pod "simpletest.rc-dzd9j" in namespace "gc-1919"
  I0127 21:27:50.778382 26 delete.go:111] Deleting pod "simpletest.rc-dzf5g" in namespace "gc-1919"
  E0127 21:27:50.818197      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:27:51.587533 26 delete.go:111] Deleting pod "simpletest.rc-fcnlv" in namespace "gc-1919"
  E0127 21:27:51.819531      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:27:52.592669 26 delete.go:111] Deleting pod "simpletest.rc-fh8p9" in namespace "gc-1919"
  E0127 21:27:52.820123      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:53.820196      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:27:54.075007 26 delete.go:111] Deleting pod "simpletest.rc-fj4tw" in namespace "gc-1919"
  E0127 21:27:54.820359      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:27:55.642549 26 delete.go:111] Deleting pod "simpletest.rc-fqgqd" in namespace "gc-1919"
  E0127 21:27:55.820785      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:27:56.820934      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:27:57.428851 26 delete.go:111] Deleting pod "simpletest.rc-fv454" in namespace "gc-1919"
  E0127 21:27:57.821496      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:27:58.772786 26 delete.go:111] Deleting pod "simpletest.rc-gjq52" in namespace "gc-1919"
  E0127 21:27:58.822293      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:27:59.537729 26 delete.go:111] Deleting pod "simpletest.rc-h9bxf" in namespace "gc-1919"
  E0127 21:27:59.823340      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:00.727945 26 delete.go:111] Deleting pod "simpletest.rc-hqxc4" in namespace "gc-1919"
  E0127 21:28:00.824115      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:28:01.824817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:01.968254 26 delete.go:111] Deleting pod "simpletest.rc-htw29" in namespace "gc-1919"
  E0127 21:28:02.825364      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:02.863579 26 delete.go:111] Deleting pod "simpletest.rc-j6b7r" in namespace "gc-1919"
  E0127 21:28:03.825578      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:04.182665 26 delete.go:111] Deleting pod "simpletest.rc-jkjrn" in namespace "gc-1919"
  I0127 21:28:04.457976 26 delete.go:111] Deleting pod "simpletest.rc-jmmdv" in namespace "gc-1919"
  E0127 21:28:04.826194      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:05.012832 26 delete.go:111] Deleting pod "simpletest.rc-jpc4j" in namespace "gc-1919"
  I0127 21:28:05.702166 26 delete.go:111] Deleting pod "simpletest.rc-jskms" in namespace "gc-1919"
  E0127 21:28:05.826417      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:06.148074 26 delete.go:111] Deleting pod "simpletest.rc-jx4c9" in namespace "gc-1919"
  I0127 21:28:06.562385 26 delete.go:111] Deleting pod "simpletest.rc-kbrzk" in namespace "gc-1919"
  E0127 21:28:06.826868      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:07.378520 26 delete.go:111] Deleting pod "simpletest.rc-kcgvh" in namespace "gc-1919"
  E0127 21:28:07.827932      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:08.367995 26 delete.go:111] Deleting pod "simpletest.rc-khr9f" in namespace "gc-1919"
  I0127 21:28:08.818150 26 delete.go:111] Deleting pod "simpletest.rc-kknzg" in namespace "gc-1919"
  E0127 21:28:08.828738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:09.398059 26 delete.go:111] Deleting pod "simpletest.rc-lnv9b" in namespace "gc-1919"
  E0127 21:28:09.829630      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:28:10.829786      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:11.198923 26 delete.go:111] Deleting pod "simpletest.rc-lxdll" in namespace "gc-1919"
  I0127 21:28:11.643164 26 delete.go:111] Deleting pod "simpletest.rc-lxpw4" in namespace "gc-1919"
  E0127 21:28:11.830637      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:12.093000 26 delete.go:111] Deleting pod "simpletest.rc-m2r4z" in namespace "gc-1919"
  I0127 21:28:12.552692 26 delete.go:111] Deleting pod "simpletest.rc-mcvps" in namespace "gc-1919"
  E0127 21:28:12.831471      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:13.602707 26 delete.go:111] Deleting pod "simpletest.rc-mf9jj" in namespace "gc-1919"
  E0127 21:28:13.833080      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:14.487734 26 delete.go:111] Deleting pod "simpletest.rc-msxsw" in namespace "gc-1919"
  E0127 21:28:14.833224      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:14.998223 26 delete.go:111] Deleting pod "simpletest.rc-mzhmr" in namespace "gc-1919"
  I0127 21:28:15.582629 26 delete.go:111] Deleting pod "simpletest.rc-n82vd" in namespace "gc-1919"
  E0127 21:28:15.833779      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:16.322932 26 delete.go:111] Deleting pod "simpletest.rc-ngxk7" in namespace "gc-1919"
  E0127 21:28:16.834223      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:17.404031 26 delete.go:111] Deleting pod "simpletest.rc-nkqxf" in namespace "gc-1919"
  E0127 21:28:17.834489      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:18.192659 26 delete.go:111] Deleting pod "simpletest.rc-nzlmr" in namespace "gc-1919"
  I0127 21:28:18.823495 26 delete.go:111] Deleting pod "simpletest.rc-p5m92" in namespace "gc-1919"
  E0127 21:28:18.834690      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:19.623616 26 delete.go:111] Deleting pod "simpletest.rc-pcsw7" in namespace "gc-1919"
  E0127 21:28:19.834897      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:20.663279 26 delete.go:111] Deleting pod "simpletest.rc-pm7vr" in namespace "gc-1919"
  E0127 21:28:20.835905      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:21.068244 26 delete.go:111] Deleting pod "simpletest.rc-psb4t" in namespace "gc-1919"
  I0127 21:28:21.763262 26 delete.go:111] Deleting pod "simpletest.rc-pxd9d" in namespace "gc-1919"
  E0127 21:28:21.836820      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:22.824402 26 delete.go:111] Deleting pod "simpletest.rc-q2pl9" in namespace "gc-1919"
  E0127 21:28:22.837572      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:23.147874 26 delete.go:111] Deleting pod "simpletest.rc-q9f9x" in namespace "gc-1919"
  I0127 21:28:23.613055 26 delete.go:111] Deleting pod "simpletest.rc-qbjnv" in namespace "gc-1919"
  E0127 21:28:23.837620      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:24.518697 26 delete.go:111] Deleting pod "simpletest.rc-qg9f2" in namespace "gc-1919"
  E0127 21:28:24.838456      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:25.188353 26 delete.go:111] Deleting pod "simpletest.rc-qjmrv" in namespace "gc-1919"
  E0127 21:28:25.838675      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:25.913386 26 delete.go:111] Deleting pod "simpletest.rc-qsh7k" in namespace "gc-1919"
  E0127 21:28:26.838812      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:27.179728 26 delete.go:111] Deleting pod "simpletest.rc-qxq98" in namespace "gc-1919"
  I0127 21:28:27.597965 26 delete.go:111] Deleting pod "simpletest.rc-qzmw7" in namespace "gc-1919"
  E0127 21:28:27.839888      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:28.037020 26 delete.go:111] Deleting pod "simpletest.rc-rghdg" in namespace "gc-1919"
  I0127 21:28:28.797928 26 delete.go:111] Deleting pod "simpletest.rc-rpsbk" in namespace "gc-1919"
  E0127 21:28:28.840160      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:29.413037 26 delete.go:111] Deleting pod "simpletest.rc-rsghd" in namespace "gc-1919"
  E0127 21:28:29.840798      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:30.223514 26 delete.go:111] Deleting pod "simpletest.rc-s7q84" in namespace "gc-1919"
  E0127 21:28:30.841476      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:28:31.842059      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:31.864273 26 delete.go:111] Deleting pod "simpletest.rc-sc5nf" in namespace "gc-1919"
  E0127 21:28:32.842807      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:33.483377 26 delete.go:111] Deleting pod "simpletest.rc-swkdl" in namespace "gc-1919"
  E0127 21:28:33.842955      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:28:34.843168      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:28:35.843795      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:36.360025 26 delete.go:111] Deleting pod "simpletest.rc-t5ck8" in namespace "gc-1919"
  E0127 21:28:36.844665      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:37.704147 26 delete.go:111] Deleting pod "simpletest.rc-v5q7s" in namespace "gc-1919"
  E0127 21:28:37.845621      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:38.796329 26 delete.go:111] Deleting pod "simpletest.rc-v5wwg" in namespace "gc-1919"
  E0127 21:28:38.845801      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:39.044605 26 delete.go:111] Deleting pod "simpletest.rc-vqwrw" in namespace "gc-1919"
  E0127 21:28:39.846356      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:39.903572 26 delete.go:111] Deleting pod "simpletest.rc-vwsgv" in namespace "gc-1919"
  I0127 21:28:40.673385 26 delete.go:111] Deleting pod "simpletest.rc-vxnng" in namespace "gc-1919"
  E0127 21:28:40.846928      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:41.753726 26 delete.go:111] Deleting pod "simpletest.rc-w8hhh" in namespace "gc-1919"
  E0127 21:28:41.847045      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:42.603500 26 delete.go:111] Deleting pod "simpletest.rc-wbzqb" in namespace "gc-1919"
  E0127 21:28:42.847173      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:43.038298 26 delete.go:111] Deleting pod "simpletest.rc-wn289" in namespace "gc-1919"
  E0127 21:28:43.848271      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:44.156889 26 delete.go:111] Deleting pod "simpletest.rc-wnzvq" in namespace "gc-1919"
  E0127 21:28:44.849713      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:45.728336 26 delete.go:111] Deleting pod "simpletest.rc-wvr7r" in namespace "gc-1919"
  E0127 21:28:45.850423      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:28:46.850641      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:47.083467 26 delete.go:111] Deleting pod "simpletest.rc-xbdgc" in namespace "gc-1919"
  E0127 21:28:47.850810      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:48.049556 26 delete.go:111] Deleting pod "simpletest.rc-xdg7j" in namespace "gc-1919"
  I0127 21:28:48.779183 26 delete.go:111] Deleting pod "simpletest.rc-xhqk5" in namespace "gc-1919"
  E0127 21:28:48.851706      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:49.254067 26 delete.go:111] Deleting pod "simpletest.rc-xkpkk" in namespace "gc-1919"
  I0127 21:28:49.694042 26 delete.go:111] Deleting pod "simpletest.rc-z8kwm" in namespace "gc-1919"
  E0127 21:28:49.852946      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:50.139533 26 delete.go:111] Deleting pod "simpletest.rc-z9ss9" in namespace "gc-1919"
  I0127 21:28:50.322811 26 delete.go:111] Deleting pod "simpletest.rc-zg8nr" in namespace "gc-1919"
  E0127 21:28:50.853403      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:51.028280 26 delete.go:111] Deleting pod "simpletest.rc-zj4rm" in namespace "gc-1919"
  I0127 21:28:51.701836 26 delete.go:111] Deleting pod "simpletest.rc-zjprt" in namespace "gc-1919"
  E0127 21:28:51.854371      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:51.937835 26 delete.go:111] Deleting pod "simpletest.rc-zjzn7" in namespace "gc-1919"
  I0127 21:28:52.232928 26 delete.go:111] Deleting pod "simpletest.rc-zq5cg" in namespace "gc-1919"
  I0127 21:28:52.738186 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1919" for this suite. @ 01/27/26 21:28:52.741
  E0127 21:28:52.855250      26 retrywatcher.go:169] "Watch failed" err="context canceled"
• [114.481 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:648
  STEP: Creating a kubernetes client @ 01/27/26 21:28:52.923
  I0127 21:28:52.923358 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 21:28:52.924
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:28:53.087
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:28:53.132
  STEP: Setting up server cert @ 01/27/26 21:28:53.433
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 21:28:53.797
  E0127 21:28:53.855704      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook pod @ 01/27/26 21:28:53.948
  STEP: Wait for the deployment to be ready @ 01/27/26 21:28:54.203
  I0127 21:28:54.218401 26 deployment.go:223] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0127 21:28:54.856098      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:28:55.856827      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:28:56.260130 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc002031100), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 21, 28, 54, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 28, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 28, 54, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 28, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c5c95bb96\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:28:56.857830      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:28:57.858886      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/27/26 21:28:58.265
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 21:28:58.29
  I0127 21:28:58.290301 26 wait.go:65] Waiting for amount of service webhook-5356/e2e-test-webhook endpoints to be 1
  I0127 21:28:58.297368 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  E0127 21:28:58.859290      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Listing all of the created validation webhooks @ 01/27/26 21:28:59.475
  STEP: Creating a configMap that should be mutated @ 01/27/26 21:28:59.494
  STEP: Deleting the collection of validation webhooks @ 01/27/26 21:28:59.529
  STEP: Creating a configMap that should not be mutated @ 01/27/26 21:28:59.657
  I0127 21:28:59.778079 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5356" for this suite. @ 01/27/26 21:28:59.79
  STEP: Destroying namespace "webhook-markers-4878" for this suite. @ 01/27/26 21:28:59.808
• [6.897 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 01/27/26 21:28:59.82
  I0127 21:28:59.820756 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pod-network-test @ 01/27/26 21:28:59.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:28:59.85
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:28:59.857
  E0127 21:28:59.859571      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Performing setup for networking test in namespace pod-network-test-8594 @ 01/27/26 21:28:59.863
  STEP: creating a selector @ 01/27/26 21:28:59.864
  STEP: Creating the service pods in kubernetes @ 01/27/26 21:28:59.864
  I0127 21:28:59.864036 26 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0127 21:29:00.859906      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:01.860024      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:02.860669      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:03.860779      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:04.861807      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:05.862041      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:06.862100      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:07.862314      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:08.863212      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:09.863340      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:10.863514      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:11.863940      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:12.863747      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:13.863773      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 01/27/26 21:29:14.661
  E0127 21:29:14.864295      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:15.864436      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:16.865165      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:17.865387      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:18.865583      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:29:18.944898 26 utils.go:803] Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  I0127 21:29:18.944929 26 networking.go:42] Breadth first check of 10.52.1.134 on host 10.42.0.10...
  I0127 21:29:18.946240 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.52.1.135:9080/dial?request=hostname&protocol=udp&host=10.52.1.134&port=8081&tries=1'] Namespace:pod-network-test-8594 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:29:18.946265 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:29:18.946310 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-network-test-8594/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.52.1.135%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.52.1.134%26port%3D8081%26tries%3D1%27&container=webserver&stderr=true&stdout=true)
  I0127 21:29:19.025716 26 utils.go:356] Waiting for responses: map[]
  I0127 21:29:19.025746 26 utils.go:360] reached 10.52.1.134 after 0/1 tries
  I0127 21:29:19.025757 26 networking.go:42] Breadth first check of 10.52.0.248 on host 10.42.0.12...
  I0127 21:29:19.028196 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.52.1.135:9080/dial?request=hostname&protocol=udp&host=10.52.0.248&port=8081&tries=1'] Namespace:pod-network-test-8594 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:29:19.028234 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:29:19.028283 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-network-test-8594/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.52.1.135%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.52.0.248%26port%3D8081%26tries%3D1%27&container=webserver&stderr=true&stdout=true)
  I0127 21:29:19.148875 26 utils.go:356] Waiting for responses: map[]
  I0127 21:29:19.148909 26 utils.go:360] reached 10.52.0.248 after 0/1 tries
  I0127 21:29:19.148919 26 networking.go:53] Going to retry 0 out of 2 pods....
  I0127 21:29:19.149027 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-8594" for this suite. @ 01/27/26 21:29:19.153
• [19.365 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 01/27/26 21:29:19.185
  I0127 21:29:19.185618 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename container-probe @ 01/27/26 21:29:19.186
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:29:19.374
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:29:19.376
  E0127 21:29:19.866269      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:20.866580      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:21.867450      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:22.868011      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:23.868850      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:24.869525      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:25.870485      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:26.871532      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:27.872501      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:28.872917      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:29.873737      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:30.873958      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:31.874117      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:32.875022      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:33.875614      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:34.875995      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:35.876853      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:36.876907      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:37.877136      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:38.878081      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:39.878245      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:40.878735      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:41.879014      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:42.879094      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:43.879899      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:44.880206      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:45.880832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:46.881416      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:47.882050      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:48.882714      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:49.883278      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:50.883575      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:51.884934      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:52.885041      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:53.885947      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:54.886130      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:55.887218      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:56.888033      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:57.888075      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:58.888793      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:29:59.889060      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:00.889541      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:01.891074      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:02.891702      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:03.891894      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:04.893371      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:05.894355      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:06.895021      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:07.895919      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:08.896109      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:09.896857      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:10.897971      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:11.898526      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:12.899136      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:13.900062      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:14.900561      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:15.901304      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:16.901609      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:17.901800      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:18.902213      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:30:19.467496 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8865" for this suite. @ 01/27/26 21:30:19.469
• [60.298 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should create a serviceAccountToken and ensure a successful TokenReview [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:882
  STEP: Creating a kubernetes client @ 01/27/26 21:30:19.483
  I0127 21:30:19.483561 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename svcaccounts @ 01/27/26 21:30:19.484
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:30:19.499
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:30:19.504
  STEP: Creating a Serviceaccount "e2e-sa-hb5tw" in namespace "svcaccounts-1768" @ 01/27/26 21:30:19.507
  STEP: Creating a ServiceaccountToken "e2e-sa-hb5tw" in namespace "svcaccounts-1768" @ 01/27/26 21:30:19.514
  STEP: Creating a TokenReview for "e2e-sa-hb5tw" in namespace "svcaccounts-1768" @ 01/27/26 21:30:19.518
  I0127 21:30:19.520744 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-1768" for this suite. @ 01/27/26 21:30:19.57
• [0.101 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:488
  STEP: Creating a kubernetes client @ 01/27/26 21:30:19.584
  I0127 21:30:19.584816 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename gc @ 01/27/26 21:30:19.585
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:30:19.601
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:30:19.604
  STEP: create the deployment @ 01/27/26 21:30:19.605
  I0127 21:30:19.620655      26 warnings.go:107] "Warning: metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]"
  STEP: Wait for the Deployment to create new ReplicaSet @ 01/27/26 21:30:19.62
  E0127 21:30:19.903032      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 01/27/26 21:30:20.124
  STEP: wait for all rs to be garbage collected @ 01/27/26 21:30:20.133
  STEP: expected 0 pods, got 2 pods @ 01/27/26 21:30:20.149
  STEP: Gathering metrics @ 01/27/26 21:30:20.644
  W0127 21:30:20.647008      26 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I0127 21:30:20.647039 26 garbage_collector.go:273] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0127 21:30:20.647236 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5992" for this suite. @ 01/27/26 21:30:20.649
• [1.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 01/27/26 21:30:20.658
  I0127 21:30:20.658340 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename var-expansion @ 01/27/26 21:30:20.658
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:30:20.682
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:30:20.685
  STEP: creating the pod @ 01/27/26 21:30:20.688
  STEP: waiting for pod running @ 01/27/26 21:30:20.697
  E0127 21:30:20.903631      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:21.903755      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 01/27/26 21:30:22.702
  I0127 21:30:22.705277 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-5018 PodName:var-expansion-b2ea04da-593f-4602-91c5-8d3ed66711d5 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:30:22.705318 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:30:22.705371 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/var-expansion-5018/pods/var-expansion-b2ea04da-593f-4602-91c5-8d3ed66711d5/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 01/27/26 21:30:22.753
  I0127 21:30:22.754989 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-5018 PodName:var-expansion-b2ea04da-593f-4602-91c5-8d3ed66711d5 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:30:22.755019 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:30:22.755056 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/var-expansion-5018/pods/var-expansion-b2ea04da-593f-4602-91c5-8d3ed66711d5/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 01/27/26 21:30:22.796
  E0127 21:30:22.904158      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:30:23.320346 26 pod_client.go:187] Successfully updated pod "var-expansion-b2ea04da-593f-4602-91c5-8d3ed66711d5"
  STEP: waiting for annotated pod running @ 01/27/26 21:30:23.32
  STEP: deleting the pod gracefully @ 01/27/26 21:30:23.322
  I0127 21:30:23.322464 26 delete.go:78] Deleting pod "var-expansion-b2ea04da-593f-4602-91c5-8d3ed66711d5" in namespace "var-expansion-5018"
  I0127 21:30:23.335432 26 delete.go:86] Wait up to 5m0s for pod "var-expansion-b2ea04da-593f-4602-91c5-8d3ed66711d5" to be fully deleted
  E0127 21:30:23.904320      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:24.905547      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:25.905091      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:26.905307      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:27.906121      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:28.907122      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:29.907349      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:30.907491      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:31.908334      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:32.908817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:33.909554      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:34.909782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:35.910781      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:36.911283      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:37.911545      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:38.911704      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:39.911908      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:40.912826      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:41.912961      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:42.913179      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:43.913548      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:44.914031      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:45.914625      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:46.915749      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:47.915864      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:48.916824      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:49.917427      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:50.917562      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:51.918556      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:52.918969      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:53.919852      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:54.920858      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:55.921406      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:56.921648      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:30:57.400333 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5018" for this suite. @ 01/27/26 21:30:57.402
• [36.753 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:140
  STEP: Creating a kubernetes client @ 01/27/26 21:30:57.41
  I0127 21:30:57.410967 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename crd-webhook @ 01/27/26 21:30:57.411
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:30:57.432
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:30:57.435
  STEP: Setting up server cert @ 01/27/26 21:30:57.437
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 01/27/26 21:30:57.607
  STEP: Deploying the custom resource conversion webhook pod @ 01/27/26 21:30:57.616
  STEP: Wait for the deployment to be ready @ 01/27/26 21:30:57.645
  I0127 21:30:57.658446 26 deployment.go:223] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0127 21:30:57.921706      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:30:58.921983      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/27/26 21:30:59.665
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 21:30:59.686
  I0127 21:30:59.687008 26 wait.go:65] Waiting for amount of service crd-webhook-4210/e2e-test-crd-conversion-webhook endpoints to be 1
  I0127 21:30:59.689914 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  E0127 21:30:59.922358      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:31:00.689499 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  E0127 21:31:00.922613      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:01.923528      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:02.923720      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 01/27/26 21:31:03.25
  STEP: v2 custom resource should be converted @ 01/27/26 21:31:03.258
  I0127 21:31:03.861567 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-4210" for this suite. @ 01/27/26 21:31:03.864
• [6.477 seconds]
------------------------------
SSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:274
  STEP: Creating a kubernetes client @ 01/27/26 21:31:03.887
  I0127 21:31:03.887765 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename endpointslice @ 01/27/26 21:31:03.888
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:31:03.905
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:31:03.91
  STEP: getting /apis @ 01/27/26 21:31:03.913
  STEP: getting /apis/discovery.k8s.io @ 01/27/26 21:31:03.915
  STEP: getting /apis/discovery.k8s.iov1 @ 01/27/26 21:31:03.916
  STEP: creating @ 01/27/26 21:31:03.917
  E0127 21:31:03.924799      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: getting @ 01/27/26 21:31:03.954
  STEP: listing @ 01/27/26 21:31:03.955
  STEP: watching @ 01/27/26 21:31:03.957
  I0127 21:31:03.957785 26 endpointslice.go:366] starting watch
  STEP: cluster-wide listing @ 01/27/26 21:31:03.958
  STEP: cluster-wide watching @ 01/27/26 21:31:03.96
  I0127 21:31:03.960316 26 endpointslice.go:378] starting watch
  STEP: patching @ 01/27/26 21:31:03.961
  STEP: updating @ 01/27/26 21:31:03.969
  I0127 21:31:03.979669 26 endpointslice.go:402] waiting for watch events with expected annotations
  I0127 21:31:03.979713 26 endpointslice.go:415] saw patched and updated annotations
  STEP: deleting @ 01/27/26 21:31:03.979
  STEP: deleting a collection @ 01/27/26 21:31:03.99
  I0127 21:31:04.015161 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-6534" for this suite. @ 01/27/26 21:31:04.017
• [0.137 seconds]
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:878
  STEP: Creating a kubernetes client @ 01/27/26 21:31:04.025
  I0127 21:31:04.025165 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename statefulset @ 01/27/26 21:31:04.025
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:31:04.041
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:31:04.046
  STEP: Creating service test in namespace statefulset-4261 @ 01/27/26 21:31:04.05
  STEP: Looking for a node to schedule stateful set and pod @ 01/27/26 21:31:04.065
  STEP: Creating pod with conflicting port in namespace statefulset-4261 @ 01/27/26 21:31:04.118
  STEP: Waiting until pod test-pod will start running in namespace statefulset-4261 @ 01/27/26 21:31:04.128
  E0127 21:31:04.925886      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:05.926063      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-4261 @ 01/27/26 21:31:06.133
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4261 @ 01/27/26 21:31:06.141
  I0127 21:31:06.169578 26 statefulset.go:951] Observed stateful pod in namespace: statefulset-4261, name: ss-0, uid: fabf36c8-5d45-4cd3-8e70-50b0e1db9626, status phase: Pending. Waiting for statefulset controller to delete.
  I0127 21:31:06.187173 26 statefulset.go:951] Observed stateful pod in namespace: statefulset-4261, name: ss-0, uid: fabf36c8-5d45-4cd3-8e70-50b0e1db9626, status phase: Failed. Waiting for statefulset controller to delete.
  I0127 21:31:06.201987 26 statefulset.go:951] Observed stateful pod in namespace: statefulset-4261, name: ss-0, uid: fabf36c8-5d45-4cd3-8e70-50b0e1db9626, status phase: Failed. Waiting for statefulset controller to delete.
  I0127 21:31:06.213451 26 statefulset.go:945] Observed delete event for stateful pod ss-0 in namespace statefulset-4261
  STEP: Removing pod with conflicting port in namespace statefulset-4261 @ 01/27/26 21:31:06.213
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4261 and will be in running state @ 01/27/26 21:31:06.277
  E0127 21:31:06.926710      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:07.926918      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:31:08.282647 26 statefulset.go:137] Deleting all statefulset in ns statefulset-4261
  I0127 21:31:08.284889 26 rest.go:153] Scaling statefulset ss to 0
  E0127 21:31:08.927039      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:09.927993      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:10.928839      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:11.929296      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:12.929188      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:13.929552      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:14.929748      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:15.930267      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:16.931376      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:17.931561      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:31:18.298620 26 wait.go:160] Waiting for statefulset status.replicas updated to 0
  I0127 21:31:18.300152 26 rest.go:91] Deleting statefulset ss
  I0127 21:31:18.311879 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4261" for this suite. @ 01/27/26 21:31:18.329
• [14.312 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:146
  STEP: Creating a kubernetes client @ 01/27/26 21:31:18.337
  I0127 21:31:18.337397 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename replicaset @ 01/27/26 21:31:18.337
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:31:18.358
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:31:18.363
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 01/27/26 21:31:18.365
  I0127 21:31:18.389192 26 resource.go:64] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 01/27/26 21:31:18.389
  E0127 21:31:18.932374      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:19.933103      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 01/27/26 21:31:20.393
  STEP: updating a scale subresource @ 01/27/26 21:31:20.396
  STEP: verifying the replicaset Spec.Replicas was modified @ 01/27/26 21:31:20.409
  STEP: Patch a scale subresource @ 01/27/26 21:31:20.411
  I0127 21:31:20.434611 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3721" for this suite. @ 01/27/26 21:31:20.436
• [2.121 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 01/27/26 21:31:20.458
  I0127 21:31:20.458682 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename var-expansion @ 01/27/26 21:31:20.459
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:31:20.483
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:31:20.578
  STEP: Creating a pod to test substitution in volume subpath @ 01/27/26 21:31:20.581
  E0127 21:31:20.934040      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:21.934254      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:22.934819      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:23.934855      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:31:24.6
  I0127 21:31:24.602443 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod var-expansion-1cb91ae4-d955-4a0e-9bbe-fa7783c218f6 container dapi-container: <nil>
  STEP: delete the pod @ 01/27/26 21:31:24.612
  I0127 21:31:24.643744 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9876" for this suite. @ 01/27/26 21:31:24.646
• [4.205 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:131
  STEP: Creating a kubernetes client @ 01/27/26 21:31:24.663
  I0127 21:31:24.663904 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 21:31:24.664
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:31:24.691
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:31:24.692
  STEP: Creating the pod @ 01/27/26 21:31:24.695
  E0127 21:31:24.935105      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:25.935858      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:26.936744      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:31:27.238869 26 pod_client.go:187] Successfully updated pod "labelsupdate7a5e60fd-f05b-4012-be38-42d69fc3c578"
  E0127 21:31:27.937342      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:28.938163      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:31:29.261866 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1632" for this suite. @ 01/27/26 21:31:29.264
• [4.609 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:109
  STEP: Creating a kubernetes client @ 01/27/26 21:31:29.272
  I0127 21:31:29.272655 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename emptydir @ 01/27/26 21:31:29.273
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:31:29.291
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:31:29.302
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 01/27/26 21:31:29.303
  E0127 21:31:29.938284      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:30.939202      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:31.939422      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:32.939628      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:31:33.32
  I0127 21:31:33.321970 26 output.go:207] Trying to get logs from node k3k-k3kcluster-server-0 pod pod-55d1dc70-13ff-4155-828b-bce73fdfd116 container test-container: <nil>
  STEP: delete the pod @ 01/27/26 21:31:33.331
  I0127 21:31:33.373584 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1347" for this suite. @ 01/27/26 21:31:33.376
• [4.111 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:218
  STEP: Creating a kubernetes client @ 01/27/26 21:31:33.383
  I0127 21:31:33.383728 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename sched-preemption @ 01/27/26 21:31:33.384
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:31:33.4
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:31:33.405
  I0127 21:31:33.436335 26 wait.go:53] Waiting up to 1m0s for all nodes to be ready
  E0127 21:31:33.939770      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:34.940837      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:35.940908      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:36.941124      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:37.942223      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:38.942427      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:39.943234      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:40.943692      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:41.944592      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:42.944830      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:43.945242      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:44.945787      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:45.946206      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:46.947065      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:47.947399      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:48.948510      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:49.949409      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:50.949569      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:51.949836      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:52.950060      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:53.950873      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:54.950945      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:55.951476      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:56.951739      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:57.952588      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:58.952792      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:31:59.953508      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:00.953659      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:01.954052      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:02.954263      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:03.954364      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:04.954598      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:05.955181      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:06.955351      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:07.956432      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:08.956889      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:09.957202      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:10.957394      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:11.957610      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:12.958492      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:13.959299      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:14.959505      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:15.960249      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:16.960802      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:17.960963      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:18.961192      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:19.961451      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:20.961803      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:21.963216      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:22.963407      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:23.964106      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:24.964877      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:25.966033      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:26.967142      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:27.967273      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:28.967358      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:29.967475      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:30.967763      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:31.968822      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:32.969810      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:32:33.439772 26 util.go:389] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 01/27/26 21:32:33.442
  STEP: Adding a custom resource @ 01/27/26 21:32:33.442
  I0127 21:32:33.474208 26 preemption.go:259] Created pod: pod0-0-sched-preemption-low-priority
  I0127 21:32:33.487279 26 preemption.go:259] Created pod: pod0-1-sched-preemption-medium-priority
  STEP: Adding a custom resource @ 01/27/26 21:32:33.487
  I0127 21:32:33.519609 26 preemption.go:259] Created pod: pod1-0-sched-preemption-medium-priority
  I0127 21:32:33.535406 26 preemption.go:259] Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 01/27/26 21:32:33.535
  E0127 21:32:33.970719      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:34.971397      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:35.971637      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:36.971742      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 01/27/26 21:32:37.55
  E0127 21:32:37.971782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:38.972823      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:39.972967      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:40.974247      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Removing a custom resource @ 01/27/26 21:32:41.639
  STEP: Removing a custom resource @ 01/27/26 21:32:41.657
  I0127 21:32:41.674412 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-7074" for this suite. @ 01/27/26 21:32:41.677
• [68.303 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:163
  STEP: Creating a kubernetes client @ 01/27/26 21:32:41.686
  I0127 21:32:41.686879 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 21:32:41.687
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:32:41.719
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:32:41.722
  STEP: Creating the pod @ 01/27/26 21:32:41.725
  E0127 21:32:41.975678      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:42.976303      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:43.976504      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:32:44.276276 26 pod_client.go:187] Successfully updated pod "annotationupdate5759d57d-d6f9-4f1f-bff8-ca78ece73dec"
  E0127 21:32:44.977372      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:45.978643      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:32:46.289965 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4013" for this suite. @ 01/27/26 21:32:46.292
• [4.621 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:115
  STEP: Creating a kubernetes client @ 01/27/26 21:32:46.308
  I0127 21:32:46.308297 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename field-validation @ 01/27/26 21:32:46.309
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:32:46.33
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:32:46.332
  STEP: apply creating a deployment @ 01/27/26 21:32:46.334
  I0127 21:32:46.341925 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5875" for this suite. @ 01/27/26 21:32:46.393
• [0.095 seconds]
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:423
  STEP: Creating a kubernetes client @ 01/27/26 21:32:46.403
  I0127 21:32:46.403525 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename configmap @ 01/27/26 21:32:46.404
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:32:46.432
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:32:46.434
  STEP: Creating configMap with name configmap-test-volume-4a4395ad-f200-41a5-92e5-c137ab876403 @ 01/27/26 21:32:46.436
  STEP: Creating a pod to test consume configMaps @ 01/27/26 21:32:46.443
  E0127 21:32:46.979687      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:47.979729      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:48.980823      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:49.981040      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:32:50.478
  I0127 21:32:50.479755 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-configmaps-d41bdd80-0987-4517-9e3b-ca7b87ab907b container configmap-volume-test: <nil>
  STEP: delete the pod @ 01/27/26 21:32:50.483
  I0127 21:32:50.512956 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3924" for this suite. @ 01/27/26 21:32:50.515
• [4.121 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:561
  STEP: Creating a kubernetes client @ 01/27/26 21:32:50.524
  I0127 21:32:50.524398 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename svcaccounts @ 01/27/26 21:32:50.524
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:32:50.54
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:32:50.551
  I0127 21:32:50.569891 26 service_accounts.go:648] created pod
  E0127 21:32:50.982056      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:51.982251      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:52.982952      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:53.983999      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:32:54.577
  E0127 21:32:54.984807      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:55.985052      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:56.985315      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:57.985507      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:58.985796      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:32:59.985990      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:00.986214      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:01.986437      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:02.986654      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:03.987361      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:04.988099      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:05.988359      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:06.988594      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:07.988712      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:08.989632      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:09.990167      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:10.991461      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:11.991974      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:12.991837      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:13.991998      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:14.992120      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:15.992812      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:16.993377      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:17.993594      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:18.993826      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:19.993933      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:20.994244      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:21.994440      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:22.995376      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:23.996458      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:33:24.577432 26 service_accounts.go:654] polling logs
  I0127 21:33:24.586541 26 service_accounts.go:664] Pod logs: 
  I0127 21:32:51.380067       1 log.go:244] OK: Got token
  I0127 21:32:51.380119       1 log.go:244] validating with in-cluster discovery
  I0127 21:32:51.380343       1 log.go:244] OK: got issuer https://kubernetes.default.svc.cluster.local
  I0127 21:32:51.380367       1 log.go:244] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-4507:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0002c4e08), NotBefore:(*jwt.NumericDate)(0xc0002c4ed0), IssuedAt:(*jwt.NumericDate)(0xc0002c4e18), ID:"eaed0e39-e304-4c78-a710-74d0baa87876"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4507", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"44f6b3f1-5287-466c-a4ab-4ab0208a9933"}}}
  I0127 21:32:51.390282       1 log.go:244] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
  I0127 21:32:51.395427       1 log.go:244] OK: Validated signature on JWT
  I0127 21:32:51.395489       1 log.go:244] OK: Got valid claims from token!
  I0127 21:32:51.395506       1 log.go:244] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-4507:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0002504d8), NotBefore:(*jwt.NumericDate)(0xc000250500), IssuedAt:(*jwt.NumericDate)(0xc0002504e0), ID:"eaed0e39-e304-4c78-a710-74d0baa87876"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4507", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"44f6b3f1-5287-466c-a4ab-4ab0208a9933"}}}

  I0127 21:33:24.586597 26 service_accounts.go:668] completed pod
  I0127 21:33:24.595178 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-4507" for this suite. @ 01/27/26 21:33:24.598
• [34.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:152
  STEP: Creating a kubernetes client @ 01/27/26 21:33:24.617
  I0127 21:33:24.617580 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename dns @ 01/27/26 21:33:24.618
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:33:24.639
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:33:24.644
  STEP: Creating a test headless service @ 01/27/26 21:33:24.646
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2620.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service.dns-2620.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2620.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service.dns-2620.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2620.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/agnhost_udp@_http._tcp.dns-test-service.dns-2620.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2620.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/agnhost_tcp@_http._tcp.dns-test-service.dns-2620.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2620.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/agnhost_udp@_http._tcp.test-service-2.dns-2620.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2620.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/agnhost_tcp@_http._tcp.test-service-2.dns-2620.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 229.12.53.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.53.12.229_udp@PTR;check="$$(dig +tcp +noall +answer +search 229.12.53.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.53.12.229_tcp@PTR;sleep 1; done
   @ 01/27/26 21:33:24.679
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2620.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2620.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2620.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2620.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2620.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2620.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2620.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2620.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2620.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2620.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2620.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2620.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 229.12.53.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.53.12.229_udp@PTR;check="$$(dig +tcp +noall +answer +search 229.12.53.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.53.12.229_tcp@PTR;sleep 1; done
   @ 01/27/26 21:33:24.679
  STEP: creating a pod to probe DNS @ 01/27/26 21:33:24.679
  STEP: submitting the pod to kubernetes @ 01/27/26 21:33:24.679
  E0127 21:33:24.997229      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:25.997778      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 01/27/26 21:33:26.709
  STEP: looking for the results for each expected name from probers @ 01/27/26 21:33:26.711
  I0127 21:33:26.715730 26 dns_common.go:495] Unable to read agnhost_udp@dns-test-service.dns-2620.svc.cluster.local from pod dns-2620/dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe: the server could not find the requested resource (get pods dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe)
  I0127 21:33:26.717496 26 dns_common.go:495] Unable to read agnhost_tcp@dns-test-service.dns-2620.svc.cluster.local from pod dns-2620/dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe: the server could not find the requested resource (get pods dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe)
  I0127 21:33:26.719197 26 dns_common.go:495] Unable to read agnhost_udp@_http._tcp.dns-test-service.dns-2620.svc.cluster.local from pod dns-2620/dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe: the server could not find the requested resource (get pods dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe)
  I0127 21:33:26.720683 26 dns_common.go:495] Unable to read agnhost_tcp@_http._tcp.dns-test-service.dns-2620.svc.cluster.local from pod dns-2620/dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe: the server could not find the requested resource (get pods dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe)
  I0127 21:33:26.728622 26 dns_common.go:495] Unable to read jessie_udp@dns-test-service.dns-2620.svc.cluster.local from pod dns-2620/dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe: the server could not find the requested resource (get pods dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe)
  I0127 21:33:26.730854 26 dns_common.go:495] Unable to read jessie_tcp@dns-test-service.dns-2620.svc.cluster.local from pod dns-2620/dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe: the server could not find the requested resource (get pods dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe)
  I0127 21:33:26.734692 26 dns_common.go:495] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2620.svc.cluster.local from pod dns-2620/dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe: the server could not find the requested resource (get pods dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe)
  I0127 21:33:26.736586 26 dns_common.go:495] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2620.svc.cluster.local from pod dns-2620/dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe: the server could not find the requested resource (get pods dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe)
  I0127 21:33:26.742640 26 dns_common.go:506] Lookups using dns-2620/dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe failed for: [agnhost_udp@dns-test-service.dns-2620.svc.cluster.local agnhost_tcp@dns-test-service.dns-2620.svc.cluster.local agnhost_udp@_http._tcp.dns-test-service.dns-2620.svc.cluster.local agnhost_tcp@_http._tcp.dns-test-service.dns-2620.svc.cluster.local jessie_udp@dns-test-service.dns-2620.svc.cluster.local jessie_tcp@dns-test-service.dns-2620.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2620.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2620.svc.cluster.local]

  I0127 21:33:26.745581 26 dns_common.go:514] Pod client logs for webserver: 
  I0127 21:33:26.749834 26 dns_common.go:514] Pod client logs for agnhost-querier: 
  I0127 21:33:26.753726 26 dns_common.go:514] Pod client logs for jessie-querier: 
  E0127 21:33:26.998205      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:27.998454      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:28.998889      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:29.999208      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:30.999423      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:33:31.715162 26 dns_common.go:495] Unable to read agnhost_udp@dns-test-service.dns-2620.svc.cluster.local from pod dns-2620/dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe: the server could not find the requested resource (get pods dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe)
  I0127 21:33:31.716907 26 dns_common.go:495] Unable to read agnhost_tcp@dns-test-service.dns-2620.svc.cluster.local from pod dns-2620/dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe: the server could not find the requested resource (get pods dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe)
  I0127 21:33:31.718410 26 dns_common.go:495] Unable to read agnhost_udp@_http._tcp.dns-test-service.dns-2620.svc.cluster.local from pod dns-2620/dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe: the server could not find the requested resource (get pods dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe)
  I0127 21:33:31.721129 26 dns_common.go:495] Unable to read agnhost_tcp@_http._tcp.dns-test-service.dns-2620.svc.cluster.local from pod dns-2620/dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe: the server could not find the requested resource (get pods dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe)
  I0127 21:33:31.759756 26 dns_common.go:506] Lookups using dns-2620/dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe failed for: [agnhost_udp@dns-test-service.dns-2620.svc.cluster.local agnhost_tcp@dns-test-service.dns-2620.svc.cluster.local agnhost_udp@_http._tcp.dns-test-service.dns-2620.svc.cluster.local agnhost_tcp@_http._tcp.dns-test-service.dns-2620.svc.cluster.local]

  I0127 21:33:31.763514 26 dns_common.go:514] Pod client logs for webserver: 
  I0127 21:33:31.767792 26 dns_common.go:514] Pod client logs for agnhost-querier: 
  I0127 21:33:31.784691 26 dns_common.go:514] Pod client logs for jessie-querier: 
  E0127 21:33:32.000636      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:33.000783      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:34.000890      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:35.001145      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:36.001370      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:33:36.753257 26 dns_common.go:546] DNS probes using dns-2620/dns-test-1c13d5cc-7086-4a95-856e-a563bbd968fe succeeded

  STEP: deleting the pod @ 01/27/26 21:33:36.753
  STEP: deleting the test service @ 01/27/26 21:33:36.791
  STEP: deleting the test headless service @ 01/27/26 21:33:36.863
  I0127 21:33:36.878330 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2620" for this suite. @ 01/27/26 21:33:36.881
• [12.275 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:176
  STEP: Creating a kubernetes client @ 01/27/26 21:33:36.892
  I0127 21:33:36.892894 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename configmap @ 01/27/26 21:33:36.893
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:33:36.919
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:33:36.921
  STEP: creating a ConfigMap @ 01/27/26 21:33:36.924
  STEP: fetching the ConfigMap @ 01/27/26 21:33:36.932
  STEP: patching the ConfigMap @ 01/27/26 21:33:36.934
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 01/27/26 21:33:36.942
  STEP: deleting the ConfigMap by collection with a label selector @ 01/27/26 21:33:36.944
  STEP: listing all ConfigMaps in test namespace @ 01/27/26 21:33:36.958
  I0127 21:33:36.960920 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2780" for this suite. @ 01/27/26 21:33:36.98
• [0.097 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 01/27/26 21:33:36.989
  I0127 21:33:36.989949 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename chunking @ 01/27/26 21:33:36.99
  E0127 21:33:37.001836      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:33:37.022
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:33:37.024
  STEP: creating a large number of resources @ 01/27/26 21:33:37.027
  E0127 21:33:38.002699      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:39.003173      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:40.003641      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:41.003933      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:42.004605      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:43.004677      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:44.005447      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:45.006292      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:46.006749      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:47.007371      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:48.008344      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:49.008904      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:50.009240      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:51.010243      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:52.010664      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:53.010996      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:33:54.011020      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving those results in paged fashion several times @ 01/27/26 21:33:54.549
  I0127 21:33:54.594048 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMTZcdTAwMDAifQ
  I0127 21:33:54.642777 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzNcdTAwMDAifQ
  I0127 21:33:54.692784 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwNTBcdTAwMDAifQ
  I0127 21:33:54.742689 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwNjdcdTAwMDAifQ
  I0127 21:33:54.793180 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwODRcdTAwMDAifQ
  I0127 21:33:54.844982 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAxMDFcdTAwMDAifQ
  I0127 21:33:54.892938 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAxMThcdTAwMDAifQ
  I0127 21:33:54.942973 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAxMzVcdTAwMDAifQ
  I0127 21:33:54.993310 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAxNTJcdTAwMDAifQ
  E0127 21:33:55.011077      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:33:55.042836 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAxNjlcdTAwMDAifQ
  I0127 21:33:55.092724 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAxODZcdTAwMDAifQ
  I0127 21:33:55.142980 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAyMDNcdTAwMDAifQ
  I0127 21:33:55.193006 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAyMjBcdTAwMDAifQ
  I0127 21:33:55.243565 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAyMzdcdTAwMDAifQ
  I0127 21:33:55.292920 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAyNTRcdTAwMDAifQ
  I0127 21:33:55.343717 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAyNzFcdTAwMDAifQ
  I0127 21:33:55.392686 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAyODhcdTAwMDAifQ
  I0127 21:33:55.443040 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAzMDVcdTAwMDAifQ
  I0127 21:33:55.493953 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAzMjJcdTAwMDAifQ
  I0127 21:33:55.542765 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAzMzlcdTAwMDAifQ
  I0127 21:33:55.593349 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAzNTZcdTAwMDAifQ
  I0127 21:33:55.643870 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAzNzNcdTAwMDAifQ
  I0127 21:33:55.692676 26 chunking.go:98] Retrieved 17/17 results with rv 40476 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzYsInN0YXJ0IjoiL3RlbXBsYXRlLTAzOTBcdTAwMDAifQ
  I0127 21:33:55.743203 26 chunking.go:98] Retrieved 9/17 results with rv 40476 and continue 
  I0127 21:33:55.794250 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAwMTZcdTAwMDAifQ
  I0127 21:33:55.843099 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzNcdTAwMDAifQ
  I0127 21:33:55.893774 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAwNTBcdTAwMDAifQ
  I0127 21:33:55.943157 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAwNjdcdTAwMDAifQ
  I0127 21:33:55.993732 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAwODRcdTAwMDAifQ
  E0127 21:33:56.012030      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:33:56.042961 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAxMDFcdTAwMDAifQ
  I0127 21:33:56.093212 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAxMThcdTAwMDAifQ
  I0127 21:33:56.143133 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAxMzVcdTAwMDAifQ
  I0127 21:33:56.192998 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAxNTJcdTAwMDAifQ
  I0127 21:33:56.243780 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAxNjlcdTAwMDAifQ
  I0127 21:33:56.292813 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAxODZcdTAwMDAifQ
  I0127 21:33:56.343011 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAyMDNcdTAwMDAifQ
  I0127 21:33:56.393782 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAyMjBcdTAwMDAifQ
  I0127 21:33:56.442609 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAyMzdcdTAwMDAifQ
  I0127 21:33:56.492843 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAyNTRcdTAwMDAifQ
  I0127 21:33:56.542731 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAyNzFcdTAwMDAifQ
  I0127 21:33:56.592691 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAyODhcdTAwMDAifQ
  I0127 21:33:56.643205 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAzMDVcdTAwMDAifQ
  I0127 21:33:56.693324 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAzMjJcdTAwMDAifQ
  I0127 21:33:56.744592 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAzMzlcdTAwMDAifQ
  I0127 21:33:56.792856 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAzNTZcdTAwMDAifQ
  I0127 21:33:56.843282 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAzNzNcdTAwMDAifQ
  I0127 21:33:56.893333 26 chunking.go:98] Retrieved 17/17 results with rv 40479 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0NzksInN0YXJ0IjoiL3RlbXBsYXRlLTAzOTBcdTAwMDAifQ
  I0127 21:33:56.943584 26 chunking.go:98] Retrieved 9/17 results with rv 40479 and continue 
  I0127 21:33:56.994719 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMTZcdTAwMDAifQ
  E0127 21:33:57.012813      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:33:57.042862 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzNcdTAwMDAifQ
  I0127 21:33:57.092863 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAwNTBcdTAwMDAifQ
  I0127 21:33:57.143393 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAwNjdcdTAwMDAifQ
  I0127 21:33:57.193521 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAwODRcdTAwMDAifQ
  I0127 21:33:57.242717 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAxMDFcdTAwMDAifQ
  I0127 21:33:57.293443 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAxMThcdTAwMDAifQ
  I0127 21:33:57.342493 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAxMzVcdTAwMDAifQ
  I0127 21:33:57.392510 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAxNTJcdTAwMDAifQ
  I0127 21:33:57.442587 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAxNjlcdTAwMDAifQ
  I0127 21:33:57.492816 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAxODZcdTAwMDAifQ
  I0127 21:33:57.542319 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAyMDNcdTAwMDAifQ
  I0127 21:33:57.593625 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAyMjBcdTAwMDAifQ
  I0127 21:33:57.642610 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAyMzdcdTAwMDAifQ
  I0127 21:33:57.693503 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAyNTRcdTAwMDAifQ
  I0127 21:33:57.742270 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAyNzFcdTAwMDAifQ
  I0127 21:33:57.793631 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAyODhcdTAwMDAifQ
  I0127 21:33:57.843039 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAzMDVcdTAwMDAifQ
  I0127 21:33:57.892490 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAzMjJcdTAwMDAifQ
  I0127 21:33:57.942680 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAzMzlcdTAwMDAifQ
  I0127 21:33:57.992594 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAzNTZcdTAwMDAifQ
  E0127 21:33:58.013759      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:33:58.042715 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAzNzNcdTAwMDAifQ
  I0127 21:33:58.092657 26 chunking.go:98] Retrieved 17/17 results with rv 40483 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDA0ODMsInN0YXJ0IjoiL3RlbXBsYXRlLTAzOTBcdTAwMDAifQ
  I0127 21:33:58.142680 26 chunking.go:98] Retrieved 9/17 results with rv 40483 and continue 
  STEP: retrieving those results all at once @ 01/27/26 21:33:58.143
  I0127 21:33:58.198475 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-9636" for this suite. @ 01/27/26 21:33:58.243
• [21.310 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:236
  STEP: Creating a kubernetes client @ 01/27/26 21:33:58.3
  I0127 21:33:58.300225 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 21:33:58.3
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:33:58.326
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:33:58.329
  STEP: Creating a pod to test downward API volume plugin @ 01/27/26 21:33:58.332
  E0127 21:33:59.014617      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:00.014737      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:01.015643      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:02.016495      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:34:02.35
  I0127 21:34:02.352293 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downwardapi-volume-20d679ef-ae49-420e-bb53-98b0ec29688b container client-container: <nil>
  STEP: delete the pod @ 01/27/26 21:34:02.356
  I0127 21:34:02.385742 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3889" for this suite. @ 01/27/26 21:34:02.388
• [4.102 seconds]
------------------------------
S
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:492
  STEP: Creating a kubernetes client @ 01/27/26 21:34:02.402
  I0127 21:34:02.402377 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename deployment @ 01/27/26 21:34:02.402
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:34:02.422
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:34:02.423
  STEP: creating a Deployment @ 01/27/26 21:34:02.427
  I0127 21:34:02.427893 26 deployment.go:510] Creating simple deployment test-deployment-9cwwk
  I0127 21:34:02.463533 26 deployment.go:223] deployment "test-deployment-9cwwk" doesn't have the required revision set
  E0127 21:34:03.016855      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:04.017081      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Getting /status @ 01/27/26 21:34:04.495
  I0127 21:34:04.502114 26 deployment.go:535] Deployment test-deployment-9cwwk has Conditions: [{Available True 2026-01-27 21:34:03 +0000 UTC 2026-01-27 21:34:03 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2026-01-27 21:34:03 +0000 UTC 2026-01-27 21:34:02 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9cwwk-77765fd584" has successfully progressed.}]
  STEP: updating Deployment Status @ 01/27/26 21:34:04.502
  I0127 21:34:04.535998 26 deployment.go:555] updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 34, 3, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 34, 3, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 34, 3, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 34, 2, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-9cwwk-77765fd584\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 01/27/26 21:34:04.536
  I0127 21:34:04.537687 26 deployment.go:582] Observed &Deployment event: ADDED
  I0127 21:34:04.537725 26 deployment.go:578] Observed Deployment test-deployment-9cwwk in namespace deployment-7033 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2026-01-27 21:34:02 +0000 UTC 2026-01-27 21:34:02 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9cwwk-77765fd584"}
  I0127 21:34:04.537785 26 deployment.go:582] Observed &Deployment event: MODIFIED
  I0127 21:34:04.537812 26 deployment.go:578] Observed Deployment test-deployment-9cwwk in namespace deployment-7033 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2026-01-27 21:34:02 +0000 UTC 2026-01-27 21:34:02 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9cwwk-77765fd584"}
  I0127 21:34:04.537821 26 deployment.go:578] Observed Deployment test-deployment-9cwwk in namespace deployment-7033 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2026-01-27 21:34:02 +0000 UTC 2026-01-27 21:34:02 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0127 21:34:04.537900 26 deployment.go:582] Observed &Deployment event: MODIFIED
  I0127 21:34:04.537967 26 deployment.go:578] Observed Deployment test-deployment-9cwwk in namespace deployment-7033 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2026-01-27 21:34:02 +0000 UTC 2026-01-27 21:34:02 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0127 21:34:04.537979 26 deployment.go:578] Observed Deployment test-deployment-9cwwk in namespace deployment-7033 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2026-01-27 21:34:02 +0000 UTC 2026-01-27 21:34:02 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-9cwwk-77765fd584" is progressing.}
  I0127 21:34:04.538055 26 deployment.go:582] Observed &Deployment event: MODIFIED
  I0127 21:34:04.538071 26 deployment.go:578] Observed Deployment test-deployment-9cwwk in namespace deployment-7033 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2026-01-27 21:34:03 +0000 UTC 2026-01-27 21:34:03 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0127 21:34:04.538079 26 deployment.go:578] Observed Deployment test-deployment-9cwwk in namespace deployment-7033 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2026-01-27 21:34:03 +0000 UTC 2026-01-27 21:34:02 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9cwwk-77765fd584" has successfully progressed.}
  I0127 21:34:04.538130 26 deployment.go:582] Observed &Deployment event: MODIFIED
  I0127 21:34:04.538143 26 deployment.go:578] Observed Deployment test-deployment-9cwwk in namespace deployment-7033 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2026-01-27 21:34:03 +0000 UTC 2026-01-27 21:34:03 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0127 21:34:04.538152 26 deployment.go:578] Observed Deployment test-deployment-9cwwk in namespace deployment-7033 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2026-01-27 21:34:03 +0000 UTC 2026-01-27 21:34:02 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9cwwk-77765fd584" has successfully progressed.}
  I0127 21:34:04.538161 26 deployment.go:575] Found Deployment test-deployment-9cwwk in namespace deployment-7033 with labels: map[e2e:testing name:agnhost] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0127 21:34:04.538171 26 deployment.go:586] Deployment test-deployment-9cwwk has an updated status
  STEP: patching the Statefulset Status @ 01/27/26 21:34:04.538
  I0127 21:34:04.538196 26 deployment.go:590] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0127 21:34:04.547673 26 deployment.go:594] Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 01/27/26 21:34:04.547
  I0127 21:34:04.550121 26 deployment.go:619] Observed &Deployment event: ADDED
  I0127 21:34:04.550160 26 deployment.go:615] Observed deployment test-deployment-9cwwk in namespace deployment-7033 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2026-01-27 21:34:02 +0000 UTC 2026-01-27 21:34:02 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9cwwk-77765fd584"}
  I0127 21:34:04.550218 26 deployment.go:619] Observed &Deployment event: MODIFIED
  I0127 21:34:04.550231 26 deployment.go:615] Observed deployment test-deployment-9cwwk in namespace deployment-7033 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2026-01-27 21:34:02 +0000 UTC 2026-01-27 21:34:02 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9cwwk-77765fd584"}
  I0127 21:34:04.550240 26 deployment.go:615] Observed deployment test-deployment-9cwwk in namespace deployment-7033 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2026-01-27 21:34:02 +0000 UTC 2026-01-27 21:34:02 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0127 21:34:04.550300 26 deployment.go:619] Observed &Deployment event: MODIFIED
  I0127 21:34:04.550433 26 deployment.go:615] Observed deployment test-deployment-9cwwk in namespace deployment-7033 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2026-01-27 21:34:02 +0000 UTC 2026-01-27 21:34:02 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0127 21:34:04.550459 26 deployment.go:615] Observed deployment test-deployment-9cwwk in namespace deployment-7033 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2026-01-27 21:34:02 +0000 UTC 2026-01-27 21:34:02 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-9cwwk-77765fd584" is progressing.}
  I0127 21:34:04.550570 26 deployment.go:619] Observed &Deployment event: MODIFIED
  I0127 21:34:04.550599 26 deployment.go:615] Observed deployment test-deployment-9cwwk in namespace deployment-7033 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2026-01-27 21:34:03 +0000 UTC 2026-01-27 21:34:03 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0127 21:34:04.550610 26 deployment.go:615] Observed deployment test-deployment-9cwwk in namespace deployment-7033 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2026-01-27 21:34:03 +0000 UTC 2026-01-27 21:34:02 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9cwwk-77765fd584" has successfully progressed.}
  I0127 21:34:04.550680 26 deployment.go:619] Observed &Deployment event: MODIFIED
  I0127 21:34:04.550698 26 deployment.go:615] Observed deployment test-deployment-9cwwk in namespace deployment-7033 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2026-01-27 21:34:03 +0000 UTC 2026-01-27 21:34:03 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0127 21:34:04.550708 26 deployment.go:615] Observed deployment test-deployment-9cwwk in namespace deployment-7033 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2026-01-27 21:34:03 +0000 UTC 2026-01-27 21:34:02 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9cwwk-77765fd584" has successfully progressed.}
  I0127 21:34:04.550719 26 deployment.go:615] Observed deployment test-deployment-9cwwk in namespace deployment-7033 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0127 21:34:04.550799 26 deployment.go:619] Observed &Deployment event: MODIFIED
  I0127 21:34:04.550883 26 deployment.go:612] Found deployment test-deployment-9cwwk in namespace deployment-7033 with labels: map[e2e:testing name:agnhost] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  I0127 21:34:04.550922 26 deployment.go:623] Deployment test-deployment-9cwwk has a patched status
  I0127 21:34:04.553764 26 deployment.go:636] Deployment "test-deployment-9cwwk":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-9cwwk",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7033",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "224c4211-e070-43c9-a07c-0c19ecc9ba1d",
      ResourceVersion: (string) (len=5) "40688",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905146442,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=7) "agnhost"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146442,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=659) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              00000170  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              00000180  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000190  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              000001a0  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              000001b0  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              000001c0  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              000001d0  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              000001e0  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              000001f0  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000200  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000210  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000220  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000230  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000240  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000250  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              00000260  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000270  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000280  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000290  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146443,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=251) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |ions":{},"f:obse|
              00000090  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              000000a0  7b 7d 2c 22 66 3a 72 65  61 64 79 52 65 70 6c 69  |{},"f:readyRepli|
              000000b0  63 61 73 22 3a 7b 7d 2c  22 66 3a 72 65 70 6c 69  |cas":{},"f:repli|
              000000c0  63 61 73 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |cas":{},"f:termi|
              000000d0  6e 61 74 69 6e 67 52 65  70 6c 69 63 61 73 22 3a  |natingReplicas":|
              000000e0  7b 7d 2c 22 66 3a 75 70  64 61 74 65 64 52 65 70  |{},"f:updatedRep|
              000000f0  6c 69 63 61 73 22 3a 7b  7d 7d 7d                 |licas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146444,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=7) "agnhost"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=7) "agnhost",
            (string) (len=3) "e2e": (string) (len=7) "testing"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(0),
      Conditions: ([]v1.DeploymentCondition) (len=1) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0127 21:34:04.574001 26 deployment.go:40] New ReplicaSet "test-deployment-9cwwk-77765fd584" of Deployment "test-deployment-9cwwk":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-9cwwk-77765fd584",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7033",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5aeaabca-ea4d-4988-b89b-1199477dba35",
      ResourceVersion: (string) (len=5) "40617",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905146442,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "77765fd584",
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=7) "agnhost"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-9cwwk",
          UID: (types.UID) (len=36) "224c4211-e070-43c9-a07c-0c19ecc9ba1d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146442,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=805) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 32 32 34  |k:{\"uid\":\"224|
              00000120  63 34 32 31 31 2d 65 30  37 30 2d 34 33 63 39 2d  |c4211-e070-43c9-|
              00000130  61 30 37 63 2d 30 63 31  39 65 63 63 39 62 61 31  |a07c-0c19ecc9ba1|
              00000140  64 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |d\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 61  |"k:{\"name\":\"a|
              00000200  67 6e 68 6f 73 74 5c 22  7d 22 3a 7b 22 2e 22 3a  |gnhost\"}":{".":|
              00000210  7b 7d 2c 22 66 3a 69 6d  61 67 65 22 3a 7b 7d 2c  |{},"f:image":{},|
              00000220  22 66 3a 69 6d 61 67 65  50 75 6c 6c 50 6f 6c 69  |"f:imagePullPoli|
              00000230  63 79 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |cy":{},"f:name":|
              00000240  7b 7d 2c 22 66 3a 72 65  73 6f 75 72 63 65 73 22  |{},"f:resources"|
              00000250  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              00000260  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000270  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000280  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000290  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              000002a0  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000002b0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000002c0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000002d0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000002e0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000002f0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              00000300  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000310  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000320  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146443,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=157) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6e 67 52  |,"f:terminatingR|
              00000090  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=7) "agnhost",
          (string) (len=17) "pod-template-hash": (string) (len=10) "77765fd584"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "77765fd584",
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=7) "agnhost"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      TerminatingReplicas: (*int32)(0),
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0127 21:34:04.577961 26 deployment.go:68] Pod "test-deployment-9cwwk-77765fd584-6rdbs" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=38) "test-deployment-9cwwk-77765fd584-6rdbs",
      GenerateName: (string) (len=33) "test-deployment-9cwwk-77765fd584-",
      Namespace: (string) (len=15) "deployment-7033",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a0b55a42-a978-47c6-bfea-9423d7108c06",
      ResourceVersion: (string) (len=5) "40615",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905146442,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77765fd584"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=32) "test-deployment-9cwwk-77765fd584",
          UID: (types.UID) (len=36) "5aeaabca-ea4d-4988-b89b-1199477dba35",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146442,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=550) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 35 61 65 61 61 62 63  61 2d 65 61 34 64 2d 34  |"5aeaabca-ea4d-4|
              000000a0  39 38 38 2d 62 38 39 62  2d 31 31 39 39 34 37 37  |988-b89b-1199477|
              000000b0  64 62 61 33 35 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |dba35\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  61 67 6e 68 6f 73 74 5c  |ame\":\"agnhost\|
              000000f0  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 69  |"}":{".":{},"f:i|
              00000100  6d 61 67 65 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |mage":{},"f:imag|
              00000110  65 50 75 6c 6c 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |ePullPolicy":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 72  |"f:name":{},"f:r|
              00000130  65 73 6f 75 72 63 65 73  22 3a 7b 7d 2c 22 66 3a  |esources":{},"f:|
              00000140  73 65 63 75 72 69 74 79  43 6f 6e 74 65 78 74 22  |securityContext"|
              00000150  3a 7b 7d 2c 22 66 3a 74  65 72 6d 69 6e 61 74 69  |:{},"f:terminati|
              00000160  6f 6e 4d 65 73 73 61 67  65 50 61 74 68 22 3a 7b  |onMessagePath":{|
              00000170  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000180  4d 65 73 73 61 67 65 50  6f 6c 69 63 79 22 3a 7b  |MessagePolicy":{|
              00000190  7d 7d 7d 2c 22 66 3a 64  6e 73 50 6f 6c 69 63 79  |}}},"f:dnsPolicy|
              000001a0  22 3a 7b 7d 2c 22 66 3a  65 6e 61 62 6c 65 53 65  |":{},"f:enableSe|
              000001b0  72 76 69 63 65 4c 69 6e  6b 73 22 3a 7b 7d 2c 22  |rviceLinks":{},"|
              000001c0  66 3a 72 65 73 74 61 72  74 50 6f 6c 69 63 79 22  |f:restartPolicy"|
              000001d0  3a 7b 7d 2c 22 66 3a 73  63 68 65 64 75 6c 65 72  |:{},"f:scheduler|
              000001e0  4e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |Name":{},"f:secu|
              000001f0  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000200  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 47 72  |"f:terminationGr|
              00000210  61 63 65 50 65 72 69 6f  64 53 65 63 6f 6e 64 73  |acePeriodSeconds|
              00000220  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146443,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=850) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 35  |k:{\"ip\":\"10.5|
              00000320  32 2e 31 2e 31 35 30 5c  22 7d 22 3a 7b 22 2e 22  |2.1.150\"}":{"."|
              00000330  3a 7b 7d 2c 22 66 3a 69  70 22 3a 7b 7d 7d 7d 2c  |:{},"f:ip":{}}},|
              00000340  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              00000350  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-kr9ch",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-kr9ch",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146443,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146442,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146443,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146443,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146442,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.10",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.10"
        }
      },
      PodIP: (string) (len=11) "10.52.1.150",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.52.1.150"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905146442,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63905146443,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:10ed98804c877e505e17bced991682b6fd50ab1da9cddcd19935b48d645da40a",
          ContainerID: (string) (len=77) "containerd://74fa1dacbcf3d3eec533337da6efa02d0cee26334356ef243cfa3137ba86ef8e",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-kr9ch",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:34:04.579564 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7033" for this suite. @ 01/27/26 21:34:04.588
• [2.198 seconds]
------------------------------
SS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:284
  STEP: Creating a kubernetes client @ 01/27/26 21:34:04.6
  I0127 21:34:04.600686 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename taint-single-pod @ 01/27/26 21:34:04.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:34:04.628
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:34:04.717
  I0127 21:34:04.721490 26 wait.go:53] Waiting up to 1m0s for all nodes to be ready
  E0127 21:34:05.017285      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:06.017443      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:07.017884      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:08.018225      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:09.018822      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:10.019660      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:11.020421      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:12.021128      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:13.022034      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:14.022262      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:15.022393      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:16.022634      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:17.023746      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:18.024856      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:19.025310      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:20.026044      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:21.026976      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:22.027193      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:23.027613      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:24.027801      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:25.028011      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:26.029012      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:27.029062      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:28.029315      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:29.029510      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:30.029987      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:31.030462      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:32.030941      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:33.031860      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:34.032825      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:35.033076      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:36.033616      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:37.034227      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:38.034460      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:39.035056      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:40.035497      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:41.036380      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:42.036585      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:43.037736      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:44.037960      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:45.038490      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:46.038623      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:47.039382      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:48.039724      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:49.039935      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:50.040855      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:51.041143      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:52.041220      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:53.041703      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:54.041960      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:55.042232      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:56.042563      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:57.043053      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:58.043264      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:34:59.044348      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:00.045194      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:01.045839      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:02.046606      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:03.047099      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:04.047319      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:35:04.722064 26 util.go:389] Waiting for terminating namespaces to be deleted...
  I0127 21:35:04.725515 26 taints.go:144] Starting informer...
  STEP: Starting pod... @ 01/27/26 21:35:04.725
  I0127 21:35:04.939315 26 taints.go:294] Pod is running on k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2. Tainting Node
  STEP: Trying to apply a taint on the Node @ 01/27/26 21:35:04.939
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 01/27/26 21:35:04.957
  STEP: Waiting short time to make sure Pod is queued for deletion @ 01/27/26 21:35:04.959
  I0127 21:35:04.959158 26 taints.go:313] Pod wasn't evicted. Proceeding
  I0127 21:35:04.959172 26 taints.go:320] Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 01/27/26 21:35:04.977
  STEP: Waiting some time to make sure that toleration time passed. @ 01/27/26 21:35:04.993
  E0127 21:35:05.048318      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:06.048840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:07.049543      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:08.049612      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:09.049883      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:10.050117      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:11.050407      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:12.050766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:13.050905      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:14.051132      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:15.051774      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:16.052665      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:17.053128      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:18.053312      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:19.053511      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:20.053739      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:21.054387      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:22.055003      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:23.055222      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:24.055516      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:25.055861      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:26.056118      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:27.056231      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:28.056463      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:29.057041      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:30.057213      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:31.057445      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:32.057579      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:33.057810      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:34.058037      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:35.059063      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:36.059291      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:37.059716      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:38.059752      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:39.060038      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:40.060723      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:41.060935      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:42.061820      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:43.062045      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:44.062251      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:45.062471      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:46.062762      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:47.062958      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:48.063170      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:49.063388      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:50.063562      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:51.064098      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:52.064817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:53.065009      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:54.065248      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:55.065787      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:56.066477      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:57.066663      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:58.067695      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:35:59.067753      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:00.067877      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:01.067929      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:02.068861      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:03.069055      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:04.069304      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:05.069806      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:06.070180      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:07.070410      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:08.070624      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:09.070824      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:10.071571      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:11.071782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:12.072813      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:13.073029      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:14.073257      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:15.073471      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:16.073652      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:17.073851      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:18.074043      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:19.074648      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:36:19.994354 26 taints.go:329] Pod wasn't evicted. Test successful
  I0127 21:36:19.994530 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-4926" for this suite. @ 01/27/26 21:36:19.998
• [135.406 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:54
  STEP: Creating a kubernetes client @ 01/27/26 21:36:20.006
  I0127 21:36:20.006588 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 21:36:20.007
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:36:20.024
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:36:20.035
  STEP: Creating a pod to test downward API volume plugin @ 01/27/26 21:36:20.038
  E0127 21:36:20.076364      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:21.076612      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:22.077061      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:23.077258      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:36:24.055
  I0127 21:36:24.057214 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downwardapi-volume-d2199db5-b1e3-4748-ae95-7ab394b5a527 container client-container: <nil>
  STEP: delete the pod @ 01/27/26 21:36:24.067
  E0127 21:36:24.078322      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:36:24.094813 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8876" for this suite. @ 01/27/26 21:36:24.098
• [4.100 seconds]
------------------------------
SS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:1066
  STEP: Creating a kubernetes client @ 01/27/26 21:36:24.106
  I0127 21:36:24.106727 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename job @ 01/27/26 21:36:24.107
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:36:24.134
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:36:24.136
  STEP: Creating a job @ 01/27/26 21:36:24.138
  STEP: Ensure pods equal to parallelism count is attached to the job @ 01/27/26 21:36:24.147
  E0127 21:36:25.078399      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:26.078630      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: patching /status @ 01/27/26 21:36:26.154
  STEP: updating /status @ 01/27/26 21:36:26.171
  STEP: get /status @ 01/27/26 21:36:26.176
  I0127 21:36:26.179028 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4588" for this suite. @ 01/27/26 21:36:26.181
• [2.082 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:115
  STEP: Creating a kubernetes client @ 01/27/26 21:36:26.188
  I0127 21:36:26.188803 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename deployment @ 01/27/26 21:36:26.189
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:36:26.215
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:36:26.217
  I0127 21:36:26.220074 26 deployment.go:802] Creating deployment "test-recreate-deployment"
  I0127 21:36:26.229147 26 deployment.go:808] Waiting deployment "test-recreate-deployment" to be updated to revision 1
  I0127 21:36:26.232545 26 deployment.go:223] new replicaset for deployment "test-recreate-deployment" is yet to be created
  E0127 21:36:27.079481      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:28.079738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:36:28.238416 26 deployment.go:812] Waiting deployment "test-recreate-deployment" to complete
  I0127 21:36:28.240607 26 deployment.go:817] Triggering a new rollout for deployment "test-recreate-deployment"
  I0127 21:36:28.250174 26 deployment.go:314] Updating deployment test-recreate-deployment
  I0127 21:36:28.250216 26 deployment.go:824] Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  I0127 21:36:28.442424 26 deployment.go:636] Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3170",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "dca2272b-0127-4457-b6b6-e790d60adc3d",
      ResourceVersion: (string) (len=5) "41531",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905146586,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146588,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=572) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 61 67  6e 68 6f 73 74 5c 22 7d  |e\":\"agnhost\"}|
              00000120  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000130  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000140  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000150  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000160  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000170  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000180  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000190  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              000001a0  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              000001b0  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              000001c0  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001d0  7b 7d 2c 22 66 3a 72 65  73 74 61 72 74 50 6f 6c  |{},"f:restartPol|
              000001e0  69 63 79 22 3a 7b 7d 2c  22 66 3a 73 63 68 65 64  |icy":{},"f:sched|
              000001f0  75 6c 65 72 4e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |ulerName":{},"f:|
              00000200  73 65 63 75 72 69 74 79  43 6f 6e 74 65 78 74 22  |securityContext"|
              00000210  3a 7b 7d 2c 22 66 3a 74  65 72 6d 69 6e 61 74 69  |:{},"f:terminati|
              00000220  6f 6e 47 72 61 63 65 50  65 72 69 6f 64 53 65 63  |onGracePeriodSec|
              00000230  6f 6e 64 73 22 3a 7b 7d  7d 7d 7d 7d              |onds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146588,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=522) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 74  |eplicas":{},"f:t|
              000001c0  65 72 6d 69 6e 61 74 69  6e 67 52 65 70 6c 69 63  |erminatingReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 6e 61 76 61 69  |as":{},"f:unavai|
              000001e0  6c 61 62 6c 65 52 65 70  6c 69 63 61 73 22 3a 7b  |lableReplicas":{|
              000001f0  7d 2c 22 66 3a 75 70 64  61 74 65 64 52 65 70 6c  |},"f:updatedRepl|
              00000200  69 63 61 73 22 3a 7b 7d  7d 7d                    |icas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      TerminatingReplicas: (*int32)(0),
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146588,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146588,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146588,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146586,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=63) "ReplicaSet \"test-recreate-deployment-f9959f67b\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0127 21:36:28.454570 26 deployment.go:40] New ReplicaSet "test-recreate-deployment-f9959f67b" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-f9959f67b",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3170",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fd6f8b5d-f2d8-4431-a7ee-f515ce541b2c",
      ResourceVersion: (string) (len=5) "41529",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905146588,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "f9959f67b"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "dca2272b-0127-4457-b6b6-e790d60adc3d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146588,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 64 63 61 32 32 37  32 62 2d 30 31 32 37 2d  |\"dca2272b-0127-|
              00000120  34 34 35 37 2d 62 36 62  36 2d 65 37 39 30 64 36  |4457-b6b6-e790d6|
              00000130  30 61 64 63 33 64 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |0adc3d\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146588,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=111) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6e  |{},"f:terminatin|
              00000060  67 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |gReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "f9959f67b"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=9) "f9959f67b",
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(0),
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0127 21:36:28.455365 26 deployment.go:45] All old ReplicaSets of Deployment "test-recreate-deployment":
  I0127 21:36:28.455935 26 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-544d8d5b4d",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3170",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "498ba77b-0a80-4850-8bdd-f9061c18a297",
      ResourceVersion: (string) (len=5) "41519",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905146586,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "544d8d5b4d"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "dca2272b-0127-4457-b6b6-e790d60adc3d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146588,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 64 63 61 32 32 37  32 62 2d 30 31 32 37 2d  |\"dca2272b-0127-|
              00000120  34 34 35 37 2d 62 36 62  36 2d 65 37 39 30 64 36  |4457-b6b6-e790d6|
              00000130  30 61 64 63 33 64 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |0adc3d\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146588,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=83) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |as":{},"f:termin|
              00000040  61 74 69 6e 67 52 65 70  6c 69 63 61 73 22 3a 7b  |atingReplicas":{|
              00000050  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "544d8d5b4d"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "544d8d5b4d"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.55",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(0),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0127 21:36:28.459789 26 deployment.go:68] Pod "test-recreate-deployment-f9959f67b-7p96s" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-recreate-deployment-f9959f67b-7p96s",
      GenerateName: (string) (len=35) "test-recreate-deployment-f9959f67b-",
      Namespace: (string) (len=15) "deployment-3170",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2cdeff43-980e-4cbe-915c-ec2627d880bb",
      ResourceVersion: (string) (len=5) "41530",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905146588,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "f9959f67b",
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-recreate-deployment-f9959f67b",
          UID: (types.UID) (len=36) "fd6f8b5d-f2d8-4431-a7ee-f515ce541b2c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146588,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 64  36 66 38 62 35 64 2d 66  |d\":\"fd6f8b5d-f|
              00000090  32 64 38 2d 34 34 33 31  2d 61 37 65 65 2d 66 35  |2d8-4431-a7ee-f5|
              000000a0  31 35 63 65 35 34 31 62  32 63 5c 22 7d 22 3a 7b  |15ce541b2c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146588,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-89lk7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-89lk7",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146588,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146588,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146588,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146588,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905146588,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.10",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.10"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905146588,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-89lk7",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:36:28.462159 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3170" for this suite. @ 01/27/26 21:36:28.465
• [2.285 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 01/27/26 21:36:28.473
  I0127 21:36:28.473797 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 01/27/26 21:36:28.474
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:36:28.489
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:36:28.495
  STEP: creating a target pod @ 01/27/26 21:36:28.497
  E0127 21:36:29.079909      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:30.080798      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 01/27/26 21:36:30.519
  E0127 21:36:31.081266      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:32.081470      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:33.081826      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:34.082071      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: verifying the pod's generation is 2 @ 01/27/26 21:36:34.541
  STEP: checking pod container endpoints @ 01/27/26 21:36:34.542
  I0127 21:36:34.542901 26 exec_util.go:63] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-5957 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:36:34.542919 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:36:34.542952 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/ephemeral-containers-test-5957/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&stderr=true&stdout=true)
  I0127 21:36:34.592252 26 exec_util.go:112] Exec stderr: ""
  I0127 21:36:34.599287 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-5957" for this suite. @ 01/27/26 21:36:34.601
• [6.137 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:272
  STEP: Creating a kubernetes client @ 01/27/26 21:36:34.61
  I0127 21:36:34.610461 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename custom-resource-definition @ 01/27/26 21:36:34.611
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:36:34.639
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:36:34.643
  I0127 21:36:34.650691 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  E0127 21:36:35.082191      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:36.083096      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:37.083316      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:36:37.741880 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-8688" for this suite. @ 01/27/26 21:36:37.744
• [3.148 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:339
  STEP: Creating a kubernetes client @ 01/27/26 21:36:37.758
  I0127 21:36:37.758402 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename statefulset @ 01/27/26 21:36:37.759
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:36:37.775
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:36:37.791
  STEP: Creating service test in namespace statefulset-5278 @ 01/27/26 21:36:37.794
  STEP: Creating a new StatefulSet @ 01/27/26 21:36:37.802
  I0127 21:36:37.822617 26 wait.go:45] Found 0 stateful pods, waiting for 3
  E0127 21:36:38.084219      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:39.084817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:40.085742      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:41.086135      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:42.086344      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:43.086977      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:44.087185      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:45.088187      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:46.089912      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:47.090130      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:36:47.821288 26 wait.go:55] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0127 21:36:47.821316 26 wait.go:55] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0127 21:36:47.821324 26 wait.go:55] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/agnhost:2.55 to registry.k8s.io/e2e-test-images/agnhost:2.59 @ 01/27/26 21:36:47.827
  I0127 21:36:47.837874 26 statefulset.go:2574] Updating stateful set ss2
  STEP: Creating a new revision @ 01/27/26 21:36:47.837
  E0127 21:36:48.090355      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:49.091668      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:50.091852      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:51.092362      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:52.092822      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:53.093298      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:54.093746      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:55.093966      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:56.094205      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:57.094412      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 01/27/26 21:36:57.848
  STEP: Performing a canary update @ 01/27/26 21:36:57.848
  I0127 21:36:57.859179 26 statefulset.go:2574] Updating stateful set ss2
  I0127 21:36:57.872539 26 wait.go:75] Waiting for Pod statefulset-5278/ss2-2 to have revision ss2-76d96865f5 update revision ss2-69f59f8c99
  E0127 21:36:58.095111      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:36:59.095297      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:00.095505      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:01.095906      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:02.096842      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:03.097943      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:04.098137      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:05.098389      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:06.098815      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:07.099291      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 01/27/26 21:37:07.863
  I0127 21:37:07.980468 26 wait.go:45] Found 2 stateful pods, waiting for 3
  E0127 21:37:08.099719      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:09.100831      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:10.101083      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:11.101346      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:12.101577      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:13.101818      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:14.102007      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:15.102089      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:16.103163      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:17.103362      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:37:17.965386 26 wait.go:55] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0127 21:37:17.965424 26 wait.go:55] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0127 21:37:17.965433 26 wait.go:55] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 01/27/26 21:37:17.969
  I0127 21:37:17.985056 26 statefulset.go:2574] Updating stateful set ss2
  I0127 21:37:18.001175 26 wait.go:75] Waiting for Pod statefulset-5278/ss2-1 to have revision ss2-76d96865f5 update revision ss2-69f59f8c99
  E0127 21:37:18.104316      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:19.104818      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:20.105019      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:21.105480      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:22.106077      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:23.106309      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:24.106557      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:25.107663      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:26.107744      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:27.107988      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:37:28.006198 26 statefulset.go:2574] Updating stateful set ss2
  I0127 21:37:28.022581 26 wait.go:57] Waiting for StatefulSet statefulset-5278/ss2 to complete update
  I0127 21:37:28.022633 26 wait.go:64] Waiting for Pod statefulset-5278/ss2-0 to have revision ss2-76d96865f5 update revision ss2-69f59f8c99
  E0127 21:37:28.108747      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:29.108940      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:30.109144      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:31.109333      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:32.110059      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:33.110571      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:34.110779      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:35.110977      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:36.111207      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:37.112153      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:37:38.018950 26 statefulset.go:137] Deleting all statefulset in ns statefulset-5278
  I0127 21:37:38.021143 26 rest.go:153] Scaling statefulset ss2 to 0
  E0127 21:37:38.112740      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:39.113436      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:40.113486      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:41.113711      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:42.113891      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:43.114312      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:44.114515      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:45.114751      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:46.114973      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:47.115176      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:37:48.042041 26 wait.go:160] Waiting for statefulset status.replicas updated to 0
  I0127 21:37:48.044117 26 rest.go:91] Deleting statefulset ss2
  I0127 21:37:48.055570 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5278" for this suite. @ 01/27/26 21:37:48.057
• [70.312 seconds]
------------------------------
SSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:127
  STEP: Creating a kubernetes client @ 01/27/26 21:37:48.07
  I0127 21:37:48.070471 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename podtemplate @ 01/27/26 21:37:48.07
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:37:48.086
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:37:48.097
  STEP: Create set of pod templates @ 01/27/26 21:37:48.099
  E0127 21:37:48.115775      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:37:48.117651 26 podtemplates.go:147] created test-podtemplate-1
  I0127 21:37:48.126726 26 podtemplates.go:147] created test-podtemplate-2
  I0127 21:37:48.134985 26 podtemplates.go:147] created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 01/27/26 21:37:48.135
  STEP: delete collection of pod templates @ 01/27/26 21:37:48.136
  I0127 21:37:48.136765 26 podtemplates.go:162] requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 01/27/26 21:37:48.163
  I0127 21:37:48.163222 26 podtemplates.go:223] requesting list of pod templates to confirm quantity
  I0127 21:37:48.165083 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-9607" for this suite. @ 01/27/26 21:37:48.167
• [0.105 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1499
  STEP: Creating a kubernetes client @ 01/27/26 21:37:48.175
  I0127 21:37:48.175964 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename services @ 01/27/26 21:37:48.176
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:37:48.196
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:37:48.198
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-349 @ 01/27/26 21:37:48.2
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 01/27/26 21:37:48.227
  STEP: creating service externalsvc in namespace services-349 @ 01/27/26 21:37:48.228
  I0127 21:37:48.270068 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0127 21:37:49.116821      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:50.117018      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: changing the ClusterIP service to type=ExternalName @ 01/27/26 21:37:50.278
  I0127 21:37:50.299987 26 resource.go:344] Creating new exec pod
  E0127 21:37:51.117425      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:52.118410      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:37:52.322122 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-349 exec execpodrt6pd -- /bin/sh -x -c nslookup clusterip-service.services-349.svc.cluster.local'
  I0127 21:37:52.437180 26 builder.go:156] stderr: "+ nslookup clusterip-service.services-349.svc.cluster.local\n"
  I0127 21:37:52.437230 26 builder.go:157] stdout: ";; Got recursion not available from 10.53.0.10\n;; Got recursion not available from 10.53.0.10\n;; Got recursion not available from 10.53.0.10\n;; Got recursion not available from 10.53.0.10\n;; Got recursion not available from 10.53.0.10\nServer:\t\t10.53.0.10\nAddress:\t10.53.0.10#53\n\nclusterip-service.services-349.svc.cluster.local\tcanonical name = externalsvc.services-349.svc.cluster.local.\nName:\texternalsvc.services-349.svc.cluster.local\nAddress: 10.53.52.2\n;; Got recursion not available from 10.53.0.10\n\n"
  I0127 21:37:52.494613 26 service.go:1508] Cleaning up the ClusterIP to ExternalName test service
  I0127 21:37:52.517677 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-349" for this suite. @ 01/27/26 21:37:52.519
• [4.361 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:314
  STEP: Creating a kubernetes client @ 01/27/26 21:37:52.537
  I0127 21:37:52.537037 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename crd-publish-openapi @ 01/27/26 21:37:52.538
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:37:52.553
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:37:52.558
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 01/27/26 21:37:52.561
  I0127 21:37:52.561709 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  E0127 21:37:53.118756      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:54.119632      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:55.120665      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:56.121148      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:57.121820      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 01/27/26 21:37:58.059
  I0127 21:37:58.059476 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  E0127 21:37:58.122832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:37:59.123651      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:37:59.431294 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  E0127 21:38:00.123782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:01.124853      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:02.125525      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:03.126016      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:04.126164      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:38:04.820991 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1947" for this suite. @ 01/27/26 21:38:04.825
• [12.297 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1400
  STEP: Creating a kubernetes client @ 01/27/26 21:38:04.834
  I0127 21:38:04.834628 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubectl @ 01/27/26 21:38:04.835
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:38:04.851
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:38:04.861
  STEP: validating cluster-info @ 01/27/26 21:38:04.864
  I0127 21:38:04.864054 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-4532 cluster-info'
  I0127 21:38:04.922365 26 builder.go:156] stderr: ""
  I0127 21:38:04.922405 26 builder.go:157] stdout: "Kubernetes control plane is running at https://10.53.0.1:443\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  I0127 21:38:04.922516 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4532" for this suite. @ 01/27/26 21:38:04.925
• [0.099 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 01/27/26 21:38:04.933
  I0127 21:38:04.933618 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename var-expansion @ 01/27/26 21:38:04.934
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:38:04.96
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:38:04.962
  STEP: Creating a pod to test substitution in container's args @ 01/27/26 21:38:04.964
  E0127 21:38:05.126544      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:06.127018      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:07.128069      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:08.128287      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:38:08.994
  I0127 21:38:08.997146 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod var-expansion-4b91d59b-5e8f-460e-ad5e-904f6ec04a2a container dapi-container: <nil>
  STEP: delete the pod @ 01/27/26 21:38:09.005
  I0127 21:38:09.032877 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6213" for this suite. @ 01/27/26 21:38:09.035
• [4.110 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:57
  STEP: Creating a kubernetes client @ 01/27/26 21:38:09.043
  I0127 21:38:09.043516 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename configmap @ 01/27/26 21:38:09.044
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:38:09.058
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:38:09.063
  STEP: Creating configMap with name configmap-test-volume-6c94a0e4-2c89-4566-a89f-7b75b33b519e @ 01/27/26 21:38:09.065
  STEP: Creating a pod to test consume configMaps @ 01/27/26 21:38:09.082
  E0127 21:38:09.129325      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:10.129451      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:11.130368      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:12.130862      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:38:13.101
  I0127 21:38:13.103389 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-configmaps-8c700cef-b650-4b50-bcbd-e901b3001d9c container agnhost-container: <nil>
  STEP: delete the pod @ 01/27/26 21:38:13.107
  I0127 21:38:13.129424 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0127 21:38:13.131564      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Destroying namespace "configmap-3729" for this suite. @ 01/27/26 21:38:13.132
• [4.098 seconds]
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:193
  STEP: Creating a kubernetes client @ 01/27/26 21:38:13.141
  I0127 21:38:13.141528 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename svcaccounts @ 01/27/26 21:38:13.142
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:38:13.174
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:38:13.176
  I0127 21:38:13.204278 26 service_accounts.go:283] created pod pod-service-account-defaultsa
  I0127 21:38:13.204315 26 service_accounts.go:297] pod pod-service-account-defaultsa service account token volume mount: true
  I0127 21:38:13.218562 26 service_accounts.go:283] created pod pod-service-account-mountsa
  I0127 21:38:13.218600 26 service_accounts.go:297] pod pod-service-account-mountsa service account token volume mount: true
  I0127 21:38:13.233246 26 service_accounts.go:283] created pod pod-service-account-nomountsa
  I0127 21:38:13.233280 26 service_accounts.go:297] pod pod-service-account-nomountsa service account token volume mount: false
  I0127 21:38:13.254981 26 service_accounts.go:283] created pod pod-service-account-defaultsa-mountspec
  I0127 21:38:13.255014 26 service_accounts.go:297] pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  I0127 21:38:13.263041 26 service_accounts.go:283] created pod pod-service-account-mountsa-mountspec
  I0127 21:38:13.263085 26 service_accounts.go:297] pod pod-service-account-mountsa-mountspec service account token volume mount: true
  I0127 21:38:13.287262 26 service_accounts.go:283] created pod pod-service-account-nomountsa-mountspec
  I0127 21:38:13.287294 26 service_accounts.go:297] pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  I0127 21:38:13.314346 26 service_accounts.go:283] created pod pod-service-account-defaultsa-nomountspec
  I0127 21:38:13.314381 26 service_accounts.go:297] pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  I0127 21:38:13.337236 26 service_accounts.go:283] created pod pod-service-account-mountsa-nomountspec
  I0127 21:38:13.337269 26 service_accounts.go:297] pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  I0127 21:38:13.355126 26 service_accounts.go:283] created pod pod-service-account-nomountsa-nomountspec
  I0127 21:38:13.355163 26 service_accounts.go:297] pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  I0127 21:38:13.355260 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6335" for this suite. @ 01/27/26 21:38:13.369
• [0.256 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:168
  STEP: Creating a kubernetes client @ 01/27/26 21:38:13.397
  I0127 21:38:13.397827 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename replicaset @ 01/27/26 21:38:13.399
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:38:13.421
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:38:13.433
  STEP: Create a ReplicaSet @ 01/27/26 21:38:13.48
  STEP: Verify that the required pods have come up @ 01/27/26 21:38:13.495
  I0127 21:38:13.508368 26 resource.go:64] Pod name sample-pod: Found 0 pods out of 3
  E0127 21:38:14.131924      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:15.133200      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:16.133427      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:17.133672      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:18.134519      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:38:18.522776 26 resource.go:64] Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 01/27/26 21:38:18.522
  E0127 21:38:19.135296      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:20.135410      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:21.136308      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:22.136814      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:38:22.646783 26 replica_set.go:592] Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 TerminatingReplicas:0xc0018e339c ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 01/27/26 21:38:22.646
  STEP: DeleteCollection of the ReplicaSets @ 01/27/26 21:38:22.648
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 01/27/26 21:38:22.655
  I0127 21:38:22.656989 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-1253" for this suite. @ 01/27/26 21:38:22.659
• [9.270 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should update ConfigMap successfully [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:150
  STEP: Creating a kubernetes client @ 01/27/26 21:38:22.667
  I0127 21:38:22.667988 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename configmap @ 01/27/26 21:38:22.669
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:38:22.713
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:38:22.842
  STEP: Creating ConfigMap configmap-5118/configmap-test-bb36c898-34a6-44f3-aeee-a0bd7cbfb475 @ 01/27/26 21:38:22.845
  STEP: Updating configMap configmap-5118/configmap-test-bb36c898-34a6-44f3-aeee-a0bd7cbfb475 @ 01/27/26 21:38:22.858
  STEP: Verifying update of ConfigMap configmap-5118/configmap-test-bb36c898-34a6-44f3-aeee-a0bd7cbfb475 @ 01/27/26 21:38:22.863
  I0127 21:38:22.864084 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5118" for this suite. @ 01/27/26 21:38:22.865
• [0.208 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:196
  STEP: Creating a kubernetes client @ 01/27/26 21:38:22.875
  I0127 21:38:22.875662 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename runtimeclass @ 01/27/26 21:38:22.876
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:38:22.988
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:38:22.99
  STEP: getting /apis @ 01/27/26 21:38:22.994
  STEP: getting /apis/node.k8s.io @ 01/27/26 21:38:22.998
  STEP: getting /apis/node.k8s.io/v1 @ 01/27/26 21:38:22.998
  STEP: creating @ 01/27/26 21:38:22.999
  STEP: watching @ 01/27/26 21:38:23.067
  I0127 21:38:23.067975 26 runtimeclass.go:280] starting watch
  E0127 21:38:23.136917      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: getting @ 01/27/26 21:38:23.187
  STEP: listing @ 01/27/26 21:38:23.189
  STEP: patching @ 01/27/26 21:38:23.191
  STEP: updating @ 01/27/26 21:38:23.233
  I0127 21:38:23.307628 26 runtimeclass.go:312] waiting for watch events with expected annotations
  STEP: deleting @ 01/27/26 21:38:23.307
  STEP: deleting a collection @ 01/27/26 21:38:23.32
  I0127 21:38:23.494392 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-6271" for this suite. @ 01/27/26 21:38:23.497
• [0.829 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1539
  STEP: Creating a kubernetes client @ 01/27/26 21:38:23.705
  I0127 21:38:23.705207 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename services @ 01/27/26 21:38:23.705
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:38:23.873
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:38:23.876
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-7212 @ 01/27/26 21:38:23.878
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 01/27/26 21:38:24.097
  STEP: creating service externalsvc in namespace services-7212 @ 01/27/26 21:38:24.098
  E0127 21:38:24.137916      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:38:24.144321 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0127 21:38:25.138609      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:26.139275      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:38:26.148096 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:2, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:2, TerminatingReplicas:(*int32)(0xc004271920), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 21, 38, 24, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 38, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 38, 24, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 38, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"externalsvc-7855f7c5cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:38:27.139741      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:28.140864      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: changing the NodePort service to type=ExternalName @ 01/27/26 21:38:28.152
  I0127 21:38:28.181117 26 resource.go:344] Creating new exec pod
  E0127 21:38:29.140981      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:30.141978      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:38:30.193870 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-7212 exec execpods4gp6 -- /bin/sh -x -c nslookup nodeport-service.services-7212.svc.cluster.local'
  I0127 21:38:30.310150 26 builder.go:156] stderr: "+ nslookup nodeport-service.services-7212.svc.cluster.local\n"
  I0127 21:38:30.310195 26 builder.go:157] stdout: ";; Got recursion not available from 10.53.0.10\n;; Got recursion not available from 10.53.0.10\n;; Got recursion not available from 10.53.0.10\n;; Got recursion not available from 10.53.0.10\n;; Got recursion not available from 10.53.0.10\nServer:\t\t10.53.0.10\nAddress:\t10.53.0.10#53\n\nnodeport-service.services-7212.svc.cluster.local\tcanonical name = externalsvc.services-7212.svc.cluster.local.\nName:\texternalsvc.services-7212.svc.cluster.local\nAddress: 10.53.113.102\n;; Got recursion not available from 10.53.0.10\n\n"
  I0127 21:38:30.347183 26 service.go:1550] Cleaning up the NodePort to ExternalName test service
  I0127 21:38:30.384573 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7212" for this suite. @ 01/27/26 21:38:30.399
• [6.716 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:217
  STEP: Creating a kubernetes client @ 01/27/26 21:38:30.421
  I0127 21:38:30.421742 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename container-runtime @ 01/27/26 21:38:30.422
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:38:30.437
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:38:30.443
  STEP: create the container @ 01/27/26 21:38:30.445
  I0127 21:38:30.461184      26 warnings.go:107] "Warning: metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]"
  STEP: wait for the container to reach Failed @ 01/27/26 21:38:30.461
  E0127 21:38:31.142121      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:32.142312      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:33.143378      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: get the container status @ 01/27/26 21:38:33.47
  STEP: the container should be terminated @ 01/27/26 21:38:33.472
  STEP: the termination message should be set @ 01/27/26 21:38:33.472
  I0127 21:38:33.472466 26 runtime.go:168] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 01/27/26 21:38:33.472
  I0127 21:38:33.492690 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-9283" for this suite. @ 01/27/26 21:38:33.494
• [3.080 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_selectable_fields.go:124
  STEP: Creating a kubernetes client @ 01/27/26 21:38:33.502
  I0127 21:38:33.502016 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename crd-selectable-fields @ 01/27/26 21:38:33.502
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:38:33.523
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:38:33.525
  STEP: Setting up server cert @ 01/27/26 21:38:33.527
  E0127 21:38:34.143920      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 01/27/26 21:38:34.29
  STEP: Deploying the custom resource conversion webhook pod @ 01/27/26 21:38:34.31
  STEP: Wait for the deployment to be ready @ 01/27/26 21:38:34.332
  I0127 21:38:34.346735 26 deployment.go:223] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0127 21:38:35.144930      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:36.145105      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/27/26 21:38:36.353
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 21:38:36.369
  I0127 21:38:36.369315 26 wait.go:65] Waiting for amount of service crd-selectable-fields-8481/e2e-test-crd-conversion-webhook endpoints to be 1
  I0127 21:38:36.371462 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  E0127 21:38:37.145959      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a custom resource definition with selectable fields @ 01/27/26 21:38:37.372
  I0127 21:38:37.372913 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Creating a custom resource conversion webhook @ 01/27/26 21:38:37.893
  E0127 21:38:38.146183      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:39.147239      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Watching with field selectors @ 01/27/26 21:38:39.935
  STEP: Registering informers with field selectors @ 01/27/26 21:38:39.939
  STEP: Creating custom resources @ 01/27/26 21:38:39.939
  STEP: Listing v2 custom resources with field selector host=host1 @ 01/27/26 21:38:39.974
  STEP: Listing v2 custom resources with field selector host=host1,port=80 @ 01/27/26 21:38:39.976
  STEP: Listing v1 custom resources with field selector hostPort=host1:80 @ 01/27/26 21:38:39.978
  STEP: Listing v1 custom resources with field selector hostPort=host1:8080 @ 01/27/26 21:38:39.98
  STEP: Waiting for watch events to contain v2 custom resources for field selector host=host1 @ 01/27/26 21:38:39.981
  STEP: Waiting for watch events to contain v2 custom resources for field selector host=host1,port=80 @ 01/27/26 21:38:39.987
  STEP: Waiting for watch events to contain v1 custom resources for field selector hostPort=host1:80 @ 01/27/26 21:38:39.987
  STEP: Waiting for informer events to contain v2 custom resources for field selector host=host1 @ 01/27/26 21:38:39.987
  STEP: Waiting for informer events to contain v2 custom resources for field selector host=host1,port=80 @ 01/27/26 21:38:39.987
  STEP: Deleting one custom resources to ensure that deletions are observed @ 01/27/26 21:38:39.987
  STEP: Updating one custom resources to ensure that deletions are observed @ 01/27/26 21:38:40.003
  STEP: Listing v2 custom resources after updates and deletes for field selector host=host1 @ 01/27/26 21:38:40.017
  STEP: Listing v2 custom resources after updates and deletes for field selector host=host1,port=80 @ 01/27/26 21:38:40.019
  STEP: Waiting for v2 watch events after updates and deletes for field selector host=host1 @ 01/27/26 21:38:40.02
  STEP: Waiting for v2 watch events after updates and deletes for field selector host=host1,port=80 @ 01/27/26 21:38:40.026
  STEP: Waiting for v1 watch events after updates and deletes for field selector hostPort=host1:80 @ 01/27/26 21:38:40.026
  STEP: Waiting for v2 informer events after updates and deletes for field selector host=host1 @ 01/27/26 21:38:40.026
  STEP: Waiting for v2 informer events after updates and deletes for field selector host=host1,port=80 @ 01/27/26 21:38:40.026
  E0127 21:38:40.148053      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:38:40.607721 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-selectable-fields-8481" for this suite. @ 01/27/26 21:38:40.618
• [7.134 seconds]
------------------------------
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:328
  STEP: Creating a kubernetes client @ 01/27/26 21:38:40.636
  I0127 21:38:40.636256 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename statefulset @ 01/27/26 21:38:40.637
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:38:40.653
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:38:40.663
  STEP: Creating service test in namespace statefulset-7085 @ 01/27/26 21:38:40.665
  STEP: Creating a new StatefulSet @ 01/27/26 21:38:40.672
  I0127 21:38:40.694914 26 wait.go:45] Found 0 stateful pods, waiting for 3
  E0127 21:38:41.148464      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:42.148573      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:43.149483      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:44.149585      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:45.150322      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:46.150615      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:47.151025      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:48.151227      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:49.151436      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:50.152020      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:38:50.696224 26 wait.go:55] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0127 21:38:50.696264 26 wait.go:55] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0127 21:38:50.696273 26 wait.go:55] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  I0127 21:38:50.701324 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=statefulset-7085 exec ss2-1 -- /bin/sh -x -c mv -v /localhost.crt /tmp/ || true'
  I0127 21:38:50.828886 26 builder.go:156] stderr: "+ mv -v /localhost.crt /tmp/\n"
  I0127 21:38:50.828930 26 builder.go:157] stdout: "'/localhost.crt' -> '/tmp/localhost.crt'\n"
  I0127 21:38:50.828942 26 statefulset.go:2517] stdout of mv -v /localhost.crt /tmp/ || true on ss2-1: '/localhost.crt' -> '/tmp/localhost.crt'

  E0127 21:38:51.152196      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:52.152801      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:53.153908      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:54.154148      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:55.155329      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:56.155562      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:57.155804      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:58.158107      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:38:59.158319      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:00.158525      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/agnhost:2.55 to registry.k8s.io/e2e-test-images/agnhost:2.59 @ 01/27/26 21:39:00.834
  I0127 21:39:00.859347 26 statefulset.go:2574] Updating stateful set ss2
  STEP: Creating a new revision @ 01/27/26 21:39:00.859
  E0127 21:39:01.159621      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:02.159730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:03.159786      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:04.159832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:05.160040      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:06.160935      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:07.161381      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:08.161929      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:09.162074      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:10.162385      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 01/27/26 21:39:10.864
  I0127 21:39:10.866714 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=statefulset-7085 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/localhost.crt / || true'
  I0127 21:39:10.972060 26 builder.go:156] stderr: "+ mv -v /tmp/localhost.crt /\n"
  I0127 21:39:10.972107 26 builder.go:157] stdout: "'/tmp/localhost.crt' -> '/localhost.crt'\n"
  I0127 21:39:10.972117 26 statefulset.go:2541] stdout of mv -v /tmp/localhost.crt / || true on ss2-1: '/tmp/localhost.crt' -> '/localhost.crt'

  E0127 21:39:11.163326      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:12.163511      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:13.163763      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:14.164823      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:15.165025      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:16.165276      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:17.165470      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:18.165671      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:19.165923      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:20.166154      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 01/27/26 21:39:20.98
  I0127 21:39:20.980384 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=statefulset-7085 exec ss2-1 -- /bin/sh -x -c mv -v /localhost.crt /tmp/ || true'
  I0127 21:39:21.092912 26 builder.go:156] stderr: "+ mv -v /localhost.crt /tmp/\n"
  I0127 21:39:21.092954 26 builder.go:157] stdout: "'/localhost.crt' -> '/tmp/localhost.crt'\n"
  I0127 21:39:21.092965 26 statefulset.go:2517] stdout of mv -v /localhost.crt /tmp/ || true on ss2-1: '/localhost.crt' -> '/tmp/localhost.crt'

  E0127 21:39:21.166910      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:22.167140      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:23.167509      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:24.168065      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:25.168832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:26.169119      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:27.169233      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:28.170154      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:29.170354      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:30.170546      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:39:31.109269 26 statefulset.go:2574] Updating stateful set ss2
  E0127 21:39:31.171267      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:32.171806      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:33.172918      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:34.173126      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:35.173339      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:36.173705      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:37.173942      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:38.174167      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:39.174389      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:40.174942      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 01/27/26 21:39:41.114
  I0127 21:39:41.116243 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=statefulset-7085 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/localhost.crt / || true'
  E0127 21:39:41.175662      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:39:41.221226 26 builder.go:156] stderr: "+ mv -v /tmp/localhost.crt /\n"
  I0127 21:39:41.221268 26 builder.go:157] stdout: "'/tmp/localhost.crt' -> '/localhost.crt'\n"
  I0127 21:39:41.221279 26 statefulset.go:2541] stdout of mv -v /tmp/localhost.crt / || true on ss2-1: '/tmp/localhost.crt' -> '/localhost.crt'

  E0127 21:39:42.175738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:43.175770      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:44.176990      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:45.177481      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:46.177708      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:47.177897      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:48.178721      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:49.178967      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:50.179174      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:51.179744      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:39:51.230019 26 statefulset.go:137] Deleting all statefulset in ns statefulset-7085
  I0127 21:39:51.232451 26 rest.go:153] Scaling statefulset ss2 to 0
  E0127 21:39:52.180842      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:53.181050      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:54.181265      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:55.182292      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:56.182841      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:57.183031      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:58.183261      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:39:59.183454      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:00.183668      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:01.184211      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:40:01.246623 26 wait.go:160] Waiting for statefulset status.replicas updated to 0
  I0127 21:40:01.248299 26 rest.go:91] Deleting statefulset ss2
  I0127 21:40:01.259845 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7085" for this suite. @ 01/27/26 21:40:01.262
• [80.634 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:497
  STEP: Creating a kubernetes client @ 01/27/26 21:40:01.27
  I0127 21:40:01.270440 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 21:40:01.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:40:01.298
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:40:01.3
  STEP: Setting up server cert @ 01/27/26 21:40:01.326
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 21:40:01.538
  STEP: Deploying the webhook pod @ 01/27/26 21:40:01.547
  STEP: Wait for the deployment to be ready @ 01/27/26 21:40:01.581
  I0127 21:40:01.594603 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0127 21:40:02.184311      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:03.184833      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/27/26 21:40:03.6
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 21:40:03.622
  I0127 21:40:03.622195 26 wait.go:65] Waiting for amount of service webhook-8286/e2e-test-webhook endpoints to be 1
  I0127 21:40:03.624449 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  E0127 21:40:04.185136      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a mutating webhook configuration @ 01/27/26 21:40:04.624
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 01/27/26 21:40:04.65
  STEP: Creating a configMap that should not be mutated @ 01/27/26 21:40:04.667
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 01/27/26 21:40:04.682
  STEP: Creating a configMap that should be mutated @ 01/27/26 21:40:04.697
  I0127 21:40:04.806438 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8286" for this suite. @ 01/27/26 21:40:04.809
  STEP: Destroying namespace "webhook-markers-5574" for this suite. @ 01/27/26 21:40:04.825
• [3.576 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:54
  STEP: Creating a kubernetes client @ 01/27/26 21:40:04.846
  I0127 21:40:04.846617 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename dns @ 01/27/26 21:40:04.847
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:40:04.873
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:40:04.876
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 01/27/26 21:40:04.878
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 01/27/26 21:40:04.878
  STEP: creating a pod to probe DNS @ 01/27/26 21:40:04.878
  STEP: submitting the pod to kubernetes @ 01/27/26 21:40:04.878
  E0127 21:40:05.185887      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:06.186350      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 01/27/26 21:40:06.97
  STEP: looking for the results for each expected name from probers @ 01/27/26 21:40:06.999
  I0127 21:40:07.067623 26 dns_common.go:546] DNS probes using dns-1439/dns-test-24049bed-6d12-42bb-98f5-33f308561413 succeeded

  STEP: deleting the pod @ 01/27/26 21:40:07.067
  E0127 21:40:07.186879      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:40:07.333635 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-1439" for this suite. @ 01/27/26 21:40:07.393
• [2.687 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 01/27/26 21:40:07.534
  I0127 21:40:07.534361 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename subpath @ 01/27/26 21:40:07.535
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:40:07.679
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:40:07.823
  STEP: Setting up data @ 01/27/26 21:40:07.864
  STEP: Creating pod pod-subpath-test-secret-cmdl @ 01/27/26 21:40:07.979
  STEP: Creating a pod to test atomic-volume-subpath @ 01/27/26 21:40:07.979
  E0127 21:40:08.187860      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:09.188828      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:10.189801      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:11.190846      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:12.191412      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:13.191793      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:14.192478      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:15.192832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:16.193753      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:17.193899      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:18.194844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:19.195056      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:20.195466      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:21.196249      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:22.196810      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:23.197039      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:24.197883      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:25.198120      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:26.198457      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:27.199269      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:28.199725      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:29.200800      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:30.201505      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:31.201801      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:40:32.088
  I0127 21:40:32.090695 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-subpath-test-secret-cmdl container test-container-subpath-secret-cmdl: <nil>
  STEP: delete the pod @ 01/27/26 21:40:32.1
  STEP: Deleting pod pod-subpath-test-secret-cmdl @ 01/27/26 21:40:32.134
  I0127 21:40:32.134589 26 delete.go:78] Deleting pod "pod-subpath-test-secret-cmdl" in namespace "subpath-2588"
  I0127 21:40:32.136195 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-2588" for this suite. @ 01/27/26 21:40:32.137
• [24.612 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 01/27/26 21:40:32.146
  I0127 21:40:32.146702 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename secrets @ 01/27/26 21:40:32.147
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:40:32.164
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:40:32.167
  E0127 21:40:32.202520      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating secret with name s-test-opt-del-5c9a041a-d3c8-42a2-b528-a91e1fbf8d61 @ 01/27/26 21:40:32.238
  STEP: Creating secret with name s-test-opt-upd-442dfdaa-2f62-4b77-9d60-20d6aa1b3fbf @ 01/27/26 21:40:32.253
  STEP: Creating the pod @ 01/27/26 21:40:32.261
  E0127 21:40:33.203361      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:34.203605      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-5c9a041a-d3c8-42a2-b528-a91e1fbf8d61 @ 01/27/26 21:40:34.296
  STEP: Updating secret s-test-opt-upd-442dfdaa-2f62-4b77-9d60-20d6aa1b3fbf @ 01/27/26 21:40:34.305
  STEP: Creating secret with name s-test-opt-create-6cbf135b-b9a5-4efa-9db0-33b455c11fdd @ 01/27/26 21:40:34.313
  STEP: waiting to observe update in volume @ 01/27/26 21:40:34.327
  E0127 21:40:35.204448      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:36.205352      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:37.206301      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:38.206525      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:40:38.352867 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6555" for this suite. @ 01/27/26 21:40:38.355
• [6.217 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Pod InPlace Resize Container guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, c2, decrease cpu & mem on c3 - net increase [MinimumKubeletVersion:1.34] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pod_resize.go:145
  STEP: Creating a kubernetes client @ 01/27/26 21:40:38.363
  I0127 21:40:38.363953 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pod-resize-tests @ 01/27/26 21:40:38.364
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:40:38.386
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:40:38.388
  STEP: creating and verifying pod @ 01/27/26 21:40:38.465
  E0127 21:40:39.207279      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:40.207504      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:41.207799      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:42.208861      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:43.209646      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:44.209872      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:40:44.495735 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c1 - looking for one of the expected cgroup values [20971520] in path /sys/fs/cgroup/memory.max
  I0127 21:40:44.495771 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:40:44.495781 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:40:44.496079 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c1&stderr=true&stdout=true)
  E0127 21:40:45.210350      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:40:45.901877 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c1 - looking for one of the expected cgroup values [2000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:40:45.902098 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:40:45.902140 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:40:45.902192 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c1&stderr=true&stdout=true)
  E0127 21:40:46.210824      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:47.211038      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:40:47.599998 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c1 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 21:40:47.600039 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:40:47.600050 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:40:47.600098 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c1&stderr=true&stdout=true)
  E0127 21:40:48.211329      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:49.212307      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:40:49.300147 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c2 - looking for one of the expected cgroup values [23068672] in path /sys/fs/cgroup/memory.max
  I0127 21:40:49.300190 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:40:49.300201 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:40:49.300246 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c2&stderr=true&stdout=true)
  E0127 21:40:50.212820      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:40:50.641576 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c2 - looking for one of the expected cgroup values [2200 100000 3000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:40:50.641631 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:40:50.641642 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:40:50.641691 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c2&stderr=true&stdout=true)
  E0127 21:40:51.213918      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:40:52.042932 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c2 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 21:40:52.042974 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:40:52.042985 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:40:52.043040 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c2&stderr=true&stdout=true)
  E0127 21:40:52.214785      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:53.214885      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:40:53.541749 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c3 - looking for one of the expected cgroup values [25165824] in path /sys/fs/cgroup/memory.max
  I0127 21:40:53.541791 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:40:53.541803 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:40:53.541851 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c3&stderr=true&stdout=true)
  E0127 21:40:54.215503      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:40:54.705237 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c3 - looking for one of the expected cgroup values [2400 100000 3000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:40:54.705576 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:40:54.705588 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:40:54.705634 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c3&stderr=true&stdout=true)
  E0127 21:40:55.216161      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:40:56.006054 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c3 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 21:40:56.006092 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:40:56.006102 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:40:56.006149 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c3&stderr=true&stdout=true)
  E0127 21:40:56.217059      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:57.217301      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: patching and verifying pod for resize @ 01/27/26 21:40:57.305
  E0127 21:40:58.218340      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:40:59.218503      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:40:59.347979 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c1 - looking for one of the expected cgroup values [26214400] in path /sys/fs/cgroup/memory.max
  I0127 21:40:59.348017 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:40:59.348029 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:40:59.348068 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c1&stderr=true&stdout=true)
  E0127 21:41:00.218956      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:00.703171 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c1 - looking for one of the expected cgroup values [2500 100000 3000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:41:00.703216 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:41:00.703227 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:41:00.703271 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c1&stderr=true&stdout=true)
  E0127 21:41:01.219776      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:02.003073 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c1 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 21:41:02.003116 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:41:02.003130 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:41:02.003181 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c1&stderr=true&stdout=true)
  E0127 21:41:02.220506      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:03.220903      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:03.300898 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c2 - looking for one of the expected cgroup values [28311552] in path /sys/fs/cgroup/memory.max
  I0127 21:41:03.300946 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:41:03.300957 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:41:03.301009 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c2&stderr=true&stdout=true)
  E0127 21:41:04.221132      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:04.541394 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c2 - looking for one of the expected cgroup values [2700 100000 3000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:41:04.541438 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:41:04.541449 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:41:04.541499 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c2&stderr=true&stdout=true)
  E0127 21:41:05.221593      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:05.642689 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c2 - looking for one of the expected cgroup values [1 7] in path /sys/fs/cgroup/cpu.weight
  I0127 21:41:05.642740 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:41:05.642750 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:41:05.642799 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c2&stderr=true&stdout=true)
  E0127 21:41:06.221793      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:06.742812 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c3 - looking for one of the expected cgroup values [19922944] in path /sys/fs/cgroup/memory.max
  I0127 21:41:06.742855 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:41:06.742866 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:41:06.742912 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c3&stderr=true&stdout=true)
  E0127 21:41:07.222609      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:08.222862      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:08.606029 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c3 - looking for one of the expected cgroup values [1900 100000 2000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:41:08.606070 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:41:08.606083 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:41:08.606128 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c3&stderr=true&stdout=true)
  E0127 21:41:09.223473      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:10.223926      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:10.304741 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c3 - looking for one of the expected cgroup values [1 5] in path /sys/fs/cgroup/cpu.weight
  I0127 21:41:10.304797 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:41:10.304809 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:41:10.304863 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c3&stderr=true&stdout=true)
  E0127 21:41:11.224833      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: patching and verifying pod for rollback @ 01/27/26 21:41:12.105
  E0127 21:41:12.225371      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:13.225607      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:14.135689 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c1 - looking for one of the expected cgroup values [20971520] in path /sys/fs/cgroup/memory.max
  I0127 21:41:14.135728 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:41:14.135738 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:41:14.135779 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c1&stderr=true&stdout=true)
  E0127 21:41:14.226275      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:15.227052      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:15.901704 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c1 - looking for one of the expected cgroup values [2000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:41:15.901758 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:41:15.901773 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:41:15.901838 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c1&stderr=true&stdout=true)
  E0127 21:41:16.227281      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:17.227507      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:17.401364 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c1 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 21:41:17.401413 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:41:17.401425 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:41:17.401491 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c1&stderr=true&stdout=true)
  E0127 21:41:18.227856      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:19.201499 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c2 - looking for one of the expected cgroup values [23068672] in path /sys/fs/cgroup/memory.max
  I0127 21:41:19.201548 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:41:19.201561 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:41:19.201606 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c2&stderr=true&stdout=true)
  E0127 21:41:19.228749      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:20.229055      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:20.640101 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c2 - looking for one of the expected cgroup values [2200 100000 3000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:41:20.640142 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:41:20.640156 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:41:20.640202 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c2&stderr=true&stdout=true)
  E0127 21:41:21.229111      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:22.139366 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c2 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 21:41:22.139423 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:41:22.139437 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:41:22.139488 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c2&stderr=true&stdout=true)
  E0127 21:41:22.229227      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:23.229786      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:23.542927 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c3 - looking for one of the expected cgroup values [25165824] in path /sys/fs/cgroup/memory.max
  I0127 21:41:23.542971 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:41:23.542981 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:41:23.543031 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c3&stderr=true&stdout=true)
  E0127 21:41:24.230356      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:24.907886 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c3 - looking for one of the expected cgroup values [2400 100000 3000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:41:24.907930 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:41:24.907941 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:41:24.907989 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c3&stderr=true&stdout=true)
  E0127 21:41:25.231470      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:26.206147 26 cgroups.go:379] Namespace pod-resize-tests-2402 Pod resize-test-6nj75 Container c3 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 21:41:26.206192 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-2402 PodName:resize-test-6nj75 ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:41:26.206202 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:41:26.206254 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-2402/pods/resize-test-6nj75/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c3&stderr=true&stdout=true)
  E0127 21:41:26.232065      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:27.232814      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting pod @ 01/27/26 21:41:27.504
  I0127 21:41:27.545458 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-resize-tests-2402" for this suite. @ 01/27/26 21:41:27.553
• [49.198 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:159
  STEP: Creating a kubernetes client @ 01/27/26 21:41:27.562
  I0127 21:41:27.562420 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename csiinlinevolumes @ 01/27/26 21:41:27.562
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:41:27.584
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:41:27.598
  STEP: Creating two CSIDrivers @ 01/27/26 21:41:27.6
  STEP: Getting "inline-driver-19976591-59ee-4416-abb8-450f796ecb9a" & "inline-driver-f9da5129-2345-44d2-8bd4-55aa00c95c2b" @ 01/27/26 21:41:27.631
  STEP: Patching the CSIDriver "inline-driver-f9da5129-2345-44d2-8bd4-55aa00c95c2b" @ 01/27/26 21:41:27.634
  STEP: Updating the CSIDriver "inline-driver-f9da5129-2345-44d2-8bd4-55aa00c95c2b" @ 01/27/26 21:41:27.644
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-3941" @ 01/27/26 21:41:27.654
  STEP: Deleting CSIDriver "inline-driver-19976591-59ee-4416-abb8-450f796ecb9a" @ 01/27/26 21:41:27.656
  STEP: Confirm deletion of CSIDriver "inline-driver-19976591-59ee-4416-abb8-450f796ecb9a" @ 01/27/26 21:41:27.664
  STEP: Deleting CSIDriver "inline-driver-f9da5129-2345-44d2-8bd4-55aa00c95c2b" via DeleteCollection @ 01/27/26 21:41:27.666
  STEP: Confirm deletion of CSIDriver "inline-driver-f9da5129-2345-44d2-8bd4-55aa00c95c2b" @ 01/27/26 21:41:27.675
  I0127 21:41:27.676466 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-3941" for this suite. @ 01/27/26 21:41:27.678
• [0.124 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:199
  STEP: Creating a kubernetes client @ 01/27/26 21:41:27.687
  I0127 21:41:27.687097 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename emptydir @ 01/27/26 21:41:27.688
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:41:27.722
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:41:27.725
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 01/27/26 21:41:27.727
  E0127 21:41:28.233190      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:29.233595      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:30.233934      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:31.234135      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:41:31.751
  I0127 21:41:31.753427 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-8ddc3a1b-3328-4a9a-bf52-a57f8e6ae24d container test-container: <nil>
  STEP: delete the pod @ 01/27/26 21:41:31.757
  I0127 21:41:31.783141 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5035" for this suite. @ 01/27/26 21:41:31.786
• [4.106 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3556
  STEP: Creating a kubernetes client @ 01/27/26 21:41:31.793
  I0127 21:41:31.793722 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename services @ 01/27/26 21:41:31.794
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:41:31.82
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:41:31.825
  STEP: creating service multiprotocol-test in namespace services-1574 @ 01/27/26 21:41:31.827
  STEP: creating pod pod1 in namespace services-1574 @ 01/27/26 21:41:31.842
  STEP: Creating pod pod1 in namespace services-1574 @ 01/27/26 21:41:31.842
  E0127 21:41:32.234424      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:33.234766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: waiting for EndpointSlices for all ports @ 01/27/26 21:41:33.88
  I0127 21:41:33.880754 26 wait.go:139] Waiting for service services-1574/multiprotocol-test to have endpoints for ports [{tcp-port TCP pod1 80} {udp-port UDP pod1 80}]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 01/27/26 21:41:33.883
  I0127 21:41:33.883364 26 resource.go:344] Creating new exec pod
  E0127 21:41:34.234837      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:35.234906      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:35.895585 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1574 exec execpod82xqw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.29.46 80'
  I0127 21:41:36.002571 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.53.29.46 80\nConnection to 10.53.29.46 80 port [tcp/http] succeeded!\n"
  I0127 21:41:36.002613 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 21:41:36.002674 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1574 exec execpod82xqw -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.53.29.46 80'
  E0127 21:41:36.235623      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:37.235759      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:38.097163 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.53.29.46 80\n"
  I0127 21:41:38.097212 26 builder.go:157] stdout: "pod1"
  STEP: updating the service to have only a TCP port @ 01/27/26 21:41:38.097
  STEP: Checking if the Service forwards traffic to TCP only @ 01/27/26 21:41:38.108
  I0127 21:41:38.108476 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1574 exec execpod82xqw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.29.46 80'
  I0127 21:41:38.209460 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.53.29.46 80\nConnection to 10.53.29.46 80 port [tcp/http] succeeded!\n"
  I0127 21:41:38.209511 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 21:41:38.209596 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1574 exec execpod82xqw -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.53.29.46 80'
  E0127 21:41:38.235972      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:39.236932      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:40.237184      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:40.300406 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.53.29.46 80\n"
  I0127 21:41:40.300456 26 builder.go:157] stdout: ""
  I0127 21:41:40.300514 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1574 exec execpod82xqw -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.53.29.46 80'
  E0127 21:41:41.237878      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:42.238101      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:42.400545 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.53.29.46 80\n"
  I0127 21:41:42.400595 26 builder.go:157] stdout: ""
  I0127 21:41:42.400643 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1574 exec execpod82xqw -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.53.29.46 80'
  E0127 21:41:43.238235      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:44.238496      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:44.499747 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.53.29.46 80\n"
  I0127 21:41:44.499794 26 builder.go:157] stdout: ""
  STEP: updating the service to have only a UDP port @ 01/27/26 21:41:44.499
  STEP: Checking if the Service forwards traffic to UDP only @ 01/27/26 21:41:44.51
  I0127 21:41:44.510935 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1574 exec execpod82xqw -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.53.29.46 80'
  I0127 21:41:44.615124 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.53.29.46 80\n"
  I0127 21:41:44.615162 26 builder.go:157] stdout: ""
  E0127 21:41:45.239243      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:46.239353      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:46.511826 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1574 exec execpod82xqw -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.53.29.46 80'
  E0127 21:41:47.239737      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:48.240863      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:48.607154 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.53.29.46 80\n"
  I0127 21:41:48.607204 26 builder.go:157] stdout: "pod1"
  I0127 21:41:48.607275 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1574 exec execpod82xqw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.29.46 80'
  E0127 21:41:49.241059      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:50.241986      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:50.703342 26 builder.go:145] rc: 1
  I0127 21:41:50.703405 26 util.go:240] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1574 exec execpod82xqw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.29.46 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.53.29.46 80
  nc: connect to 10.53.29.46 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0127 21:41:50.703468 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1574 exec execpod82xqw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.29.46 80'
  E0127 21:41:51.242922      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:52.243129      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:52.799334 26 builder.go:145] rc: 1
  I0127 21:41:52.799401 26 util.go:240] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1574 exec execpod82xqw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.29.46 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.53.29.46 80
  nc: connect to 10.53.29.46 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0127 21:41:52.799470 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1574 exec execpod82xqw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.29.46 80'
  E0127 21:41:53.244148      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:54.244354      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:54.896964 26 builder.go:145] rc: 1
  I0127 21:41:54.897019 26 util.go:240] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1574 exec execpod82xqw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.29.46 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.53.29.46 80
  nc: connect to 10.53.29.46 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0127 21:41:54.897164 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1574" for this suite. @ 01/27/26 21:41:54.899
• [23.114 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:201
  STEP: Creating a kubernetes client @ 01/27/26 21:41:54.907
  I0127 21:41:54.907573 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename custom-resource-definition @ 01/27/26 21:41:54.908
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:41:54.922
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:41:54.933
  STEP: fetching the /apis discovery document @ 01/27/26 21:41:54.935
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 01/27/26 21:41:54.936
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 01/27/26 21:41:54.936
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 01/27/26 21:41:54.936
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 01/27/26 21:41:54.937
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 01/27/26 21:41:54.937
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 01/27/26 21:41:54.939
  I0127 21:41:54.939189 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-8957" for this suite. @ 01/27/26 21:41:55
• [0.105 seconds]
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:348
  STEP: Creating a kubernetes client @ 01/27/26 21:41:55.013
  I0127 21:41:55.013080 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pods @ 01/27/26 21:41:55.013
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:41:55.028
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:41:55.038
  STEP: creating the pod @ 01/27/26 21:41:55.04
  STEP: submitting the pod to kubernetes @ 01/27/26 21:41:55.04
  E0127 21:41:55.245529      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:56.245720      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 01/27/26 21:41:57.085
  STEP: updating the pod @ 01/27/26 21:41:57.087
  E0127 21:41:57.246423      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:41:57.604484 26 pod_client.go:187] Successfully updated pod "pod-update-882de040-fc1d-4f59-99d6-71d665bb30b2"
  STEP: verifying the updated pod is in kubernetes @ 01/27/26 21:41:57.606
  I0127 21:41:57.608046 26 pods.go:394] Pod update OK
  I0127 21:41:57.608162 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9786" for this suite. @ 01/27/26 21:41:57.611
• [2.607 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 01/27/26 21:41:57.62
  I0127 21:41:57.620849 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 21:41:57.621
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:41:57.642
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:41:57.644
  STEP: Creating secret with name projected-secret-test-08356bdf-f9db-45a6-9271-a86bea75230a @ 01/27/26 21:41:57.647
  STEP: Creating a pod to test consume secrets @ 01/27/26 21:41:57.661
  E0127 21:41:58.247609      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:41:59.247969      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:00.248366      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:01.248936      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:42:01.68
  I0127 21:42:01.682561 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-projected-secrets-0a13322c-68d8-4c91-8025-2884c406497d container secret-volume-test: <nil>
  STEP: delete the pod @ 01/27/26 21:42:01.688
  I0127 21:42:01.719340 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4325" for this suite. @ 01/27/26 21:42:01.722
• [4.110 seconds]
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:174
  STEP: Creating a kubernetes client @ 01/27/26 21:42:01.73
  I0127 21:42:01.730425 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 21:42:01.73
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:42:01.754
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:42:01.855
  STEP: Creating configMap with name cm-test-opt-del-c298c455-ccbe-4be1-9128-c173a8fd214e @ 01/27/26 21:42:01.861
  STEP: Creating configMap with name cm-test-opt-upd-4621e917-b2dc-4227-a39c-fe152973d224 @ 01/27/26 21:42:01.868
  STEP: Creating the pod @ 01/27/26 21:42:01.882
  E0127 21:42:02.249259      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:03.249811      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-c298c455-ccbe-4be1-9128-c173a8fd214e @ 01/27/26 21:42:03.915
  STEP: Updating configmap cm-test-opt-upd-4621e917-b2dc-4227-a39c-fe152973d224 @ 01/27/26 21:42:03.923
  STEP: Creating configMap with name cm-test-opt-create-5328e3e6-6714-47eb-a6e0-f1ab36ea4ce3 @ 01/27/26 21:42:03.932
  STEP: waiting to observe update in volume @ 01/27/26 21:42:03.939
  E0127 21:42:04.250844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:05.251608      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:06.252782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:07.252981      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:08.253330      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:09.253533      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:10.253933      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:11.254135      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:12.254806      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:13.254977      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:14.255475      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:15.255763      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:16.256730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:17.256910      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:18.257595      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:19.258246      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:20.259256      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:21.259465      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:22.259586      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:23.259782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:24.260545      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:25.260914      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:26.261725      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:27.263152      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:28.263701      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:29.263748      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:30.264005      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:31.264861      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:32.265557      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:33.265821      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:34.266129      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:35.267128      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:36.267231      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:37.268139      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:38.268301      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:39.269357      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:40.270700      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:41.271112      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:42.271700      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:43.271733      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:44.272738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:45.273362      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:46.273418      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:47.273635      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:48.274447      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:49.274695      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:50.275044      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:51.275252      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:52.275699      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:53.275787      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:54.275994      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:55.276284      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:56.277074      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:57.277932      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:58.278128      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:42:59.278354      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:00.278418      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:01.278623      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:02.279055      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:03.279278      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:04.280350      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:05.280545      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:06.281267      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:07.281473      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:08.282050      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:09.282278      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:10.283322      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:11.284019      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:12.284424      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:13.284847      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:14.285859      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:15.286114      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:16.286203      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:17.286377      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:18.286958      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:19.287178      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:20.287859      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:21.288883      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:22.289723      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:23.289931      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:24.290967      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:25.291217      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:26.291731      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:27.292086      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:28.293074      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:29.293379      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:30.293701      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:31.293909      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:43:32.254577 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-694" for this suite. @ 01/27/26 21:43:32.258
• [90.537 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] CSINodes CSI Conformance should run through the lifecycle of a csinode [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_node.go:56
  STEP: Creating a kubernetes client @ 01/27/26 21:43:32.267
  I0127 21:43:32.267667 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename csinodes @ 01/27/26 21:43:32.268
  E0127 21:43:32.294837      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:43:32.295
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:43:32.299
  STEP: Creating initial csiNode "e2e-csinode-f28wj" @ 01/27/26 21:43:32.302
  STEP: Getting initial csiNode "e2e-csinode-f28wj" @ 01/27/26 21:43:32.31
  STEP: Patching initial csiNode: "e2e-csinode-f28wj" @ 01/27/26 21:43:32.312
  STEP: Listing csiNodes with LabelSelector "e2e-csinode-f28wj=patched" @ 01/27/26 21:43:32.321
  STEP: Delete initial csiNode: "e2e-csinode-f28wj" @ 01/27/26 21:43:32.328
  STEP: Confirm deletion of csiNode "e2e-csinode-f28wj" @ 01/27/26 21:43:32.345
  STEP: Creating replacement csiNode "e2e-csinode-8mzll" @ 01/27/26 21:43:32.348
  STEP: Getting replacement csiNode "e2e-csinode-8mzll" @ 01/27/26 21:43:32.356
  STEP: Updating replacement csiNode "e2e-csinode-8mzll" @ 01/27/26 21:43:32.358
  STEP: DeleteCollection of CSINodes with "e2e-csinode-8mzll=updated" label @ 01/27/26 21:43:32.373
  STEP: Confirm deletion of replacement csiNode with LabelSelector "e2e-csinode-8mzll=updated" @ 01/27/26 21:43:32.381
  I0127 21:43:32.383792 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csinodes-8576" for this suite. @ 01/27/26 21:43:32.386
• [0.127 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:170
  STEP: Creating a kubernetes client @ 01/27/26 21:43:32.394
  I0127 21:43:32.394999 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename cronjob @ 01/27/26 21:43:32.395
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:43:32.411
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:43:32.416
  STEP: Creating a ReplaceConcurrent cronjob @ 01/27/26 21:43:32.418
  STEP: Ensuring a job is scheduled @ 01/27/26 21:43:32.431
  E0127 21:43:33.294886      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:34.295613      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:35.296156      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:36.296846      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:37.297368      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:38.297582      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:39.298106      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:40.298169      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:41.298256      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:42.298649      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:43.299703      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:44.299738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:45.300035      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:46.300234      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:47.300830      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:48.301030      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:49.301663      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:50.302204      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:51.302231      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:52.302444      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:53.302913      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:54.303113      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:55.304247      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:56.304915      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:57.305128      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:58.305394      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:43:59.305944      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:00.306251      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 01/27/26 21:44:00.434
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 01/27/26 21:44:00.436
  STEP: Ensuring the job is replaced with a new one @ 01/27/26 21:44:00.438
  E0127 21:44:01.306338      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:02.306588      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:03.306759      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:04.306969      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:05.307429      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:06.308007      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:07.308837      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:08.309515      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:09.310291      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:10.310519      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:11.311117      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:12.311304      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:13.312394      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:14.313346      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:15.313915      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:16.314142      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:17.315189      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:18.315318      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:19.315758      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:20.316012      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:21.316838      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:22.317343      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:23.317805      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:24.318633      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:25.319276      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:26.319504      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:27.320165      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:28.320261      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:29.320975      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:30.321140      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:31.321300      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:32.321482      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:33.322518      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:34.323500      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:35.324025      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:36.324230      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:37.325150      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:38.325353      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:39.326165      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:40.326309      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:41.326824      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:42.327043      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:43.327963      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:44.328964      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:45.329430      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:46.329639      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:47.329796      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:48.330019      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:49.330638      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:50.330945      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:51.331740      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:52.331857      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:53.332866      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:54.333869      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:55.334513      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:56.334762      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:57.335144      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:58.335727      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:44:59.336828      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:00.336976      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 01/27/26 21:45:00.441
  I0127 21:45:00.458012 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-8959" for this suite. @ 01/27/26 21:45:00.46
• [88.078 seconds]
------------------------------
SS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:143
  STEP: Creating a kubernetes client @ 01/27/26 21:45:00.472
  I0127 21:45:00.472818 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename secrets @ 01/27/26 21:45:00.473
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:45:00.503
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:45:00.604
  STEP: Creating projection with secret that has name secret-emptykey-test-1d586cdb-a065-47de-9111-faab4c0dccc0 @ 01/27/26 21:45:00.607
  I0127 21:45:00.609363 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6176" for this suite. @ 01/27/26 21:45:00.611
• [0.152 seconds]
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 01/27/26 21:45:00.624
  I0127 21:45:00.624950 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename discovery @ 01/27/26 21:45:00.625
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:45:00.641
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:45:00.646
  STEP: Setting up server cert @ 01/27/26 21:45:00.649
  I0127 21:45:00.867066 26 discovery.go:139] Checking APIGroup: apiregistration.k8s.io
  I0127 21:45:00.868107 26 discovery.go:147] PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  I0127 21:45:00.868147 26 discovery.go:148] Versions found [{apiregistration.k8s.io/v1 v1}]
  I0127 21:45:00.868154 26 discovery.go:154] apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  I0127 21:45:00.868162 26 discovery.go:139] Checking APIGroup: apps
  I0127 21:45:00.868868 26 discovery.go:147] PreferredVersion.GroupVersion: apps/v1
  I0127 21:45:00.868894 26 discovery.go:148] Versions found [{apps/v1 v1}]
  I0127 21:45:00.868904 26 discovery.go:154] apps/v1 matches apps/v1
  I0127 21:45:00.868911 26 discovery.go:139] Checking APIGroup: events.k8s.io
  I0127 21:45:00.869543 26 discovery.go:147] PreferredVersion.GroupVersion: events.k8s.io/v1
  I0127 21:45:00.869566 26 discovery.go:148] Versions found [{events.k8s.io/v1 v1}]
  I0127 21:45:00.869574 26 discovery.go:154] events.k8s.io/v1 matches events.k8s.io/v1
  I0127 21:45:00.869581 26 discovery.go:139] Checking APIGroup: authentication.k8s.io
  I0127 21:45:00.870189 26 discovery.go:147] PreferredVersion.GroupVersion: authentication.k8s.io/v1
  I0127 21:45:00.870211 26 discovery.go:148] Versions found [{authentication.k8s.io/v1 v1}]
  I0127 21:45:00.870218 26 discovery.go:154] authentication.k8s.io/v1 matches authentication.k8s.io/v1
  I0127 21:45:00.870228 26 discovery.go:139] Checking APIGroup: authorization.k8s.io
  I0127 21:45:00.870853 26 discovery.go:147] PreferredVersion.GroupVersion: authorization.k8s.io/v1
  I0127 21:45:00.870880 26 discovery.go:148] Versions found [{authorization.k8s.io/v1 v1}]
  I0127 21:45:00.870887 26 discovery.go:154] authorization.k8s.io/v1 matches authorization.k8s.io/v1
  I0127 21:45:00.870894 26 discovery.go:139] Checking APIGroup: autoscaling
  I0127 21:45:00.871499 26 discovery.go:147] PreferredVersion.GroupVersion: autoscaling/v2
  I0127 21:45:00.871522 26 discovery.go:148] Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  I0127 21:45:00.871531 26 discovery.go:154] autoscaling/v2 matches autoscaling/v2
  I0127 21:45:00.871538 26 discovery.go:139] Checking APIGroup: batch
  I0127 21:45:00.872225 26 discovery.go:147] PreferredVersion.GroupVersion: batch/v1
  I0127 21:45:00.872244 26 discovery.go:148] Versions found [{batch/v1 v1}]
  I0127 21:45:00.872251 26 discovery.go:154] batch/v1 matches batch/v1
  I0127 21:45:00.872258 26 discovery.go:139] Checking APIGroup: certificates.k8s.io
  I0127 21:45:00.872859 26 discovery.go:147] PreferredVersion.GroupVersion: certificates.k8s.io/v1
  I0127 21:45:00.872875 26 discovery.go:148] Versions found [{certificates.k8s.io/v1 v1}]
  I0127 21:45:00.872882 26 discovery.go:154] certificates.k8s.io/v1 matches certificates.k8s.io/v1
  I0127 21:45:00.872889 26 discovery.go:139] Checking APIGroup: networking.k8s.io
  I0127 21:45:00.873975 26 discovery.go:147] PreferredVersion.GroupVersion: networking.k8s.io/v1
  I0127 21:45:00.873998 26 discovery.go:148] Versions found [{networking.k8s.io/v1 v1}]
  I0127 21:45:00.874006 26 discovery.go:154] networking.k8s.io/v1 matches networking.k8s.io/v1
  I0127 21:45:00.874014 26 discovery.go:139] Checking APIGroup: policy
  I0127 21:45:00.875477 26 discovery.go:147] PreferredVersion.GroupVersion: policy/v1
  I0127 21:45:00.875498 26 discovery.go:148] Versions found [{policy/v1 v1}]
  I0127 21:45:00.875505 26 discovery.go:154] policy/v1 matches policy/v1
  I0127 21:45:00.875513 26 discovery.go:139] Checking APIGroup: rbac.authorization.k8s.io
  I0127 21:45:00.876193 26 discovery.go:147] PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  I0127 21:45:00.876210 26 discovery.go:148] Versions found [{rbac.authorization.k8s.io/v1 v1}]
  I0127 21:45:00.876217 26 discovery.go:154] rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  I0127 21:45:00.876224 26 discovery.go:139] Checking APIGroup: storage.k8s.io
  I0127 21:45:00.876782 26 discovery.go:147] PreferredVersion.GroupVersion: storage.k8s.io/v1
  I0127 21:45:00.876804 26 discovery.go:148] Versions found [{storage.k8s.io/v1 v1}]
  I0127 21:45:00.876812 26 discovery.go:154] storage.k8s.io/v1 matches storage.k8s.io/v1
  I0127 21:45:00.876820 26 discovery.go:139] Checking APIGroup: admissionregistration.k8s.io
  I0127 21:45:00.877376 26 discovery.go:147] PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  I0127 21:45:00.877392 26 discovery.go:148] Versions found [{admissionregistration.k8s.io/v1 v1}]
  I0127 21:45:00.877399 26 discovery.go:154] admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  I0127 21:45:00.877406 26 discovery.go:139] Checking APIGroup: apiextensions.k8s.io
  I0127 21:45:00.877929 26 discovery.go:147] PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  I0127 21:45:00.877947 26 discovery.go:148] Versions found [{apiextensions.k8s.io/v1 v1}]
  I0127 21:45:00.877954 26 discovery.go:154] apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  I0127 21:45:00.877961 26 discovery.go:139] Checking APIGroup: scheduling.k8s.io
  I0127 21:45:00.878596 26 discovery.go:147] PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  I0127 21:45:00.878617 26 discovery.go:148] Versions found [{scheduling.k8s.io/v1 v1}]
  I0127 21:45:00.878625 26 discovery.go:154] scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  I0127 21:45:00.878633 26 discovery.go:139] Checking APIGroup: coordination.k8s.io
  I0127 21:45:00.879169 26 discovery.go:147] PreferredVersion.GroupVersion: coordination.k8s.io/v1
  I0127 21:45:00.879184 26 discovery.go:148] Versions found [{coordination.k8s.io/v1 v1}]
  I0127 21:45:00.879192 26 discovery.go:154] coordination.k8s.io/v1 matches coordination.k8s.io/v1
  I0127 21:45:00.879199 26 discovery.go:139] Checking APIGroup: node.k8s.io
  I0127 21:45:00.879884 26 discovery.go:147] PreferredVersion.GroupVersion: node.k8s.io/v1
  I0127 21:45:00.879902 26 discovery.go:148] Versions found [{node.k8s.io/v1 v1}]
  I0127 21:45:00.879909 26 discovery.go:154] node.k8s.io/v1 matches node.k8s.io/v1
  I0127 21:45:00.879921 26 discovery.go:139] Checking APIGroup: discovery.k8s.io
  I0127 21:45:00.880661 26 discovery.go:147] PreferredVersion.GroupVersion: discovery.k8s.io/v1
  I0127 21:45:00.880694 26 discovery.go:148] Versions found [{discovery.k8s.io/v1 v1}]
  I0127 21:45:00.880703 26 discovery.go:154] discovery.k8s.io/v1 matches discovery.k8s.io/v1
  I0127 21:45:00.880710 26 discovery.go:139] Checking APIGroup: resource.k8s.io
  I0127 21:45:00.881399 26 discovery.go:147] PreferredVersion.GroupVersion: resource.k8s.io/v1
  I0127 21:45:00.881420 26 discovery.go:148] Versions found [{resource.k8s.io/v1 v1}]
  I0127 21:45:00.881427 26 discovery.go:154] resource.k8s.io/v1 matches resource.k8s.io/v1
  I0127 21:45:00.881433 26 discovery.go:139] Checking APIGroup: flowcontrol.apiserver.k8s.io
  I0127 21:45:00.882047 26 discovery.go:147] PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  I0127 21:45:00.882069 26 discovery.go:148] Versions found [{flowcontrol.apiserver.k8s.io/v1 v1}]
  I0127 21:45:00.882077 26 discovery.go:154] flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  I0127 21:45:00.882084 26 discovery.go:139] Checking APIGroup: gateway.networking.k8s.io
  I0127 21:45:00.883300 26 discovery.go:147] PreferredVersion.GroupVersion: gateway.networking.k8s.io/v1
  I0127 21:45:00.883321 26 discovery.go:148] Versions found [{gateway.networking.k8s.io/v1 v1} {gateway.networking.k8s.io/v1beta1 v1beta1}]
  I0127 21:45:00.883328 26 discovery.go:154] gateway.networking.k8s.io/v1 matches gateway.networking.k8s.io/v1
  I0127 21:45:00.883334 26 discovery.go:139] Checking APIGroup: helm.cattle.io
  I0127 21:45:00.883973 26 discovery.go:147] PreferredVersion.GroupVersion: helm.cattle.io/v1
  I0127 21:45:00.883994 26 discovery.go:148] Versions found [{helm.cattle.io/v1 v1}]
  I0127 21:45:00.884001 26 discovery.go:154] helm.cattle.io/v1 matches helm.cattle.io/v1
  I0127 21:45:00.884009 26 discovery.go:139] Checking APIGroup: k3s.cattle.io
  I0127 21:45:00.884955 26 discovery.go:147] PreferredVersion.GroupVersion: k3s.cattle.io/v1
  I0127 21:45:00.884979 26 discovery.go:148] Versions found [{k3s.cattle.io/v1 v1}]
  I0127 21:45:00.884989 26 discovery.go:154] k3s.cattle.io/v1 matches k3s.cattle.io/v1
  I0127 21:45:00.884997 26 discovery.go:139] Checking APIGroup: hub.traefik.io
  I0127 21:45:00.885571 26 discovery.go:147] PreferredVersion.GroupVersion: hub.traefik.io/v1alpha1
  I0127 21:45:00.885589 26 discovery.go:148] Versions found [{hub.traefik.io/v1alpha1 v1alpha1}]
  I0127 21:45:00.885597 26 discovery.go:154] hub.traefik.io/v1alpha1 matches hub.traefik.io/v1alpha1
  I0127 21:45:00.885603 26 discovery.go:139] Checking APIGroup: traefik.io
  I0127 21:45:00.886240 26 discovery.go:147] PreferredVersion.GroupVersion: traefik.io/v1alpha1
  I0127 21:45:00.886256 26 discovery.go:148] Versions found [{traefik.io/v1alpha1 v1alpha1}]
  I0127 21:45:00.886262 26 discovery.go:154] traefik.io/v1alpha1 matches traefik.io/v1alpha1
  I0127 21:45:00.886269 26 discovery.go:139] Checking APIGroup: metrics.k8s.io
  I0127 21:45:00.887690 26 discovery.go:147] PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
  I0127 21:45:00.887711 26 discovery.go:148] Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
  I0127 21:45:00.887719 26 discovery.go:154] metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
  I0127 21:45:00.887872 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-7916" for this suite. @ 01/27/26 21:45:00.892
• [0.282 seconds]
------------------------------
SS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:504
  STEP: Creating a kubernetes client @ 01/27/26 21:45:00.907
  I0127 21:45:00.907383 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename configmap @ 01/27/26 21:45:00.907
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:45:00.927
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:45:00.929
  I0127 21:45:00.989069 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6926" for this suite. @ 01/27/26 21:45:01.002
• [0.104 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:197
  STEP: Creating a kubernetes client @ 01/27/26 21:45:01.012
  I0127 21:45:01.012028 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename downward-api @ 01/27/26 21:45:01.013
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:45:01.038
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:45:01.04
  STEP: Creating a pod to test downward api env vars @ 01/27/26 21:45:01.043
  E0127 21:45:01.337019      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:02.337215      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:03.337305      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:04.337551      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:45:05.068
  I0127 21:45:05.071031 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downward-api-0a189460-dd78-409b-b70e-1d0416e28321 container dapi-container: <nil>
  STEP: delete the pod @ 01/27/26 21:45:05.08
  I0127 21:45:05.115711 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4396" for this suite. @ 01/27/26 21:45:05.118
• [4.116 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:339
  STEP: Creating a kubernetes client @ 01/27/26 21:45:05.128
  I0127 21:45:05.128405 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename resourcequota @ 01/27/26 21:45:05.128
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:45:05.155
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:45:05.157
  E0127 21:45:05.337614      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:06.338730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:07.339522      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:08.340250      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:09.340519      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:10.340924      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:11.341311      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:12.342369      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:13.342900      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:14.343538      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:15.344076      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:16.344534      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:17.344822      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:18.345596      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:19.345615      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:20.345952      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:21.346739      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 01/27/26 21:45:22.162
  E0127 21:45:22.347476      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:23.347769      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:24.347908      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:25.348923      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:26.349710      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 01/27/26 21:45:27.166
  STEP: Ensuring resource quota status is calculated @ 01/27/26 21:45:27.181
  E0127 21:45:27.350707      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:28.350910      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:45:29.187502 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc000d852c0>: 
          metadata:
            creationTimestamp: "2026-01-27T21:45:27Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:45:27Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T21:45:27Z"
            name: test-quota
            namespace: resourcequota-8260
            resourceVersion: "45040"
            uid: 5adb3756-d1e5-4111-818f-171a43678750
          spec:
            hard:
              configmaps: "2"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "2"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Creating a ConfigMap @ 01/27/26 21:45:29.187
  STEP: Ensuring resource quota status captures configMap creation @ 01/27/26 21:45:29.209
  I0127 21:45:29.212457 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001696000>: 
          metadata:
            creationTimestamp: "2026-01-27T21:45:27Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:45:27Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T21:45:29Z"
            name: test-quota
            namespace: resourcequota-8260
            resourceVersion: "45047"
            uid: 5adb3756-d1e5-4111-818f-171a43678750
          spec:
            hard:
              configmaps: "2"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "2"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "2"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Deleting a ConfigMap @ 01/27/26 21:45:29.212
  STEP: Ensuring resource quota status released usage @ 01/27/26 21:45:29.22
  E0127 21:45:29.351157      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:30.351209      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:45:31.226361 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001466dc0>: 
          metadata:
            creationTimestamp: "2026-01-27T21:45:27Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:45:27Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T21:45:29Z"
            name: test-quota
            namespace: resourcequota-8260
            resourceVersion: "45050"
            uid: 5adb3756-d1e5-4111-818f-171a43678750
          spec:
            hard:
              configmaps: "2"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "2"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  I0127 21:45:31.227246 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8260" for this suite. @ 01/27/26 21:45:31.229
• [26.121 seconds]
------------------------------
S
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:113
  STEP: Creating a kubernetes client @ 01/27/26 21:45:31.249
  I0127 21:45:31.249299 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename disruption @ 01/27/26 21:45:31.25
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:45:31.271
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:45:31.272
  STEP: creating the pdb @ 01/27/26 21:45:31.275
  STEP: Waiting for the pdb to be processed @ 01/27/26 21:45:31.283
  E0127 21:45:31.351352      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:32.351896      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: updating the pdb @ 01/27/26 21:45:33.286
  STEP: Waiting for the pdb to be processed @ 01/27/26 21:45:33.296
  E0127 21:45:33.352360      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:34.352809      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: patching the pdb @ 01/27/26 21:45:35.299
  STEP: Waiting for the pdb to be processed @ 01/27/26 21:45:35.309
  E0127 21:45:35.353670      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:36.353894      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be deleted @ 01/27/26 21:45:37.32
  I0127 21:45:37.322309 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-8944" for this suite. @ 01/27/26 21:45:37.324
• [6.084 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] API Server should provide secure master service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/apiserver.go:48
  STEP: Creating a kubernetes client @ 01/27/26 21:45:37.333
  I0127 21:45:37.333604 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename apiserver @ 01/27/26 21:45:37.334
  E0127 21:45:37.354240      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:45:37.359
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:45:37.361
  I0127 21:45:37.365798 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apiserver-3706" for this suite. @ 01/27/26 21:45:37.425
• [0.100 seconds]
------------------------------
S
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:732
  STEP: Creating a kubernetes client @ 01/27/26 21:45:37.433
  I0127 21:45:37.433665 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename services @ 01/27/26 21:45:37.434
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:45:37.455
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:45:37.456
  STEP: creating service endpoint-test2 in namespace services-3163 @ 01/27/26 21:45:37.463
  I0127 21:45:37.485143 26 wait.go:65] Waiting for amount of service services-3163/endpoint-test2 endpoints to be 0
  I0127 21:45:37.488341 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  E0127 21:45:38.354775      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: creating first endpoint pod for service @ 01/27/26 21:45:38.488
  STEP: Creating pod pod1 in namespace services-3163 @ 01/27/26 21:45:38.488
  E0127 21:45:39.355635      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:40.355755      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:45:40.505553 26 wait.go:96] Waiting for service services-3163/endpoint-test2 to have endpoints pointing to [pod1]
  STEP: Checking if the Service forwards traffic to pod1 @ 01/27/26 21:45:40.508
  I0127 21:45:40.508504 26 resource.go:344] Creating new exec pod
  E0127 21:45:41.355757      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:42.357174      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:45:42.531212 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-3163 exec execpod7x52w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0127 21:45:42.639986 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 (10.53.212.150) 80 port [tcp/http] succeeded!\n"
  I0127 21:45:42.640031 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 21:45:42.640096 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-3163 exec execpod7x52w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.212.150 80'
  I0127 21:45:42.750738 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.53.212.150 80\nConnection to 10.53.212.150 80 port [tcp/http] succeeded!\n"
  I0127 21:45:42.750779 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: creating second endpoint pod for service @ 01/27/26 21:45:42.75
  STEP: Creating pod pod2 in namespace services-3163 @ 01/27/26 21:45:42.75
  E0127 21:45:43.357910      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:44.358109      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:45:44.781336 26 wait.go:96] Waiting for service services-3163/endpoint-test2 to have endpoints pointing to [pod1 pod2]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 01/27/26 21:45:44.783
  I0127 21:45:44.784930 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-3163 exec execpod7x52w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0127 21:45:44.897019 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 (10.53.212.150) 80 port [tcp/http] succeeded!\n"
  I0127 21:45:44.897072 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 21:45:44.897136 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-3163 exec execpod7x52w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.212.150 80'
  I0127 21:45:45.002736 26 builder.go:156] stderr: "+ nc -v -t -w 2 10.53.212.150 80\n+ echo hostName\nConnection to 10.53.212.150 80 port [tcp/http] succeeded!\n"
  I0127 21:45:45.002781 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: deleting first endpoint pod @ 01/27/26 21:45:45.002
  STEP: Deleting pod pod1 in namespace services-3163 @ 01/27/26 21:45:45.002
  I0127 21:45:45.024612 26 wait.go:96] Waiting for service services-3163/endpoint-test2 to have endpoints pointing to [pod2]
  I0127 21:45:45.035698 26 wait.go:114] Unexpected endpoints on slices, missing: [], extra: [pod1]
  E0127 21:45:45.358825      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Checking if the Service forwards traffic to pod2 @ 01/27/26 21:45:46.027
  I0127 21:45:46.030028 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-3163 exec execpod7x52w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0127 21:45:46.142583 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 (10.53.212.150) 80 port [tcp/http] succeeded!\n"
  I0127 21:45:46.142627 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 21:45:46.142698 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-3163 exec execpod7x52w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.212.150 80'
  I0127 21:45:46.252465 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.53.212.150 80\nConnection to 10.53.212.150 80 port [tcp/http] succeeded!\n"
  I0127 21:45:46.252506 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: deleting second endpoint pod @ 01/27/26 21:45:46.252
  STEP: Deleting pod pod2 in namespace services-3163 @ 01/27/26 21:45:46.252
  I0127 21:45:46.288439 26 wait.go:65] Waiting for amount of service services-3163/endpoint-test2 endpoints to be 0
  I0127 21:45:46.290641 26 wait.go:83] Unexpected number of Endpoints on Slices, got 1, expected 0
  E0127 21:45:46.359125      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:45:47.329418 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3163" for this suite. @ 01/27/26 21:45:47.331
• [9.906 seconds]
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:162
  STEP: Creating a kubernetes client @ 01/27/26 21:45:47.339
  I0127 21:45:47.339368 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename deployment @ 01/27/26 21:45:47.339
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:45:47.354
  E0127 21:45:47.359453      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:45:47.365
  I0127 21:45:47.368022 26 deployment.go:1219] Creating deployment "webserver-deployment"
  I0127 21:45:47.376398 26 deployment.go:1223] Waiting for observed generation 1
  E0127 21:45:48.360074      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:49.360183      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:45:49.402087 26 deployment.go:1228] Waiting for all required pods to come up
  I0127 21:45:49.557066 26 resource.go:64] Pod name agnhost: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 01/27/26 21:45:49.557
  E0127 21:45:50.360817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:51.361181      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:52.361721      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:53.362021      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:54.362889      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:55.363429      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:56.363779      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:57.364830      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:58.365300      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:45:59.365521      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:46:00.185425 26 deployment.go:1232] Waiting for deployment "webserver-deployment" to complete
  I0127 21:46:00.197670 26 deployment.go:1241] Updating deployment "webserver-deployment" with a non-existent image
  I0127 21:46:00.212875 26 deployment.go:314] Updating deployment webserver-deployment
  I0127 21:46:00.212909 26 deployment.go:1247] Waiting for observed generation 2
  E0127 21:46:00.365922      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:01.366065      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:02.366125      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:46:02.393203 26 deployment.go:1257] Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  I0127 21:46:02.395029 26 deployment.go:1262] Waiting for the first rollout's replicaset to have .spec.replicas = 8
  I0127 21:46:02.401896 26 deployment.go:1267] Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0127 21:46:02.406554 26 deployment.go:1281] Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  I0127 21:46:02.406590 26 deployment.go:1286] Waiting for the second rollout's replicaset to have .spec.replicas = 5
  I0127 21:46:02.408423 26 deployment.go:1291] Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0127 21:46:02.412279 26 deployment.go:1298] Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  I0127 21:46:02.412305 26 deployment.go:1306] Scaling up the deployment "webserver-deployment" from 10 to 30
  I0127 21:46:02.597195 26 deployment.go:314] Updating deployment webserver-deployment
  I0127 21:46:02.597249 26 deployment.go:1312] Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  I0127 21:46:02.612076 26 deployment.go:1320] Verifying that first rollout's replicaset has .spec.replicas = 20
  E0127 21:46:03.367074      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:04.367537      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:46:04.707894 26 deployment.go:1326] Verifying that second rollout's replicaset has .spec.replicas = 13
  I0127 21:46:05.018300 26 deployment.go:636] Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "90f552ba-8f70-478b-8935-693dcf649c72",
      ResourceVersion: (string) (len=5) "45552",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147147,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=7) "agnhost"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=568) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 74 65 72  |licas":{},"f:ter|
              000001f0  6d 69 6e 61 74 69 6e 67  52 65 70 6c 69 63 61 73  |minatingReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 6e 61 76 61 69 6c 61  |":{},"f:unavaila|
              00000210  62 6c 65 52 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |bleReplicas":{},|
              00000220  22 66 3a 75 70 64 61 74  65 64 52 65 70 6c 69 63  |"f:updatedReplic|
              00000230  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=7) "agnhost"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=7) "agnhost"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 3,
      Replicas: (int32) 33,
      UpdatedReplicas: (int32) 13,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 25,
      TerminatingReplicas: (*int32)(0),
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=60) "ReplicaSet \"webserver-deployment-5d75f69fd6\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0127 21:46:05.204480 26 deployment.go:40] New ReplicaSet "webserver-deployment-5d75f69fd6" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-5d75f69fd6",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "452b5840-b3a5-4f17-abcd-1307699bab79",
      ResourceVersion: (string) (len=5) "45540",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147160,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d75f69fd6"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "90f552ba-8f70-478b-8935-693dcf649c72",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 30 66 35 35 32  62 61 2d 38 66 37 30 2d  |\"90f552ba-8f70-|
              00000120  34 37 38 62 2d 38 39 33  35 2d 36 39 33 64 63 66  |478b-8935-693dcf|
              00000130  36 34 39 63 37 32 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |649c72\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=111) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6e  |{},"f:terminatin|
              00000060  67 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |gReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=7) "agnhost",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d75f69fd6"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=7) "agnhost",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d75f69fd6"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 13,
      FullyLabeledReplicas: (int32) 13,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(0),
      ObservedGeneration: (int64) 3,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0127 21:46:05.205251 26 deployment.go:45] All old ReplicaSets of Deployment "webserver-deployment":
  I0127 21:46:05.205401 26 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-79f99d89dd",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
      ResourceVersion: (string) (len=5) "45546",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147147,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "90f552ba-8f70-478b-8935-693dcf649c72",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 30 66 35 35 32  62 61 2d 38 66 37 30 2d  |\"90f552ba-8f70-|
              00000120  34 37 38 62 2d 38 39 33  35 2d 36 39 33 64 63 66  |478b-8935-693dcf|
              00000130  36 34 39 63 37 32 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |649c72\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=157) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6e 67 52  |,"f:terminatingR|
              00000090  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=7) "agnhost",
          (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=7) "agnhost",
            (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 20,
      FullyLabeledReplicas: (int32) 20,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      TerminatingReplicas: (*int32)(0),
      ObservedGeneration: (int64) 3,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0127 21:46:05.225638 26 deployment.go:68] Pod "webserver-deployment-5d75f69fd6-2pbkv" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-5d75f69fd6-2pbkv",
      GenerateName: (string) (len=32) "webserver-deployment-5d75f69fd6-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "086e443b-ba2f-42d6-a0ce-db2988fc3ed5",
      ResourceVersion: (string) (len=5) "45570",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d75f69fd6"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-5d75f69fd6",
          UID: (types.UID) (len=36) "452b5840-b3a5-4f17-abcd-1307699bab79",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 35  32 62 35 38 34 30 2d 62  |d\":\"452b5840-b|
              00000090  33 61 35 2d 34 66 31 37  2d 61 62 63 64 2d 31 33  |3a5-4f17-abcd-13|
              000000a0  30 37 36 39 39 62 61 62  37 39 5c 22 7d 22 3a 7b  |07699bab79\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147164,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-fhqx2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-fhqx2",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.10",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.10"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147163,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-fhqx2",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.227361 26 deployment.go:68] Pod "webserver-deployment-5d75f69fd6-2q2n6" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-5d75f69fd6-2q2n6",
      GenerateName: (string) (len=32) "webserver-deployment-5d75f69fd6-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3eda34bb-ff24-4cab-8acc-5da541909e8e",
      ResourceVersion: (string) (len=5) "45457",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147160,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d75f69fd6"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-5d75f69fd6",
          UID: (types.UID) (len=36) "452b5840-b3a5-4f17-abcd-1307699bab79",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 35  32 62 35 38 34 30 2d 62  |d\":\"452b5840-b|
              00000090  33 61 35 2d 34 66 31 37  2d 61 62 63 64 2d 31 33  |3a5-4f17-abcd-13|
              000000a0  30 37 36 39 39 62 61 62  37 39 5c 22 7d 22 3a 7b  |07699bab79\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=894) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 70  |eration":{},"f:p|
              00000320  6f 64 49 50 22 3a 7b 7d  2c 22 66 3a 70 6f 64 49  |odIP":{},"f:podI|
              00000330  50 73 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 6b 3a 7b  |Ps":{".":{},"k:{|
              00000340  5c 22 69 70 5c 22 3a 5c  22 31 30 2e 35 32 2e 30  |\"ip\":\"10.52.0|
              00000350  2e 33 30 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |.30\"}":{".":{},|
              00000360  22 66 3a 69 70 22 3a 7b  7d 7d 7d 2c 22 66 3a 73  |"f:ip":{}}},"f:s|
              00000370  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6xk9j",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6xk9j",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.12",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.12"
        }
      },
      PodIP: (string) (len=10) "10.52.0.30",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.52.0.30"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147160,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-6xk9j",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.229660 26 deployment.go:68] Pod "webserver-deployment-5d75f69fd6-44vjn" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-5d75f69fd6-44vjn",
      GenerateName: (string) (len=32) "webserver-deployment-5d75f69fd6-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a847f18f-5188-4308-b6e8-9a9a6d746865",
      ResourceVersion: (string) (len=5) "45564",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147160,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d75f69fd6"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-5d75f69fd6",
          UID: (types.UID) (len=36) "452b5840-b3a5-4f17-abcd-1307699bab79",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 35  32 62 35 38 34 30 2d 62  |d\":\"452b5840-b|
              00000090  33 61 35 2d 34 66 31 37  2d 61 62 63 64 2d 31 33  |3a5-4f17-abcd-13|
              000000a0  30 37 36 39 39 62 61 62  37 39 5c 22 7d 22 3a 7b  |07699bab79\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147164,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=895) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 70  |eration":{},"f:p|
              00000320  6f 64 49 50 22 3a 7b 7d  2c 22 66 3a 70 6f 64 49  |odIP":{},"f:podI|
              00000330  50 73 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 6b 3a 7b  |Ps":{".":{},"k:{|
              00000340  5c 22 69 70 5c 22 3a 5c  22 31 30 2e 35 32 2e 31  |\"ip\":\"10.52.1|
              00000350  2e 31 39 39 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |.199\"}":{".":{}|
              00000360  2c 22 66 3a 69 70 22 3a  7b 7d 7d 7d 2c 22 66 3a  |,"f:ip":{}}},"f:|
              00000370  73 74 61 72 74 54 69 6d  65 22 3a 7b 7d 7d 7d     |startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ncvfs",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ncvfs",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.10",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.10"
        }
      },
      PodIP: (string) (len=11) "10.52.1.199",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.52.1.199"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147160,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-ncvfs",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.232510 26 deployment.go:68] Pod "webserver-deployment-5d75f69fd6-59qfg" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-5d75f69fd6-59qfg",
      GenerateName: (string) (len=32) "webserver-deployment-5d75f69fd6-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c0e6ec42-1b73-46d6-95ae-a61fd9c1632c",
      ResourceVersion: (string) (len=5) "45421",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147160,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d75f69fd6"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-5d75f69fd6",
          UID: (types.UID) (len=36) "452b5840-b3a5-4f17-abcd-1307699bab79",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 35  32 62 35 38 34 30 2d 62  |d\":\"452b5840-b|
              00000090  33 61 35 2d 34 66 31 37  2d 61 62 63 64 2d 31 33  |3a5-4f17-abcd-13|
              000000a0  30 37 36 39 39 62 61 62  37 39 5c 22 7d 22 3a 7b  |07699bab79\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-txtx7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-txtx7",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.10",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.10"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147160,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-txtx7",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.234238 26 deployment.go:68] Pod "webserver-deployment-5d75f69fd6-6j7zd" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-5d75f69fd6-6j7zd",
      GenerateName: (string) (len=32) "webserver-deployment-5d75f69fd6-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6ab13b86-b150-4b1d-ab2e-bd8147f058f5",
      ResourceVersion: (string) (len=5) "45575",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d75f69fd6",
        (string) (len=4) "name": (string) (len=7) "agnhost"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-5d75f69fd6",
          UID: (types.UID) (len=36) "452b5840-b3a5-4f17-abcd-1307699bab79",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 35  32 62 35 38 34 30 2d 62  |d\":\"452b5840-b|
              00000090  33 61 35 2d 34 66 31 37  2d 61 62 63 64 2d 31 33  |3a5-4f17-abcd-13|
              000000a0  30 37 36 39 39 62 61 62  37 39 5c 22 7d 22 3a 7b  |07699bab79\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147164,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jp9hj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jp9hj",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.10",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.10"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147163,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-jp9hj",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.236823 26 deployment.go:68] Pod "webserver-deployment-5d75f69fd6-flhzj" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-5d75f69fd6-flhzj",
      GenerateName: (string) (len=32) "webserver-deployment-5d75f69fd6-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4bc78a17-edf1-49de-ad89-927bc8d100b8",
      ResourceVersion: (string) (len=5) "45542",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d75f69fd6"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-5d75f69fd6",
          UID: (types.UID) (len=36) "452b5840-b3a5-4f17-abcd-1307699bab79",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 35  32 62 35 38 34 30 2d 62  |d\":\"452b5840-b|
              00000090  33 61 35 2d 34 66 31 37  2d 61 62 63 64 2d 31 33  |3a5-4f17-abcd-13|
              000000a0  30 37 36 39 39 62 61 62  37 39 5c 22 7d 22 3a 7b  |07699bab79\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-t69xx",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-t69xx",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.12",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.12"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147163,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-t69xx",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.238721 26 deployment.go:68] Pod "webserver-deployment-5d75f69fd6-lsxxn" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-5d75f69fd6-lsxxn",
      GenerateName: (string) (len=32) "webserver-deployment-5d75f69fd6-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8c2cdded-a9a6-4451-b005-1c592981aa76",
      ResourceVersion: (string) (len=5) "45506",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d75f69fd6",
        (string) (len=4) "name": (string) (len=7) "agnhost"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-5d75f69fd6",
          UID: (types.UID) (len=36) "452b5840-b3a5-4f17-abcd-1307699bab79",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 35  32 62 35 38 34 30 2d 62  |d\":\"452b5840-b|
              00000090  33 61 35 2d 34 66 31 37  2d 61 62 63 64 2d 31 33  |3a5-4f17-abcd-13|
              000000a0  30 37 36 39 39 62 61 62  37 39 5c 22 7d 22 3a 7b  |07699bab79\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ngsmt",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ngsmt",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.12",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.12"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-ngsmt",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.241972 26 deployment.go:68] Pod "webserver-deployment-5d75f69fd6-lx4hz" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-5d75f69fd6-lx4hz",
      GenerateName: (string) (len=32) "webserver-deployment-5d75f69fd6-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8d2a5d2d-b041-4219-b59e-0e18d4ef1e0a",
      ResourceVersion: (string) (len=5) "45511",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d75f69fd6"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-5d75f69fd6",
          UID: (types.UID) (len=36) "452b5840-b3a5-4f17-abcd-1307699bab79",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 35  32 62 35 38 34 30 2d 62  |d\":\"452b5840-b|
              00000090  33 61 35 2d 34 66 31 37  2d 61 62 63 64 2d 31 33  |3a5-4f17-abcd-13|
              000000a0  30 37 36 39 39 62 61 62  37 39 5c 22 7d 22 3a 7b  |07699bab79\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-b68c7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-b68c7",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.244500 26 deployment.go:68] Pod "webserver-deployment-5d75f69fd6-q24pk" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-5d75f69fd6-q24pk",
      GenerateName: (string) (len=32) "webserver-deployment-5d75f69fd6-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1dc7eeee-b22c-482c-95a1-800476830712",
      ResourceVersion: (string) (len=5) "45555",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147160,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d75f69fd6"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-5d75f69fd6",
          UID: (types.UID) (len=36) "452b5840-b3a5-4f17-abcd-1307699bab79",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 35  32 62 35 38 34 30 2d 62  |d\":\"452b5840-b|
              00000090  33 61 35 2d 34 66 31 37  2d 61 62 63 64 2d 31 33  |3a5-4f17-abcd-13|
              000000a0  30 37 36 39 39 62 61 62  37 39 5c 22 7d 22 3a 7b  |07699bab79\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=895) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 70  |eration":{},"f:p|
              00000320  6f 64 49 50 22 3a 7b 7d  2c 22 66 3a 70 6f 64 49  |odIP":{},"f:podI|
              00000330  50 73 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 6b 3a 7b  |Ps":{".":{},"k:{|
              00000340  5c 22 69 70 5c 22 3a 5c  22 31 30 2e 35 32 2e 31  |\"ip\":\"10.52.1|
              00000350  2e 31 39 37 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |.197\"}":{".":{}|
              00000360  2c 22 66 3a 69 70 22 3a  7b 7d 7d 7d 2c 22 66 3a  |,"f:ip":{}}},"f:|
              00000370  73 74 61 72 74 54 69 6d  65 22 3a 7b 7d 7d 7d     |startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gqgwx",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gqgwx",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.10",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.10"
        }
      },
      PodIP: (string) (len=11) "10.52.1.197",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.52.1.197"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147160,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-gqgwx",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.246604 26 deployment.go:68] Pod "webserver-deployment-5d75f69fd6-qpbdk" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-5d75f69fd6-qpbdk",
      GenerateName: (string) (len=32) "webserver-deployment-5d75f69fd6-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3c2d7d19-fd71-430b-877a-7f8151faaa41",
      ResourceVersion: (string) (len=5) "45558",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147160,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d75f69fd6"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-5d75f69fd6",
          UID: (types.UID) (len=36) "452b5840-b3a5-4f17-abcd-1307699bab79",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 35  32 62 35 38 34 30 2d 62  |d\":\"452b5840-b|
              00000090  33 61 35 2d 34 66 31 37  2d 61 62 63 64 2d 31 33  |3a5-4f17-abcd-13|
              000000a0  30 37 36 39 39 62 61 62  37 39 5c 22 7d 22 3a 7b  |07699bab79\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=894) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 70  |eration":{},"f:p|
              00000320  6f 64 49 50 22 3a 7b 7d  2c 22 66 3a 70 6f 64 49  |odIP":{},"f:podI|
              00000330  50 73 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 6b 3a 7b  |Ps":{".":{},"k:{|
              00000340  5c 22 69 70 5c 22 3a 5c  22 31 30 2e 35 32 2e 30  |\"ip\":\"10.52.0|
              00000350  2e 33 31 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |.31\"}":{".":{},|
              00000360  22 66 3a 69 70 22 3a 7b  7d 7d 7d 2c 22 66 3a 73  |"f:ip":{}}},"f:s|
              00000370  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2jwnh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2jwnh",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147160,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.12",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.12"
        }
      },
      PodIP: (string) (len=10) "10.52.0.31",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.52.0.31"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147160,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-2jwnh",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.248316 26 deployment.go:68] Pod "webserver-deployment-5d75f69fd6-rbx77" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-5d75f69fd6-rbx77",
      GenerateName: (string) (len=32) "webserver-deployment-5d75f69fd6-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "da974045-fd75-479a-91a9-30a98f37b25c",
      ResourceVersion: (string) (len=5) "45569",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d75f69fd6"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-5d75f69fd6",
          UID: (types.UID) (len=36) "452b5840-b3a5-4f17-abcd-1307699bab79",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 35  32 62 35 38 34 30 2d 62  |d\":\"452b5840-b|
              00000090  33 61 35 2d 34 66 31 37  2d 61 62 63 64 2d 31 33  |3a5-4f17-abcd-13|
              000000a0  30 37 36 39 39 62 61 62  37 39 5c 22 7d 22 3a 7b  |07699bab79\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147164,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-lxsch",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-lxsch",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.12",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.12"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147163,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-lxsch",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.250854 26 deployment.go:68] Pod "webserver-deployment-5d75f69fd6-rwtgg" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-5d75f69fd6-rwtgg",
      GenerateName: (string) (len=32) "webserver-deployment-5d75f69fd6-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "719abc63-756c-47d5-995e-767145b5210b",
      ResourceVersion: (string) (len=5) "45513",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d75f69fd6"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-5d75f69fd6",
          UID: (types.UID) (len=36) "452b5840-b3a5-4f17-abcd-1307699bab79",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 35  32 62 35 38 34 30 2d 62  |d\":\"452b5840-b|
              00000090  33 61 35 2d 34 66 31 37  2d 61 62 63 64 2d 31 33  |3a5-4f17-abcd-13|
              000000a0  30 37 36 39 39 62 61 62  37 39 5c 22 7d 22 3a 7b  |07699bab79\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-w7cfm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-w7cfm",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.252361 26 deployment.go:68] Pod "webserver-deployment-5d75f69fd6-xkxnx" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-5d75f69fd6-xkxnx",
      GenerateName: (string) (len=32) "webserver-deployment-5d75f69fd6-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ba13daf0-3748-426b-8319-ae86b1a9ea8e",
      ResourceVersion: (string) (len=5) "45527",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147163,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d75f69fd6"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-5d75f69fd6",
          UID: (types.UID) (len=36) "452b5840-b3a5-4f17-abcd-1307699bab79",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 35  32 62 35 38 34 30 2d 62  |d\":\"452b5840-b|
              00000090  33 61 35 2d 34 66 31 37  2d 61 62 63 64 2d 31 33  |3a5-4f17-abcd-13|
              000000a0  30 37 36 39 39 62 61 62  37 39 5c 22 7d 22 3a 7b  |07699bab79\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-h7zs6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-h7zs6",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.253493 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-2t9xm" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-2t9xm",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "18b9dc2a-34a5-42d5-8d4c-a7ca18afb8c4",
      ResourceVersion: (string) (len=5) "45538",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-qg45d",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-qg45d",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.10",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.10"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-qg45d",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.256034 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-4gbkx" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-4gbkx",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9f158ca2-1952-4180-a116-9911320fe3df",
      ResourceVersion: (string) (len=5) "45500",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mm6bl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mm6bl",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.10",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.10"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-mm6bl",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.258192 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-5klvw" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-5klvw",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4246523b-3f77-462c-8400-053ea187dcca",
      ResourceVersion: (string) (len=5) "45314",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147147,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147154,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=849) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 35  |k:{\"ip\":\"10.5|
              00000320  32 2e 30 2e 32 35 5c 22  7d 22 3a 7b 22 2e 22 3a  |2.0.25\"}":{".":|
              00000330  7b 7d 2c 22 66 3a 69 70  22 3a 7b 7d 7d 7d 2c 22  |{},"f:ip":{}}},"|
              00000340  66 3a 73 74 61 72 74 54  69 6d 65 22 3a 7b 7d 7d  |f:startTime":{}}|
              00000350  7d                                                |}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mttfq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mttfq",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147154,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147154,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147154,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.12",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.12"
        }
      },
      PodIP: (string) (len=10) "10.52.0.25",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.52.0.25"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147147,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63905147153,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:10ed98804c877e505e17bced991682b6fd50ab1da9cddcd19935b48d645da40a",
          ContainerID: (string) (len=77) "containerd://31effeb0bfa5a09b9e7640cf792a9e8cce8c6d6d29248477b9e9c02dc9bc6748",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-mttfq",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.260682 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-6kb4r" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-6kb4r",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4a717bc6-e37b-40ed-b1e5-f654bf60a216",
      ResourceVersion: (string) (len=5) "45377",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147147,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147158,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=849) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 35  |k:{\"ip\":\"10.5|
              00000320  32 2e 30 2e 32 39 5c 22  7d 22 3a 7b 22 2e 22 3a  |2.0.29\"}":{".":|
              00000330  7b 7d 2c 22 66 3a 69 70  22 3a 7b 7d 7d 7d 2c 22  |{},"f:ip":{}}},"|
              00000340  66 3a 73 74 61 72 74 54  69 6d 65 22 3a 7b 7d 7d  |f:startTime":{}}|
              00000350  7d                                                |}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-5vq69",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-5vq69",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147156,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147156,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147156,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.12",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.12"
        }
      },
      PodIP: (string) (len=10) "10.52.0.29",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.52.0.29"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147147,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63905147155,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:10ed98804c877e505e17bced991682b6fd50ab1da9cddcd19935b48d645da40a",
          ContainerID: (string) (len=77) "containerd://869931cd18d6348cb752893b981e2f0c136d2dfa0b679fab706b6452132eb8ee",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-5vq69",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.262741 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-74gw7" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-74gw7",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f357049e-dead-48d3-8b8a-efe181f5acb3",
      ResourceVersion: (string) (len=5) "45360",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147147,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147156,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=850) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 35  |k:{\"ip\":\"10.5|
              00000320  32 2e 31 2e 31 39 34 5c  22 7d 22 3a 7b 22 2e 22  |2.1.194\"}":{"."|
              00000330  3a 7b 7d 2c 22 66 3a 69  70 22 3a 7b 7d 7d 7d 2c  |:{},"f:ip":{}}},|
              00000340  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              00000350  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-m9lxs",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-m9lxs",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147155,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147155,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147155,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.10",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.10"
        }
      },
      PodIP: (string) (len=11) "10.52.1.194",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.52.1.194"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147147,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63905147155,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:10ed98804c877e505e17bced991682b6fd50ab1da9cddcd19935b48d645da40a",
          ContainerID: (string) (len=77) "containerd://c2886d2bf1f3efe3c4e14d256d0ccfe550489a50e351218c0caf7c0365aad5a8",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-m9lxs",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.265055 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-87q22" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-87q22",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f6aba5a7-f4c1-4638-8a0d-41ffb3230af7",
      ResourceVersion: (string) (len=5) "45372",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147147,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147157,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=849) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 35  |k:{\"ip\":\"10.5|
              00000320  32 2e 30 2e 32 36 5c 22  7d 22 3a 7b 22 2e 22 3a  |2.0.26\"}":{".":|
              00000330  7b 7d 2c 22 66 3a 69 70  22 3a 7b 7d 7d 7d 2c 22  |{},"f:ip":{}}},"|
              00000340  66 3a 73 74 61 72 74 54  69 6d 65 22 3a 7b 7d 7d  |f:startTime":{}}|
              00000350  7d                                                |}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bjzg7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bjzg7",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147156,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147156,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147156,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.12",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.12"
        }
      },
      PodIP: (string) (len=10) "10.52.0.26",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.52.0.26"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147147,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63905147155,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:10ed98804c877e505e17bced991682b6fd50ab1da9cddcd19935b48d645da40a",
          ContainerID: (string) (len=77) "containerd://eb2fb2becf8fb440c39fe87dae9983d277f88385599abefcadf3b0496c9cfb8e",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-bjzg7",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.267697 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-8gzgv" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-8gzgv",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f7351afb-d57e-4582-b2c5-d49eda46c591",
      ResourceVersion: (string) (len=5) "45492",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-cxh8g",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-cxh8g",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.269302 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-8jcgc" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-8jcgc",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d2ed6424-4bbb-45b6-870f-b75099872e4b",
      ResourceVersion: (string) (len=5) "45351",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147147,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147156,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=850) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 35  |k:{\"ip\":\"10.5|
              00000320  32 2e 31 2e 31 39 35 5c  22 7d 22 3a 7b 22 2e 22  |2.1.195\"}":{"."|
              00000330  3a 7b 7d 2c 22 66 3a 69  70 22 3a 7b 7d 7d 7d 2c  |:{},"f:ip":{}}},|
              00000340  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              00000350  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9skcs",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9skcs",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147155,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147155,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147155,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.10",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.10"
        }
      },
      PodIP: (string) (len=11) "10.52.1.195",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.52.1.195"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147147,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63905147155,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:10ed98804c877e505e17bced991682b6fd50ab1da9cddcd19935b48d645da40a",
          ContainerID: (string) (len=77) "containerd://5704daa6171e7adba23512d724490f7e20ce692d3f979894d72c0ae9efe01033",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-9skcs",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.271064 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-9d9zp" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-9d9zp",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "824451c4-e67d-4378-8e9e-3a069e8aa42b",
      ResourceVersion: (string) (len=5) "45550",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd",
        (string) (len=4) "name": (string) (len=7) "agnhost"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-29bhh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-29bhh",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.12",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.12"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147163,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-29bhh",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.273635 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-c8v5w" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-c8v5w",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0c531d71-2eca-4940-af59-1cbff68c083e",
      ResourceVersion: (string) (len=5) "45573",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd",
        (string) (len=4) "name": (string) (len=7) "agnhost"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147164,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xxmm4",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xxmm4",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.12",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.12"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147163,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-xxmm4",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.275683 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-fb6l9" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-fb6l9",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ac916c5c-6e91-4b41-a881-1dc5815a256b",
      ResourceVersion: (string) (len=5) "45355",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147147,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147156,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=850) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 35  |k:{\"ip\":\"10.5|
              00000320  32 2e 31 2e 31 39 36 5c  22 7d 22 3a 7b 22 2e 22  |2.1.196\"}":{"."|
              00000330  3a 7b 7d 2c 22 66 3a 69  70 22 3a 7b 7d 7d 7d 2c  |:{},"f:ip":{}}},|
              00000340  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              00000350  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-l8pr7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-l8pr7",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147155,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147155,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147155,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.10",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.10"
        }
      },
      PodIP: (string) (len=11) "10.52.1.196",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.52.1.196"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147147,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63905147155,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:10ed98804c877e505e17bced991682b6fd50ab1da9cddcd19935b48d645da40a",
          ContainerID: (string) (len=77) "containerd://bb2fe7925d01c977167ecebc5a900cfb67b46c85f455adf370e6f102969677b4",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-l8pr7",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.277361 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-gdlsc" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-gdlsc",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ddf65404-7eef-4db3-aab0-494398e9915f",
      ResourceVersion: (string) (len=5) "45521",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-42mt7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-42mt7",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.278823 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-jsmmx" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-jsmmx",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9428d546-20f3-4ee9-a6b5-a7fcfdddcc3b",
      ResourceVersion: (string) (len=5) "45493",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-w8vdf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-w8vdf",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.280988 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-nklxt" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-nklxt",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b782f9d3-c057-40a3-8b35-32ba9600c8ba",
      ResourceVersion: (string) (len=5) "45367",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147147,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147156,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=849) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 35  |k:{\"ip\":\"10.5|
              00000320  32 2e 30 2e 32 38 5c 22  7d 22 3a 7b 22 2e 22 3a  |2.0.28\"}":{".":|
              00000330  7b 7d 2c 22 66 3a 69 70  22 3a 7b 7d 7d 7d 2c 22  |{},"f:ip":{}}},"|
              00000340  66 3a 73 74 61 72 74 54  69 6d 65 22 3a 7b 7d 7d  |f:startTime":{}}|
              00000350  7d                                                |}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-hr4jp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-hr4jp",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147156,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147156,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147156,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.12",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.12"
        }
      },
      PodIP: (string) (len=10) "10.52.0.28",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.52.0.28"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147147,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63905147155,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:10ed98804c877e505e17bced991682b6fd50ab1da9cddcd19935b48d645da40a",
          ContainerID: (string) (len=77) "containerd://72260bf14a24a2caea79c71f3020a37e3a7abf7077a1ae0e08434965df3b28d0",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-hr4jp",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.283223 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-qw26k" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-qw26k",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1c3a5c4c-ddc2-42b3-b55e-fcc80e797ea0",
      ResourceVersion: (string) (len=5) "45563",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147164,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4hgp8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4hgp8",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.12",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.12"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147163,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-4hgp8",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.284858 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-rg9z5" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-rg9z5",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6f0229f3-0128-4a73-b682-baed6769610c",
      ResourceVersion: (string) (len=5) "45523",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7z49b",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7z49b",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.286742 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-sqnkp" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-sqnkp",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4aaa866b-11f0-4137-b8ec-f61278027546",
      ResourceVersion: (string) (len=5) "45524",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-nj5d6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-nj5d6",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.287892 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-sqqmt" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-sqqmt",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fd86df1c-b540-4496-84fc-13ed349634fb",
      ResourceVersion: (string) (len=5) "45548",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-kp2p6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-kp2p6",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147163,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.10",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.10"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147163,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-kp2p6",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.289433 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-t5qv9" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-t5qv9",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d1ec8075-d433-4d5a-b3aa-ca2672d9eaec",
      ResourceVersion: (string) (len=5) "45503",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147162,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-x8xbc",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-x8xbc",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147162,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.291441 26 deployment.go:68] Pod "webserver-deployment-79f99d89dd-xjdtl" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-79f99d89dd-xjdtl",
      GenerateName: (string) (len=32) "webserver-deployment-79f99d89dd-",
      Namespace: (string) (len=15) "deployment-4630",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2b76a7bc-8963-448a-90dc-2a7365d0c4ad",
      ResourceVersion: (string) (len=5) "45331",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147147,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=7) "agnhost",
        (string) (len=17) "pod-template-hash": (string) (len=10) "79f99d89dd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-79f99d89dd",
          UID: (types.UID) (len=36) "84562802-9085-4c2b-9efd-fe3f9524d9ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 34  35 36 32 38 30 32 2d 39  |d\":\"84562802-9|
              00000090  30 38 35 2d 34 63 32 62  2d 39 65 66 64 2d 66 65  |085-4c2b-9efd-fe|
              000000a0  33 66 39 35 32 34 64 39  61 64 5c 22 7d 22 3a 7b  |3f9524d9ad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147155,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=849) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 35  |k:{\"ip\":\"10.5|
              00000320  32 2e 30 2e 32 37 5c 22  7d 22 3a 7b 22 2e 22 3a  |2.0.27\"}":{".":|
              00000330  7b 7d 2c 22 66 3a 69 70  22 3a 7b 7d 7d 7d 2c 22  |{},"f:ip":{}}},"|
              00000340  66 3a 73 74 61 72 74 54  69 6d 65 22 3a 7b 7d 7d  |f:startTime":{}}|
              00000350  7d                                                |}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gs26f",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gs26f",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147155,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147155,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147155,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147147,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.12",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.12"
        }
      },
      PodIP: (string) (len=10) "10.52.0.27",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.52.0.27"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147147,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63905147155,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:10ed98804c877e505e17bced991682b6fd50ab1da9cddcd19935b48d645da40a",
          ContainerID: (string) (len=77) "containerd://27bd239e43667c5db646a2c3165a91e82f012da7ddcee2053882ec02e476f633",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-gs26f",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }

  I0127 21:46:05.293426 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0127 21:46:05.367744      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Destroying namespace "deployment-4630" for this suite. @ 01/27/26 21:46:05.429
• [18.133 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:259
  STEP: Creating a kubernetes client @ 01/27/26 21:46:05.474
  I0127 21:46:05.474176 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename aggregateddiscovery @ 01/27/26 21:46:05.474
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:46:05.811
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:46:05.999
  I0127 21:46:06.020859 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-3006" for this suite. @ 01/27/26 21:46:06.168
• [0.783 seconds]
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:173
  STEP: Creating a kubernetes client @ 01/27/26 21:46:06.257
  I0127 21:46:06.257286 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 01/27/26 21:46:06.257
  E0127 21:46:06.368590      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:46:06.587
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:46:06.612
  STEP: create the container to handle the HTTPGet hook request. @ 01/27/26 21:46:06.837
  E0127 21:46:07.368891      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:08.369430      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:09.370396      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:10.370674      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:11.370845      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:12.371069      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:13.371901      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:14.372856      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:15.372987      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:16.373044      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:17.373358      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:18.373621      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:19.373813      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:20.374720      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:21.374839      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:22.375611      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:23.375762      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 01/27/26 21:46:24.102
  E0127 21:46:24.376314      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:25.376357      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:26.377050      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:27.377599      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:28.378088      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:29.378412      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:30.378778      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:31.379806      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:32.380956      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 01/27/26 21:46:33.212
  STEP: delete the pod with lifecycle hook @ 01/27/26 21:46:33.223
  E0127 21:46:33.381712      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:34.382003      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:46:35.287333 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4702" for this suite. @ 01/27/26 21:46:35.289
• [29.040 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/certificates.go:202
  STEP: Creating a kubernetes client @ 01/27/26 21:46:35.297
  I0127 21:46:35.297473 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename certificates @ 01/27/26 21:46:35.298
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:46:35.312
  E0127 21:46:35.382332      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:46:35.408
  STEP: getting /apis @ 01/27/26 21:46:35.718
  STEP: getting /apis/certificates.k8s.io @ 01/27/26 21:46:35.722
  STEP: getting /apis/certificates.k8s.io/v1 @ 01/27/26 21:46:35.723
  STEP: creating @ 01/27/26 21:46:35.725
  STEP: getting @ 01/27/26 21:46:35.76
  STEP: listing @ 01/27/26 21:46:35.762
  STEP: watching @ 01/27/26 21:46:35.764
  I0127 21:46:35.764392 26 certificates.go:319] starting watch
  STEP: patching @ 01/27/26 21:46:35.765
  STEP: updating @ 01/27/26 21:46:35.778
  I0127 21:46:35.786486 26 certificates.go:336] waiting for watch events with expected annotations
  I0127 21:46:35.786537 26 certificates.go:349] saw patched and updated annotations
  STEP: getting /approval @ 01/27/26 21:46:35.786
  STEP: patching /approval @ 01/27/26 21:46:35.788
  STEP: updating /approval @ 01/27/26 21:46:35.801
  STEP: getting /status @ 01/27/26 21:46:35.81
  STEP: patching /status @ 01/27/26 21:46:35.813
  STEP: updating /status @ 01/27/26 21:46:35.829
  STEP: deleting @ 01/27/26 21:46:35.844
  STEP: deleting a collection @ 01/27/26 21:46:35.856
  I0127 21:46:35.873476 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-9042" for this suite. @ 01/27/26 21:46:35.875
• [0.592 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:56
  STEP: Creating a kubernetes client @ 01/27/26 21:46:35.89
  I0127 21:46:35.890117 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename podtemplate @ 01/27/26 21:46:35.89
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:46:35.905
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:46:35.912
  I0127 21:46:35.965347 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-368" for this suite. @ 01/27/26 21:46:35.976
• [0.094 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1565
  STEP: Creating a kubernetes client @ 01/27/26 21:46:35.984
  I0127 21:46:35.984388 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubectl @ 01/27/26 21:46:35.984
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:46:36
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:46:36.01
  STEP: creating Agnhost RC @ 01/27/26 21:46:36.012
  I0127 21:46:36.012743 26 kubectl.go:1572] namespace kubectl-2225
  I0127 21:46:36.012776 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-2225 create -f -'
  I0127 21:46:36.129371 26 builder.go:156] stderr: ""
  I0127 21:46:36.129423 26 builder.go:157] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 01/27/26 21:46:36.129
  E0127 21:46:36.383245      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:46:37.132614 26 framework.go:697] Selector matched 1 pods for map[app:agnhost]
  I0127 21:46:37.132651 26 framework.go:738] Found 0 / 1
  E0127 21:46:37.384147      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:46:38.132696 26 framework.go:697] Selector matched 1 pods for map[app:agnhost]
  I0127 21:46:38.132733 26 framework.go:738] Found 1 / 1
  I0127 21:46:38.132748 26 framework.go:747] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0127 21:46:38.134641 26 framework.go:697] Selector matched 1 pods for map[app:agnhost]
  I0127 21:46:38.134670 26 framework.go:770] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0127 21:46:38.134678 26 kubectl.go:1579] wait on agnhost-primary startup in kubectl-2225 
  I0127 21:46:38.134715 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-2225 logs agnhost-primary-tmbh9 agnhost-primary'
  I0127 21:46:38.201798 26 builder.go:156] stderr: ""
  I0127 21:46:38.201857 26 builder.go:157] stdout: "Paused\nSignals registered\n"
  STEP: exposing RC @ 01/27/26 21:46:38.201
  I0127 21:46:38.201919 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-2225 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  I0127 21:46:38.276290 26 builder.go:156] stderr: ""
  I0127 21:46:38.276327 26 builder.go:157] stdout: "service/rm2 exposed\n"
  I0127 21:46:38.281457 26 utils.go:1116] Service rm2 in namespace kubectl-2225 found.
  E0127 21:46:38.384705      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:39.385092      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: exposing service @ 01/27/26 21:46:40.287
  I0127 21:46:40.287268 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-2225 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  I0127 21:46:40.365353 26 builder.go:156] stderr: ""
  I0127 21:46:40.365402 26 builder.go:157] stdout: "service/rm3 exposed\n"
  E0127 21:46:40.385487      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:46:40.393697 26 utils.go:1116] Service rm3 in namespace kubectl-2225 found.
  E0127 21:46:41.385593      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:42.385826      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:46:42.398277 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2225" for this suite. @ 01/27/26 21:46:42.4
• [6.424 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on DisruptionTarget condition [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:200
  STEP: Creating a kubernetes client @ 01/27/26 21:46:42.408
  I0127 21:46:42.408771 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename job @ 01/27/26 21:46:42.409
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:46:42.441
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:46:42.536
  STEP: Looking for a node to schedule job pods @ 01/27/26 21:46:42.539
  STEP: Creating a job @ 01/27/26 21:46:42.541
  STEP: Waiting for all the pods to be ready @ 01/27/26 21:46:42.555
  E0127 21:46:43.386575      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:44.387031      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:45.387404      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:46.387642      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:47.388019      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:48.388208      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Fetch all running pods @ 01/27/26 21:46:48.565
  STEP: Evict all the Pods @ 01/27/26 21:46:48.568
  STEP: Evicting the running pod: evicted-pod-ignore-on-disruption-condition-0-jjgbf/job-8430 @ 01/27/26 21:46:48.568
  STEP: Evicting the running pod: evicted-pod-ignore-on-disruption-condition-1-dqblk/job-8430 @ 01/27/26 21:46:48.568
  STEP: Evicting the running pod: evicted-pod-ignore-on-disruption-condition-2-fzpbp/job-8430 @ 01/27/26 21:46:48.568
  STEP: Awaiting for the pod: evicted-pod-ignore-on-disruption-condition-0-jjgbf/job-8430 to be deleted @ 01/27/26 21:46:48.612
  STEP: Awaiting for the pod: evicted-pod-ignore-on-disruption-condition-1-dqblk/job-8430 to be deleted @ 01/27/26 21:46:48.62
  STEP: Awaiting for the pod: evicted-pod-ignore-on-disruption-condition-2-fzpbp/job-8430 to be deleted @ 01/27/26 21:46:48.631
  E0127 21:46:49.388955      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:50.389074      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:51.389407      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:52.389636      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensuring job reaches completions @ 01/27/26 21:46:52.637
  E0127 21:46:53.390595      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:54.390879      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:55.391575      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:56.391882      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:57.392841      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:58.393085      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:46:59.394056      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:00.394224      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:01.394479      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:02.394698      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:03.394744      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:04.395101      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:05.395602      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:06.395797      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:07.396850      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:08.397226      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:09.397484      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:10.397409      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:11.398165      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:12.398426      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:13.398557      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:14.398787      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:15.399329      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:16.399552      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:17.400295      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:18.400509      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:19.400966      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:20.401670      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:21.402738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:22.402924      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:23.403512      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:24.403850      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:25.404857      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:26.405086      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:27.405357      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:28.405553      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:29.405881      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:30.406245      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:31.406637      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:32.406951      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:33.408020      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:34.408943      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:35.409342      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:36.409517      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:47:36.896898 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8430" for this suite. @ 01/27/26 21:47:36.899
• [54.499 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Pod InPlace Resize Container burstable pods - extended 6 containers - various operations performed (including adding limits and requests) [MinimumKubeletVersion:1.34] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pod_resize.go:287
  STEP: Creating a kubernetes client @ 01/27/26 21:47:36.907
  I0127 21:47:36.907549 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pod-resize-tests @ 01/27/26 21:47:36.908
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:47:36.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:47:36.938
  STEP: creating and verifying pod @ 01/27/26 21:47:37.001
  E0127 21:47:37.410079      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:38.410273      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:39.411140      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:40.411289      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:47:41.031468 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c1 - looking for one of the expected cgroup values [max] in path /sys/fs/cgroup/memory.max
  I0127 21:47:41.031508 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:41.031519 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:41.031555 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c1&stderr=true&stdout=true)
  I0127 21:47:41.104646 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c1 - looking for one of the expected cgroup values [max 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:47:41.104686 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:41.104697 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:41.104743 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c1&stderr=true&stdout=true)
  I0127 21:47:41.176481 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c1 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 21:47:41.176527 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:41.176542 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:41.176587 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c1&stderr=true&stdout=true)
  I0127 21:47:41.240474 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c2 - looking for one of the expected cgroup values [max] in path /sys/fs/cgroup/memory.max
  I0127 21:47:41.240510 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:41.240521 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:41.240567 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c2&stderr=true&stdout=true)
  I0127 21:47:41.310390 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c2 - looking for one of the expected cgroup values [max 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:47:41.310434 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:41.310445 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:41.310500 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c2&stderr=true&stdout=true)
  I0127 21:47:41.378193 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c2 - looking for one of the expected cgroup values [1 1] in path /sys/fs/cgroup/cpu.weight
  I0127 21:47:41.378241 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:41.378252 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:41.378309 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c2&stderr=true&stdout=true)
  E0127 21:47:41.411876      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:47:41.445743 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c3 - looking for one of the expected cgroup values [max] in path /sys/fs/cgroup/memory.max
  I0127 21:47:41.445798 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:41.445809 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:41.445869 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c3&stderr=true&stdout=true)
  I0127 21:47:41.508502 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c3 - looking for one of the expected cgroup values [max 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:47:41.508549 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:41.508560 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:41.508620 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c3&stderr=true&stdout=true)
  I0127 21:47:41.575321 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c3 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 21:47:41.575383 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:41.575395 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:41.575442 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c3&stderr=true&stdout=true)
  I0127 21:47:41.643113 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c4 - looking for one of the expected cgroup values [max] in path /sys/fs/cgroup/memory.max
  I0127 21:47:41.643157 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c4 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:41.643167 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:41.643217 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c4&stderr=true&stdout=true)
  I0127 21:47:41.715781 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c4 - looking for one of the expected cgroup values [max 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:47:41.715837 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c4 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:41.715853 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:41.715905 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c4&stderr=true&stdout=true)
  I0127 21:47:41.781339 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c4 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 21:47:41.781381 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c4 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:41.781392 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:41.781438 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c4&stderr=true&stdout=true)
  I0127 21:47:41.856267 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c5 - looking for one of the expected cgroup values [max] in path /sys/fs/cgroup/memory.max
  I0127 21:47:41.856307 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c5 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:41.856321 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:41.856366 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c5&stderr=true&stdout=true)
  I0127 21:47:41.925730 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c5 - looking for one of the expected cgroup values [max 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:47:41.925769 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c5 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:41.925780 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:41.925834 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c5&stderr=true&stdout=true)
  I0127 21:47:42.001661 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c5 - looking for one of the expected cgroup values [1 1] in path /sys/fs/cgroup/cpu.weight
  I0127 21:47:42.001707 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c5 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:42.001721 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:42.001767 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c5&stderr=true&stdout=true)
  STEP: patching and verifying pod for resize @ 01/27/26 21:47:42.078
  E0127 21:47:42.412863      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:43.413495      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:47:44.105561 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c1 - looking for one of the expected cgroup values [max] in path /sys/fs/cgroup/memory.max
  I0127 21:47:44.105601 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:44.105612 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:44.105650 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c1&stderr=true&stdout=true)
  E0127 21:47:44.414019      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:47:45.146518 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c1 - looking for one of the expected cgroup values [3500 100000 4000 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:47:45.146569 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:45.146580 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:45.146625 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c1&stderr=true&stdout=true)
  E0127 21:47:45.414173      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:47:46.046143 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c1 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 21:47:46.046205 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:46.046216 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:46.046263 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c1&stderr=true&stdout=true)
  E0127 21:47:46.414991      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:47:46.946887 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c2 - looking for one of the expected cgroup values [36700160] in path /sys/fs/cgroup/memory.max
  I0127 21:47:46.946931 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:46.946942 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:46.946988 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c2&stderr=true&stdout=true)
  I0127 21:47:47.012051 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c2 - looking for one of the expected cgroup values [max 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:47:47.012092 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:47.012105 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:47.012152 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c2&stderr=true&stdout=true)
  I0127 21:47:47.076866 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c2 - looking for one of the expected cgroup values [1 1] in path /sys/fs/cgroup/cpu.weight
  I0127 21:47:47.076910 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:47.076924 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:47.076984 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c2&stderr=true&stdout=true)
  I0127 21:47:47.141068 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c3 - looking for one of the expected cgroup values [max] in path /sys/fs/cgroup/memory.max
  I0127 21:47:47.141115 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:47.141126 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:47.141173 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c3&stderr=true&stdout=true)
  I0127 21:47:47.209594 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c3 - looking for one of the expected cgroup values [max 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:47:47.209636 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:47.209649 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:47.209708 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c3&stderr=true&stdout=true)
  I0127 21:47:47.279794 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c3 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 21:47:47.279879 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:47.279896 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:47.279960 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c3&stderr=true&stdout=true)
  I0127 21:47:47.345576 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c4 - looking for one of the expected cgroup values [max] in path /sys/fs/cgroup/memory.max
  I0127 21:47:47.345622 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c4 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:47.345632 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:47.345681 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c4&stderr=true&stdout=true)
  I0127 21:47:47.414635 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c4 - looking for one of the expected cgroup values [max 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:47:47.414681 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c4 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:47.414694 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:47.414742 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c4&stderr=true&stdout=true)
  E0127 21:47:47.415103      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:47:47.484701 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c4 - looking for one of the expected cgroup values [1 5] in path /sys/fs/cgroup/cpu.weight
  I0127 21:47:47.484746 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c4 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:47.484757 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:47.484802 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c4&stderr=true&stdout=true)
  I0127 21:47:47.550604 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c5 - looking for one of the expected cgroup values [max] in path /sys/fs/cgroup/memory.max
  I0127 21:47:47.550648 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c5 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:47.550658 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:47.550715 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c5&stderr=true&stdout=true)
  I0127 21:47:47.617175 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c5 - looking for one of the expected cgroup values [max 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:47:47.617219 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c5 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:47.617231 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:47.617287 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c5&stderr=true&stdout=true)
  I0127 21:47:47.688007 26 cgroups.go:379] Namespace pod-resize-tests-622 Pod resize-test-zsvhb Container c5 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 21:47:47.688049 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-622 PodName:resize-test-zsvhb ContainerName:c5 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:47:47.688061 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:47:47.688108 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-622/pods/resize-test-zsvhb/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c5&stderr=true&stdout=true)
  STEP: deleting pod @ 01/27/26 21:47:47.766
  I0127 21:47:47.807526 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-resize-tests-622" for this suite. @ 01/27/26 21:47:47.811
• [10.914 seconds]
------------------------------
SS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:148
  STEP: Creating a kubernetes client @ 01/27/26 21:47:47.821
  I0127 21:47:47.821396 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubelet-test @ 01/27/26 21:47:47.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:47:47.852
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:47:47.854
  STEP: Waiting for pod completion @ 01/27/26 21:47:47.871
  E0127 21:47:48.415178      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:49.415628      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:50.416044      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:51.416253      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:47:51.885752 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-5734" for this suite. @ 01/27/26 21:47:51.887
• [4.074 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] VolumeAttributesClass [FeatureGate:VolumeAttributesClass] should run through the lifecycle of a VolumeAttributesClass [Conformance] [sig-storage, FeatureGate:VolumeAttributesClass, Conformance]
k8s.io/kubernetes/test/e2e/storage/volumeattributesclass.go:51
  STEP: Creating a kubernetes client @ 01/27/26 21:47:51.896
  I0127 21:47:51.896247 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename csi-volumeattributesclass @ 01/27/26 21:47:51.896
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:47:51.912
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:47:51.923
  STEP: Creating a VolumeAttributesClass @ 01/27/26 21:47:51.925
  STEP: Get VolumeAttributesClass "e2e-4qtlg" @ 01/27/26 21:47:51.933
  STEP: Patching the VolumeAttributesClass "e2e-4qtlg" @ 01/27/26 21:47:51.935
  STEP: Delete VolumeAttributesClass "e2e-4qtlg" @ 01/27/26 21:47:51.943
  STEP: Confirm deletion of VolumeAttributesClass "e2e-4qtlg" @ 01/27/26 21:47:51.951
  E0127 21:47:52.417309      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:53.417519      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create a replacement VolumeAttributesClass @ 01/27/26 21:47:53.956
  STEP: Updating VolumeAttributesClass "e2e-v2-5fwt5" @ 01/27/26 21:47:53.965
  STEP: Listing all VolumeAttributesClasses with the labelSelector: "e2e-v2-5fwt5=updated" @ 01/27/26 21:47:53.986
  STEP: Deleting VolumeAttributesClass "e2e-v2-5fwt5" via DeleteCollection @ 01/27/26 21:47:53.988
  STEP: Confirm deletion of VolumeAttributesClass "e2e-v2-5fwt5" @ 01/27/26 21:47:53.998
  E0127 21:47:54.418275      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:55.418439      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:47:56.002811 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-volumeattributesclass-2012" for this suite. @ 01/27/26 21:47:56.005
• [4.117 seconds]
------------------------------
SSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:352
  STEP: Creating a kubernetes client @ 01/27/26 21:47:56.013
  I0127 21:47:56.013035 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename dns @ 01/27/26 21:47:56.013
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:47:56.041
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:47:56.043
  STEP: Creating a test externalName service @ 01/27/26 21:47:56.046
  STEP: Running these commands on agnhost: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5332.svc.cluster.local CNAME > /results/agnhost_udp@dns-test-service-3.dns-5332.svc.cluster.local; sleep 1; done
   @ 01/27/26 21:47:56.054
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5332.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-5332.svc.cluster.local; sleep 1; done
   @ 01/27/26 21:47:56.054
  STEP: creating a pod to probe DNS @ 01/27/26 21:47:56.054
  STEP: submitting the pod to kubernetes @ 01/27/26 21:47:56.054
  E0127 21:47:56.418931      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:57.419141      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:58.419745      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:47:59.419753      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 01/27/26 21:48:00.077
  STEP: looking for the results for each expected name from probers @ 01/27/26 21:48:00.08
  I0127 21:48:00.087907 26 dns_common.go:571] DNS probes using dns-test-9145c897-2ed4-4048-ae64-7a1f339246f3 succeeded

  STEP: changing the externalName to bar.example.com @ 01/27/26 21:48:00.087
  STEP: Running these commands on agnhost: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5332.svc.cluster.local CNAME > /results/agnhost_udp@dns-test-service-3.dns-5332.svc.cluster.local; sleep 1; done
   @ 01/27/26 21:48:00.095
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5332.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-5332.svc.cluster.local; sleep 1; done
   @ 01/27/26 21:48:00.095
  STEP: creating a second pod to probe DNS @ 01/27/26 21:48:00.095
  STEP: submitting the pod to kubernetes @ 01/27/26 21:48:00.095
  E0127 21:48:00.420020      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:01.420841      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:02.421248      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:03.421382      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:04.422542      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:05.422912      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:06.422760      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:07.422975      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 01/27/26 21:48:08.12
  STEP: looking for the results for each expected name from probers @ 01/27/26 21:48:08.121
  I0127 21:48:08.129122 26 dns_common.go:571] DNS probes using dns-test-ea4a449b-bcba-42b5-8a1c-0c8f0105b9ed succeeded

  STEP: changing the service to type=ClusterIP @ 01/27/26 21:48:08.129
  I0127 21:48:08.147366      26 warnings.go:107] "Warning: spec.externalName is ignored when spec.type is not \"ExternalName\""
  STEP: Running these commands on agnhost: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5332.svc.cluster.local A > /results/agnhost_udp@dns-test-service-3.dns-5332.svc.cluster.local; sleep 1; done
   @ 01/27/26 21:48:08.147
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5332.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-5332.svc.cluster.local; sleep 1; done
   @ 01/27/26 21:48:08.147
  STEP: creating a third pod to probe DNS @ 01/27/26 21:48:08.147
  STEP: submitting the pod to kubernetes @ 01/27/26 21:48:08.149
  E0127 21:48:08.423766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:09.424143      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:10.424821      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:11.425042      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 01/27/26 21:48:12.174
  STEP: looking for the results for each expected name from probers @ 01/27/26 21:48:12.175
  I0127 21:48:12.183974 26 dns_common.go:571] DNS probes using dns-test-15abeea3-0a3c-4800-a7f8-9d91ef97a4f8 succeeded

  STEP: deleting the pod @ 01/27/26 21:48:12.184
  STEP: deleting the pod @ 01/27/26 21:48:12.204
  STEP: deleting the pod @ 01/27/26 21:48:12.238
  STEP: deleting the test externalName service @ 01/27/26 21:48:12.283
  I0127 21:48:12.317568 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-5332" for this suite. @ 01/27/26 21:48:12.32
  E0127 21:48:12.425342      26 retrywatcher.go:169] "Watch failed" err="context canceled"
• [16.421 seconds]
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:895
  STEP: Creating a kubernetes client @ 01/27/26 21:48:12.434
  I0127 21:48:12.434424 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename daemonsets @ 01/27/26 21:48:12.434
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:48:12.513
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:48:12.619
  STEP: Creating simple DaemonSet "daemon-set" @ 01/27/26 21:48:12.8
  STEP: Check that daemon pods launch on every node of the cluster. @ 01/27/26 21:48:12.828
  I0127 21:48:13.038514 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:48:13.038550 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 21:48:13.426051      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:14.022308 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:48:14.022347 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 21:48:14.426242      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:15.040539 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:48:15.040578 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 21:48:15.427419      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:15.927026 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:48:15.927062 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 21:48:16.428093      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:16.833105 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:48:16.833134 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 21:48:17.428736      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:17.833677 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:48:17.833714 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 21:48:18.429376      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:19.139527 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:48:19.139565 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 21:48:19.430502      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:20.158477 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:48:20.158514 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 21:48:20.429985      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:21.008541 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:48:21.008577 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 21:48:21.431029      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:22.023452 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:48:22.023479 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 21:48:22.431973      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:22.833959 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:48:22.834011 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 21:48:23.432591      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:23.834129 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:48:23.834165 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 21:48:24.432803      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:24.861794 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:48:24.861827 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 21:48:25.433780      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:25.833627 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0127 21:48:25.833659 26 fixtures.go:138] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Getting /status @ 01/27/26 21:48:25.836
  I0127 21:48:25.838021 26 daemon_set.go:932] Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 01/27/26 21:48:25.838
  I0127 21:48:25.855272 26 daemon_set.go:952] updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 01/27/26 21:48:25.855
  I0127 21:48:25.856729 26 daemon_set.go:977] Observed &DaemonSet event: ADDED
  I0127 21:48:25.856795 26 daemon_set.go:977] Observed &DaemonSet event: MODIFIED
  I0127 21:48:25.856848 26 daemon_set.go:977] Observed &DaemonSet event: MODIFIED
  I0127 21:48:25.856937 26 daemon_set.go:977] Observed &DaemonSet event: MODIFIED
  I0127 21:48:25.857009 26 daemon_set.go:970] Found daemon set daemon-set in namespace daemonsets-8778 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0127 21:48:25.857040 26 daemon_set.go:981] Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 01/27/26 21:48:25.857
  STEP: watching for the daemon set status to be patched @ 01/27/26 21:48:25.864
  I0127 21:48:25.865943 26 daemon_set.go:1021] Observed &DaemonSet event: ADDED
  I0127 21:48:25.866026 26 daemon_set.go:1021] Observed &DaemonSet event: MODIFIED
  I0127 21:48:25.866092 26 daemon_set.go:1021] Observed &DaemonSet event: MODIFIED
  I0127 21:48:25.866223 26 daemon_set.go:1021] Observed &DaemonSet event: MODIFIED
  I0127 21:48:25.866237 26 daemon_set.go:1017] Observed daemon set daemon-set in namespace daemonsets-8778 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0127 21:48:25.866304 26 daemon_set.go:1021] Observed &DaemonSet event: MODIFIED
  I0127 21:48:25.866318 26 daemon_set.go:1014] Found daemon set daemon-set in namespace daemonsets-8778 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  I0127 21:48:25.866329 26 daemon_set.go:1025] Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 01/27/26 21:48:25.867
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8778, will wait for the garbage collector to delete the pods @ 01/27/26 21:48:25.867
  I0127 21:48:25.985203 26 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 9.162437ms
  I0127 21:48:26.085648 26 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.442594ms
  E0127 21:48:26.434209      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:27.434647      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:28.435084      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:28.703243 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:48:28.703282 26 fixtures.go:138] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0127 21:48:28.705148 26 daemon_set.go:137] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"46897"},"items":null}

  I0127 21:48:28.707009 26 daemon_set.go:142] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"46897"},"items":null}

  I0127 21:48:28.716805 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8778" for this suite. @ 01/27/26 21:48:28.816
• [16.391 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:919
  STEP: Creating a kubernetes client @ 01/27/26 21:48:28.825
  I0127 21:48:28.825597 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename job @ 01/27/26 21:48:28.826
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:48:28.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:48:28.854
  STEP: Creating a job @ 01/27/26 21:48:28.856
  STEP: Ensuring active pods == parallelism @ 01/27/26 21:48:28.864
  E0127 21:48:29.435332      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:30.435541      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:31.436529      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:32.436806      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:33.437210      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:34.437413      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 01/27/26 21:48:35.345
  E0127 21:48:35.438462      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:35.876889 26 pod_client.go:187] Successfully updated pod "adopt-release-5nwr7"
  STEP: Checking that the Job readopts the Pod @ 01/27/26 21:48:35.876
  E0127 21:48:36.439253      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:37.439480      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 01/27/26 21:48:37.883
  I0127 21:48:38.396223 26 pod_client.go:187] Successfully updated pod "adopt-release-5nwr7"
  STEP: Checking that the Job releases the Pod @ 01/27/26 21:48:38.396
  E0127 21:48:38.439949      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:39.440811      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:40.401523 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4333" for this suite. @ 01/27/26 21:48:40.403
• [11.587 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:187
  STEP: Creating a kubernetes client @ 01/27/26 21:48:40.412
  I0127 21:48:40.412473 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename deployment @ 01/27/26 21:48:40.413
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:48:40.437
  E0127 21:48:40.441365      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:48:40.442
  STEP: creating a Deployment @ 01/27/26 21:48:40.447
  STEP: waiting for Deployment to be created @ 01/27/26 21:48:40.461
  STEP: waiting for all Replicas to be Ready @ 01/27/26 21:48:40.462
  I0127 21:48:40.464038 26 deployment.go:249] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0127 21:48:40.464064 26 deployment.go:251] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0127 21:48:40.482699 26 deployment.go:249] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0127 21:48:40.482740 26 deployment.go:251] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0127 21:48:40.510052 26 deployment.go:249] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0127 21:48:40.510088 26 deployment.go:251] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0127 21:48:40.579789 26 deployment.go:249] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0127 21:48:40.579872 26 deployment.go:251] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0127 21:48:41.441551      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:41.805361 26 deployment.go:249] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0127 21:48:41.805398 26 deployment.go:251] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0127 21:48:42.332284 26 deployment.go:251] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 01/27/26 21:48:42.332
  I0127 21:48:42.358629 26 deployment.go:294] observed event type ADDED
  STEP: waiting for Replicas to scale @ 01/27/26 21:48:42.358
  I0127 21:48:42.360211 26 deployment.go:313] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 0
  I0127 21:48:42.360235 26 deployment.go:315] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 0
  I0127 21:48:42.360353 26 deployment.go:313] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 0
  I0127 21:48:42.360379 26 deployment.go:315] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 0
  I0127 21:48:42.360390 26 deployment.go:313] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 0
  I0127 21:48:42.360403 26 deployment.go:315] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 0
  I0127 21:48:42.360418 26 deployment.go:313] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 0
  I0127 21:48:42.360433 26 deployment.go:315] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 0
  I0127 21:48:42.360542 26 deployment.go:313] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1
  I0127 21:48:42.360566 26 deployment.go:315] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1
  I0127 21:48:42.360576 26 deployment.go:313] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 2
  I0127 21:48:42.360587 26 deployment.go:315] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 2
  I0127 21:48:42.360597 26 deployment.go:313] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 2
  I0127 21:48:42.360607 26 deployment.go:315] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 2
  I0127 21:48:42.389597 26 deployment.go:313] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 2
  I0127 21:48:42.389634 26 deployment.go:315] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 2
  I0127 21:48:42.426128 26 deployment.go:313] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 2
  I0127 21:48:42.426164 26 deployment.go:315] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 2
  E0127 21:48:42.442295      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:42.468235 26 deployment.go:313] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1
  I0127 21:48:42.468273 26 deployment.go:315] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1
  I0127 21:48:42.482475 26 deployment.go:313] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1
  I0127 21:48:42.482516 26 deployment.go:315] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1
  E0127 21:48:43.442511      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:43.849350 26 deployment.go:313] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 2
  I0127 21:48:43.849381 26 deployment.go:315] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 2
  I0127 21:48:43.903291 26 deployment.go:315] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1
  STEP: listing Deployments @ 01/27/26 21:48:43.903
  I0127 21:48:43.905974 26 deployment.go:331] Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 01/27/26 21:48:43.906
  I0127 21:48:43.921972 26 deployment.go:364] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 01/27/26 21:48:43.922
  I0127 21:48:43.936035 26 deployment.go:393] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0127 21:48:43.958787 26 deployment.go:393] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0127 21:48:43.991246 26 deployment.go:393] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0127 21:48:44.019333 26 deployment.go:393] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0127 21:48:44.047046 26 deployment.go:393] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0127 21:48:44.147086 26 deployment.go:393] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0127 21:48:44.443516      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:44.956472 26 deployment.go:393] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0127 21:48:45.443525      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:46.443735      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:46.534104 26 deployment.go:393] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0127 21:48:47.396248 26 deployment.go:393] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  E0127 21:48:47.445335      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:47.575786 26 deployment.go:393] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0127 21:48:47.608605 26 deployment.go:393] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0127 21:48:48.446603      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:48.850236 26 deployment.go:393] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 01/27/26 21:48:49.017
  STEP: fetching the DeploymentStatus @ 01/27/26 21:48:49.044
  I0127 21:48:49.076382 26 deployment.go:452] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1
  I0127 21:48:49.076424 26 deployment.go:452] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1
  I0127 21:48:49.076436 26 deployment.go:452] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1
  I0127 21:48:49.076585 26 deployment.go:452] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1
  I0127 21:48:49.076921 26 deployment.go:452] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1
  I0127 21:48:49.076943 26 deployment.go:452] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1
  I0127 21:48:49.076954 26 deployment.go:452] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 1
  I0127 21:48:49.077068 26 deployment.go:452] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 2
  I0127 21:48:49.077096 26 deployment.go:452] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 3
  I0127 21:48:49.077109 26 deployment.go:452] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 2
  I0127 21:48:49.077207 26 deployment.go:452] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 2
  I0127 21:48:49.077216 26 deployment.go:452] observed Deployment test-deployment in namespace deployment-4175 with ReadyReplicas 3
  STEP: deleting the Deployment @ 01/27/26 21:48:49.077
  I0127 21:48:49.093013 26 deployment.go:478] observed event type MODIFIED
  I0127 21:48:49.093046 26 deployment.go:478] observed event type MODIFIED
  I0127 21:48:49.093056 26 deployment.go:478] observed event type MODIFIED
  I0127 21:48:49.093895 26 deployment.go:478] observed event type MODIFIED
  I0127 21:48:49.093921 26 deployment.go:478] observed event type MODIFIED
  I0127 21:48:49.093946 26 deployment.go:478] observed event type MODIFIED
  I0127 21:48:49.094041 26 deployment.go:478] observed event type MODIFIED
  I0127 21:48:49.094100 26 deployment.go:478] observed event type MODIFIED
  I0127 21:48:49.094137 26 deployment.go:478] observed event type MODIFIED
  I0127 21:48:49.094152 26 deployment.go:478] observed event type MODIFIED
  I0127 21:48:49.094240 26 deployment.go:478] observed event type MODIFIED
  I0127 21:48:49.094391 26 deployment.go:478] observed event type MODIFIED
  I0127 21:48:49.094410 26 deployment.go:478] observed event type MODIFIED
  I0127 21:48:49.094435 26 deployment.go:478] observed event type MODIFIED
  I0127 21:48:49.094590 26 deployment.go:478] observed event type MODIFIED
  I0127 21:48:49.101536 26 deployment.go:653] Log out all the ReplicaSets if there is no deployment created
  I0127 21:48:49.106226 26 deployment.go:660] ReplicaSet "test-deployment-5f9c6bd5bf":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-5f9c6bd5bf",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4175",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4414df4b-4286-4e90-81f2-7ea27626d54e",
      ResourceVersion: (string) (len=5) "47172",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147323,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "5f9c6bd5bf",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "3"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "f4f7b0f6-4f30-4049-9768-64a38d445132",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 66 34 66 37  62 30 66 36 2d 34 66 33  |":\"f4f7b0f6-4f3|
              00000130  30 2d 34 30 34 39 2d 39  37 36 38 2d 36 34 61 33  |0-4049-9768-64a3|
              00000140  38 64 34 34 35 31 33 32  5c 22 7d 22 3a 7b 7d 7d  |8d445132\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=157) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6e 67 52  |,"f:terminatingR|
              00000090  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=22) "test-deployment-static": (string) (len=4) "true",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5f9c6bd5bf"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "5f9c6bd5bf",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 2,
      AvailableReplicas: (int32) 2,
      TerminatingReplicas: (*int32)(0),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I0127 21:48:49.109996 26 deployment.go:672] pod: "test-deployment-5f9c6bd5bf-r5msw":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-5f9c6bd5bf-r5msw",
      GenerateName: (string) (len=27) "test-deployment-5f9c6bd5bf-",
      Namespace: (string) (len=15) "deployment-4175",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c460ddba-c328-4b32-89ad-7977850ea4bd",
      ResourceVersion: (string) (len=5) "47171",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=22) "test-deployment-static": (string) (len=4) "true",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5f9c6bd5bf"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-5f9c6bd5bf",
          UID: (types.UID) (len=36) "4414df4b-4286-4e90-81f2-7ea27626d54e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  34 34 31 34 64 66 34 62  |uid\":\"4414df4b|
              000000a0  2d 34 32 38 36 2d 34 65  39 30 2d 38 31 66 32 2d  |-4286-4e90-81f2-|
              000000b0  37 65 61 32 37 36 32 36  64 35 34 65 5c 22 7d 22  |7ea27626d54e\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=850) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 35  |k:{\"ip\":\"10.5|
              00000320  32 2e 31 2e 32 32 36 5c  22 7d 22 3a 7b 22 2e 22  |2.1.226\"}":{"."|
              00000330  3a 7b 7d 2c 22 66 3a 69  70 22 3a 7b 7d 7d 7d 2c  |:{},"f:ip":{}}},|
              00000340  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              00000350  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7k5kp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7k5kp",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.10",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.10"
        }
      },
      PodIP: (string) (len=11) "10.52.1.226",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.52.1.226"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63905147328,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:10ed98804c877e505e17bced991682b6fd50ab1da9cddcd19935b48d645da40a",
          ContainerID: (string) (len=77) "containerd://541bfdd1a9410ed94aef43766f997feb368306ac50b86045f00fd410bd0b5865",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-7k5kp",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }


  I0127 21:48:49.111687 26 deployment.go:672] pod: "test-deployment-5f9c6bd5bf-vbswk":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-5f9c6bd5bf-vbswk",
      GenerateName: (string) (len=27) "test-deployment-5f9c6bd5bf-",
      Namespace: (string) (len=15) "deployment-4175",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b2c391fd-ea03-4410-a195-c9d10e512764",
      ResourceVersion: (string) (len=5) "47139",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147323,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=22) "test-deployment-static": (string) (len=4) "true",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5f9c6bd5bf"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-5f9c6bd5bf",
          UID: (types.UID) (len=36) "4414df4b-4286-4e90-81f2-7ea27626d54e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  34 34 31 34 64 66 34 62  |uid\":\"4414df4b|
              000000a0  2d 34 32 38 36 2d 34 65  39 30 2d 38 31 66 32 2d  |-4286-4e90-81f2-|
              000000b0  37 65 61 32 37 36 32 36  64 35 34 65 5c 22 7d 22  |7ea27626d54e\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=849) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 35  |k:{\"ip\":\"10.5|
              00000320  32 2e 30 2e 34 39 5c 22  7d 22 3a 7b 22 2e 22 3a  |2.0.49\"}":{".":|
              00000330  7b 7d 2c 22 66 3a 69 70  22 3a 7b 7d 7d 7d 2c 22  |{},"f:ip":{}}},"|
              00000340  66 3a 73 74 61 72 74 54  69 6d 65 22 3a 7b 7d 7d  |f:startTime":{}}|
              00000350  7d                                                |}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-p46pm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-p46pm",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147324,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.12",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.12"
        }
      },
      PodIP: (string) (len=10) "10.52.0.49",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.52.0.49"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147324,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63905147326,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.59",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:10ed98804c877e505e17bced991682b6fd50ab1da9cddcd19935b48d645da40a",
          ContainerID: (string) (len=77) "containerd://1e17e4d0afc6a1e2f116e1b96fa4434e5cee9bfb5e28a7a081f7f5c3dc4a5905",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-p46pm",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }


  I0127 21:48:49.114001 26 deployment.go:660] ReplicaSet "test-deployment-698dfcf79d":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-698dfcf79d",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4175",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e2202c38-9dd3-469f-9c5e-86ef57e2c0aa",
      ResourceVersion: (string) (len=5) "47182",
      Generation: (int64) 4,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147322,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=22) "test-deployment-static": (string) (len=4) "true",
        (string) (len=17) "pod-template-hash": (string) (len=10) "698dfcf79d"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "f4f7b0f6-4f30-4049-9768-64a38d445132",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 66 34 66 37  62 30 66 36 2d 34 66 33  |":\"f4f7b0f6-4f3|
              00000130  30 2d 34 30 34 39 2d 39  37 36 38 2d 36 34 61 33  |0-4049-9768-64a3|
              00000140  38 64 34 34 35 31 33 32  5c 22 7d 22 3a 7b 7d 7d  |8d445132\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=83) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |as":{},"f:termin|
              00000040  61 74 69 6e 67 52 65 70  6c 69 63 61 73 22 3a 7b  |atingReplicas":{|
              00000050  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "698dfcf79d",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "698dfcf79d",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=28) "registry.k8s.io/pause:3.10.1",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(2),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>),
          WorkloadRef: (*v1.WorkloadReference)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(1),
      ObservedGeneration: (int64) 4,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I0127 21:48:49.185336 26 deployment.go:672] pod: "test-deployment-698dfcf79d-bhjg6":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-698dfcf79d-bhjg6",
      GenerateName: (string) (len=27) "test-deployment-698dfcf79d-",
      Namespace: (string) (len=15) "deployment-4175",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b6e1287f-1ad5-48e2-8078-ba8ac023edc3",
      ResourceVersion: (string) (len=5) "47174",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147323,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147329,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(2),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "698dfcf79d",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-698dfcf79d",
          UID: (types.UID) (len=36) "e2202c38-9dd3-469f-9c5e-86ef57e2c0aa",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  65 32 32 30 32 63 33 38  |uid\":\"e2202c38|
              000000a0  2d 39 64 64 33 2d 34 36  39 66 2d 39 63 35 65 2d  |-9dd3-469f-9c5e-|
              000000b0  38 36 65 66 35 37 65 32  63 30 61 61 5c 22 7d 22  |86ef57e2c0aa\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=891) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              000000a0  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000000b0  74 79 70 65 22 3a 7b 7d  7d 2c 22 6b 3a 7b 5c 22  |type":{}},"k:{\"|
              000000c0  74 79 70 65 5c 22 3a 5c  22 49 6e 69 74 69 61 6c  |type\":\"Initial|
              000000d0  69 7a 65 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ized\"}":{".":{}|
              000000e0  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              000000f0  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000100  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000110  22 66 3a 6f 62 73 65 72  76 65 64 47 65 6e 65 72  |"f:observedGener|
              00000120  61 74 69 6f 6e 22 3a 7b  7d 2c 22 66 3a 72 65 61  |ation":{},"f:rea|
              00000130  73 6f 6e 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |son":{},"f:statu|
              00000140  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000150  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000160  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000170  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000180  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000190  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              000001a0  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              000001b0  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              000001c0  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              000001d0  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000001e0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000001f0  5c 22 74 79 70 65 5c 22  3a 5c 22 50 6f 64 53 63  |\"type\":\"PodSc|
              00000200  68 65 64 75 6c 65 64 5c  22 7d 22 3a 7b 22 66 3a  |heduled\"}":{"f:|
              00000210  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000220  6f 6e 22 3a 7b 7d 7d 2c  22 6b 3a 7b 5c 22 74 79  |on":{}},"k:{\"ty|
              00000230  70 65 5c 22 3a 5c 22 52  65 61 64 79 5c 22 7d 22  |pe\":\"Ready\"}"|
              00000240  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000250  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              00000260  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              00000270  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              00000280  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              00000290  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002a0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002b0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002c0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002d0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002e0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              000002f0  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000300  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 70  |eration":{},"f:p|
              00000310  68 61 73 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 49  |hase":{},"f:podI|
              00000320  50 22 3a 7b 7d 2c 22 66  3a 70 6f 64 49 50 73 22  |P":{},"f:podIPs"|
              00000330  3a 7b 22 2e 22 3a 7b 7d  2c 22 6b 3a 7b 5c 22 69  |:{".":{},"k:{\"i|
              00000340  70 5c 22 3a 5c 22 31 30  2e 35 32 2e 30 2e 34 38  |p\":\"10.52.0.48|
              00000350  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000360  69 70 22 3a 7b 7d 7d 7d  2c 22 66 3a 73 74 61 72  |ip":{}}},"f:star|
              00000370  74 54 69 6d 65 22 3a 7b  7d 7d 7d                 |tTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-lg8dl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=28) "registry.k8s.io/pause:3.10.1",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-lg8dl",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(2),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=23) "k3k-k3kcluster-server-0",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 2,
      Phase: (v1.PodPhase) (len=9) "Succeeded",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 2,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 2,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=12) "PodCompleted",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 2,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=12) "PodCompleted",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 2,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=12) "PodCompleted",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 2,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.12",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.12"
        }
      },
      PodIP: (string) (len=10) "10.52.0.48",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.52.0.48"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147323,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)({
              ExitCode: (int32) 0,
              Signal: (int32) 0,
              Reason: (string) (len=9) "Completed",
              Message: (string) "",
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63905147326,
                  loc: (*time.Location)(<already shown>)
                }
              },
              FinishedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63905147328,
                  loc: (*time.Location)(<already shown>)
                }
              },
              ContainerID: (string) (len=77) "containerd://0ff82275661346420a6e1838a2cc76f0d64c0b61d49da2da5cbc6712d59f1997"
            })
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=28) "registry.k8s.io/pause:3.10.1",
          ImageID: (string) (len=93) "registry.k8s.io/pause@sha256:278fb9dbcca9518083ad1e11276933a2e96f23de604a3a08cc3c80002767d24c",
          ContainerID: (string) (len=77) "containerd://0ff82275661346420a6e1838a2cc76f0d64c0b61d49da2da5cbc6712d59f1997",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-lg8dl",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 65535,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=1) {
                (int64) 0
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }


  I0127 21:48:49.187540 26 deployment.go:672] pod: "test-deployment-698dfcf79d-r2nvd":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-698dfcf79d-r2nvd",
      GenerateName: (string) (len=27) "test-deployment-698dfcf79d-",
      Namespace: (string) (len=15) "deployment-4175",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "58de166a-a047-4a83-bddc-0049b28f1b8c",
      ResourceVersion: (string) (len=5) "47181",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147322,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147330,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(2),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "698dfcf79d",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-698dfcf79d",
          UID: (types.UID) (len=36) "e2202c38-9dd3-469f-9c5e-86ef57e2c0aa",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147322,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  65 32 32 30 32 63 33 38  |uid\":\"e2202c38|
              000000a0  2d 39 64 64 33 2d 34 36  39 66 2d 39 63 35 65 2d  |-9dd3-469f-9c5e-|
              000000b0  38 36 65 66 35 37 65 32  63 30 61 61 5c 22 7d 22  |86ef57e2c0aa\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=3) "k3s",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=850) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 35  |k:{\"ip\":\"10.5|
              00000320  32 2e 31 2e 32 32 35 5c  22 7d 22 3a 7b 22 2e 22  |2.1.225\"}":{"."|
              00000330  3a 7b 7d 2c 22 66 3a 69  70 22 3a 7b 7d 7d 7d 2c  |:{},"f:ip":{}}},|
              00000340  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              00000350  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-djh4c",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=28) "registry.k8s.io/pause:3.10.1",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-djh4c",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(2),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=46) "k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>),
      WorkloadRef: (*v1.WorkloadReference)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 2,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 2,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 2,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147322,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 2,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 2,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 2,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63905147322,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "10.42.0.10",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "10.42.0.10"
        }
      },
      PodIP: (string) (len=11) "10.52.1.225",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.52.1.225"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63905147322,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63905147323,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=28) "registry.k8s.io/pause:3.10.1",
          ImageID: (string) (len=93) "registry.k8s.io/pause@sha256:278fb9dbcca9518083ad1e11276933a2e96f23de604a3a08cc3c80002767d24c",
          ContainerID: (string) (len=77) "containerd://089556050fc027e29907912a2d88c34326327a1fa0b1c81cf7b6c1d4d1ec41c0",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-djh4c",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 65535,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=1) {
                (int64) 0
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>),
      AllocatedResources: (v1.ResourceList) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    }
  }


  I0127 21:48:49.189178 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4175" for this suite. @ 01/27/26 21:48:49.191
• [8.792 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:208
  STEP: Creating a kubernetes client @ 01/27/26 21:48:49.204
  I0127 21:48:49.204520 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename downward-api @ 01/27/26 21:48:49.205
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:48:49.227
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:48:49.231
  STEP: Creating a pod to test downward API volume plugin @ 01/27/26 21:48:49.233
  E0127 21:48:49.446644      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:50.447354      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:51.448344      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:52.448840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:48:53.359
  I0127 21:48:53.364004 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downwardapi-volume-6788f0e5-ad58-4e90-b12f-26e8079d5179 container client-container: <nil>
  STEP: delete the pod @ 01/27/26 21:48:53.369
  I0127 21:48:53.408898 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9577" for this suite. @ 01/27/26 21:48:53.411
• [4.214 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:331
  STEP: Creating a kubernetes client @ 01/27/26 21:48:53.418
  I0127 21:48:53.418873 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename webhook @ 01/27/26 21:48:53.419
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:48:53.441
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:48:53.446
  E0127 21:48:53.449087      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Setting up server cert @ 01/27/26 21:48:53.476
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/27/26 21:48:53.729
  STEP: Deploying the webhook pod @ 01/27/26 21:48:53.745
  STEP: Wait for the deployment to be ready @ 01/27/26 21:48:53.769
  I0127 21:48:53.783878 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0127 21:48:54.449495      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:55.449829      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/27/26 21:48:55.79
  STEP: Verifying the service has paired with the endpoint @ 01/27/26 21:48:55.806
  I0127 21:48:55.806243 26 wait.go:65] Waiting for amount of service webhook-135/e2e-test-webhook endpoints to be 1
  I0127 21:48:55.809064 26 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  E0127 21:48:56.450866      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:56.809764 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-135-8287-crds.webhook.example.com via the AdmissionRegistration API @ 01/27/26 21:48:57.326
  STEP: Creating a custom resource that should be mutated by the webhook @ 01/27/26 21:48:57.352
  E0127 21:48:57.451729      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:58.451737      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:48:59.452468      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:48:59.998022 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-135" for this suite. @ 01/27/26 21:49:00.001
  STEP: Destroying namespace "webhook-markers-1519" for this suite. @ 01/27/26 21:49:00.009
• [6.599 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:406
  STEP: Creating a kubernetes client @ 01/27/26 21:49:00.018
  I0127 21:49:00.018387 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename resourcequota @ 01/27/26 21:49:00.018
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:49:00.035
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:49:00.051
  STEP: Counting existing ResourceQuota @ 01/27/26 21:49:00.053
  E0127 21:49:00.453166      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:01.453492      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:02.453671      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:03.454487      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:04.455298      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 01/27/26 21:49:05.055
  STEP: Ensuring resource quota status is calculated @ 01/27/26 21:49:05.079
  E0127 21:49:05.455984      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:06.456854      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:49:07.085080 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc003df2c80>: 
          metadata:
            creationTimestamp: "2026-01-27T21:49:05Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:49:05Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T21:49:05Z"
            name: test-quota
            namespace: resourcequota-3518
            resourceVersion: "47412"
            uid: 88c82484-906e-45bd-b5ec-19f49d1933f8
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Creating a ReplicationController @ 01/27/26 21:49:07.085
  STEP: Ensuring resource quota status captures replication controller creation @ 01/27/26 21:49:07.107
  I0127 21:49:07.111177 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc003e5f540>: 
          metadata:
            creationTimestamp: "2026-01-27T21:49:05Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:49:05Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T21:49:07Z"
            name: test-quota
            namespace: resourcequota-3518
            resourceVersion: "47432"
            uid: 88c82484-906e-45bd-b5ec-19f49d1933f8
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "1"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Deleting a ReplicationController @ 01/27/26 21:49:07.111
  STEP: Ensuring resource quota status released usage @ 01/27/26 21:49:07.123
  E0127 21:49:07.457685      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:08.457919      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:49:09.129507 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc003e5fb80>: 
          metadata:
            creationTimestamp: "2026-01-27T21:49:05Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:49:05Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T21:49:07Z"
            name: test-quota
            namespace: resourcequota-3518
            resourceVersion: "47436"
            uid: 88c82484-906e-45bd-b5ec-19f49d1933f8
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  I0127 21:49:09.129932 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3518" for this suite. @ 01/27/26 21:49:09.131
• [9.121 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaimTemplate [Conformance] [sig-node, DRA, Conformance]
k8s.io/kubernetes/test/e2e/dra/dra.go:167
  STEP: Creating a kubernetes client @ 01/27/26 21:49:09.139
  I0127 21:49:09.139631 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename dra @ 01/27/26 21:49:09.14
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:49:09.166
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:49:09.169
  STEP: Get resource.k8s.io/v1 @ 01/27/26 21:49:09.172
  I0127 21:49:09.174040      26 shared_informer.go:370] "Waiting for caches to sync"
  I0127 21:49:09.275025      26 shared_informer.go:377] "Caches are synced"
  STEP: Creating:
      <*unstructured.Unstructured | 0xc00008fee0>: 
          metadata:
            labels:
              e2e-test.kubernetes.io: dra-8167
            name: test
            namespace: dra-8167
          spec:
            metadata: {}
            spec:
              devices:
                requests:
                - exactly:
                    deviceClassName: dra.example.com
                  name: req-0 @ 01/27/26 21:49:09.275
  STEP: Getting dra-8167/test @ 01/27/26 21:49:09.283
  STEP: Updating:
      <*unstructured.Unstructured | 0xc001b962d8>: 
          apiVersion: resource.k8s.io/v1
          kind: ResourceClaimTemplate
          metadata:
            creationTimestamp: "2026-01-27T21:49:09Z"
            labels:
              e2e-test.kubernetes.io: dra-8167
              test.dra.example.com: test
            managedFields:
            - apiVersion: resource.k8s.io/v1
              fieldsType: FieldsV1
              fieldsV1:
                f:metadata:
                  f:labels:
                    .: {}
                    f:e2e-test.kubernetes.io: {}
                f:spec:
                  f:spec:
                    f:devices:
                      f:requests: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:49:09Z"
            name: test
            namespace: dra-8167
            resourceVersion: "47446"
            uid: 8dd0aa4d-b2d5-4c3a-abbf-3b3d1d6675ae
          spec:
            metadata: {}
            spec:
              devices:
                requests:
                - exactly:
                    allocationMode: ExactCount
                    count: 1
                    deviceClassName: dra.example.com
                  name: req-0 @ 01/27/26 21:49:09.286
  STEP: Deleting dra-8167/test @ 01/27/26 21:49:09.296
  STEP: Checking for existence @ 01/27/26 21:49:09.304
  STEP: Creating again:
      <*unstructured.Unstructured | 0xc00008fee0>: 
          metadata:
            labels:
              e2e-test.kubernetes.io: dra-8167
            name: test
            namespace: dra-8167
          spec:
            metadata: {}
            spec:
              devices:
                requests:
                - exactly:
                    deviceClassName: dra.example.com
                  name: req-0 @ 01/27/26 21:49:09.307
  STEP: Patching with application/strategic-merge-patch+json:
  {"apiVersion":"resource.k8s.io/v1","kind":"ResourceClaimTemplate","metadata":{"labels":{"test.dra.example.com":"test"},"name":"test","namespace":"dra-8167","uid":"9a68f8da-6158-44c4-a211-1933fc75f37d"}}
   @ 01/27/26 21:49:09.314
  STEP: Listing resource.k8s.io/v1, Resource=resourceclaimtemplates collection with label selector e2e-test.kubernetes.io=dra-8167 @ 01/27/26 21:49:09.324
  STEP: Listing resource.k8s.io/v1, Resource=resourceclaimtemplates without namespace and with label selector e2e-test.kubernetes.io=dra-8167 @ 01/27/26 21:49:09.326
  STEP: Deleting resource.k8s.io/v1, Resource=resourceclaimtemplates collection with label selector e2e-test.kubernetes.io=dra-8167 @ 01/27/26 21:49:09.328
  STEP: Checking for existence @ 01/27/26 21:49:09.336
  I0127 21:49:09.339373 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dra-8167" for this suite. @ 01/27/26 21:49:09.351
• [0.225 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:826
  STEP: Creating a kubernetes client @ 01/27/26 21:49:09.364
  I0127 21:49:09.364980 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename gc @ 01/27/26 21:49:09.365
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:49:09.385
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:49:09.387
  E0127 21:49:09.459392      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:49:09.462632 26 garbage_collector.go:848] pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"1a60a4f1-493c-44bc-bb7f-c9f7c02573e8", Controller:(*bool)(0xc0022e2f56), BlockOwnerDeletion:(*bool)(0xc0022e2f57)}}
  I0127 21:49:09.479191 26 garbage_collector.go:852] pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"e231aa5d-c291-4b08-b6c5-4cdc7eb981f7", Controller:(*bool)(0xc0022e30fe), BlockOwnerDeletion:(*bool)(0xc0022e30ff)}}
  I0127 21:49:09.514075 26 garbage_collector.go:856] pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"f4f066c5-fe0f-49c8-a96d-e72620ac3489", Controller:(*bool)(0xc0022e3286), BlockOwnerDeletion:(*bool)(0xc0022e3287)}}
  E0127 21:49:10.459541      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:11.459755      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:12.459983      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:13.460589      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:14.460769      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:49:14.572900 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3890" for this suite. @ 01/27/26 21:49:14.574
• [5.224 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Pods Extended (pod generation) Pod Generation pod generation should start at 1 and increment per update [MinimumKubeletVersion:1.34] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:437
  STEP: Creating a kubernetes client @ 01/27/26 21:49:14.588
  I0127 21:49:14.588786 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pods @ 01/27/26 21:49:14.589
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:49:14.604
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:49:14.658
  STEP: creating the pod @ 01/27/26 21:49:14.66
  STEP: submitting the pod to kubernetes @ 01/27/26 21:49:14.66
  E0127 21:49:15.461418      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:16.461730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:17.461767      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:18.462326      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: verifying pod generation bumps as expected @ 01/27/26 21:49:18.692
  STEP: empty update @ 01/27/26 21:49:18.692
  I0127 21:49:19.199658 26 pod_client.go:187] Successfully updated pod "pod-generation-c291dbda-5789-41f5-8d24-71319e9188d3"
  STEP: updating Tolerations to trigger generation bump @ 01/27/26 21:49:19.202
  E0127 21:49:19.463096      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:49:19.722891 26 pod_client.go:187] Successfully updated pod "pod-generation-c291dbda-5789-41f5-8d24-71319e9188d3"
  E0127 21:49:20.464051      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:21.464419      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: updating ActiveDeadlineSeconds to trigger generation bump @ 01/27/26 21:49:21.742
  I0127 21:49:22.261187 26 pod_client.go:187] Successfully updated pod "pod-generation-c291dbda-5789-41f5-8d24-71319e9188d3"
  E0127 21:49:22.465208      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:23.465893      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: updating container image to trigger generation bump @ 01/27/26 21:49:24.269
  E0127 21:49:24.466479      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:49:24.789317 26 pod_client.go:187] Successfully updated pod "pod-generation-c291dbda-5789-41f5-8d24-71319e9188d3"
  E0127 21:49:25.467788      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:26.468036      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: updating initContainer image to trigger generation bump @ 01/27/26 21:49:26.794
  I0127 21:49:27.313549 26 pod_client.go:187] Successfully updated pod "pod-generation-c291dbda-5789-41f5-8d24-71319e9188d3"
  E0127 21:49:27.468762      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:28.469191      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: updates to pod metadata should not trigger generation bump @ 01/27/26 21:49:29.32
  E0127 21:49:29.470342      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:49:29.850319 26 pod_client.go:187] Successfully updated pod "pod-generation-c291dbda-5789-41f5-8d24-71319e9188d3"
  STEP: pod generation updated by client should be ignored @ 01/27/26 21:49:29.857
  I0127 21:49:30.364187 26 pod_client.go:187] Successfully updated pod "pod-generation-c291dbda-5789-41f5-8d24-71319e9188d3"
  STEP: deleting the pod @ 01/27/26 21:49:30.368
  I0127 21:49:30.400782 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5339" for this suite. @ 01/27/26 21:49:30.403
• [15.824 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:140
  STEP: Creating a kubernetes client @ 01/27/26 21:49:30.412
  I0127 21:49:30.412852 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 01/27/26 21:49:30.413
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:49:30.441
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:49:30.444
  E0127 21:49:30.471378      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: create the container to handle the HTTPGet hook request. @ 01/27/26 21:49:30.503
  E0127 21:49:31.471746      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:32.472833      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:33.473660      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:34.473922      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 01/27/26 21:49:34.542
  E0127 21:49:35.474511      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:36.474699      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 01/27/26 21:49:36.558
  STEP: delete the pod with lifecycle hook @ 01/27/26 21:49:36.562
  E0127 21:49:37.475745      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:38.475898      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:49:38.583141 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-6132" for this suite. @ 01/27/26 21:49:38.585
• [8.182 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:472
  STEP: Creating a kubernetes client @ 01/27/26 21:49:38.595
  I0127 21:49:38.595084 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename field-validation @ 01/27/26 21:49:38.595
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:49:38.621
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:49:38.623
  I0127 21:49:38.626154 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  E0127 21:49:39.476831      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:40.477108      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:49:41.160661      26 warnings.go:107] "Warning: unknown field \"alpha\""
  I0127 21:49:41.160696      26 warnings.go:107] "Warning: unknown field \"beta\""
  I0127 21:49:41.160707      26 warnings.go:107] "Warning: unknown field \"delta\""
  I0127 21:49:41.160714      26 warnings.go:107] "Warning: unknown field \"epsilon\""
  I0127 21:49:41.160721      26 warnings.go:107] "Warning: unknown field \"gamma\""
  E0127 21:49:41.477205      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:49:41.707176 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7048" for this suite. @ 01/27/26 21:49:41.709
• [3.127 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:194
  STEP: Creating a kubernetes client @ 01/27/26 21:49:41.722
  I0127 21:49:41.722743 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename downward-api @ 01/27/26 21:49:41.723
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:49:41.744
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:49:41.746
  STEP: Creating a pod to test downward API volume plugin @ 01/27/26 21:49:41.748
  E0127 21:49:42.477368      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:43.478075      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:44.478696      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:45.478847      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:49:45.776
  I0127 21:49:45.778625 26 output.go:207] Trying to get logs from node k3k-k3kcluster-server-0 pod downwardapi-volume-b4712f5b-12f8-4bc6-87e5-8da7d15de1c2 container client-container: <nil>
  STEP: delete the pod @ 01/27/26 21:49:45.786
  I0127 21:49:45.818714 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3271" for this suite. @ 01/27/26 21:49:45.821
• [4.114 seconds]
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 01/27/26 21:49:45.836
  I0127 21:49:45.836604 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename container-probe @ 01/27/26 21:49:45.837
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:49:45.853
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:49:45.859
  STEP: Creating pod liveness-4b112c3f-702e-4f96-8eb2-2e1c977d3bbe in namespace container-probe-1648 @ 01/27/26 21:49:45.861
  E0127 21:49:46.479501      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:47.480141      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 01/27/26 21:49:47.882
  I0127 21:49:47.884352 26 container_probe.go:1746] Initial restart count of pod liveness-4b112c3f-702e-4f96-8eb2-2e1c977d3bbe is 0
  I0127 21:49:47.886402 26 container_probe.go:1756] Get pod liveness-4b112c3f-702e-4f96-8eb2-2e1c977d3bbe in namespace container-probe-1648
  E0127 21:49:48.480158      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:49.481295      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:49:49.893889 26 container_probe.go:1756] Get pod liveness-4b112c3f-702e-4f96-8eb2-2e1c977d3bbe in namespace container-probe-1648
  E0127 21:49:50.481756      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:51.481916      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:49:51.896798 26 container_probe.go:1756] Get pod liveness-4b112c3f-702e-4f96-8eb2-2e1c977d3bbe in namespace container-probe-1648
  E0127 21:49:52.482171      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:53.482278      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:49:53.899986 26 container_probe.go:1756] Get pod liveness-4b112c3f-702e-4f96-8eb2-2e1c977d3bbe in namespace container-probe-1648
  E0127 21:49:54.482715      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:55.482943      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:49:55.902840 26 container_probe.go:1756] Get pod liveness-4b112c3f-702e-4f96-8eb2-2e1c977d3bbe in namespace container-probe-1648
  E0127 21:49:56.483669      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:57.483728      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:49:57.908001 26 container_probe.go:1756] Get pod liveness-4b112c3f-702e-4f96-8eb2-2e1c977d3bbe in namespace container-probe-1648
  E0127 21:49:58.484963      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:49:59.485221      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:49:59.911516 26 container_probe.go:1756] Get pod liveness-4b112c3f-702e-4f96-8eb2-2e1c977d3bbe in namespace container-probe-1648
  E0127 21:50:00.486255      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:01.486837      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:50:01.914695 26 container_probe.go:1756] Get pod liveness-4b112c3f-702e-4f96-8eb2-2e1c977d3bbe in namespace container-probe-1648
  E0127 21:50:02.487458      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:03.487705      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:50:03.917562 26 container_probe.go:1756] Get pod liveness-4b112c3f-702e-4f96-8eb2-2e1c977d3bbe in namespace container-probe-1648
  E0127 21:50:04.487779      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:05.488090      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:50:05.920701 26 container_probe.go:1756] Get pod liveness-4b112c3f-702e-4f96-8eb2-2e1c977d3bbe in namespace container-probe-1648
  E0127 21:50:06.488591      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:07.488790      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:50:07.923756 26 container_probe.go:1756] Get pod liveness-4b112c3f-702e-4f96-8eb2-2e1c977d3bbe in namespace container-probe-1648
  I0127 21:50:07.923811 26 container_probe.go:1760] Restart count of pod container-probe-1648/liveness-4b112c3f-702e-4f96-8eb2-2e1c977d3bbe is now 1 (20.039418541s elapsed)
  STEP: deleting the pod @ 01/27/26 21:50:07.923
  I0127 21:50:07.950315 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1648" for this suite. @ 01/27/26 21:50:07.952
• [22.131 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:802
  STEP: Creating a kubernetes client @ 01/27/26 21:50:07.967
  I0127 21:50:07.967631 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename services @ 01/27/26 21:50:07.968
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:50:07.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:50:07.995
  STEP: creating service multi-endpoint-test in namespace services-1904 @ 01/27/26 21:50:07.997
  I0127 21:50:08.018699 26 wait.go:65] Waiting for amount of service services-1904/multi-endpoint-test endpoints to be 0
  STEP: creating pod1 serving port1 @ 01/27/26 21:50:08.031
  STEP: Creating pod pod1 in namespace services-1904 @ 01/27/26 21:50:08.031
  E0127 21:50:08.489096      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:09.489324      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:50:10.050936 26 wait.go:139] Waiting for service services-1904/multi-endpoint-test to have endpoints for ports [{portname1  pod1 100}]
  STEP: creating pod2 serving port2 @ 01/27/26 21:50:10.052
  STEP: Creating pod pod2 in namespace services-1904 @ 01/27/26 21:50:10.052
  E0127 21:50:10.490221      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:11.490450      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:50:12.067714 26 wait.go:139] Waiting for service services-1904/multi-endpoint-test to have endpoints for ports [{portname1  pod1 100} {portname2  pod2 101}]
  STEP: Checking if the Service forwards traffic to pods @ 01/27/26 21:50:12.069
  I0127 21:50:12.069613 26 resource.go:344] Creating new exec pod
  E0127 21:50:12.490744      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:13.490997      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:50:14.085631 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1904 exec execpodzwlsf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  I0127 21:50:14.193978 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test (10.53.228.223) 80 port [tcp/http] succeeded!\n"
  I0127 21:50:14.194023 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 21:50:14.194100 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1904 exec execpodzwlsf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.228.223 80'
  I0127 21:50:14.308032 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.53.228.223 80\nConnection to 10.53.228.223 80 port [tcp/http] succeeded!\n"
  I0127 21:50:14.308079 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 21:50:14.308152 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1904 exec execpodzwlsf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  I0127 21:50:14.424771 26 builder.go:156] stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test (10.53.228.223) 81 port [tcp/*] succeeded!\n"
  I0127 21:50:14.424819 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 21:50:14.424875 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1904 exec execpodzwlsf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.228.223 81'
  E0127 21:50:14.491322      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:50:14.531968 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.53.228.223 81\nConnection to 10.53.228.223 81 port [tcp/*] succeeded!\n"
  I0127 21:50:14.532016 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: deleting pod1 serving port1 @ 01/27/26 21:50:14.532
  STEP: Deleting pod pod1 in namespace services-1904 @ 01/27/26 21:50:14.532
  I0127 21:50:14.570589 26 wait.go:139] Waiting for service services-1904/multi-endpoint-test to have endpoints for ports [{portname2  pod2 101}]
  I0127 21:50:14.575574 26 wait.go:169] Unexpected port mappings on slices, missing: [], extra: [{portname1 TCP pod1 100}]
  E0127 21:50:15.491861      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting pod2 serving port2 @ 01/27/26 21:50:15.574
  STEP: Deleting pod pod2 in namespace services-1904 @ 01/27/26 21:50:15.574
  I0127 21:50:15.616731 26 wait.go:65] Waiting for amount of service services-1904/multi-endpoint-test endpoints to be 0
  I0127 21:50:15.660941 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1904" for this suite. @ 01/27/26 21:50:15.666
• [7.713 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:139
  STEP: Creating a kubernetes client @ 01/27/26 21:50:15.68
  I0127 21:50:15.680828 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename emptydir @ 01/27/26 21:50:15.681
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:50:15.701
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:50:15.704
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 01/27/26 21:50:15.752
  E0127 21:50:16.492026      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:17.492841      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:18.493630      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:19.493852      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:50:19.784
  I0127 21:50:19.786669 26 output.go:207] Trying to get logs from node k3k-k3kcluster-server-0 pod pod-e7496cba-acf5-4dad-a436-00bab94f12b7 container test-container: <nil>
  STEP: delete the pod @ 01/27/26 21:50:19.79
  I0127 21:50:19.819769 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-771" for this suite. @ 01/27/26 21:50:19.823
• [4.151 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:243
  STEP: Creating a kubernetes client @ 01/27/26 21:50:19.831
  I0127 21:50:19.831880 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename resourcequota @ 01/27/26 21:50:19.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:50:19.858
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:50:19.86
  STEP: Counting existing ResourceQuota @ 01/27/26 21:50:19.862
  E0127 21:50:20.494512      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:21.494898      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:22.495344      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:23.495692      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:24.496559      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 01/27/26 21:50:24.865
  STEP: Ensuring resource quota status is calculated @ 01/27/26 21:50:24.878
  E0127 21:50:25.497119      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:26.497379      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:50:26.884718 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc000f39e00>: 
          metadata:
            creationTimestamp: "2026-01-27T21:50:24Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:50:24Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T21:50:24Z"
            name: test-quota
            namespace: resourcequota-9299
            resourceVersion: "47991"
            uid: 03064971-8694-4c1e-b67f-f6a4293877f1
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Creating a Pod that fits quota @ 01/27/26 21:50:26.885
  STEP: Ensuring ResourceQuota status captures the pod usage @ 01/27/26 21:50:26.915
  I0127 21:50:26.917985 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc000c9d540>: 
          metadata:
            creationTimestamp: "2026-01-27T21:50:24Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:50:24Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T21:50:26Z"
            name: test-quota
            namespace: resourcequota-9299
            resourceVersion: "48005"
            uid: 03064971-8694-4c1e-b67f-f6a4293877f1
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: 500m
              ephemeral-storage: 30Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: 252Mi
              persistentvolumeclaims: "0"
              pods: "1"
              replicationcontrollers: "0"
              requests.example.com/dongle: "2"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 01/27/26 21:50:26.918
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 01/27/26 21:50:26.921
  STEP: Ensuring a pod cannot update its resource requirements @ 01/27/26 21:50:26.922
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 01/27/26 21:50:26.928
  I0127 21:50:26.930872 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001a73180>: 
          metadata:
            creationTimestamp: "2026-01-27T21:50:24Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:50:24Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T21:50:26Z"
            name: test-quota
            namespace: resourcequota-9299
            resourceVersion: "48005"
            uid: 03064971-8694-4c1e-b67f-f6a4293877f1
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: 500m
              ephemeral-storage: 30Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: 252Mi
              persistentvolumeclaims: "0"
              pods: "1"
              replicationcontrollers: "0"
              requests.example.com/dongle: "2"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Deleting the pod @ 01/27/26 21:50:26.931
  STEP: Ensuring resource quota status released the pod usage @ 01/27/26 21:50:26.952
  E0127 21:50:27.497627      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:28.498254      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:50:28.966744 26 resource_quota.go:2499] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc0004b7540>: 
          metadata:
            creationTimestamp: "2026-01-27T21:50:24Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2026-01-27T21:50:24Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: k3s
              operation: Update
              subresource: status
              time: "2026-01-27T21:50:26Z"
            name: test-quota
            namespace: resourcequota-9299
            resourceVersion: "48011"
            uid: 03064971-8694-4c1e-b67f-f6a4293877f1
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  I0127 21:50:28.967186 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9299" for this suite. @ 01/27/26 21:50:28.969
• [9.145 seconds]
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:62
  STEP: Creating a kubernetes client @ 01/27/26 21:50:28.976
  I0127 21:50:28.976778 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename containers @ 01/27/26 21:50:28.977
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:50:29.008
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:50:29.009
  STEP: Creating a pod to test override arguments @ 01/27/26 21:50:29.013
  E0127 21:50:29.499193      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:30.499325      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:31.499974      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:32.501004      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:50:33.031
  I0127 21:50:33.033983 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod client-containers-25dff623-2e22-4d1a-b1b0-e54312f8b9c7 container agnhost-container: <nil>
  STEP: delete the pod @ 01/27/26 21:50:33.037
  I0127 21:50:33.060686 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-8027" for this suite. @ 01/27/26 21:50:33.063
• [4.091 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 01/27/26 21:50:33.067
  I0127 21:50:33.067680 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename container-probe @ 01/27/26 21:50:33.068
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:50:33.082
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:50:33.084
  E0127 21:50:33.501986      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:34.502181      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:35.502921      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:36.503108      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:37.503297      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:38.503793      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:39.503998      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:40.504120      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:41.504957      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:42.505257      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:43.506005      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:44.506112      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:45.507120      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:46.507340      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:47.508173      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:48.508846      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:49.509757      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:50.509959      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:51.510400      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:52.510606      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:53.510937      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:54.511242      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:55.512107      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:56.512874      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:50:57.133404 26 container_probe.go:91] Container started at 2026-01-27 21:50:34 +0000 UTC, pod became ready at 2026-01-27 21:50:56 +0000 UTC
  I0127 21:50:57.133543 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2140" for this suite. @ 01/27/26 21:50:57.136
• [24.077 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] EndpointsController should create Endpoints for Pods matching a Service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpoints.go:307
  STEP: Creating a kubernetes client @ 01/27/26 21:50:57.144
  I0127 21:50:57.144641 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename endpoints @ 01/27/26 21:50:57.145
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:50:57.167
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:50:57.17
  E0127 21:50:57.513348      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:50:58.513545      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 01/27/26 21:50:59.255
  I0127 21:50:59.256999      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: referencing matching pods with named port @ 01/27/26 21:50:59.257
  I0127 21:50:59.258252      26 warnings.go:107] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0127 21:50:59.258401 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpoints-7534" for this suite. @ 01/27/26 21:50:59.261
• [2.125 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 01/27/26 21:50:59.269
  I0127 21:50:59.269827 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename discovery @ 01/27/26 21:50:59.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:50:59.296
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:50:59.298
  STEP: Setting up server cert @ 01/27/26 21:50:59.302
  STEP: Requesting APIResourceList from "/api/v1" @ 01/27/26 21:50:59.504
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 01/27/26 21:50:59.507
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 01/27/26 21:50:59.508
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 01/27/26 21:50:59.508
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 01/27/26 21:50:59.509
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 01/27/26 21:50:59.51
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 01/27/26 21:50:59.511
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 01/27/26 21:50:59.512
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 01/27/26 21:50:59.513
  E0127 21:50:59.513535      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 01/27/26 21:50:59.514
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 01/27/26 21:50:59.514
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 01/27/26 21:50:59.515
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 01/27/26 21:50:59.516
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 01/27/26 21:50:59.516
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 01/27/26 21:50:59.517
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 01/27/26 21:50:59.518
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 01/27/26 21:50:59.519
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 01/27/26 21:50:59.52
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 01/27/26 21:50:59.521
  I0127 21:50:59.522222 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-2595" for this suite. @ 01/27/26 21:50:59.524
• [0.262 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:175
  STEP: Creating a kubernetes client @ 01/27/26 21:50:59.532
  I0127 21:50:59.532470 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename configmap @ 01/27/26 21:50:59.533
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:50:59.553
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:50:59.558
  STEP: Creating configMap with name configmap-test-upd-6571ef64-3b6a-445d-a997-92f0745f66fc @ 01/27/26 21:50:59.624
  STEP: Creating the pod @ 01/27/26 21:50:59.635
  E0127 21:51:00.514243      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:01.514804      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:02.515160      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:03.515742      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 01/27/26 21:51:03.669
  STEP: Waiting for pod with binary data @ 01/27/26 21:51:03.673
  I0127 21:51:03.677445 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6554" for this suite. @ 01/27/26 21:51:03.679
• [4.230 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:333
  STEP: Creating a kubernetes client @ 01/27/26 21:51:03.762
  I0127 21:51:03.762199 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename sched-pred @ 01/27/26 21:51:03.763
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:51:03.862
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:51:03.864
  I0127 21:51:03.866835 26 helper.go:125] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0127 21:51:03.870565 26 util.go:389] Waiting for terminating namespaces to be deleted...
  I0127 21:51:03.872669 26 predicates.go:120] 
  Logging pods the apiserver thinks is on node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 before test
  I0127 21:51:03.874619 26 predicates.go:958] pod2 from endpoints-7534 started at 2026-01-27 21:50:57 +0000 UTC (1 container statuses recorded)
  I0127 21:51:03.874641 26 predicates.go:960] 	Container container1 ready: true, restart count 0
  I0127 21:51:03.874649 26 predicates.go:958] svclb-traefik-4c5baeff-bbb24 from kube-system started at 2026-01-27 21:35:05 +0000 UTC (2 container statuses recorded)
  I0127 21:51:03.874656 26 predicates.go:960] 	Container lb-tcp-443 ready: true, restart count 0
  I0127 21:51:03.874663 26 predicates.go:960] 	Container lb-tcp-80 ready: true, restart count 0
  I0127 21:51:03.874670 26 predicates.go:958] sonobuoy from sonobuoy started at 2026-01-27 19:52:38 +0000 UTC (1 container statuses recorded)
  I0127 21:51:03.874676 26 predicates.go:960] 	Container kube-sonobuoy ready: true, restart count 0
  I0127 21:51:03.874683 26 predicates.go:958] sonobuoy-e2e-job-211431d51fbc478c from sonobuoy started at 2026-01-27 19:52:42 +0000 UTC (2 container statuses recorded)
  I0127 21:51:03.874688 26 predicates.go:960] 	Container e2e ready: true, restart count 0
  I0127 21:51:03.874694 26 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0127 21:51:03.874701 26 predicates.go:958] sonobuoy-systemd-logs-daemon-set-7c9a66bc53524567-gzwrw from sonobuoy started at 2026-01-27 19:52:42 +0000 UTC (2 container statuses recorded)
  I0127 21:51:03.874707 26 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0127 21:51:03.874713 26 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  I0127 21:51:03.874720 26 predicates.go:120] 
  Logging pods the apiserver thinks is on node k3k-k3kcluster-server-0 before test
  I0127 21:51:03.876752 26 predicates.go:958] pod-configmaps-4663635d-f8b6-4c55-b3de-a107ceab4536 from configmap-6554 started at 2026-01-27 21:50:59 +0000 UTC (2 container statuses recorded)
  I0127 21:51:03.876775 26 predicates.go:960] 	Container agnhost-container ready: true, restart count 0
  I0127 21:51:03.876783 26 predicates.go:960] 	Container configmap-volume-binary-test ready: false, restart count 0
  I0127 21:51:03.876791 26 predicates.go:958] pod1 from endpoints-7534 started at 2026-01-27 21:50:57 +0000 UTC (1 container statuses recorded)
  I0127 21:51:03.876798 26 predicates.go:960] 	Container container1 ready: true, restart count 0
  I0127 21:51:03.876804 26 predicates.go:958] coredns-54bf7cdff9-hvd6n from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 21:51:03.876811 26 predicates.go:960] 	Container coredns ready: true, restart count 0
  I0127 21:51:03.876818 26 predicates.go:958] helm-install-traefik-ck8zv from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 21:51:03.876824 26 predicates.go:960] 	Container helm ready: false, restart count 1
  I0127 21:51:03.876830 26 predicates.go:958] helm-install-traefik-crd-kw4dk from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 21:51:03.876837 26 predicates.go:960] 	Container helm ready: false, restart count 0
  I0127 21:51:03.876843 26 predicates.go:958] local-path-provisioner-69879d7dd7-xrhgn from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 21:51:03.876849 26 predicates.go:960] 	Container local-path-provisioner ready: true, restart count 0
  I0127 21:51:03.876856 26 predicates.go:958] metrics-server-77dbbf84b-fkr5h from kube-system started at 2026-01-27 19:40:31 +0000 UTC (1 container statuses recorded)
  I0127 21:51:03.876863 26 predicates.go:960] 	Container metrics-server ready: true, restart count 0
  I0127 21:51:03.876873 26 predicates.go:958] svclb-traefik-4c5baeff-dqplp from kube-system started at 2026-01-27 19:41:06 +0000 UTC (2 container statuses recorded)
  I0127 21:51:03.876879 26 predicates.go:960] 	Container lb-tcp-443 ready: true, restart count 0
  I0127 21:51:03.876885 26 predicates.go:960] 	Container lb-tcp-80 ready: true, restart count 0
  I0127 21:51:03.876893 26 predicates.go:958] traefik-6d98778dfc-p2jdc from kube-system started at 2026-01-27 19:41:06 +0000 UTC (1 container statuses recorded)
  I0127 21:51:03.876899 26 predicates.go:960] 	Container traefik ready: true, restart count 0
  I0127 21:51:03.876906 26 predicates.go:958] sonobuoy-systemd-logs-daemon-set-7c9a66bc53524567-h78hs from sonobuoy started at 2026-01-27 19:52:42 +0000 UTC (2 container statuses recorded)
  I0127 21:51:03.876912 26 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0127 21:51:03.876919 26 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 @ 01/27/26 21:51:03.898
  STEP: verifying the node has the label node k3k-k3kcluster-server-0 @ 01/27/26 21:51:03.911
  I0127 21:51:03.976718 26 predicates.go:373] Pod pod-configmaps-4663635d-f8b6-4c55-b3de-a107ceab4536 requesting resource cpu=0m on Node k3k-k3kcluster-server-0
  I0127 21:51:03.976748 26 predicates.go:373] Pod pod1 requesting resource cpu=0m on Node k3k-k3kcluster-server-0
  I0127 21:51:03.976756 26 predicates.go:373] Pod pod2 requesting resource cpu=0m on Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2
  I0127 21:51:03.976763 26 predicates.go:373] Pod coredns-54bf7cdff9-hvd6n requesting resource cpu=100m on Node k3k-k3kcluster-server-0
  I0127 21:51:03.976770 26 predicates.go:373] Pod local-path-provisioner-69879d7dd7-xrhgn requesting resource cpu=0m on Node k3k-k3kcluster-server-0
  I0127 21:51:03.976778 26 predicates.go:373] Pod metrics-server-77dbbf84b-fkr5h requesting resource cpu=100m on Node k3k-k3kcluster-server-0
  I0127 21:51:03.976784 26 predicates.go:373] Pod svclb-traefik-4c5baeff-bbb24 requesting resource cpu=0m on Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2
  I0127 21:51:03.976790 26 predicates.go:373] Pod svclb-traefik-4c5baeff-dqplp requesting resource cpu=0m on Node k3k-k3kcluster-server-0
  I0127 21:51:03.976795 26 predicates.go:373] Pod traefik-6d98778dfc-p2jdc requesting resource cpu=0m on Node k3k-k3kcluster-server-0
  I0127 21:51:03.976801 26 predicates.go:373] Pod sonobuoy requesting resource cpu=0m on Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2
  I0127 21:51:03.976807 26 predicates.go:373] Pod sonobuoy-e2e-job-211431d51fbc478c requesting resource cpu=0m on Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2
  I0127 21:51:03.976813 26 predicates.go:373] Pod sonobuoy-systemd-logs-daemon-set-7c9a66bc53524567-gzwrw requesting resource cpu=0m on Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2
  I0127 21:51:03.976819 26 predicates.go:373] Pod sonobuoy-systemd-logs-daemon-set-7c9a66bc53524567-h78hs requesting resource cpu=0m on Node k3k-k3kcluster-server-0
  STEP: Starting Pods to consume most of the cluster CPU. @ 01/27/26 21:51:03.976
  I0127 21:51:03.976853 26 predicates.go:383] Creating a pod which consumes cpu=5600m on Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2
  I0127 21:51:03.999711 26 predicates.go:383] Creating a pod which consumes cpu=5460m on Node k3k-k3kcluster-server-0
  E0127 21:51:04.515754      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:05.515774      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:06.516856      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:07.517056      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 01/27/26 21:51:08.153
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-59b97add-2dc5-497c-92ae-7d6080fdecd5.188eb4f4760b9b34], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.10.1" already present on machine and can be accessed by the pod] @ 01/27/26 21:51:08.155
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-59b97add-2dc5-497c-92ae-7d6080fdecd5.188eb4f4a8f539a4], Reason = [Created], Message = [Container created] @ 01/27/26 21:51:08.155
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-59b97add-2dc5-497c-92ae-7d6080fdecd5.188eb4f4b1708409], Reason = [Started], Message = [Container started] @ 01/27/26 21:51:08.155
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-75878f45-1bf1-48cd-96ad-4a958047e189.188eb4f4148110c4], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4323/filler-pod-75878f45-1bf1-48cd-96ad-4a958047e189 to k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2] @ 01/27/26 21:51:08.155
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-75878f45-1bf1-48cd-96ad-4a958047e189.188eb4f478e3e4fb], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.10.1" already present on machine and can be accessed by the pod] @ 01/27/26 21:51:08.155
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-75878f45-1bf1-48cd-96ad-4a958047e189.188eb4f4a3ea681f], Reason = [Created], Message = [Container created] @ 01/27/26 21:51:08.155
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-75878f45-1bf1-48cd-96ad-4a958047e189.188eb4f4ad15de9c], Reason = [Started], Message = [Container started] @ 01/27/26 21:51:08.155
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-59b97add-2dc5-497c-92ae-7d6080fdecd5.188eb4f414aee1ec], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4323/filler-pod-59b97add-2dc5-497c-92ae-7d6080fdecd5 to k3k-k3kcluster-server-0] @ 01/27/26 21:51:08.155
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.188eb4f50bdf6409], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu. no new claims to deallocate, preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.] @ 01/27/26 21:51:08.176
  E0127 21:51:08.517137      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.188eb4f531677bef], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu. no new claims to deallocate, preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.] @ 01/27/26 21:51:08.8
  STEP: removing the label node off the node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 @ 01/27/26 21:51:09.166
  STEP: verifying the node doesn't have the label node @ 01/27/26 21:51:09.192
  STEP: removing the label node off the node k3k-k3kcluster-server-0 @ 01/27/26 21:51:09.194
  STEP: verifying the node doesn't have the label node @ 01/27/26 21:51:09.211
  I0127 21:51:09.213680 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-4323" for this suite. @ 01/27/26 21:51:09.215
• [5.467 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:181
  STEP: Creating a kubernetes client @ 01/27/26 21:51:09.229
  I0127 21:51:09.229531 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename podtemplate @ 01/27/26 21:51:09.23
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:51:09.251
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:51:09.253
  STEP: Create a pod template @ 01/27/26 21:51:09.255
  STEP: Replace a pod template @ 01/27/26 21:51:09.269
  I0127 21:51:09.280114 26 podtemplates.go:214] Found updated podtemplate annotation: "true"

  I0127 21:51:09.280248 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-22" for this suite. @ 01/27/26 21:51:09.282
• [0.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:479
  STEP: Creating a kubernetes client @ 01/27/26 21:51:09.291
  I0127 21:51:09.291700 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename sched-preemption @ 01/27/26 21:51:09.292
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:51:09.31
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:51:09.321
  I0127 21:51:09.345263 26 wait.go:53] Waiting up to 1m0s for all nodes to be ready
  E0127 21:51:09.517881      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:10.518120      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:11.518960      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:12.519917      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:13.520404      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:14.520918      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:15.521783      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:16.521988      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:17.522171      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:18.522380      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:19.523208      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:20.523344      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:21.523864      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:22.524069      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:23.524556      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:24.524775      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:25.525229      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:26.525745      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:27.526707      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:28.527137      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:29.527663      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:30.528335      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:31.528815      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:32.529031      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:33.529890      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:34.530113      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:35.530299      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:36.530489      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:37.531083      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:38.531288      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:39.531510      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:40.531972      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:41.532877      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:42.532941      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:43.533713      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:44.533917      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:45.534341      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:46.534634      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:47.535442      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:48.535657      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:49.535778      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:50.535908      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:51.536000      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:52.536869      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:53.537521      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:54.538328      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:55.539240      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:56.539441      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:57.540151      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:58.540822      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:51:59.541446      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:00.541786      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:01.542315      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:02.542398      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:03.542975      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:04.543637      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:05.544160      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:06.544304      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:07.544857      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:08.545058      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:52:09.348805 26 util.go:389] Waiting for terminating namespaces to be deleted...
  STEP: Select a node to run the lower and higher priority pods @ 01/27/26 21:52:09.351
  STEP: Adding a custom resource @ 01/27/26 21:52:09.351
  STEP: Create a low priority pod that consumes 1/1 of node resources @ 01/27/26 21:52:09.366
  I0127 21:52:09.382580 26 preemption.go:513] Created pod: victim-pod
  STEP: Wait for the victim pod to be scheduled @ 01/27/26 21:52:09.382
  E0127 21:52:09.545779      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:10.546659      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create a high priority pod to trigger preemption of the lower priority pod @ 01/27/26 21:52:11.388
  I0127 21:52:11.397591 26 preemption.go:531] Created pod: preemptor-pod
  STEP: Waiting for the victim pod to be terminating @ 01/27/26 21:52:11.397
  E0127 21:52:11.547327      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:12.547540      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Verifying the pod has the pod disruption condition @ 01/27/26 21:52:13.401
  I0127 21:52:13.403532 26 pod_client.go:395] Removing pod's "victim-pod" finalizer: "example.com/test-finalizer"
  E0127 21:52:13.547717      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:52:13.916966 26 pod_client.go:187] Successfully updated pod "victim-pod"
  STEP: Removing a custom resource @ 01/27/26 21:52:13.943
  STEP: Removing a custom resource @ 01/27/26 21:52:13.971
  I0127 21:52:13.980876 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-8833" for this suite. @ 01/27/26 21:52:13.983
• [64.699 seconds]
------------------------------
SS
------------------------------
[sig-network] ServiceCIDR and IPAddress API should support IPAddress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_cidrs.go:212
  STEP: Creating a kubernetes client @ 01/27/26 21:52:13.991
  I0127 21:52:13.991226 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename servicecidr @ 01/27/26 21:52:13.991
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:52:14.018
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:52:14.02
  STEP: creating @ 01/27/26 21:52:14.023
  STEP: patching @ 01/27/26 21:52:14.038
  STEP: updating @ 01/27/26 21:52:14.047
  STEP: getting @ 01/27/26 21:52:14.066
  STEP: listing @ 01/27/26 21:52:14.068
  STEP: watching @ 01/27/26 21:52:14.07
  STEP: deleting @ 01/27/26 21:52:14.071
  STEP: deleting a collection @ 01/27/26 21:52:14.079
  I0127 21:52:14.089416 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "servicecidr-9349" for this suite. @ 01/27/26 21:52:14.091
• [0.109 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1009
  STEP: Creating a kubernetes client @ 01/27/26 21:52:14.1
  I0127 21:52:14.100130 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename resourcequota @ 01/27/26 21:52:14.1
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:52:14.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:52:14.129
  STEP: Creating a ResourceQuota @ 01/27/26 21:52:14.132
  STEP: Getting a ResourceQuota @ 01/27/26 21:52:14.14
  STEP: Listing all ResourceQuotas with LabelSelector @ 01/27/26 21:52:14.141
  STEP: Patching the ResourceQuota @ 01/27/26 21:52:14.147
  STEP: Deleting a Collection of ResourceQuotas @ 01/27/26 21:52:14.156
  STEP: Verifying the deleted ResourceQuota @ 01/27/26 21:52:14.184
  I0127 21:52:14.187126 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6098" for this suite. @ 01/27/26 21:52:14.192
• [0.106 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:179
  STEP: Creating a kubernetes client @ 01/27/26 21:52:14.205
  I0127 21:52:14.205941 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename emptydir @ 01/27/26 21:52:14.206
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:52:14.227
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:52:14.229
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 01/27/26 21:52:14.231
  E0127 21:52:14.547762      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:15.547772      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:16.548305      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:17.548373      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:52:18.255
  I0127 21:52:18.257657 26 output.go:207] Trying to get logs from node k3k-k3kcluster-server-0 pod pod-fa830e22-c895-417d-8a92-87d45156899c container test-container: <nil>
  STEP: delete the pod @ 01/27/26 21:52:18.263
  I0127 21:52:18.294194 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2680" for this suite. @ 01/27/26 21:52:18.297
• [4.106 seconds]
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2287
  STEP: Creating a kubernetes client @ 01/27/26 21:52:18.312
  I0127 21:52:18.312059 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename services @ 01/27/26 21:52:18.312
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:52:18.328
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:52:18.335
  STEP: creating service in namespace services-6068 @ 01/27/26 21:52:18.337
  STEP: creating service affinity-nodeport-transition in namespace services-6068 @ 01/27/26 21:52:18.337
  I0127 21:52:18.389169 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0127 21:52:18.548492      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:19.549049      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:52:20.408731 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:3, TerminatingReplicas:(*int32)(0xc00192d3a0), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 21, 52, 18, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 52, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 52, 18, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 52, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-transition-69755df4c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:52:20.550049      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:21.550254      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:52:22.405818 26 resource.go:344] Creating new exec pod
  E0127 21:52:22.550310      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:23.550618      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:52:24.422752 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-6068 exec execpod-affinitydwjz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  I0127 21:52:24.529384 26 builder.go:156] stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition (10.53.62.90) 80 port [tcp/http] succeeded!\n"
  I0127 21:52:24.529441 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 21:52:24.529505 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-6068 exec execpod-affinitydwjz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.62.90 80'
  E0127 21:52:24.550865      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:52:24.632819 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.53.62.90 80\nConnection to 10.53.62.90 80 port [tcp/http] succeeded!\n"
  I0127 21:52:24.632866 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 21:52:24.632937 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-6068 exec execpod-affinitydwjz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.42.0.10 31538'
  I0127 21:52:24.745025 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.42.0.10 31538\nConnection to 10.42.0.10 31538 port [tcp/*] succeeded!\n"
  I0127 21:52:24.745068 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 21:52:24.745128 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-6068 exec execpod-affinitydwjz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.42.0.12 31538'
  I0127 21:52:24.851896 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.42.0.12 31538\nConnection to 10.42.0.12 31538 port [tcp/*] succeeded!\n"
  I0127 21:52:24.851964 26 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0127 21:52:24.862523 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-6068 exec execpod-affinitydwjz5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/ ; done'
  I0127 21:52:25.033045 26 builder.go:156] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n"
  I0127 21:52:25.033099 26 builder.go:157] stdout: "\naffinity-nodeport-transition-69755df4c9-6tr9s\naffinity-nodeport-transition-69755df4c9-rgfr9\naffinity-nodeport-transition-69755df4c9-rgfr9\naffinity-nodeport-transition-69755df4c9-rgfr9\naffinity-nodeport-transition-69755df4c9-6tr9s\naffinity-nodeport-transition-69755df4c9-6tr9s\naffinity-nodeport-transition-69755df4c9-6tr9s\naffinity-nodeport-transition-69755df4c9-6tr9s\naffinity-nodeport-transition-69755df4c9-rgfr9\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-rgfr9\naffinity-nodeport-transition-69755df4c9-rgfr9\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-rgfr9"
  I0127 21:52:25.033116 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-6tr9s
  I0127 21:52:25.033125 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-rgfr9
  I0127 21:52:25.033134 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-rgfr9
  I0127 21:52:25.033140 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-rgfr9
  I0127 21:52:25.033375 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-6tr9s
  I0127 21:52:25.033384 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-6tr9s
  I0127 21:52:25.033391 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-6tr9s
  I0127 21:52:25.033399 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-6tr9s
  I0127 21:52:25.033409 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-rgfr9
  I0127 21:52:25.033417 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:25.033424 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:25.033430 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:25.033437 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-rgfr9
  I0127 21:52:25.033444 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-rgfr9
  I0127 21:52:25.033452 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:25.033461 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-rgfr9
  I0127 21:52:25.043888 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-6068 exec execpod-affinitydwjz5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/ ; done'
  I0127 21:52:25.214511 26 builder.go:156] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n"
  I0127 21:52:25.214562 26 builder.go:157] stdout: "\naffinity-nodeport-transition-69755df4c9-rgfr9\naffinity-nodeport-transition-69755df4c9-6tr9s\naffinity-nodeport-transition-69755df4c9-6tr9s\naffinity-nodeport-transition-69755df4c9-rgfr9\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-6tr9s\naffinity-nodeport-transition-69755df4c9-6tr9s\naffinity-nodeport-transition-69755df4c9-rgfr9\naffinity-nodeport-transition-69755df4c9-rgfr9\naffinity-nodeport-transition-69755df4c9-6tr9s\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-6tr9s\naffinity-nodeport-transition-69755df4c9-rgfr9"
  I0127 21:52:25.214575 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-rgfr9
  I0127 21:52:25.214584 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-6tr9s
  I0127 21:52:25.214592 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-6tr9s
  I0127 21:52:25.214599 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-rgfr9
  I0127 21:52:25.214606 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:25.214613 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:25.214620 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-6tr9s
  I0127 21:52:25.214630 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-6tr9s
  I0127 21:52:25.214642 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-rgfr9
  I0127 21:52:25.214655 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-rgfr9
  I0127 21:52:25.214662 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-6tr9s
  I0127 21:52:25.214669 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:25.214676 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:25.214683 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:25.214690 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-6tr9s
  I0127 21:52:25.214697 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-rgfr9
  E0127 21:52:25.551903      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:26.552129      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:27.552988      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:28.553763      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:29.553970      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:30.554665      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:31.554914      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:32.555162      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:33.556004      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:34.556134      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:35.556295      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:36.556514      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:37.556727      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:38.556992      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:39.557143      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:40.557950      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:41.558139      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:42.558385      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:43.558583      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:44.558827      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:45.559344      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:46.559544      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:47.559767      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:48.559918      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:49.560178      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:50.560314      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:51.560542      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:52.560856      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:53.561379      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:54.561501      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:52:55.215205 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-6068 exec execpod-affinitydwjz5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/ ; done'
  I0127 21:52:55.387156 26 builder.go:156] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.42.0.10:31538/\n"
  I0127 21:52:55.387210 26 builder.go:157] stdout: "\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m\naffinity-nodeport-transition-69755df4c9-hzn7m"
  I0127 21:52:55.387225 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:55.387235 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:55.387242 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:55.387250 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:55.387257 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:55.387264 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:55.387271 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:55.387278 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:55.387287 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:55.387296 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:55.387303 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:55.387310 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:55.387317 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:55.387324 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:55.387331 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:55.387338 26 service.go:227] Received response from host: affinity-nodeport-transition-69755df4c9-hzn7m
  I0127 21:52:55.387415 26 service.go:4286] Cleaning up the exec pod
  I0127 21:52:55.490089 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6068" for this suite. @ 01/27/26 21:52:55.502
• [37.218 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Pod InPlace Resize Container resize pod via the replace endpoint [MinimumKubeletVersion:1.34] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pod_resize.go:726
  STEP: Creating a kubernetes client @ 01/27/26 21:52:55.53
  I0127 21:52:55.530383 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pod-resize-tests @ 01/27/26 21:52:55.53
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:52:55.552
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:52:55.557
  E0127 21:52:55.561628      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: creating and verifying pod @ 01/27/26 21:52:55.602
  E0127 21:52:56.561801      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:57.562244      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:52:57.619460 26 cgroups.go:379] Namespace pod-resize-tests-8950 Pod resize-test-pkkvm Container c1 - looking for one of the expected cgroup values [max] in path /sys/fs/cgroup/memory.max
  I0127 21:52:57.619502 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-8950 PodName:resize-test-pkkvm ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:52:57.619513 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:52:57.619562 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-8950/pods/resize-test-pkkvm/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c1&stderr=true&stdout=true)
  I0127 21:52:57.701102 26 cgroups.go:379] Namespace pod-resize-tests-8950 Pod resize-test-pkkvm Container c1 - looking for one of the expected cgroup values [max 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:52:57.701145 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-8950 PodName:resize-test-pkkvm ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:52:57.701154 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:52:57.701204 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-8950/pods/resize-test-pkkvm/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c1&stderr=true&stdout=true)
  I0127 21:52:57.782056 26 cgroups.go:379] Namespace pod-resize-tests-8950 Pod resize-test-pkkvm Container c1 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 21:52:57.782100 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-8950 PodName:resize-test-pkkvm ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:52:57.782112 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:52:57.782163 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-8950/pods/resize-test-pkkvm/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c1&stderr=true&stdout=true)
  STEP: updating the pod resources @ 01/27/26 21:52:57.854
  STEP: fetching updated pod @ 01/27/26 21:52:57.87
  STEP: verifying pod resources @ 01/27/26 21:52:57.873
  STEP: verifying pod resources after patch @ 01/27/26 21:52:57.873
  E0127 21:52:58.563166      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:52:59.563413      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:00.563492      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:01.563767      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:53:01.885241 26 cgroups.go:379] Namespace pod-resize-tests-8950 Pod resize-test-pkkvm Container c1 - looking for one of the expected cgroup values [max] in path /sys/fs/cgroup/memory.max
  I0127 21:53:01.885277 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/memory.max] Namespace:pod-resize-tests-8950 PodName:resize-test-pkkvm ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:53:01.885289 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:53:01.885325 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-8950/pods/resize-test-pkkvm/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fmemory.max&container=c1&stderr=true&stdout=true)
  I0127 21:53:01.956354 26 cgroups.go:379] Namespace pod-resize-tests-8950 Pod resize-test-pkkvm Container c1 - looking for one of the expected cgroup values [max 100000] in path /sys/fs/cgroup/cpu.max
  I0127 21:53:01.956397 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.max] Namespace:pod-resize-tests-8950 PodName:resize-test-pkkvm ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:53:01.956408 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:53:01.956454 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-8950/pods/resize-test-pkkvm/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.max&container=c1&stderr=true&stdout=true)
  I0127 21:53:02.027505 26 cgroups.go:379] Namespace pod-resize-tests-8950 Pod resize-test-pkkvm Container c1 - looking for one of the expected cgroup values [1 6] in path /sys/fs/cgroup/cpu.weight
  I0127 21:53:02.027546 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c head -n 1 /sys/fs/cgroup/cpu.weight] Namespace:pod-resize-tests-8950 PodName:resize-test-pkkvm ContainerName:c1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:53:02.027557 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:53:02.027632 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-resize-tests-8950/pods/resize-test-pkkvm/exec?command=%2Fbin%2Fsh&command=-c&command=head+-n+1+%2Fsys%2Ffs%2Fcgroup%2Fcpu.weight&container=c1&stderr=true&stdout=true)
  STEP: verifying pod fetched from resize subresource @ 01/27/26 21:53:02.095
  STEP: verifying pod fetched from resize subresource @ 01/27/26 21:53:02.097
  I0127 21:53:02.100594 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-resize-tests-8950" for this suite. @ 01/27/26 21:53:02.102
• [6.586 seconds]
------------------------------
S
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 01/27/26 21:53:02.116
  I0127 21:53:02.116918 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename secrets @ 01/27/26 21:53:02.117
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:53:02.132
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:53:02.136
  STEP: Creating secret with name secret-test-map-b50314ce-7b05-4d8e-8a30-a587d284fe6c @ 01/27/26 21:53:02.138
  STEP: Creating a pod to test consume secrets @ 01/27/26 21:53:02.145
  E0127 21:53:02.563817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:03.564988      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:53:04.167
  I0127 21:53:04.169914 26 output.go:207] Trying to get logs from node k3k-k3kcluster-server-0 pod pod-secrets-f367d2df-c603-48eb-8f2b-9c50b6de523c container secret-volume-test: <nil>
  STEP: delete the pod @ 01/27/26 21:53:04.173
  I0127 21:53:04.211019 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8188" for this suite. @ 01/27/26 21:53:04.212
• [2.104 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:219
  STEP: Creating a kubernetes client @ 01/27/26 21:53:04.22
  I0127 21:53:04.220842 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename emptydir @ 01/27/26 21:53:04.221
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:53:04.246
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:53:04.34
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 01/27/26 21:53:04.343
  E0127 21:53:04.565527      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:05.566283      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:06.566750      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:07.566963      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:53:08.367
  I0127 21:53:08.369567 26 output.go:207] Trying to get logs from node k3k-k3kcluster-server-0 pod pod-d94182a8-4474-4925-88db-b4b77a66c15d container test-container: <nil>
  STEP: delete the pod @ 01/27/26 21:53:08.373
  I0127 21:53:08.401206 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3168" for this suite. @ 01/27/26 21:53:08.403
• [4.192 seconds]
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:109
  STEP: Creating a kubernetes client @ 01/27/26 21:53:08.412
  I0127 21:53:08.412954 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 21:53:08.413
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:53:08.439
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:53:08.441
  STEP: Creating configMap with name projected-configmap-test-volume-map-14b8a68e-68a8-43ca-b764-bf492fc551ff @ 01/27/26 21:53:08.444
  STEP: Creating a pod to test consume configMaps @ 01/27/26 21:53:08.459
  E0127 21:53:08.567735      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:09.567747      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:10.568492      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:11.568808      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:53:12.478
  I0127 21:53:12.480113 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-projected-configmaps-fad1ec1a-387b-4601-ba40-3941fc08ab3d container agnhost-container: <nil>
  STEP: delete the pod @ 01/27/26 21:53:12.491
  I0127 21:53:12.522853 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6068" for this suite. @ 01/27/26 21:53:12.524
• [4.119 seconds]
------------------------------
SS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/controller_revision.go:128
  STEP: Creating a kubernetes client @ 01/27/26 21:53:12.531
  I0127 21:53:12.531963 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename controllerrevisions @ 01/27/26 21:53:12.532
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:53:12.553
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:53:12.568
  E0127 21:53:12.568814      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating DaemonSet "e2e-mwfc8-daemon-set" @ 01/27/26 21:53:12.629
  STEP: Check that daemon pods launch on every node of the cluster. @ 01/27/26 21:53:12.643
  I0127 21:53:12.736892 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset e2e-mwfc8-daemon-set: 0
  I0127 21:53:12.737023 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 21:53:13.568976      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:53:13.651111 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset e2e-mwfc8-daemon-set: 0
  I0127 21:53:13.651167 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 21:53:14.569450      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:53:14.649206 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset e2e-mwfc8-daemon-set: 2
  I0127 21:53:14.649243 26 fixtures.go:138] Number of running nodes: 2, number of available pods: 2 in daemonset e2e-mwfc8-daemon-set
  STEP: Confirm DaemonSet "e2e-mwfc8-daemon-set" successfully created with "daemonset-name=e2e-mwfc8-daemon-set" label @ 01/27/26 21:53:14.65
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-mwfc8-daemon-set" @ 01/27/26 21:53:14.655
  I0127 21:53:14.657221 26 controller_revision.go:164] Located ControllerRevision: "e2e-mwfc8-daemon-set-ddd648b77"
  STEP: Patching ControllerRevision "e2e-mwfc8-daemon-set-ddd648b77" @ 01/27/26 21:53:14.658
  I0127 21:53:14.674359 26 controller_revision.go:177] e2e-mwfc8-daemon-set-ddd648b77 has been patched
  STEP: Create a new ControllerRevision @ 01/27/26 21:53:14.674
  I0127 21:53:14.682876 26 controller_revision.go:195] Created ControllerRevision: e2e-mwfc8-daemon-set-5f954c8799
  STEP: Confirm that there are two ControllerRevisions @ 01/27/26 21:53:14.682
  I0127 21:53:14.682972 26 controller_revision.go:258] Requesting list of ControllerRevisions to confirm quantity
  I0127 21:53:14.685544 26 controller_revision.go:269] Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-mwfc8-daemon-set-ddd648b77" @ 01/27/26 21:53:14.685
  STEP: Confirm that there is only one ControllerRevision @ 01/27/26 21:53:14.692
  I0127 21:53:14.692790 26 controller_revision.go:258] Requesting list of ControllerRevisions to confirm quantity
  I0127 21:53:14.699670 26 controller_revision.go:269] Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-mwfc8-daemon-set-5f954c8799" @ 01/27/26 21:53:14.704
  I0127 21:53:14.720439 26 controller_revision.go:224] e2e-mwfc8-daemon-set-5f954c8799 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 01/27/26 21:53:14.72
  I0127 21:53:14.732236      26 warnings.go:107] "Warning: unknown field \"updateStrategy\""
  STEP: Confirm that there are two ControllerRevisions @ 01/27/26 21:53:14.732
  I0127 21:53:14.732358 26 controller_revision.go:258] Requesting list of ControllerRevisions to confirm quantity
  E0127 21:53:15.569652      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:53:15.732886 26 controller_revision.go:258] Requesting list of ControllerRevisions to confirm quantity
  I0127 21:53:15.735296 26 controller_revision.go:269] Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-mwfc8-daemon-set-5f954c8799=updated" @ 01/27/26 21:53:15.735
  STEP: Confirm that there is only one ControllerRevision @ 01/27/26 21:53:15.744
  I0127 21:53:15.744676 26 controller_revision.go:258] Requesting list of ControllerRevisions to confirm quantity
  I0127 21:53:15.746590 26 controller_revision.go:269] Found 1 ControllerRevisions
  I0127 21:53:15.750031 26 controller_revision.go:250] ControllerRevision "e2e-mwfc8-daemon-set-88c69cc58" has revision 3
  STEP: Deleting DaemonSet "e2e-mwfc8-daemon-set" @ 01/27/26 21:53:15.751
  STEP: deleting DaemonSet.extensions e2e-mwfc8-daemon-set in namespace controllerrevisions-1549, will wait for the garbage collector to delete the pods @ 01/27/26 21:53:15.751
  I0127 21:53:15.813286 26 resources.go:139] Deleting DaemonSet.extensions e2e-mwfc8-daemon-set took: 8.627464ms
  I0127 21:53:15.914228 26 resources.go:163] Terminating DaemonSet.extensions e2e-mwfc8-daemon-set pods took: 100.940117ms
  E0127 21:53:16.570410      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:53:17.516976 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset e2e-mwfc8-daemon-set: 0
  I0127 21:53:17.517011 26 fixtures.go:138] Number of running nodes: 0, number of available pods: 0 in daemonset e2e-mwfc8-daemon-set
  I0127 21:53:17.519721 26 controller_revision.go:75] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"49100"},"items":null}

  I0127 21:53:17.521148 26 controller_revision.go:80] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"49100"},"items":null}

  I0127 21:53:17.527794 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-1549" for this suite. @ 01/27/26 21:53:17.529
• [5.006 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:413
  STEP: Creating a kubernetes client @ 01/27/26 21:53:17.538
  I0127 21:53:17.538356 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename validating-admission-policy @ 01/27/26 21:53:17.538
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:53:17.562
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:53:17.564
  E0127 21:53:17.570857      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: getting /apis @ 01/27/26 21:53:17.575
  STEP: getting /apis/admissionregistration.k8s.io @ 01/27/26 21:53:17.578
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 01/27/26 21:53:17.579
  STEP: creating @ 01/27/26 21:53:17.58
  STEP: getting @ 01/27/26 21:53:17.614
  STEP: listing @ 01/27/26 21:53:17.616
  STEP: watching @ 01/27/26 21:53:17.617
  I0127 21:53:17.617960 26 validatingadmissionpolicy.go:531] starting watch
  STEP: patching @ 01/27/26 21:53:17.619
  STEP: updating @ 01/27/26 21:53:17.627
  I0127 21:53:17.686456 26 validatingadmissionpolicy.go:561] waiting for watch events with expected annotations
  STEP: getting /status @ 01/27/26 21:53:17.686
  STEP: patching /status @ 01/27/26 21:53:17.705
  STEP: updating /status @ 01/27/26 21:53:17.725
  STEP: deleting @ 01/27/26 21:53:17.735
  STEP: deleting a collection @ 01/27/26 21:53:17.745
  I0127 21:53:17.764086 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-6914" for this suite. @ 01/27/26 21:53:17.765
• [0.241 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lease.go:75
  STEP: Creating a kubernetes client @ 01/27/26 21:53:17.779
  I0127 21:53:17.779041 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename lease-test @ 01/27/26 21:53:17.779
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:53:17.801
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:53:17.805
  I0127 21:53:17.887784 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-234" for this suite. @ 01/27/26 21:53:17.89
• [0.125 seconds]
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:49
  STEP: Creating a kubernetes client @ 01/27/26 21:53:17.903
  I0127 21:53:17.903871 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename downward-api @ 01/27/26 21:53:17.904
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:53:17.927
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:53:18.014
  STEP: Creating a pod to test downward api env vars @ 01/27/26 21:53:18.015
  E0127 21:53:18.570985      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:19.571199      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:20.572232      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:21.572812      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:53:22.059
  I0127 21:53:22.061275 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downward-api-c9a13178-b342-4a85-bd32-39d21791458b container dapi-container: <nil>
  STEP: delete the pod @ 01/27/26 21:53:22.066
  I0127 21:53:22.094318 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4467" for this suite. @ 01/27/26 21:53:22.096
• [4.208 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:89
  STEP: Creating a kubernetes client @ 01/27/26 21:53:22.111
  I0127 21:53:22.111946 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename emptydir @ 01/27/26 21:53:22.112
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:53:22.128
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:53:22.134
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 01/27/26 21:53:22.136
  E0127 21:53:22.573654      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:23.573847      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:24.575358      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:25.575628      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:53:26.163
  I0127 21:53:26.165246 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-7bfd0221-4f1a-4cbc-a9c4-903c9b22b14e container test-container: <nil>
  STEP: delete the pod @ 01/27/26 21:53:26.17
  I0127 21:53:26.198106 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5269" for this suite. @ 01/27/26 21:53:26.2
• [4.102 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:387
  STEP: Creating a kubernetes client @ 01/27/26 21:53:26.214
  I0127 21:53:26.214124 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename daemonsets @ 01/27/26 21:53:26.215
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:53:26.231
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:53:26.237
  I0127 21:53:26.305742 26 daemon_set.go:390] Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 01/27/26 21:53:26.319
  I0127 21:53:26.420831 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:53:26.420870 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 21:53:26.576403      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:53:27.324147 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:53:27.324186 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 21:53:27.577394      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:53:28.324967 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0127 21:53:28.325003 26 fixtures.go:138] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Update daemon pods image. @ 01/27/26 21:53:28.331
  STEP: Check that daemon pods images are updated. @ 01/27/26 21:53:28.424
  I0127 21:53:28.436291 26 daemon_set.go:1198] Wrong image for pod: daemon-set-nzjkb. Expected: registry.k8s.io/e2e-test-images/agnhost:2.55, got: registry.k8s.io/e2e-test-images/agnhost:2.59.
  E0127 21:53:28.578811      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:53:29.428000 26 daemon_set.go:1198] Wrong image for pod: daemon-set-nzjkb. Expected: registry.k8s.io/e2e-test-images/agnhost:2.55, got: registry.k8s.io/e2e-test-images/agnhost:2.59.
  E0127 21:53:29.578943      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:53:30.433941 26 daemon_set.go:1198] Wrong image for pod: daemon-set-nzjkb. Expected: registry.k8s.io/e2e-test-images/agnhost:2.55, got: registry.k8s.io/e2e-test-images/agnhost:2.59.
  I0127 21:53:30.433980 26 daemon_set.go:1203] Pod daemon-set-rqhzs is not available
  E0127 21:53:30.579367      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:53:31.426547 26 daemon_set.go:1198] Wrong image for pod: daemon-set-nzjkb. Expected: registry.k8s.io/e2e-test-images/agnhost:2.55, got: registry.k8s.io/e2e-test-images/agnhost:2.59.
  I0127 21:53:31.426584 26 daemon_set.go:1203] Pod daemon-set-rqhzs is not available
  E0127 21:53:31.580411      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:53:32.428728 26 daemon_set.go:1203] Pod daemon-set-5pskf is not available
  STEP: Check that daemon pods are still running on every node of the cluster. @ 01/27/26 21:53:32.441
  I0127 21:53:32.461156 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0127 21:53:32.461194 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 21:53:32.581340      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:53:33.447668 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0127 21:53:33.447705 26 fixtures.go:133] Node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 is running 0 daemon pod, expected 1
  E0127 21:53:33.582332      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:53:34.448173 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0127 21:53:34.448212 26 fixtures.go:138] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 01/27/26 21:53:34.457
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1431, will wait for the garbage collector to delete the pods @ 01/27/26 21:53:34.457
  I0127 21:53:34.518946 26 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 9.379828ms
  E0127 21:53:34.583244      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:53:34.620616 26 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 101.661821ms
  E0127 21:53:35.583867      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:53:36.224728 26 fixtures.go:128] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0127 21:53:36.224761 26 fixtures.go:138] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0127 21:53:36.227342 26 daemon_set.go:137] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"49346"},"items":null}

  I0127 21:53:36.228658 26 daemon_set.go:142] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"49346"},"items":null}

  I0127 21:53:36.235181 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1431" for this suite. @ 01/27/26 21:53:36.236
• [10.031 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 01/27/26 21:53:36.245
  I0127 21:53:36.245039 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename var-expansion @ 01/27/26 21:53:36.245
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:53:36.265
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:53:36.268
  STEP: Creating a pod to test substitution in container's command @ 01/27/26 21:53:36.27
  E0127 21:53:36.584113      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:37.584850      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:38.585862      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:39.586084      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:40.587164      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:41.587349      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:53:42.399
  I0127 21:53:42.401050 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod var-expansion-681b6473-bf12-4e21-ad30-638e17b7d97c container dapi-container: <nil>
  STEP: delete the pod @ 01/27/26 21:53:42.405
  I0127 21:53:42.443402 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5157" for this suite. @ 01/27/26 21:53:42.445
• [6.209 seconds]
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 01/27/26 21:53:42.454
  I0127 21:53:42.454075 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename subjectreview @ 01/27/26 21:53:42.454
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:53:42.47
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:53:42.482
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-4974" @ 01/27/26 21:53:42.485
  I0127 21:53:42.492375 26 subjectreviews.go:66] saUsername: "system:serviceaccount:subjectreview-4974:e2e"
  I0127 21:53:42.492409 26 subjectreviews.go:69] saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-4974"}
  I0127 21:53:42.492427 26 subjectreviews.go:71] saUID: "3d64324d-d660-4dd0-a731-4ae48e70112f"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-4974:e2e" @ 01/27/26 21:53:42.492
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-4974:e2e" @ 01/27/26 21:53:42.492
  I0127 21:53:42.494420 26 subjectreviews.go:102] sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-4974:e2e" api 'list' configmaps in "subjectreview-4974" namespace @ 01/27/26 21:53:42.494
  I0127 21:53:42.495347 26 subjectreviews.go:121] SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-4974:e2e" @ 01/27/26 21:53:42.495
  I0127 21:53:42.496583 26 subjectreviews.go:144] lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  I0127 21:53:42.496602 26 subjectreviews.go:150] LocalSubjectAccessReview has been verified
  I0127 21:53:42.496700 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-4974" for this suite. @ 01/27/26 21:53:42.546
• [0.101 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:444
  STEP: Creating a kubernetes client @ 01/27/26 21:53:42.555
  I0127 21:53:42.555499 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename taint-multiple-pods @ 01/27/26 21:53:42.556
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:53:42.581
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:53:42.584
  I0127 21:53:42.586325 26 wait.go:53] Waiting up to 1m0s for all nodes to be ready
  E0127 21:53:42.587391      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:43.588016      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:44.588197      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:45.588878      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:46.589855      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:47.590210      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:48.590176      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:49.590718      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:50.590965      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:51.591764      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:52.592164      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:53.592319      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:54.593029      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:55.593440      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:56.593766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:57.593953      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:58.594538      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:53:59.595204      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:00.596057      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:01.596866      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:02.598196      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:03.598377      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:04.598455      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:05.598892      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:06.599836      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:07.600846      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:08.601557      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:09.601768      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:10.602579      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:11.602758      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:12.603049      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:13.603239      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:14.603759      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:15.604824      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:16.605802      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:17.605904      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:18.606314      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:19.607236      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:20.607676      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:21.607753      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:22.608618      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:23.608757      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:24.609177      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:25.609314      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:26.610036      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:27.610248      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:28.611326      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:29.611559      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:30.612000      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:31.613214      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:32.613325      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:33.613576      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:34.613631      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:35.614607      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:36.615720      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:37.615749      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:38.616124      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:39.616968      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:40.617249      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:41.618252      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:54:42.587177 26 util.go:389] Waiting for terminating namespaces to be deleted...
  I0127 21:54:42.589566 26 taints.go:144] Starting informer...
  STEP: Starting pods... @ 01/27/26 21:54:42.589
  E0127 21:54:42.618203      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:54:42.804117 26 taints.go:463] Pod1 is running on k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2. Tainting Node
  E0127 21:54:43.618694      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:44.619200      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:54:45.023791 26 taints.go:471] Pod2 is running on k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2. Tainting Node
  STEP: Trying to apply a taint on the Node @ 01/27/26 21:54:45.023
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 01/27/26 21:54:45.04
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 01/27/26 21:54:45.042
  E0127 21:54:45.620171      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:46.621159      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:47.621352      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:48.622161      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:49.622405      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:50.622827      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:54:50.729502 26 taints.go:492] Noticed Pod "taint-eviction-b1" gets evicted.
  E0127 21:54:51.623403      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:52.623891      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:53.624920      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:54.625603      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:55.625777      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:56.626024      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:57.626244      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:58.626434      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:54:59.627227      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:00.628051      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:01.629072      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:02.629283      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:03.629494      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:04.629674      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:05.629931      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:06.630316      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:07.630517      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:08.630705      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:09.630914      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:10.631766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:55:10.786942 26 taints.go:492] Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 01/27/26 21:55:10.805
  I0127 21:55:10.807338 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-7584" for this suite. @ 01/27/26 21:55:10.808
• [88.272 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1791
  STEP: Creating a kubernetes client @ 01/27/26 21:55:10.827
  I0127 21:55:10.827882 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubectl @ 01/27/26 21:55:10.828
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:55:10.86
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:55:10.862
  STEP: running the image registry.k8s.io/e2e-test-images/agnhost:2.59 @ 01/27/26 21:55:10.864
  I0127 21:55:10.864662 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3460 run e2e-test-agnhost-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/agnhost:2.59'
  I0127 21:55:10.929476 26 builder.go:156] stderr: ""
  I0127 21:55:10.929511 26 builder.go:157] stdout: "pod/e2e-test-agnhost-pod created\n"
  STEP: verifying the pod e2e-test-agnhost-pod was created @ 01/27/26 21:55:10.929
  I0127 21:55:10.941607 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-3460 delete pods e2e-test-agnhost-pod'
  E0127 21:55:11.631883      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:12.632844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:55:12.796002 26 builder.go:156] stderr: ""
  I0127 21:55:12.796040 26 builder.go:157] stdout: "pod \"e2e-test-agnhost-pod\" deleted from kubectl-3460 namespace\n"
  I0127 21:55:12.796218 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3460" for this suite. @ 01/27/26 21:55:12.801
• [1.987 seconds]
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 01/27/26 21:55:12.814
  I0127 21:55:12.815008 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename pod-network-test @ 01/27/26 21:55:12.815
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:55:12.844
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:55:12.847
  STEP: Performing setup for networking test in namespace pod-network-test-1077 @ 01/27/26 21:55:12.849
  STEP: creating a selector @ 01/27/26 21:55:12.849
  STEP: Creating the service pods in kubernetes @ 01/27/26 21:55:12.849
  I0127 21:55:12.849254 26 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0127 21:55:13.638290      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:14.638506      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:15.638644      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:16.638874      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:17.639968      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:18.640822      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:19.641184      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:20.641308      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:21.642174      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:22.642508      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:23.643731      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:24.644842      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:25.645793      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:26.646009      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 01/27/26 21:55:26.98
  E0127 21:55:27.646950      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:28.647758      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:55:29.020895 26 utils.go:803] Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  I0127 21:55:29.020932 26 utils.go:496] Going to poll 10.52.1.253 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  I0127 21:55:29.023286 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.52.1.253:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1077 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:55:29.023311 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:55:29.023357 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-network-test-1077/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.52.1.253%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&stderr=true&stdout=true)
  I0127 21:55:29.071038 26 utils.go:513] Found all 1 expected endpoints: [netserver-0]
  I0127 21:55:29.071074 26 utils.go:496] Going to poll 10.52.0.65 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  I0127 21:55:29.073076 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.52.0.65:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1077 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:55:29.073104 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:55:29.073160 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/pod-network-test-1077/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.52.0.65%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&stderr=true&stdout=true)
  I0127 21:55:29.118921 26 utils.go:513] Found all 1 expected endpoints: [netserver-1]
  I0127 21:55:29.119072 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-1077" for this suite. @ 01/27/26 21:55:29.121
• [16.331 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:109
  STEP: Creating a kubernetes client @ 01/27/26 21:55:29.145
  I0127 21:55:29.145942 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename configmap @ 01/27/26 21:55:29.146
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:55:29.165
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:55:29.166
  STEP: Creating configMap with name configmap-test-volume-map-c02fdcb5-b26c-44e3-8d8e-01fd12281538 @ 01/27/26 21:55:29.169
  STEP: Creating a pod to test consume configMaps @ 01/27/26 21:55:29.176
  E0127 21:55:29.648880      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:30.649771      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:31.650546      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:32.650633      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:55:33.203
  I0127 21:55:33.206309 26 output.go:207] Trying to get logs from node k3k-k3kcluster-server-0 pod pod-configmaps-b38b95ba-a1f2-4af1-8d98-07049066da16 container agnhost-container: <nil>
  STEP: delete the pod @ 01/27/26 21:55:33.215
  I0127 21:55:33.244054 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9735" for this suite. @ 01/27/26 21:55:33.246
• [4.108 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Job should allow to use the pod failure policy on exit code to fail the job early [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:111
  STEP: Creating a kubernetes client @ 01/27/26 21:55:33.254
  I0127 21:55:33.254491 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename job @ 01/27/26 21:55:33.255
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:55:33.271
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:55:33.282
  STEP: Looking for a node to schedule job pod @ 01/27/26 21:55:33.287
  STEP: Creating a job @ 01/27/26 21:55:33.346
  STEP: Ensuring job fails @ 01/27/26 21:55:33.355
  E0127 21:55:33.651347      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:34.651531      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:35.652267      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:36.652807      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:37.653857      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:38.653960      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:55:39.367394 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-385" for this suite. @ 01/27/26 21:55:39.369
• [6.123 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1082
  STEP: Creating a kubernetes client @ 01/27/26 21:55:39.377
  I0127 21:55:39.377542 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubectl @ 01/27/26 21:55:39.378
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:55:39.394
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:55:39.404
  STEP: create deployment with agnhost image @ 01/27/26 21:55:39.407
  I0127 21:55:39.407697 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-2176 create -f -'
  I0127 21:55:39.497863 26 builder.go:156] stderr: ""
  I0127 21:55:39.497903 26 builder.go:157] stdout: "deployment.apps/agnhost-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 01/27/26 21:55:39.497
  I0127 21:55:39.497974 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-2176 diff -f -'
  E0127 21:55:39.655058      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:40.655730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:41.655788      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:42.656789      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:43.657559      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:55:44.059867 26 builder.go:145] rc: 1
  I0127 21:55:44.059947 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-2176 delete -f -'
  I0127 21:55:44.118910 26 builder.go:156] stderr: ""
  I0127 21:55:44.118955 26 builder.go:157] stdout: "deployment.apps \"agnhost-deployment\" deleted from kubectl-2176 namespace\n"
  I0127 21:55:44.119075 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2176" for this suite. @ 01/27/26 21:55:44.12
• [4.763 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1422
  STEP: Creating a kubernetes client @ 01/27/26 21:55:44.14
  I0127 21:55:44.140765 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename services @ 01/27/26 21:55:44.141
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:55:44.178
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:55:44.262
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-1948 @ 01/27/26 21:55:44.264
  STEP: changing the ExternalName service to type=ClusterIP @ 01/27/26 21:55:44.272
  I0127 21:55:44.319672 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0127 21:55:44.658119      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:45.658271      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:55:46.322821 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:2, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(0xc0018e3070), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2026, time.January, 27, 21, 55, 44, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 55, 44, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2026, time.January, 27, 21, 55, 45, 0, time.Local), LastTransitionTime:time.Date(2026, time.January, 27, 21, 55, 44, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"externalname-service-6f6b9798d6\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0127 21:55:46.658338      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:47.658535      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:55:48.322289 26 resource.go:344] Creating new exec pod
  E0127 21:55:48.659187      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:49.659859      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:55:50.337228 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1948 exec execpodkkz5n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0127 21:55:50.444614 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service (10.53.32.83) 80 port [tcp/http] succeeded!\n"
  I0127 21:55:50.444660 26 builder.go:157] stdout: "externalname-service-6f6b9798d6-ll9fb"
  I0127 21:55:50.444726 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=services-1948 exec execpodkkz5n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.53.32.83 80'
  I0127 21:55:50.550832 26 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.53.32.83 80\nConnection to 10.53.32.83 80 port [tcp/http] succeeded!\n"
  I0127 21:55:50.550872 26 builder.go:157] stdout: "externalname-service-6f6b9798d6-qshh4"
  I0127 21:55:50.550967 26 service.go:1431] Cleaning up the ExternalName to ClusterIP test service
  I0127 21:55:50.580944 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1948" for this suite. @ 01/27/26 21:55:50.587
• [6.455 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Job with successPolicy succeededCount rule should succeeded even when some indexes remain pending [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:566
  STEP: Creating a kubernetes client @ 01/27/26 21:55:50.595
  I0127 21:55:50.595639 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename job @ 01/27/26 21:55:50.596
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:55:50.617
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:55:50.622
  STEP: Creating an indexed job with successPolicy succeededCount rule @ 01/27/26 21:55:50.624
  STEP: Awaiting for the job to have the interim SuccessCriteriaMet condition with SuccessPolicy reason @ 01/27/26 21:55:50.638
  E0127 21:55:50.660875      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:51.661101      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:52.661432      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:53.661638      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensure that the job reaches completions @ 01/27/26 21:55:54.648
  STEP: Verifying that the job status to ensure correct final state @ 01/27/26 21:55:54.651
  I0127 21:55:54.653541 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-952" for this suite. @ 01/27/26 21:55:54.655
  E0127 21:55:54.661657      26 retrywatcher.go:169] "Watch failed" err="context canceled"
• [4.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:149
  STEP: Creating a kubernetes client @ 01/27/26 21:55:54.672
  I0127 21:55:54.672862 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename emptydir @ 01/27/26 21:55:54.673
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:55:54.694
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:55:54.7
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 01/27/26 21:55:54.705
  E0127 21:55:55.662422      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:56.662632      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:57.662813      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:55:58.663003      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:55:58.727
  I0127 21:55:58.730609 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-3c0b6f49-5610-4413-ae86-26959f4bfc5a container test-container: <nil>
  STEP: delete the pod @ 01/27/26 21:55:58.74
  I0127 21:55:58.769878 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3626" for this suite. @ 01/27/26 21:55:58.772
• [4.114 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 01/27/26 21:55:58.795
  I0127 21:55:58.795406 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename watch @ 01/27/26 21:55:58.796
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:55:58.811
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:55:58.817
  STEP: creating a new configmap @ 01/27/26 21:55:58.818
  STEP: modifying the configmap once @ 01/27/26 21:55:58.826
  STEP: modifying the configmap a second time @ 01/27/26 21:55:58.835
  STEP: deleting the configmap @ 01/27/26 21:55:58.851
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 01/27/26 21:55:58.867
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 01/27/26 21:55:58.868
  I0127 21:55:58.868297 26 watch.go:426] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7820  a0ac9dc7-993a-4ea3-aef2-833fec01e581 50258 0 2026-01-27 21:55:58 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2026-01-27 21:55:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0127 21:55:58.868383 26 watch.go:426] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7820  a0ac9dc7-993a-4ea3-aef2-833fec01e581 50259 0 2026-01-27 21:55:58 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2026-01-27 21:55:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0127 21:55:58.868487 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-7820" for this suite. @ 01/27/26 21:55:58.874
• [0.087 seconds]
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 01/27/26 21:55:58.882
  I0127 21:55:58.882387 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename var-expansion @ 01/27/26 21:55:58.882
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:55:58.909
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:55:58.911
  E0127 21:55:59.663152      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:00.664093      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:56:00.929178 26 delete.go:78] Deleting pod "var-expansion-a8ad7f35-81c3-4863-98bb-af9e28d97324" in namespace "var-expansion-1922"
  I0127 21:56:00.942469 26 delete.go:86] Wait up to 5m0s for pod "var-expansion-a8ad7f35-81c3-4863-98bb-af9e28d97324" to be fully deleted
  E0127 21:56:01.665361      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:02.665554      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:56:02.947296 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1922" for this suite. @ 01/27/26 21:56:02.949
• [4.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 01/27/26 21:56:02.957
  I0127 21:56:02.957680 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 21:56:02.958
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:56:02.982
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:56:03.083
  STEP: Creating configMap with name configmap-projected-all-test-volume-f1919273-b9fb-4803-81ba-e3c5630ffe81 @ 01/27/26 21:56:03.085
  STEP: Creating secret with name secret-projected-all-test-volume-9d20ffd5-ca53-4e40-b1bf-b1d9b9b65f0b @ 01/27/26 21:56:03.093
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 01/27/26 21:56:03.107
  E0127 21:56:03.666624      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:04.666831      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:05.667207      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:06.667300      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:56:07.126
  I0127 21:56:07.128038 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod projected-volume-7828844c-7f12-4350-96db-752608df387c container projected-all-volume-test: <nil>
  STEP: delete the pod @ 01/27/26 21:56:07.131
  I0127 21:56:07.159490 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1550" for this suite. @ 01/27/26 21:56:07.161
• [4.217 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:62
  STEP: Creating a kubernetes client @ 01/27/26 21:56:07.175
  I0127 21:56:07.175222 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename field-validation @ 01/27/26 21:56:07.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:56:07.193
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:56:07.195
  STEP: apply creating a deployment @ 01/27/26 21:56:07.197
  I0127 21:56:07.204221 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8862" for this suite. @ 01/27/26 21:56:07.261
• [0.096 seconds]
------------------------------
SSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:436
  STEP: Creating a kubernetes client @ 01/27/26 21:56:07.271
  I0127 21:56:07.271199 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename dns @ 01/27/26 21:56:07.272
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:56:07.297
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:56:07.3
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 01/27/26 21:56:07.302
  I0127 21:56:07.312861 26 dns.go:448] Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-9299  1e32f44f-5ae5-4b8e-9bb1-a179b8a487de 50364 1 2026-01-27 21:56:07 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2026-01-27 21:56:07 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g958c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,PodCertificate:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,PodCertificate:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,PodCertificate:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,Image:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.59,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g958c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,RecursiveReadOnly:nil,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,AppArmorProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,RestartPolicyRules:[]ContainerRestartRule{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,AppArmorProfile:nil,SupplementalGroupsPolicy:nil,SELinuxChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},Resources:nil,HostnameOverride:nil,WorkloadRef:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},ObservedGeneration:0,ExtendedResourceClaimStatus:nil,AllocatedResources:ResourceList{},Resources:nil,},}
  E0127 21:56:07.667508      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:08.667743      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 01/27/26 21:56:09.317
  I0127 21:56:09.317549 26 exec_util.go:63] ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-9299 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:56:09.317564 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:56:09.317598 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/dns-9299/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 01/27/26 21:56:09.37
  I0127 21:56:09.370864 26 exec_util.go:63] ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-9299 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0127 21:56:09.370884 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0127 21:56:09.370944 26 exec_util.go:84] ExecWithOptions: execute(https://10.53.0.1:443/api/v1/namespaces/dns-9299/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&stderr=true&stdout=true)
  I0127 21:56:09.422033 26 dns.go:450] Deleting pod test-dns-nameservers...
  I0127 21:56:09.444208 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-9299" for this suite. @ 01/27/26 21:56:09.446
• [2.184 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:89
  STEP: Creating a kubernetes client @ 01/27/26 21:56:09.455
  I0127 21:56:09.455224 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename configmap @ 01/27/26 21:56:09.455
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:56:09.482
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:56:09.484
  STEP: Creating configMap with name configmap-test-volume-map-1d5b1c6d-46bf-4d24-9103-214e953c1ada @ 01/27/26 21:56:09.486
  STEP: Creating a pod to test consume configMaps @ 01/27/26 21:56:09.503
  E0127 21:56:09.667844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:10.668903      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:11.669263      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:12.669488      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:56:13.52
  I0127 21:56:13.522482 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod pod-configmaps-8f4d112e-e00e-4b02-83f5-e6e595cd0d48 container agnhost-container: <nil>
  STEP: delete the pod @ 01/27/26 21:56:13.527
  I0127 21:56:13.565677 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7233" for this suite. @ 01/27/26 21:56:13.567
• [4.121 seconds]
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:248
  STEP: Creating a kubernetes client @ 01/27/26 21:56:13.576
  I0127 21:56:13.576117 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename downward-api @ 01/27/26 21:56:13.576
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:56:13.603
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:56:13.606
  STEP: Creating a pod to test downward api env vars @ 01/27/26 21:56:13.609
  E0127 21:56:13.670370      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:14.670979      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:15.671782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:16.671932      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:56:17.638
  I0127 21:56:17.640222 26 output.go:207] Trying to get logs from node k3k-k3kcluster-agent-6fb558bc6f-6x7q6-756613a2 pod downward-api-1a9ee223-631e-4588-aa56-7b415a45a590 container dapi-container: <nil>
  STEP: delete the pod @ 01/27/26 21:56:17.645
  I0127 21:56:17.666888 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-538" for this suite. @ 01/27/26 21:56:17.669
  E0127 21:56:17.672678      26 retrywatcher.go:169] "Watch failed" err="context canceled"
• [4.101 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 01/27/26 21:56:17.677
  I0127 21:56:17.677689 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename sysctl @ 01/27/26 21:56:17.678
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:56:17.706
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:56:17.711
  STEP: Creating a pod with one valid and two invalid sysctls @ 01/27/26 21:56:17.714
  I0127 21:56:17.718451 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-8457" for this suite. @ 01/27/26 21:56:17.769
• [0.100 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:89
  STEP: Creating a kubernetes client @ 01/27/26 21:56:17.777
  I0127 21:56:17.777810 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename replication-controller @ 01/27/26 21:56:17.778
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:56:17.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:56:17.819
  I0127 21:56:17.822920 26 rc.go:550] Creating quota "condition-test" that allows only two pods to run in the current namespace
  E0127 21:56:18.673524      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 01/27/26 21:56:18.837
  STEP: Checking rc "condition-test" has the desired failure condition set @ 01/27/26 21:56:18.845
  E0127 21:56:19.675223      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 01/27/26 21:56:19.85
  I0127 21:56:19.867044 26 rc.go:737] Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 01/27/26 21:56:19.867
  E0127 21:56:20.676193      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:56:20.871297 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-6580" for this suite. @ 01/27/26 21:56:20.874
• [3.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:404
  STEP: Creating a kubernetes client @ 01/27/26 21:56:20.885
  I0127 21:56:20.885794 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename namespaces @ 01/27/26 21:56:20.886
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:56:20.911
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:56:20.913
  STEP: Creating namespace "e2e-ns-x6gs8" @ 01/27/26 21:56:20.915
  I0127 21:56:20.946481 26 namespace.go:415] Namespace "e2e-ns-x6gs8-1812" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-x6gs8-1812" @ 01/27/26 21:56:20.946
  I0127 21:56:20.961568 26 namespace.go:438] Namespace "e2e-ns-x6gs8-1812" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-x6gs8-1812" @ 01/27/26 21:56:20.961
  I0127 21:56:20.970958 26 namespace.go:467] Namespace "e2e-ns-x6gs8-1812" has []v1.FinalizerName{"kubernetes"}
  I0127 21:56:20.971085 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-5534" for this suite. @ 01/27/26 21:56:20.974
  STEP: Destroying namespace "e2e-ns-x6gs8-1812" for this suite. @ 01/27/26 21:56:20.983
• [0.105 seconds]
------------------------------
SS
------------------------------
[sig-node] Node Lifecycle should run through the lifecycle of a node [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/node_lifecycle.go:53
  STEP: Creating a kubernetes client @ 01/27/26 21:56:20.991
  I0127 21:56:20.991321 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename fake-node @ 01/27/26 21:56:20.992
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:56:21.018
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:56:21.02
  STEP: Create "e2e-fake-node-dcnqr" @ 01/27/26 21:56:21.022
  STEP: Getting "e2e-fake-node-dcnqr" @ 01/27/26 21:56:21.031
  STEP: Patching "e2e-fake-node-dcnqr" @ 01/27/26 21:56:21.032
  STEP: Listing nodes with LabelSelector "e2e-fake-node-dcnqr=patched" @ 01/27/26 21:56:21.09
  STEP: Updating "e2e-fake-node-dcnqr" @ 01/27/26 21:56:21.1
  STEP: Delete "e2e-fake-node-dcnqr" @ 01/27/26 21:56:21.133
  STEP: Confirm deletion of "e2e-fake-node-dcnqr" @ 01/27/26 21:56:21.146
  E0127 21:56:21.676850      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:22.677033      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:23.677685      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:24.677899      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:25.678106      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:56:26.165014 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "fake-node-3647" for this suite. @ 01/27/26 21:56:26.172
• [5.192 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:843
  STEP: Creating a kubernetes client @ 01/27/26 21:56:26.183
  I0127 21:56:26.183222 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename svcaccounts @ 01/27/26 21:56:26.184
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:56:26.218
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:56:26.223
  STEP: Creating ServiceAccount "e2e-sa-szxv4"  @ 01/27/26 21:56:26.23
  I0127 21:56:26.242448 26 service_accounts.go:858] AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-szxv4"  @ 01/27/26 21:56:26.242
  I0127 21:56:26.262636 26 service_accounts.go:872] AutomountServiceAccountToken: true
  I0127 21:56:26.262788 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5657" for this suite. @ 01/27/26 21:56:26.275
• [0.105 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 01/27/26 21:56:26.287
  I0127 21:56:26.287986 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename secrets @ 01/27/26 21:56:26.288
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:56:26.324
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:56:26.407
  I0127 21:56:26.465821 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4244" for this suite. @ 01/27/26 21:56:26.468
• [0.189 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1113
  STEP: Creating a kubernetes client @ 01/27/26 21:56:26.477
  I0127 21:56:26.477560 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubectl @ 01/27/26 21:56:26.478
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:56:26.498
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:56:26.501
  STEP: running the image registry.k8s.io/e2e-test-images/agnhost:2.59 @ 01/27/26 21:56:26.509
  I0127 21:56:26.509983 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-559 run e2e-test-agnhost-pod --image=registry.k8s.io/e2e-test-images/agnhost:2.59 --pod-running-timeout=2m0s --labels=run=e2e-test-agnhost-pod'
  I0127 21:56:26.587994 26 builder.go:156] stderr: ""
  I0127 21:56:26.588032 26 builder.go:157] stdout: "pod/e2e-test-agnhost-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 01/27/26 21:56:26.588
  I0127 21:56:26.588105 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-559 patch pod e2e-test-agnhost-pod -p {"spec":{"containers":[{"name": "e2e-test-agnhost-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.37.0-1"}]}} --dry-run=server'
  I0127 21:56:26.650983 26 builder.go:156] stderr: ""
  I0127 21:56:26.651032 26 builder.go:157] stdout: "pod/e2e-test-agnhost-pod patched\n"
  STEP: verifying the pod e2e-test-agnhost-pod has the right image registry.k8s.io/e2e-test-images/agnhost:2.59 @ 01/27/26 21:56:26.651
  I0127 21:56:26.659739 26 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-559 delete pods e2e-test-agnhost-pod'
  E0127 21:56:26.679728      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:27.679739      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:56:28.082875 26 builder.go:156] stderr: ""
  I0127 21:56:28.082920 26 builder.go:157] stdout: "pod \"e2e-test-agnhost-pod\" deleted from kubectl-559 namespace\n"
  I0127 21:56:28.083039 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-559" for this suite. @ 01/27/26 21:56:28.085
• [1.616 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:134
  STEP: Creating a kubernetes client @ 01/27/26 21:56:28.093
  I0127 21:56:28.093979 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename replicaset @ 01/27/26 21:56:28.094
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:56:28.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:56:28.132
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 01/27/26 21:56:28.135
  E0127 21:56:28.681184      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:29.681855      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 01/27/26 21:56:30.153
  STEP: Then the orphan pod is adopted @ 01/27/26 21:56:30.162
  E0127 21:56:30.682320      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 01/27/26 21:56:31.167
  I0127 21:56:31.169926 26 resource.go:64] Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 01/27/26 21:56:31.18
  E0127 21:56:31.682406      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0127 21:56:32.273072 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-1047" for this suite. @ 01/27/26 21:56:32.402
• [4.344 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:169
  STEP: Creating a kubernetes client @ 01/27/26 21:56:32.438
  I0127 21:56:32.438363 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename emptydir @ 01/27/26 21:56:32.439
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:56:32.617
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:56:32.619
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 01/27/26 21:56:32.62
  E0127 21:56:32.683456      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:33.683914      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:34.684018      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:35.684724      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:36.685812      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:56:36.805
  I0127 21:56:36.807487 26 output.go:207] Trying to get logs from node k3k-k3kcluster-server-0 pod pod-62771f38-bb15-4372-a3b1-8244931aca98 container test-container: <nil>
  STEP: delete the pod @ 01/27/26 21:56:36.81
  I0127 21:56:36.838516 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8527" for this suite. @ 01/27/26 21:56:36.84
• [4.411 seconds]
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1893
  STEP: Creating a kubernetes client @ 01/27/26 21:56:36.849
  I0127 21:56:36.849142 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename kubectl @ 01/27/26 21:56:36.849
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:56:36.87
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:56:36.875
  STEP: Starting the proxy @ 01/27/26 21:56:36.877
  I0127 21:56:36.877654 26 util.go:502] Asynchronously running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3727708954 --namespace=kubectl-4448 proxy --unix-socket=/tmp/kubectl-proxy-unix2153980789/test'
  STEP: retrieving proxy /api/ output @ 01/27/26 21:56:36.923
  I0127 21:56:36.924056 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4448" for this suite. @ 01/27/26 21:56:36.941
• [0.101 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 01/27/26 21:56:36.95
  I0127 21:56:36.950095 26 util.go:414] >>> kubeConfig: /tmp/kubeconfig-3727708954
  STEP: Building a namespace api object, basename projected @ 01/27/26 21:56:36.95
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/27/26 21:56:36.977
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/27/26 21:56:36.979
  STEP: Creating projection with secret that has name projected-secret-test-2f7769a9-abfd-490d-9d74-9fec6953fc3f @ 01/27/26 21:56:36.981
  STEP: Creating a pod to test consume secrets @ 01/27/26 21:56:36.988
  E0127 21:56:37.686669      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:38.686899      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:39.687110      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0127 21:56:40.687311      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/27/26 21:56:41.005
  I0127 21:56:41.007456 26 output.go:207] Trying to get logs from node k3k-k3kcluster-server-0 pod pod-projected-secrets-af9998d7-dfc2-471e-8646-e003f79a92f9 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 01/27/26 21:56:41.011
  I0127 21:56:41.040091 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7453" for this suite. @ 01/27/26 21:56:41.042
• [4.101 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:80
  I0127 21:56:41.051363 26 suites.go:34] Running AfterSuite actions on node 1
  I0127 21:56:41.051390 26 util.go:524] Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Invariant Metrics
k8s.io/kubernetes/test/e2e/invariants/metrics.go:46
[ReportAfterSuite] PASSED [0.001 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
k8s.io/kubernetes/test/e2e/e2e_test.go:158
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
k8s.io/kubernetes/test/e2e/framework/test_context.go:615
[ReportAfterSuite] PASSED [0.134 seconds]
------------------------------

Ran 441 of 7348 Specs in 7365.606 seconds
SUCCESS! -- 441 Passed | 0 Failed | 0 Pending | 6907 Skipped
PASS

Ginkgo ran 1 suite in 2h2m46.813959576s
Test Suite Passed
