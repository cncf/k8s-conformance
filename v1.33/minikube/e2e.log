  I0511 13:06:59.697957      26 e2e.go:109] Starting e2e run "01c2fc39-d9fb-41d9-b9dd-699f93ee27a7" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1746968819 - will randomize all specs

Will run 419 of 6731 specs
------------------------------
[ReportBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e_test.go:153
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:69
  I0511 13:06:59.806852 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  I0511 13:06:59.807396 26 helper.go:51] Waiting up to 30m0s for all (but 0) nodes to be schedulable
  I0511 13:06:59.819043 26 e2e.go:142] Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  I0511 13:06:59.820718 26 e2e.go:153] 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kindnet' (0 seconds elapsed)
  I0511 13:06:59.820741 26 e2e.go:153] 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
  I0511 13:06:59.820751 26 e2e.go:245] e2e test version: v1.33.0
  I0511 13:06:59.821141 26 e2e.go:254] kube-apiserver version: v1.33.0
  I0511 13:06:59.821214 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  I0511 13:06:59.822617 26 e2e.go:383] Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.016 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:131
  STEP: Creating a kubernetes client @ 05/11/25 13:06:59.897
  I0511 13:06:59.897580 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename dns @ 05/11/25 13:06:59.897
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:06:59.905
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:06:59.906
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9545.svc.cluster.local)" && echo OK > /results/agnhost_hosts@dns-querier-1.dns-test-service.dns-9545.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/agnhost_hosts@dns-querier-1;sleep 1; done
   @ 05/11/25 13:06:59.908
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9545.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9545.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 05/11/25 13:06:59.908
  STEP: creating a pod to probe /etc/hosts @ 05/11/25 13:06:59.908
  STEP: submitting the pod to kubernetes @ 05/11/25 13:06:59.908
  STEP: retrieving the pod @ 05/11/25 13:10:28.515
  STEP: looking for the results for each expected name from probers @ 05/11/25 13:10:28.518
  I0511 13:10:28.529056 26 dns_common.go:546] DNS probes using dns-9545/dns-test-553da515-1a05-4c40-88de-f3b39c6cd22b succeeded

  STEP: deleting the pod @ 05/11/25 13:10:28.529
  I0511 13:10:28.542148 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-9545" for this suite. @ 05/11/25 13:10:28.546
• [208.654 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 05/11/25 13:10:28.552
  I0511 13:10:28.552305 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename prestop @ 05/11/25 13:10:28.553
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:10:28.562
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:10:28.565
  STEP: Creating server pod server in namespace prestop-7499 @ 05/11/25 13:10:28.568
  STEP: Waiting for pods to come up. @ 05/11/25 13:10:28.576
  STEP: Creating tester pod tester in namespace prestop-7499 @ 05/11/25 13:10:30.587
  STEP: Deleting pre-stop pod @ 05/11/25 13:10:40.628
  I0511 13:10:45.637737 26 pre_stop.go:140] Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 05/11/25 13:10:45.638
  I0511 13:10:45.651368 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-7499" for this suite. @ 05/11/25 13:10:45.655
• [17.108 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:566
  STEP: Creating a kubernetes client @ 05/11/25 13:10:45.661
  I0511 13:10:45.661079 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 13:10:45.662
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:10:45.674
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:10:45.677
  STEP: Setting up server cert @ 05/11/25 13:10:45.689
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 13:10:45.924
  STEP: Deploying the webhook pod @ 05/11/25 13:10:45.927
  STEP: Wait for the deployment to be ready @ 05/11/25 13:10:45.934
  I0511 13:10:45.938204 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/11/25 13:10:47.95
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 13:10:47.969
  I0511 13:10:48.970248 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 05/11/25 13:10:49.034
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/11/25 13:10:49.067
  STEP: Deleting the collection of validation webhooks @ 05/11/25 13:10:49.095
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/11/25 13:10:49.136
  I0511 13:10:49.176557 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4926" for this suite. @ 05/11/25 13:10:49.178
  STEP: Destroying namespace "webhook-markers-8517" for this suite. @ 05/11/25 13:10:49.183
• [3.528 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:1162
  STEP: Creating a kubernetes client @ 05/11/25 13:10:49.189
  I0511 13:10:49.189140 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename job @ 05/11/25 13:10:49.189
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:10:49.194
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:10:49.195
  STEP: Creating a suspended job @ 05/11/25 13:10:49.2
  STEP: Patching the Job @ 05/11/25 13:10:49.203
  STEP: Watching for Job to be patched @ 05/11/25 13:10:49.21
  I0511 13:10:49.211337 26 job.go:1369] Event ADDED observed for Job e2e-7zjkw in namespace job-9798 with labels: map[e2e-job-label:e2e-7zjkw] and annotations: map[]
  I0511 13:10:49.211376 26 job.go:1372] Event MODIFIED found for Job e2e-7zjkw in namespace job-9798 with labels: map[e2e-7zjkw:patched e2e-job-label:e2e-7zjkw] and annotations: map[]
  STEP: Updating the job @ 05/11/25 13:10:49.211
  STEP: Watching for Job to be updated @ 05/11/25 13:10:49.216
  I0511 13:10:49.217825 26 job.go:1372] Event MODIFIED found for Job e2e-7zjkw in namespace job-9798 with labels: map[e2e-7zjkw:patched e2e-job-label:e2e-7zjkw] and annotations: map[updated:true]
  I0511 13:10:49.217865 26 job.go:1240] Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 05/11/25 13:10:49.217
  I0511 13:10:49.218973 26 job.go:1247] Job: e2e-7zjkw as labels: map[e2e-7zjkw:patched e2e-job-label:e2e-7zjkw]
  STEP: Waiting for job to complete @ 05/11/25 13:10:49.219
  STEP: Delete a job collection with a labelselector @ 05/11/25 13:10:57.246
  STEP: Watching for Job to be deleted @ 05/11/25 13:10:57.257
  I0511 13:10:57.259572 26 job.go:1369] Event MODIFIED observed for Job e2e-7zjkw in namespace job-9798 with labels: map[e2e-7zjkw:patched e2e-job-label:e2e-7zjkw] and annotations: map[updated:true]
  I0511 13:10:57.259654 26 job.go:1369] Event MODIFIED observed for Job e2e-7zjkw in namespace job-9798 with labels: map[e2e-7zjkw:patched e2e-job-label:e2e-7zjkw] and annotations: map[updated:true]
  I0511 13:10:57.259702 26 job.go:1369] Event MODIFIED observed for Job e2e-7zjkw in namespace job-9798 with labels: map[e2e-7zjkw:patched e2e-job-label:e2e-7zjkw] and annotations: map[updated:true]
  I0511 13:10:57.260041 26 job.go:1369] Event MODIFIED observed for Job e2e-7zjkw in namespace job-9798 with labels: map[e2e-7zjkw:patched e2e-job-label:e2e-7zjkw] and annotations: map[updated:true]
  I0511 13:10:57.260189 26 job.go:1369] Event MODIFIED observed for Job e2e-7zjkw in namespace job-9798 with labels: map[e2e-7zjkw:patched e2e-job-label:e2e-7zjkw] and annotations: map[updated:true]
  I0511 13:10:57.260305 26 job.go:1372] Event DELETED found for Job e2e-7zjkw in namespace job-9798 with labels: map[e2e-7zjkw:patched e2e-job-label:e2e-7zjkw] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 05/11/25 13:10:57.26
  I0511 13:10:57.263453 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-9798" for this suite. @ 05/11/25 13:10:57.272
• [8.090 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 05/11/25 13:10:57.279
  I0511 13:10:57.279966 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename csi-storageclass @ 05/11/25 13:10:57.281
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:10:57.289
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:10:57.291
  STEP: Creating a StorageClass @ 05/11/25 13:10:57.293
  STEP: Get StorageClass "e2e-db86t" @ 05/11/25 13:10:57.296
  STEP: Patching the StorageClass "e2e-db86t" @ 05/11/25 13:10:57.298
  STEP: Delete StorageClass "e2e-db86t" @ 05/11/25 13:10:57.303
  STEP: Confirm deletion of StorageClass "e2e-db86t" @ 05/11/25 13:10:57.306
  STEP: Create a replacement StorageClass @ 05/11/25 13:10:57.308
  STEP: Updating StorageClass "e2e-v2-rlwtt" @ 05/11/25 13:10:57.312
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-rlwtt=updated" @ 05/11/25 13:10:57.316
  STEP: Deleting StorageClass "e2e-v2-rlwtt" via DeleteCollection @ 05/11/25 13:10:57.318
  STEP: Confirm deletion of StorageClass "e2e-v2-rlwtt" @ 05/11/25 13:10:57.322
  I0511 13:10:57.324638 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-9471" for this suite. @ 05/11/25 13:10:57.373
• [0.101 seconds]
------------------------------
S
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:444
  STEP: Creating a kubernetes client @ 05/11/25 13:10:57.38
  I0511 13:10:57.380513 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename taint-multiple-pods @ 05/11/25 13:10:57.381
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:10:57.389
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:10:57.392
  I0511 13:10:57.395391 26 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  I0511 13:11:57.395880 26 util.go:390] Waiting for terminating namespaces to be deleted...
  I0511 13:11:57.401777 26 taints.go:144] Starting informer...
  STEP: Starting pods... @ 05/11/25 13:11:57.401
  I0511 13:11:57.620579 26 taints.go:463] Pod1 is running on k8sconformance-m02. Tainting Node
  I0511 13:11:59.844222 26 taints.go:471] Pod2 is running on k8sconformance-m02. Tainting Node
  STEP: Trying to apply a taint on the Node @ 05/11/25 13:11:59.844
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/11/25 13:11:59.856
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 05/11/25 13:11:59.861
  I0511 13:12:05.604607 26 taints.go:492] Noticed Pod "taint-eviction-b1" gets evicted.
  I0511 13:12:25.750168 26 taints.go:492] Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/11/25 13:12:25.762
  I0511 13:12:25.764857 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-7254" for this suite. @ 05/11/25 13:12:25.767
• [88.392 seconds]
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:659
  STEP: Creating a kubernetes client @ 05/11/25 13:12:25.772
  I0511 13:12:25.772760 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename statefulset @ 05/11/25 13:12:25.773
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:12:25.789
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:12:25.794
  STEP: Creating service test in namespace statefulset-879 @ 05/11/25 13:12:25.797
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 05/11/25 13:12:25.8
  STEP: Creating stateful set ss in namespace statefulset-879 @ 05/11/25 13:12:25.802
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-879 @ 05/11/25 13:12:25.807
  I0511 13:12:25.875019 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
  I0511 13:12:35.811619 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
  I0511 13:12:45.814259 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
  I0511 13:12:55.813396 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
  I0511 13:13:05.813944 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
  I0511 13:13:15.813833 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
  I0511 13:13:25.812309 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
  I0511 13:13:35.813727 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 05/11/25 13:13:35.813
  I0511 13:13:35.815846 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=statefulset-879 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0511 13:13:35.938786 26 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0511 13:13:35.938848 26 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0511 13:13:35.938870 26 rest.go:280] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0511 13:13:35.942085 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  I0511 13:13:45.946223 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0511 13:13:45.946287 26 wait.go:109] Waiting for statefulset status.readyReplicas updated to 0
  I0511 13:13:46.047763 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 1 for another 9.999999454s
  I0511 13:13:47.051759 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 1 for another 8.910419552s
  I0511 13:13:48.059211 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 1 for another 7.90651025s
  I0511 13:13:49.066058 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 1 for another 6.899733282s
  I0511 13:13:50.072597 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 1 for another 5.892275475s
  I0511 13:13:51.078098 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 1 for another 4.886375385s
  I0511 13:13:52.084053 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 1 for another 3.880808161s
  I0511 13:13:53.089021 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 1 for another 2.875006569s
  I0511 13:13:54.094928 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 1 for another 1.869942204s
  I0511 13:13:55.101695 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 1 for another 863.292007ms
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-879 @ 05/11/25 13:13:56.102
  I0511 13:13:56.109091 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=statefulset-879 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0511 13:13:56.199815 26 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0511 13:13:56.199875 26 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0511 13:13:56.199894 26 rest.go:280] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0511 13:13:56.203235 26 wait.go:44] Found 1 stateful pods, waiting for 3
  I0511 13:14:06.206808 26 wait.go:44] Found 2 stateful pods, waiting for 3
  I0511 13:14:16.206000 26 wait.go:44] Found 2 stateful pods, waiting for 3
  I0511 13:14:26.207481 26 wait.go:44] Found 2 stateful pods, waiting for 3
  I0511 13:14:36.207015 26 wait.go:44] Found 2 stateful pods, waiting for 3
  I0511 13:14:46.207826 26 wait.go:44] Found 2 stateful pods, waiting for 3
  I0511 13:14:56.207185 26 wait.go:44] Found 2 stateful pods, waiting for 3
  I0511 13:15:06.206445 26 wait.go:44] Found 2 stateful pods, waiting for 3
  I0511 13:15:16.207408 26 wait.go:44] Found 2 stateful pods, waiting for 3
  I0511 13:15:26.205710 26 wait.go:44] Found 2 stateful pods, waiting for 3
  I0511 13:15:36.207319 26 wait.go:44] Found 2 stateful pods, waiting for 3
  I0511 13:15:46.205645 26 wait.go:44] Found 2 stateful pods, waiting for 3
  I0511 13:15:56.204699 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0511 13:15:56.204746 26 wait.go:54] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0511 13:15:56.204761 26 wait.go:54] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 05/11/25 13:15:56.204
  STEP: Scale down will halt with unhealthy stateful pod @ 05/11/25 13:15:56.204
  I0511 13:15:56.209909 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=statefulset-879 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0511 13:15:56.296128 26 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0511 13:15:56.296188 26 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0511 13:15:56.296212 26 rest.go:280] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0511 13:15:56.296278 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=statefulset-879 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0511 13:15:56.403724 26 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0511 13:15:56.403776 26 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0511 13:15:56.403797 26 rest.go:280] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0511 13:15:56.403856 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=statefulset-879 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0511 13:15:56.516350 26 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0511 13:15:56.516413 26 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0511 13:15:56.516436 26 rest.go:280] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0511 13:15:56.516454 26 wait.go:109] Waiting for statefulset status.readyReplicas updated to 0
  I0511 13:15:56.519629 26 wait.go:122] Waiting for statefulset status.readyReplicas to become 0, currently 3
  I0511 13:16:06.524512 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0511 13:16:06.524563 26 wait.go:54] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0511 13:16:06.524582 26 wait.go:54] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I0511 13:16:06.626943 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 3 for another 9.999999562s
  I0511 13:16:07.632698 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 3 for another 8.904457981s
  I0511 13:16:08.638726 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 3 for another 7.898856105s
  I0511 13:16:09.645627 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 3 for another 6.892695997s
  I0511 13:16:10.652948 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 3 for another 5.885006846s
  I0511 13:16:11.658746 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 3 for another 4.878704601s
  I0511 13:16:12.664589 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 3 for another 3.872744822s
  I0511 13:16:13.671362 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 3 for another 2.866917436s
  I0511 13:16:14.677954 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 3 for another 1.860086471s
  I0511 13:16:15.684106 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 3 for another 853.232237ms
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-879 @ 05/11/25 13:16:16.685
  I0511 13:16:16.688704 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=statefulset-879 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0511 13:16:16.770602 26 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0511 13:16:16.770644 26 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0511 13:16:16.770661 26 rest.go:280] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0511 13:16:16.770710 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=statefulset-879 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0511 13:16:16.862811 26 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0511 13:16:16.862860 26 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0511 13:16:16.862882 26 rest.go:280] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0511 13:16:16.862939 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=statefulset-879 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0511 13:16:16.962657 26 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0511 13:16:16.962705 26 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0511 13:16:16.962723 26 rest.go:280] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0511 13:16:16.962738 26 rest.go:153] Scaling statefulset ss to 0
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 05/11/25 13:16:26.973
  I0511 13:16:26.973512 26 statefulset.go:138] Deleting all statefulset in ns statefulset-879
  I0511 13:16:26.976752 26 rest.go:153] Scaling statefulset ss to 0
  I0511 13:16:26.981011 26 wait.go:159] Waiting for statefulset status.replicas updated to 0
  I0511 13:16:26.983013 26 rest.go:91] Deleting statefulset ss
  I0511 13:16:26.995513 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-879" for this suite. @ 05/11/25 13:16:26.998
• [241.231 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:174
  STEP: Creating a kubernetes client @ 05/11/25 13:16:27.004
  I0511 13:16:27.004034 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 13:16:27.005
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:16:27.015
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:16:27.018
  STEP: Creating configMap with name cm-test-opt-del-5b4091c1-9563-40a5-babd-438febe18b84 @ 05/11/25 13:16:27.099
  STEP: Creating configMap with name cm-test-opt-upd-cf1e5a13-711b-408d-932c-a2a4385fb044 @ 05/11/25 13:16:27.103
  STEP: Creating the pod @ 05/11/25 13:16:27.107
  STEP: Deleting configmap cm-test-opt-del-5b4091c1-9563-40a5-babd-438febe18b84 @ 05/11/25 13:16:29.152
  STEP: Updating configmap cm-test-opt-upd-cf1e5a13-711b-408d-932c-a2a4385fb044 @ 05/11/25 13:16:29.158
  STEP: Creating configMap with name cm-test-opt-create-20a47582-0e35-4ea1-9aff-b16941a3d1e5 @ 05/11/25 13:16:29.162
  STEP: waiting to observe update in volume @ 05/11/25 13:16:29.168
  I0511 13:16:33.214761 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7821" for this suite. @ 05/11/25 13:16:33.217
• [6.219 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:312
  STEP: Creating a kubernetes client @ 05/11/25 13:16:33.223
  I0511 13:16:33.223186 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 13:16:33.224
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:16:33.232
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:16:33.234
  STEP: Setting up server cert @ 05/11/25 13:16:33.251
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 13:16:33.523
  STEP: Deploying the webhook pod @ 05/11/25 13:16:33.526
  STEP: Wait for the deployment to be ready @ 05/11/25 13:16:33.533
  I0511 13:16:33.538407 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/11/25 13:16:35.548
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 13:16:35.564
  I0511 13:16:36.564759 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0511 13:16:36.569656 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4285-crds.webhook.example.com via the AdmissionRegistration API @ 05/11/25 13:16:37.084
  STEP: Creating a custom resource while v1 is storage version @ 05/11/25 13:16:37.102
  STEP: Patching Custom Resource Definition to set v2 as storage @ 05/11/25 13:16:39.118
  STEP: Patching the custom resource while v2 is storage version @ 05/11/25 13:16:39.131
  I0511 13:16:39.700352 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4353" for this suite. @ 05/11/25 13:16:39.704
  STEP: Destroying namespace "webhook-markers-8738" for this suite. @ 05/11/25 13:16:39.71
• [6.493 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:747
  STEP: Creating a kubernetes client @ 05/11/25 13:16:39.716
  I0511 13:16:39.716790 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename sched-preemption @ 05/11/25 13:16:39.717
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:16:39.726
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:16:39.73
  I0511 13:16:39.744723 26 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  I0511 13:17:39.751228 26 util.go:390] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 05/11/25 13:17:39.754
  I0511 13:17:39.754793 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename sched-preemption-path @ 05/11/25 13:17:39.755
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:17:39.764
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:17:39.767
  STEP: Finding an available node @ 05/11/25 13:17:39.77
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 05/11/25 13:17:39.77
  STEP: Explicitly delete pod here to free the resource it takes. @ 05/11/25 13:17:41.787
  I0511 13:17:41.800057 26 preemption.go:710] found a healthy node: k8sconformance-m02
  STEP: Adding a custom resource @ 05/11/25 13:17:41.803
  I0511 13:17:47.864885 26 preemption.go:829] pods created so far: [1 1 1]
  I0511 13:17:47.864940 26 preemption.go:830] length of pods created so far: 3
  I0511 13:17:49.878173 26 preemption.go:847] pods created so far: [2 2 1]
  STEP: Removing a custom resource @ 05/11/25 13:17:56.88
  STEP: Removing a custom resource @ 05/11/25 13:17:56.932
  STEP: Removing a custom resource @ 05/11/25 13:17:56.94
  I0511 13:17:56.947194 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-9169" for this suite. @ 05/11/25 13:17:56.949
  I0511 13:17:56.953596 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-3329" for this suite. @ 05/11/25 13:17:57.052
• [77.344 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:301
  STEP: Creating a kubernetes client @ 05/11/25 13:17:57.061
  I0511 13:17:57.061046 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename var-expansion @ 05/11/25 13:17:57.061
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:17:57.07
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:17:57.073
  STEP: creating the pod @ 05/11/25 13:17:57.076
  STEP: waiting for pod running @ 05/11/25 13:17:57.084
  STEP: creating a file in subpath @ 05/11/25 13:17:59.094
  I0511 13:17:59.097711 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-6183 PodName:var-expansion-b3d5de79-58d2-4c74-822b-bfcf53642a1e ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 13:17:59.097745 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 13:17:59.097804 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/var-expansion-6183/pods/var-expansion-b3d5de79-58d2-4c74-822b-bfcf53642a1e/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&stderr=true&stdout=true)
  I0511 13:17:59.166152 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  STEP: test for file in mounted path @ 05/11/25 13:17:59.166
  I0511 13:17:59.171191 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-6183 PodName:var-expansion-b3d5de79-58d2-4c74-822b-bfcf53642a1e ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 13:17:59.171246 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 13:17:59.171334 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/var-expansion-6183/pods/var-expansion-b3d5de79-58d2-4c74-822b-bfcf53642a1e/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&stderr=true&stdout=true)
  I0511 13:17:59.228008 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  STEP: updating the annotation value @ 05/11/25 13:17:59.228
  I0511 13:17:59.742930 26 pod_client.go:173] Successfully updated pod "var-expansion-b3d5de79-58d2-4c74-822b-bfcf53642a1e"
  STEP: waiting for annotated pod running @ 05/11/25 13:17:59.743
  STEP: deleting the pod gracefully @ 05/11/25 13:17:59.746
  I0511 13:17:59.746094 26 delete.go:62] Deleting pod "var-expansion-b3d5de79-58d2-4c74-822b-bfcf53642a1e" in namespace "var-expansion-6183"
  I0511 13:17:59.752108 26 delete.go:70] Wait up to 5m0s for pod "var-expansion-b3d5de79-58d2-4c74-822b-bfcf53642a1e" to be fully deleted
  I0511 13:18:33.853041 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6183" for this suite. @ 05/11/25 13:18:33.856
• [36.802 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 05/11/25 13:18:33.863
  I0511 13:18:33.863144 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename watch @ 05/11/25 13:18:33.864
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:18:33.873
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:18:33.877
  STEP: creating a watch on configmaps with a certain label @ 05/11/25 13:18:33.88
  STEP: creating a new configmap @ 05/11/25 13:18:33.881
  STEP: modifying the configmap once @ 05/11/25 13:18:33.884
  STEP: changing the label value of the configmap @ 05/11/25 13:18:33.89
  STEP: Expecting to observe a delete notification for the watched object @ 05/11/25 13:18:33.894
  I0511 13:18:33.895058 26 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-888  2ec5c349-6974-498f-b1e9-40674346fe31 2534 0 2025-05-11 13:18:33 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2025-05-11 13:18:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0511 13:18:33.895194 26 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-888  2ec5c349-6974-498f-b1e9-40674346fe31 2535 0 2025-05-11 13:18:33 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2025-05-11 13:18:33 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0511 13:18:33.895279 26 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-888  2ec5c349-6974-498f-b1e9-40674346fe31 2536 0 2025-05-11 13:18:33 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2025-05-11 13:18:33 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 05/11/25 13:18:33.895
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 05/11/25 13:18:33.9
  STEP: changing the label value of the configmap back @ 05/11/25 13:18:43.903
  STEP: modifying the configmap a third time @ 05/11/25 13:18:43.915
  STEP: deleting the configmap @ 05/11/25 13:18:43.925
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 05/11/25 13:18:43.931
  I0511 13:18:43.931255 26 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-888  2ec5c349-6974-498f-b1e9-40674346fe31 2556 0 2025-05-11 13:18:33 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2025-05-11 13:18:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0511 13:18:43.931436 26 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-888  2ec5c349-6974-498f-b1e9-40674346fe31 2557 0 2025-05-11 13:18:33 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2025-05-11 13:18:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0511 13:18:43.931663 26 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-888  2ec5c349-6974-498f-b1e9-40674346fe31 2558 0 2025-05-11 13:18:33 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2025-05-11 13:18:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0511 13:18:43.931844 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-888" for this suite. @ 05/11/25 13:18:43.935
• [10.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:221
  STEP: Creating a kubernetes client @ 05/11/25 13:18:43.94
  I0511 13:18:43.940454 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename validating-admission-policy @ 05/11/25 13:18:43.941
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:18:43.95
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:18:43.953
  STEP: creating a policy with variables @ 05/11/25 13:18:43.961
  STEP: waiting until the marker is denied @ 05/11/25 13:18:43.978
  STEP: testing a replicated Deployment to be allowed @ 05/11/25 13:18:44.585
  STEP: testing a non-replicated ReplicaSet not to be denied @ 05/11/25 13:18:44.593
  I0511 13:18:44.640042 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-7261" for this suite. @ 05/11/25 13:18:44.645
• [0.709 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Node Lifecycle should run through the lifecycle of a node [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/node_lifecycle.go:51
  STEP: Creating a kubernetes client @ 05/11/25 13:18:44.649
  I0511 13:18:44.649584 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename fake-node @ 05/11/25 13:18:44.65
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:18:44.656
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:18:44.658
  STEP: Create "e2e-fake-node-jjlzd" @ 05/11/25 13:18:44.659
  STEP: Getting "e2e-fake-node-jjlzd" @ 05/11/25 13:18:44.662
  STEP: Patching "e2e-fake-node-jjlzd" @ 05/11/25 13:18:44.663
  STEP: Listing nodes with LabelSelector "e2e-fake-node-jjlzd=patched" @ 05/11/25 13:18:44.672
  STEP: Updating "e2e-fake-node-jjlzd" @ 05/11/25 13:18:44.747
  STEP: Delete "e2e-fake-node-jjlzd" @ 05/11/25 13:18:44.755
  STEP: Confirm deletion of "e2e-fake-node-jjlzd" @ 05/11/25 13:18:44.759
  I0511 13:18:44.762222 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "fake-node-8676" for this suite. @ 05/11/25 13:18:44.764
• [0.120 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 05/11/25 13:18:44.77
  I0511 13:18:44.770156 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename watch @ 05/11/25 13:18:44.771
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:18:44.781
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:18:44.784
  STEP: getting a starting resourceVersion @ 05/11/25 13:18:44.787
  STEP: starting a background goroutine to produce watch events @ 05/11/25 13:18:44.79
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 05/11/25 13:18:44.79
  I0511 13:18:47.578273 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-2647" for this suite. @ 05/11/25 13:18:47.627
• [2.908 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 05/11/25 13:18:47.678
  I0511 13:18:47.678974 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 13:18:47.68
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:18:47.689
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:18:47.692
  STEP: Creating projection with secret that has name projected-secret-test-bbb8a778-93dd-4610-956c-c25d4c933b68 @ 05/11/25 13:18:47.695
  STEP: Creating a pod to test consume secrets @ 05/11/25 13:18:47.699
  STEP: Saw pod success @ 05/11/25 13:18:51.716
  I0511 13:18:51.718748 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-projected-secrets-0b21ac46-2a2d-4e19-88b2-64c2b7604df0 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/11/25 13:18:51.732
  I0511 13:18:51.741349 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7125" for this suite. @ 05/11/25 13:18:51.743
• [4.067 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:131
  STEP: Creating a kubernetes client @ 05/11/25 13:18:51.746
  I0511 13:18:51.746126 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename downward-api @ 05/11/25 13:18:51.746
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:18:51.751
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:18:51.752
  STEP: Creating the pod @ 05/11/25 13:18:51.754
  I0511 13:18:54.285048 26 pod_client.go:173] Successfully updated pod "labelsupdate10e7469e-7ded-4861-bc77-ff4488b6a720"
  I0511 13:18:58.311340 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5691" for this suite. @ 05/11/25 13:18:58.314
• [6.575 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2244
  STEP: Creating a kubernetes client @ 05/11/25 13:18:58.321
  I0511 13:18:58.321017 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename services @ 05/11/25 13:18:58.321
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:18:58.327
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:18:58.329
  STEP: creating service in namespace services-4155 @ 05/11/25 13:18:58.331
  STEP: creating service affinity-nodeport-transition in namespace services-4155 @ 05/11/25 13:18:58.331
  I0511 13:18:58.353069 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  I0511 13:19:00.358724 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 59, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-transition-7d57658b6c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:19:02.359298 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 59, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-transition-7d57658b6c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:19:04.356572 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 59, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-transition-7d57658b6c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:19:06.358815 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 59, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-transition-7d57658b6c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:19:08.357413 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 59, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-transition-7d57658b6c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:19:10.358139 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 59, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-transition-7d57658b6c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:19:12.359203 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 59, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-transition-7d57658b6c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:19:14.359995 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 59, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-transition-7d57658b6c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:19:16.360579 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 59, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-transition-7d57658b6c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:19:18.358499 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 59, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-transition-7d57658b6c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:19:20.357502 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 59, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-transition-7d57658b6c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:19:22.358249 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 59, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-transition-7d57658b6c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:19:24.359251 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 59, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-transition-7d57658b6c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:19:26.358531 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 59, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-transition-7d57658b6c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:19:28.358865 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 59, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-transition-7d57658b6c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:19:30.357607 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 59, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-transition-7d57658b6c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:19:32.355560 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 18, 59, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 18, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-transition-7d57658b6c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:19:34.371162 26 resource.go:361] Creating new exec pod
  I0511 13:19:36.399530 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-4155 exec execpod-affinitympghh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  I0511 13:19:36.496410 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition (10.106.39.241) 80 port [tcp/http] succeeded!\n"
  I0511 13:19:36.496467 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 13:19:36.496521 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-4155 exec execpod-affinitympghh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.106.39.241 80'
  I0511 13:19:36.603709 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.106.39.241 80\nConnection to 10.106.39.241 80 port [tcp/http] succeeded!\n"
  I0511 13:19:36.603781 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 13:19:36.603903 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-4155 exec execpod-affinitympghh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.49.2 30384'
  I0511 13:19:36.689378 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.49.2 30384\nConnection to 192.168.49.2 30384 port [tcp/*] succeeded!\n"
  I0511 13:19:36.689416 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 13:19:36.689494 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-4155 exec execpod-affinitympghh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.49.3 30384'
  I0511 13:19:36.774975 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.49.3 30384\nConnection to 192.168.49.3 30384 port [tcp/*] succeeded!\n"
  I0511 13:19:36.775013 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 13:19:36.783977 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-4155 exec execpod-affinitympghh -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/ ; done'
  I0511 13:19:36.953164 26 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n"
  I0511 13:19:36.953209 26 builder.go:147] stdout: "\naffinity-nodeport-transition-7d57658b6c-w8rtk\naffinity-nodeport-transition-7d57658b6c-lpk52\naffinity-nodeport-transition-7d57658b6c-w8rtk\naffinity-nodeport-transition-7d57658b6c-w8rtk\naffinity-nodeport-transition-7d57658b6c-5xb7n\naffinity-nodeport-transition-7d57658b6c-w8rtk\naffinity-nodeport-transition-7d57658b6c-lpk52\naffinity-nodeport-transition-7d57658b6c-w8rtk\naffinity-nodeport-transition-7d57658b6c-lpk52\naffinity-nodeport-transition-7d57658b6c-lpk52\naffinity-nodeport-transition-7d57658b6c-5xb7n\naffinity-nodeport-transition-7d57658b6c-5xb7n\naffinity-nodeport-transition-7d57658b6c-lpk52\naffinity-nodeport-transition-7d57658b6c-lpk52\naffinity-nodeport-transition-7d57658b6c-5xb7n\naffinity-nodeport-transition-7d57658b6c-w8rtk"
  I0511 13:19:36.953228 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-w8rtk
  I0511 13:19:36.953235 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-lpk52
  I0511 13:19:36.953241 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-w8rtk
  I0511 13:19:36.953247 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-w8rtk
  I0511 13:19:36.953252 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:36.953257 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-w8rtk
  I0511 13:19:36.953262 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-lpk52
  I0511 13:19:36.953267 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-w8rtk
  I0511 13:19:36.953272 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-lpk52
  I0511 13:19:36.953277 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-lpk52
  I0511 13:19:36.953282 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:36.953290 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:36.953295 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-lpk52
  I0511 13:19:36.953300 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-lpk52
  I0511 13:19:36.953304 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:36.953321 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-w8rtk
  I0511 13:19:36.960602 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-4155 exec execpod-affinitympghh -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/ ; done'
  I0511 13:19:37.122023 26 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30384/\n"
  I0511 13:19:37.122077 26 builder.go:147] stdout: "\naffinity-nodeport-transition-7d57658b6c-5xb7n\naffinity-nodeport-transition-7d57658b6c-5xb7n\naffinity-nodeport-transition-7d57658b6c-5xb7n\naffinity-nodeport-transition-7d57658b6c-5xb7n\naffinity-nodeport-transition-7d57658b6c-5xb7n\naffinity-nodeport-transition-7d57658b6c-5xb7n\naffinity-nodeport-transition-7d57658b6c-5xb7n\naffinity-nodeport-transition-7d57658b6c-5xb7n\naffinity-nodeport-transition-7d57658b6c-5xb7n\naffinity-nodeport-transition-7d57658b6c-5xb7n\naffinity-nodeport-transition-7d57658b6c-5xb7n\naffinity-nodeport-transition-7d57658b6c-5xb7n\naffinity-nodeport-transition-7d57658b6c-5xb7n\naffinity-nodeport-transition-7d57658b6c-5xb7n\naffinity-nodeport-transition-7d57658b6c-5xb7n\naffinity-nodeport-transition-7d57658b6c-5xb7n"
  I0511 13:19:37.122094 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:37.122104 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:37.122112 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:37.122119 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:37.122126 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:37.122133 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:37.122141 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:37.122148 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:37.122155 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:37.122166 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:37.122174 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:37.122181 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:37.122189 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:37.122196 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:37.122203 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:37.122209 26 service.go:238] Received response from host: affinity-nodeport-transition-7d57658b6c-5xb7n
  I0511 13:19:37.122265 26 service.go:4352] Cleaning up the exec pod
  I0511 13:19:37.156560 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4155" for this suite. @ 05/11/25 13:19:37.163
• [38.853 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 05/11/25 13:19:37.174
  I0511 13:19:37.174393 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename endpointslice @ 05/11/25 13:19:37.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:19:37.185
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:19:37.187
  STEP: getting /apis @ 05/11/25 13:19:37.189
  STEP: getting /apis/discovery.k8s.io @ 05/11/25 13:19:37.191
  STEP: getting /apis/discovery.k8s.iov1 @ 05/11/25 13:19:37.192
  STEP: creating @ 05/11/25 13:19:37.193
  STEP: getting @ 05/11/25 13:19:37.204
  STEP: listing @ 05/11/25 13:19:37.205
  STEP: watching @ 05/11/25 13:19:37.207
  I0511 13:19:37.207258 26 endpointslice.go:447] starting watch
  STEP: cluster-wide listing @ 05/11/25 13:19:37.208
  STEP: cluster-wide watching @ 05/11/25 13:19:37.21
  I0511 13:19:37.210491 26 endpointslice.go:459] starting watch
  STEP: patching @ 05/11/25 13:19:37.211
  STEP: updating @ 05/11/25 13:19:37.215
  I0511 13:19:37.219558 26 endpointslice.go:482] waiting for watch events with expected annotations
  I0511 13:19:37.219621 26 endpointslice.go:495] saw patched and updated annotations
  STEP: deleting @ 05/11/25 13:19:37.219
  STEP: deleting a collection @ 05/11/25 13:19:37.227
  I0511 13:19:37.237337 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-2944" for this suite. @ 05/11/25 13:19:37.264
• [0.096 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:163
  STEP: Creating a kubernetes client @ 05/11/25 13:19:37.27
  I0511 13:19:37.270024 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename downward-api @ 05/11/25 13:19:37.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:19:37.278
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:19:37.281
  STEP: Creating the pod @ 05/11/25 13:19:37.284
  I0511 13:19:39.837670 26 pod_client.go:173] Successfully updated pod "annotationupdate402c4ac2-c066-4b9e-8cc3-7e739c1da4d3"
  I0511 13:19:43.870429 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1761" for this suite. @ 05/11/25 13:19:43.874
• [6.611 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:57
  STEP: Creating a kubernetes client @ 05/11/25 13:19:43.881
  I0511 13:19:43.881107 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 13:19:43.882
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:19:43.893
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:19:43.897
  STEP: Creating configMap with name projected-configmap-test-volume-1e9a825c-8f09-42ed-9a03-5c6df9635f51 @ 05/11/25 13:19:43.9
  STEP: Creating a pod to test consume configMaps @ 05/11/25 13:19:43.904
  STEP: Saw pod success @ 05/11/25 13:19:47.928
  I0511 13:19:47.932362 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-projected-configmaps-b75e377b-497b-423c-b64a-8020c3e7a377 container agnhost-container: <nil>
  STEP: delete the pod @ 05/11/25 13:19:47.94
  I0511 13:19:47.954991 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1028" for this suite. @ 05/11/25 13:19:47.959
• [4.084 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:125
  STEP: Creating a kubernetes client @ 05/11/25 13:19:47.964
  I0511 13:19:47.965027 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename sched-preemption @ 05/11/25 13:19:47.966
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:19:47.975
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:19:47.979
  I0511 13:19:47.996324 26 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  I0511 13:20:48.001147 26 util.go:390] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 05/11/25 13:20:48.004
  STEP: Adding a custom resource @ 05/11/25 13:20:48.004
  I0511 13:20:48.021570 26 preemption.go:169] Created pod: pod0-0-sched-preemption-low-priority
  I0511 13:20:48.028660 26 preemption.go:169] Created pod: pod0-1-sched-preemption-medium-priority
  STEP: Adding a custom resource @ 05/11/25 13:20:48.028
  I0511 13:20:48.051278 26 preemption.go:169] Created pod: pod1-0-sched-preemption-medium-priority
  I0511 13:20:48.064892 26 preemption.go:169] Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 05/11/25 13:20:48.064
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 05/11/25 13:20:50.082
  STEP: Removing a custom resource @ 05/11/25 13:20:52.131
  STEP: Removing a custom resource @ 05/11/25 13:20:52.163
  I0511 13:20:52.172382 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-5161" for this suite. @ 05/11/25 13:20:52.173
• [64.212 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:306
  STEP: Creating a kubernetes client @ 05/11/25 13:20:52.177
  I0511 13:20:52.177225 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename namespaces @ 05/11/25 13:20:52.177
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:20:52.184
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:20:52.185
  STEP: Read namespace status @ 05/11/25 13:20:52.187
  I0511 13:20:52.189018 26 namespace.go:319] Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 05/11/25 13:20:52.189
  I0511 13:20:52.191918 26 namespace.go:339] Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 05/11/25 13:20:52.191
  I0511 13:20:52.197386 26 namespace.go:364] Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  I0511 13:20:52.197518 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-2957" for this suite. @ 05/11/25 13:20:52.2
• [0.026 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on DisruptionTarget condition [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:199
  STEP: Creating a kubernetes client @ 05/11/25 13:20:52.203
  I0511 13:20:52.203777 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename job @ 05/11/25 13:20:52.204
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:20:52.21
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:20:52.212
  STEP: Looking for a node to schedule job pods @ 05/11/25 13:20:52.214
  STEP: Creating a job @ 05/11/25 13:20:52.302
  STEP: Waiting for all the pods to be ready @ 05/11/25 13:20:52.309
  STEP: Fetch all running pods @ 05/11/25 13:20:56.322
  STEP: Evict all the Pods @ 05/11/25 13:20:56.326
  STEP: Evicting the running pod: evicted-pod-ignore-on-disruption-condition-0-29tpj/job-8792 @ 05/11/25 13:20:56.326
  STEP: Evicting the running pod: evicted-pod-ignore-on-disruption-condition-1-8xkh4/job-8792 @ 05/11/25 13:20:56.326
  STEP: Evicting the running pod: evicted-pod-ignore-on-disruption-condition-2-rjt79/job-8792 @ 05/11/25 13:20:56.326
  STEP: Awaiting for the pod: evicted-pod-ignore-on-disruption-condition-2-rjt79/job-8792 to be deleted @ 05/11/25 13:20:56.343
  STEP: Awaiting for the pod: evicted-pod-ignore-on-disruption-condition-0-29tpj/job-8792 to be deleted @ 05/11/25 13:20:56.346
  STEP: Awaiting for the pod: evicted-pod-ignore-on-disruption-condition-1-8xkh4/job-8792 to be deleted @ 05/11/25 13:20:56.347
  STEP: Ensuring job reaches completions @ 05/11/25 13:21:00.361
  I0511 13:21:42.472082 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8792" for this suite. @ 05/11/25 13:21:42.475
• [50.276 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 05/11/25 13:21:42.48
  I0511 13:21:42.480160 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename init-container @ 05/11/25 13:21:42.481
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:21:42.491
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:21:42.495
  STEP: creating the pod @ 05/11/25 13:21:42.497
  I0511 13:21:42.497817 26 init_container.go:374] PodSpec: initContainers in spec.initContainers
  I0511 13:22:30.087419 26 init_container.go:432] init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-fd2f4bdf-50ff-4272-ab4d-8799cff409d9", GenerateName:"", Namespace:"init-container-875", SelfLink:"", UID:"01adbfa0-8535-4f48-a54a-71a3f6991010", ResourceVersion:"3594", Generation:1, CreationTimestamp:time.Date(2025, time.May, 11, 13, 21, 42, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"497804871"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 21, 42, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004780048), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 22, 30, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004780078), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-nrmf6", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc001648020), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil), Image:(*v1.ImageVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-nrmf6", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-nrmf6", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.10", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-nrmf6", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00372a0d8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8sconformance-m02", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0032e2000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00372a150)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00372a170)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00372a178), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00372a17c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000f10070), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil), Resources:(*v1.ResourceRequirements)(nil)}, Status:v1.PodStatus{ObservedGeneration:0, Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", ObservedGeneration:0, Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2025, time.May, 11, 13, 21, 43, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", ObservedGeneration:0, Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2025, time.May, 11, 13, 21, 42, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", ObservedGeneration:0, Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2025, time.May, 11, 13, 21, 42, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", ObservedGeneration:0, Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2025, time.May, 11, 13, 21, 42, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", ObservedGeneration:0, Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2025, time.May, 11, 13, 21, 42, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.49.3", HostIPs:[]v1.HostIP{v1.HostIP{IP:"192.168.49.3"}}, PodIP:"10.244.1.39", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.1.39"}}, StartTime:time.Date(2025, time.May, 11, 13, 21, 42, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00034c000)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00034c070)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"docker-pullable://registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9", ContainerID:"docker://7ce309edeb0c3115af670bea574b9de1d9a1514a2a4dbf77dcb2a1b2e5d23373", Started:(*bool)(0xc00372a22a), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(0xc002dba270), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-nrmf6", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc000f10090)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil), StopSignal:(*v1.Signal)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001648080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc00372a23d), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-nrmf6", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc000f100a0)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil), StopSignal:(*v1.Signal)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001648060), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.10", ImageID:"", ContainerID:"", Started:(*bool)(0xc00372a1ff), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-nrmf6", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc000f10080)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil), StopSignal:(*v1.Signal)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  I0511 13:22:30.087691 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-875" for this suite. @ 05/11/25 13:22:30.092
• [47.619 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:48
  STEP: Creating a kubernetes client @ 05/11/25 13:22:30.1
  I0511 13:22:30.100066 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename var-expansion @ 05/11/25 13:22:30.101
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:22:30.109
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:22:30.111
  STEP: Creating a pod to test env composition @ 05/11/25 13:22:30.113
  STEP: Saw pod success @ 05/11/25 13:22:34.128
  I0511 13:22:34.130888 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod var-expansion-1bc01d0f-8d85-4bcf-92f7-ff29ef815572 container dapi-container: <nil>
  STEP: delete the pod @ 05/11/25 13:22:34.145
  I0511 13:22:34.160495 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7544" for this suite. @ 05/11/25 13:22:34.163
• [4.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:547
  STEP: Creating a kubernetes client @ 05/11/25 13:22:34.17
  I0511 13:22:34.170235 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename gc @ 05/11/25 13:22:34.171
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:22:34.181
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:22:34.184
  STEP: create the deployment @ 05/11/25 13:22:34.187
  I0511 13:22:34.192891      26 warnings.go:110] "Warning: metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]"
  STEP: Wait for the Deployment to create new ReplicaSet @ 05/11/25 13:22:34.192
  STEP: delete the deployment @ 05/11/25 13:22:34.699
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 05/11/25 13:22:34.704
  STEP: Gathering metrics @ 05/11/25 13:22:35.217
  I0511 13:22:35.280068 26 garbage_collector.go:273] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0511 13:22:35.280186 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8944" for this suite. @ 05/11/25 13:22:35.282
• [1.117 seconds]
------------------------------
SS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 05/11/25 13:22:35.287
  I0511 13:22:35.287075 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename deployment @ 05/11/25 13:22:35.287
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:22:35.293
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:22:35.295
  I0511 13:22:35.302447 26 resource.go:81] Pod name rollover-pod: Found 0 pods out of 1
  I0511 13:22:40.310213 26 resource.go:81] Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/11/25 13:22:40.31
  I0511 13:22:40.310380 26 deployment.go:930] Waiting for pods owned by replica set "test-rollover-controller" to become ready
  I0511 13:22:42.314745 26 deployment.go:940] Creating deployment "test-rollover-deployment"
  I0511 13:22:42.324413 26 deployment.go:953] Make sure deployment "test-rollover-deployment" performs scaling operations
  I0511 13:22:44.329972 26 deployment.go:958] Check revision of new replica set for deployment "test-rollover-deployment"
  I0511 13:22:44.334771 26 deployment.go:962] Ensure that both replica sets have 1 created replica
  I0511 13:22:44.338818 26 deployment.go:971] Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  I0511 13:22:44.348630 26 deployment.go:314] Updating deployment test-rollover-deployment
  I0511 13:22:44.348689 26 deployment.go:980] Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  I0511 13:22:46.357316 26 deployment.go:985] Wait for revision update of deployment "test-rollover-deployment" to 2
  I0511 13:22:46.363131 26 deployment.go:989] Make sure deployment "test-rollover-deployment" is complete
  I0511 13:22:46.367708 26 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0511 13:22:46.367767 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 22, 42, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 22, 42, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 22, 45, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 22, 42, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7fb4c746bc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:22:48.377721 26 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0511 13:22:48.377803 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 22, 42, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 22, 42, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 22, 45, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 22, 42, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7fb4c746bc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:22:50.376842 26 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0511 13:22:50.376913 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 22, 42, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 22, 42, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 22, 45, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 22, 42, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7fb4c746bc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:22:52.378174 26 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0511 13:22:52.378263 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 22, 42, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 22, 42, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 22, 45, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 22, 42, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7fb4c746bc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:22:54.377063 26 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0511 13:22:54.377141 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 22, 42, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 22, 42, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 22, 45, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 22, 42, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7fb4c746bc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0511 13:22:56.374249 26 deployment.go:95] 
  I0511 13:22:56.374300 26 deployment.go:993] Ensure that both old replica sets have no replicas
  I0511 13:22:56.380616 26 deployment.go:632] Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9497",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f92f838d-655b-47cf-b46b-49ad7191488d",
      ResourceVersion: (string) (len=4) "3777",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882566562,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566564,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566575,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566562,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566562,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566575,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566562,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-7fb4c746bc\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0511 13:22:56.383871 26 deployment.go:40] New ReplicaSet "test-rollover-deployment-7fb4c746bc" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-7fb4c746bc",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9497",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "08cbdbdb-f69c-4e7c-a37e-d22fffef6400",
      ResourceVersion: (string) (len=4) "3767",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882566564,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7fb4c746bc"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "f92f838d-655b-47cf-b46b-49ad7191488d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566564,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 66 39 32 66 38 33  38 64 2d 36 35 35 62 2d  |\"f92f838d-655b-|
              00000120  34 37 63 66 2d 62 34 36  62 2d 34 39 61 64 37 31  |47cf-b46b-49ad71|
              00000130  39 31 34 38 38 64 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |91488d\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566575,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "7fb4c746bc",
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7fb4c746bc"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0511 13:22:56.384851 26 deployment.go:45] All old ReplicaSets of Deployment "test-rollover-deployment":
  I0511 13:22:56.385112 26 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9497",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d6c7d02d-acd5-429e-8560-758f38f77cc6",
      ResourceVersion: (string) (len=4) "3776",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882566555,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "f92f838d-655b-47cf-b46b-49ad7191488d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566555,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566575,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  66 39 32 66 38 33 38 64  2d 36 35 35 62 2d 34 37  |f92f838d-655b-47|
              000000c0  63 66 2d 62 34 36 62 2d  34 39 61 64 37 31 39 31  |cf-b46b-49ad7191|
              000000d0  34 38 38 64 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |488d\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566575,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "pod": (string) (len=5) "httpd",
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0511 13:22:56.386299 26 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-6f6c9688c5",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9497",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "028f0bdf-8647-4f0c-9caa-4a45ad3a5c8d",
      ResourceVersion: (string) (len=4) "3741",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882566562,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6f6c9688c5"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "f92f838d-655b-47cf-b46b-49ad7191488d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566564,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 66 39 32 66 38 33  38 64 2d 36 35 35 62 2d  |\"f92f838d-655b-|
              00000120  34 37 63 66 2d 62 34 36  62 2d 34 39 61 64 37 31  |47cf-b46b-49ad71|
              00000130  39 31 34 38 38 64 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |91488d\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566564,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6f6c9688c5"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6f6c9688c5"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0511 13:22:56.389191 26 deployment.go:68] Pod "test-rollover-deployment-7fb4c746bc-95xh6" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-7fb4c746bc-95xh6",
      GenerateName: (string) (len=36) "test-rollover-deployment-7fb4c746bc-",
      Namespace: (string) (len=15) "deployment-9497",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "800a1779-d7b8-46dc-a539-41cb9dbc8d2c",
      ResourceVersion: (string) (len=4) "3755",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882566564,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7fb4c746bc"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-7fb4c746bc",
          UID: (types.UID) (len=36) "08cbdbdb-f69c-4e7c-a37e-d22fffef6400",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566564,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 38  63 62 64 62 64 62 2d 66  |d\":\"08cbdbdb-f|
              00000090  36 39 63 2d 34 65 37 63  2d 61 33 37 65 2d 64 32  |69c-4e7c-a37e-d2|
              000000a0  32 66 66 66 65 66 36 34  30 30 5c 22 7d 22 3a 7b  |2fffef6400\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566565,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 34  34 5c 22 7d 22 3a 7b 22  |.244.1.44\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2p9hc",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2p9hc",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566565,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566564,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566565,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566565,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882566564,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.3"
        }
      },
      PodIP: (string) (len=11) "10.244.1.44",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.1.44"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882566564,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63882566564,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
          ImageID: (string) (len=129) "docker-pullable://registry.k8s.io/e2e-test-images/agnhost@sha256:99c6b4bb4a1e1df3f0b3752168c89358794d02258ebebc26bf21c29399011a85",
          ContainerID: (string) (len=73) "docker://0a00a9f64bf138fcdc3bfe92323a2cf705f6ef245eceec53be14efb344af416c",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-2p9hc",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 13:22:56.390654 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9497" for this suite. @ 05/11/25 13:22:56.392
• [21.110 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:295
  STEP: Creating a kubernetes client @ 05/11/25 13:22:56.397
  I0511 13:22:56.397612 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename downward-api @ 05/11/25 13:22:56.398
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:22:56.404
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:22:56.406
  STEP: Creating a pod to test downward api env vars @ 05/11/25 13:22:56.407
  STEP: Saw pod success @ 05/11/25 13:23:00.425
  I0511 13:23:00.428368 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downward-api-bd6b82c3-034d-4e77-a71d-aa206a503fa0 container dapi-container: <nil>
  STEP: delete the pod @ 05/11/25 13:23:00.435
  I0511 13:23:00.452288 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7042" for this suite. @ 05/11/25 13:23:00.455
• [4.061 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:393
  STEP: Creating a kubernetes client @ 05/11/25 13:23:00.459
  I0511 13:23:00.459360 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/11/25 13:23:00.46
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:23:00.468
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:23:00.472
  STEP: set up a multi version CRD @ 05/11/25 13:23:00.474
  I0511 13:23:00.474664 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: rename a version @ 05/11/25 13:23:03.512
  STEP: check the new version name is served @ 05/11/25 13:23:03.525
  STEP: check the old version name is removed @ 05/11/25 13:23:04.177
  STEP: check the other version is not changed @ 05/11/25 13:23:04.794
  I0511 13:23:07.153859 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1515" for this suite. @ 05/11/25 13:23:07.158
• [6.704 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:1068
  STEP: Creating a kubernetes client @ 05/11/25 13:23:07.163
  I0511 13:23:07.163408 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename job @ 05/11/25 13:23:07.163
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:23:07.169
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:23:07.17
  STEP: Creating a job @ 05/11/25 13:23:07.171
  STEP: Ensure pods equal to parallelism count is attached to the job @ 05/11/25 13:23:07.174
  STEP: patching /status @ 05/11/25 13:23:09.182
  STEP: updating /status @ 05/11/25 13:23:09.193
  STEP: get /status @ 05/11/25 13:23:09.212
  I0511 13:23:09.214028 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1148" for this suite. @ 05/11/25 13:23:09.215
• [2.055 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] CSINodes CSI Conformance should run through the lifecycle of a csinode [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_node.go:54
  STEP: Creating a kubernetes client @ 05/11/25 13:23:09.218
  I0511 13:23:09.218487 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename csinodes @ 05/11/25 13:23:09.219
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:23:09.224
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:23:09.226
  STEP: Creating initial csiNode "e2e-csinode-l9dvw" @ 05/11/25 13:23:09.227
  STEP: Getting initial csiNode "e2e-csinode-l9dvw" @ 05/11/25 13:23:09.229
  STEP: Patching initial csiNode: "e2e-csinode-l9dvw" @ 05/11/25 13:23:09.231
  STEP: Listing csiNodes with LabelSelector "e2e-csinode-l9dvw=patched" @ 05/11/25 13:23:09.233
  STEP: Delete initial csiNode: "e2e-csinode-l9dvw" @ 05/11/25 13:23:09.234
  STEP: Confirm deletion of csiNode "e2e-csinode-l9dvw" @ 05/11/25 13:23:09.237
  STEP: Creating replacement csiNode "e2e-csinode-dltkm" @ 05/11/25 13:23:09.238
  STEP: Getting replacement csiNode "e2e-csinode-dltkm" @ 05/11/25 13:23:09.24
  STEP: Updating replacement csiNode "e2e-csinode-dltkm" @ 05/11/25 13:23:09.241
  STEP: DeleteCollection of CSINodes with "e2e-csinode-dltkm=updated" label @ 05/11/25 13:23:09.244
  STEP: Confirm deletion of replacement csiNode with LabelSelector "e2e-csinode-dltkm=updated" @ 05/11/25 13:23:09.249
  I0511 13:23:09.250524 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csinodes-8168" for this suite. @ 05/11/25 13:23:09.318
• [0.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2185
  STEP: Creating a kubernetes client @ 05/11/25 13:23:09.325
  I0511 13:23:09.325064 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename services @ 05/11/25 13:23:09.326
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:23:09.336
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:23:09.338
  STEP: creating service in namespace services-4955 @ 05/11/25 13:23:09.34
  STEP: creating service affinity-clusterip in namespace services-4955 @ 05/11/25 13:23:09.34
  I0511 13:23:09.363013 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  I0511 13:23:11.376974 26 resource.go:361] Creating new exec pod
  I0511 13:23:13.396186 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-4955 exec execpod-affinityltkr5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  I0511 13:23:13.492072 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip (10.100.97.15) 80 port [tcp/http] succeeded!\n"
  I0511 13:23:13.492124 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 13:23:13.492214 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-4955 exec execpod-affinityltkr5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.97.15 80'
  I0511 13:23:13.593724 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.100.97.15 80\nConnection to 10.100.97.15 80 port [tcp/http] succeeded!\n"
  I0511 13:23:13.593819 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 13:23:13.593993 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-4955 exec execpod-affinityltkr5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://10.100.97.15:80/ ; done'
  I0511 13:23:13.743536 26 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.100.97.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.100.97.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.100.97.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.100.97.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.100.97.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.100.97.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.100.97.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.100.97.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.100.97.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.100.97.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.100.97.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.100.97.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.100.97.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.100.97.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.100.97.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.100.97.15:80/\n"
  I0511 13:23:13.743579 26 builder.go:147] stdout: "\naffinity-clusterip-6dd57cf8dc-wsvzh\naffinity-clusterip-6dd57cf8dc-wsvzh\naffinity-clusterip-6dd57cf8dc-wsvzh\naffinity-clusterip-6dd57cf8dc-wsvzh\naffinity-clusterip-6dd57cf8dc-wsvzh\naffinity-clusterip-6dd57cf8dc-wsvzh\naffinity-clusterip-6dd57cf8dc-wsvzh\naffinity-clusterip-6dd57cf8dc-wsvzh\naffinity-clusterip-6dd57cf8dc-wsvzh\naffinity-clusterip-6dd57cf8dc-wsvzh\naffinity-clusterip-6dd57cf8dc-wsvzh\naffinity-clusterip-6dd57cf8dc-wsvzh\naffinity-clusterip-6dd57cf8dc-wsvzh\naffinity-clusterip-6dd57cf8dc-wsvzh\naffinity-clusterip-6dd57cf8dc-wsvzh\naffinity-clusterip-6dd57cf8dc-wsvzh"
  I0511 13:23:13.743594 26 service.go:238] Received response from host: affinity-clusterip-6dd57cf8dc-wsvzh
  I0511 13:23:13.743604 26 service.go:238] Received response from host: affinity-clusterip-6dd57cf8dc-wsvzh
  I0511 13:23:13.743612 26 service.go:238] Received response from host: affinity-clusterip-6dd57cf8dc-wsvzh
  I0511 13:23:13.743619 26 service.go:238] Received response from host: affinity-clusterip-6dd57cf8dc-wsvzh
  I0511 13:23:13.743629 26 service.go:238] Received response from host: affinity-clusterip-6dd57cf8dc-wsvzh
  I0511 13:23:13.743636 26 service.go:238] Received response from host: affinity-clusterip-6dd57cf8dc-wsvzh
  I0511 13:23:13.743643 26 service.go:238] Received response from host: affinity-clusterip-6dd57cf8dc-wsvzh
  I0511 13:23:13.743651 26 service.go:238] Received response from host: affinity-clusterip-6dd57cf8dc-wsvzh
  I0511 13:23:13.743659 26 service.go:238] Received response from host: affinity-clusterip-6dd57cf8dc-wsvzh
  I0511 13:23:13.743667 26 service.go:238] Received response from host: affinity-clusterip-6dd57cf8dc-wsvzh
  I0511 13:23:13.743673 26 service.go:238] Received response from host: affinity-clusterip-6dd57cf8dc-wsvzh
  I0511 13:23:13.743680 26 service.go:238] Received response from host: affinity-clusterip-6dd57cf8dc-wsvzh
  I0511 13:23:13.743686 26 service.go:238] Received response from host: affinity-clusterip-6dd57cf8dc-wsvzh
  I0511 13:23:13.743693 26 service.go:238] Received response from host: affinity-clusterip-6dd57cf8dc-wsvzh
  I0511 13:23:13.743699 26 service.go:238] Received response from host: affinity-clusterip-6dd57cf8dc-wsvzh
  I0511 13:23:13.743706 26 service.go:238] Received response from host: affinity-clusterip-6dd57cf8dc-wsvzh
  I0511 13:23:13.743765 26 service.go:4352] Cleaning up the exec pod
  I0511 13:23:13.776180 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4955" for this suite. @ 05/11/25 13:23:13.781
• [4.463 seconds]
------------------------------
S
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 05/11/25 13:23:13.789
  I0511 13:23:13.789108 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename secrets @ 05/11/25 13:23:13.789
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:23:13.798
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:23:13.801
  STEP: Creating secret with name secret-test-map-98d804e9-c548-4764-8af4-767a74a49104 @ 05/11/25 13:23:13.803
  STEP: Creating a pod to test consume secrets @ 05/11/25 13:23:13.806
  STEP: Saw pod success @ 05/11/25 13:23:15.82
  I0511 13:23:15.824873 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-secrets-f379cb85-46b0-4eeb-a9a1-2690020684b4 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/11/25 13:23:15.837
  I0511 13:23:15.851612 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2624" for this suite. @ 05/11/25 13:23:15.857
• [2.075 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:236
  STEP: Creating a kubernetes client @ 05/11/25 13:23:15.864
  I0511 13:23:15.864786 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 13:23:15.866
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:23:15.875
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:23:15.877
  STEP: Creating a pod to test downward API volume plugin @ 05/11/25 13:23:15.879
  STEP: Saw pod success @ 05/11/25 13:23:17.896
  I0511 13:23:17.898754 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-0c7d3f0c-70fa-4c06-bc2b-e2233e6a4949 container client-container: <nil>
  STEP: delete the pod @ 05/11/25 13:23:17.905
  I0511 13:23:17.923079 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-573" for this suite. @ 05/11/25 13:23:17.926
• [2.067 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:96
  STEP: Creating a kubernetes client @ 05/11/25 13:23:17.931
  I0511 13:23:17.931920 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename replication-controller @ 05/11/25 13:23:17.932
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:23:17.942
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:23:17.945
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 05/11/25 13:23:17.947
  STEP: When a replication controller with a matching selector is created @ 05/11/25 13:23:19.964
  STEP: Then the orphan pod is adopted @ 05/11/25 13:23:19.97
  I0511 13:23:20.978319 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-1663" for this suite. @ 05/11/25 13:23:20.981
• [3.054 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:135
  STEP: Creating a kubernetes client @ 05/11/25 13:23:20.986
  I0511 13:23:20.986307 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubelet-test @ 05/11/25 13:23:20.987
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:23:20.995
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:23:20.999
  I0511 13:23:21.038270 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-3142" for this suite. @ 05/11/25 13:23:21.081
• [0.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:151
  STEP: Creating a kubernetes client @ 05/11/25 13:23:21.086
  I0511 13:23:21.086122 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename aggregateddiscovery @ 05/11/25 13:23:21.086
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:23:21.095
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:23:21.098
  I0511 13:23:21.104340 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-862" for this suite. @ 05/11/25 13:23:21.181
• [0.100 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:400
  STEP: Creating a kubernetes client @ 05/11/25 13:23:21.186
  I0511 13:23:21.186921 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 13:23:21.188
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:23:21.198
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:23:21.203
  STEP: Setting up server cert @ 05/11/25 13:23:21.217
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 13:23:21.581
  STEP: Deploying the webhook pod @ 05/11/25 13:23:21.584
  STEP: Wait for the deployment to be ready @ 05/11/25 13:23:21.592
  I0511 13:23:21.596005 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/11/25 13:23:23.605
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 13:23:23.621
  I0511 13:23:24.621724 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 05/11/25 13:23:24.626
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/11/25 13:23:24.642
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 05/11/25 13:23:24.65
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/11/25 13:23:24.657
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 05/11/25 13:23:24.667
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/11/25 13:23:24.674
  I0511 13:23:24.709970 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7501" for this suite. @ 05/11/25 13:23:24.712
  STEP: Destroying namespace "webhook-markers-9187" for this suite. @ 05/11/25 13:23:24.717
• [3.536 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:111
  STEP: Creating a kubernetes client @ 05/11/25 13:23:24.722
  I0511 13:23:24.722945 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename disruption @ 05/11/25 13:23:24.723
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:23:24.731
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:23:24.732
  STEP: creating the pdb @ 05/11/25 13:23:24.734
  STEP: Waiting for the pdb to be processed @ 05/11/25 13:23:24.737
  STEP: updating the pdb @ 05/11/25 13:23:26.742
  STEP: Waiting for the pdb to be processed @ 05/11/25 13:23:26.751
  STEP: patching the pdb @ 05/11/25 13:23:28.757
  STEP: Waiting for the pdb to be processed @ 05/11/25 13:23:28.769
  STEP: Waiting for the pdb to be deleted @ 05/11/25 13:23:30.78
  I0511 13:23:30.783934 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-1579" for this suite. @ 05/11/25 13:23:30.787
• [6.069 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet_etc_hosts.go:65
  STEP: Creating a kubernetes client @ 05/11/25 13:23:30.791
  I0511 13:23:30.791729 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 05/11/25 13:23:30.792
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:23:30.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:23:30.806
  STEP: Setting up the test @ 05/11/25 13:23:30.81
  STEP: Creating hostNetwork=false pod @ 05/11/25 13:23:30.81
  STEP: Creating hostNetwork=true pod @ 05/11/25 13:23:32.831
  STEP: Running the test @ 05/11/25 13:23:34.849
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 05/11/25 13:23:34.849
  I0511 13:23:34.849433 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3172 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 13:23:34.849454 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 13:23:34.849525 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3172/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&stderr=true&stdout=true)
  I0511 13:23:34.909595 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 13:23:34.909645 26 exec_util.go:112] Exec stderr: ""
  I0511 13:23:34.909685 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3172 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 13:23:34.909701 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 13:23:34.909779 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3172/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&stderr=true&stdout=true)
  I0511 13:23:34.961805 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 13:23:34.961854 26 exec_util.go:112] Exec stderr: ""
  I0511 13:23:34.961883 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3172 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 13:23:34.961895 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 13:23:34.961967 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3172/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&stderr=true&stdout=true)
  I0511 13:23:35.022788 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 13:23:35.022842 26 exec_util.go:112] Exec stderr: ""
  I0511 13:23:35.022874 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3172 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 13:23:35.022890 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 13:23:35.022969 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3172/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&stderr=true&stdout=true)
  I0511 13:23:35.089478 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 13:23:35.089540 26 exec_util.go:112] Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 05/11/25 13:23:35.089
  I0511 13:23:35.089616 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3172 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 13:23:35.089633 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 13:23:35.089725 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3172/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&stderr=true&stdout=true)
  I0511 13:23:35.162714 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 13:23:35.162761 26 exec_util.go:112] Exec stderr: ""
  I0511 13:23:35.162785 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3172 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 13:23:35.162797 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 13:23:35.162863 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3172/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&stderr=true&stdout=true)
  I0511 13:23:35.220426 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 13:23:35.220485 26 exec_util.go:112] Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 05/11/25 13:23:35.22
  I0511 13:23:35.220542 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3172 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 13:23:35.220558 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 13:23:35.220621 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3172/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&stderr=true&stdout=true)
  I0511 13:23:35.269691 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 13:23:35.269743 26 exec_util.go:112] Exec stderr: ""
  I0511 13:23:35.269772 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3172 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 13:23:35.269788 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 13:23:35.269871 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3172/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&stderr=true&stdout=true)
  I0511 13:23:35.327024 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 13:23:35.327058 26 exec_util.go:112] Exec stderr: ""
  I0511 13:23:35.327079 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3172 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 13:23:35.327088 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 13:23:35.327144 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3172/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&stderr=true&stdout=true)
  I0511 13:23:35.389423 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 13:23:35.389499 26 exec_util.go:112] Exec stderr: ""
  I0511 13:23:35.389531 26 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3172 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 13:23:35.389547 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 13:23:35.389638 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3172/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&stderr=true&stdout=true)
  I0511 13:23:35.458426 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 13:23:35.458498 26 exec_util.go:112] Exec stderr: ""
  I0511 13:23:35.458717 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-3172" for this suite. @ 05/11/25 13:23:35.462
• [4.678 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 05/11/25 13:23:35.469
  I0511 13:23:35.469667 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 05/11/25 13:23:35.47
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:23:35.479
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:23:35.482
  STEP: creating a target pod @ 05/11/25 13:23:35.485
  STEP: adding an ephemeral container @ 05/11/25 13:23:45.529
  STEP: verifying the pod's generation is 2 @ 05/11/25 13:23:47.551
  STEP: checking pod container endpoints @ 05/11/25 13:23:47.554
  I0511 13:23:47.554053 26 exec_util.go:63] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-5921 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 13:23:47.554077 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 13:23:47.554132 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-5921/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&stderr=true&stdout=true)
  I0511 13:23:47.617663 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 13:23:47.617722 26 exec_util.go:112] Exec stderr: ""
  I0511 13:23:47.625578 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-5921" for this suite. @ 05/11/25 13:23:47.629
• [12.166 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:218
  STEP: Creating a kubernetes client @ 05/11/25 13:23:47.636
  I0511 13:23:47.636027 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 13:23:47.636
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:23:47.65
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:23:47.654
  STEP: Setting up server cert @ 05/11/25 13:23:47.667
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 13:23:48.216
  STEP: Deploying the webhook pod @ 05/11/25 13:23:48.219
  STEP: Wait for the deployment to be ready @ 05/11/25 13:23:48.226
  I0511 13:23:48.230121 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/11/25 13:23:50.238
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 13:23:50.254
  I0511 13:23:51.254539 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0511 13:23:51.259542 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 05/11/25 13:23:51.769
  STEP: Creating a custom resource that should be denied by the webhook @ 05/11/25 13:23:51.786
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 05/11/25 13:23:53.807
  STEP: Updating the custom resource with disallowed data should be denied @ 05/11/25 13:23:53.815
  STEP: Deleting the custom resource should be denied @ 05/11/25 13:23:53.822
  STEP: Remove the offending key and value from the custom resource data @ 05/11/25 13:23:53.827
  STEP: Deleting the updated custom resource should be successful @ 05/11/25 13:23:53.834
  I0511 13:23:54.384703 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1442" for this suite. @ 05/11/25 13:23:54.387
  STEP: Destroying namespace "webhook-markers-7704" for this suite. @ 05/11/25 13:23:54.392
• [6.761 seconds]
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:470
  STEP: Creating a kubernetes client @ 05/11/25 13:23:54.396
  I0511 13:23:54.397018 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename sched-preemption @ 05/11/25 13:23:54.397
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:23:54.406
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:23:54.409
  I0511 13:23:54.422259 26 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  I0511 13:24:54.428390 26 util.go:390] Waiting for terminating namespaces to be deleted...
  STEP: Select a node to run the lower and higher priority pods @ 05/11/25 13:24:54.431
  STEP: Adding a custom resource @ 05/11/25 13:24:54.431
  STEP: Create a low priority pod that consumes 1/1 of node resources @ 05/11/25 13:24:54.44
  I0511 13:24:54.451149 26 preemption.go:504] Created pod: victim-pod
  STEP: Wait for the victim pod to be scheduled @ 05/11/25 13:24:54.451
  STEP: Create a high priority pod to trigger preemption of the lower priority pod @ 05/11/25 13:24:56.459
  I0511 13:24:56.467318 26 preemption.go:522] Created pod: preemptor-pod
  STEP: Waiting for the victim pod to be terminating @ 05/11/25 13:24:56.467
  STEP: Verifying the pod has the pod disruption condition @ 05/11/25 13:24:58.48
  I0511 13:24:58.482789 26 pod_client.go:383] Removing pod's "victim-pod" finalizer: "example.com/test-finalizer"
  I0511 13:24:58.997853 26 pod_client.go:173] Successfully updated pod "victim-pod"
  STEP: Removing a custom resource @ 05/11/25 13:24:59.013
  STEP: Removing a custom resource @ 05/11/25 13:24:59.025
  I0511 13:24:59.033520 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-4426" for this suite. @ 05/11/25 13:24:59.036
• [64.644 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:116
  STEP: Creating a kubernetes client @ 05/11/25 13:24:59.041
  I0511 13:24:59.041326 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 13:24:59.042
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:24:59.051
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:24:59.054
  STEP: Setting up server cert @ 05/11/25 13:24:59.07
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 13:24:59.425
  STEP: Deploying the webhook pod @ 05/11/25 13:24:59.428
  STEP: Wait for the deployment to be ready @ 05/11/25 13:24:59.435
  I0511 13:24:59.438760 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/11/25 13:25:01.448
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 13:25:01.464
  I0511 13:25:02.465813 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 05/11/25 13:25:02.472
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 05/11/25 13:25:02.473
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 05/11/25 13:25:02.473
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 05/11/25 13:25:02.473
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 05/11/25 13:25:02.474
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 05/11/25 13:25:02.474
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 05/11/25 13:25:02.475
  I0511 13:25:02.511716 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5053" for this suite. @ 05/11/25 13:25:02.513
  STEP: Destroying namespace "webhook-markers-7287" for this suite. @ 05/11/25 13:25:02.518
• [3.483 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:238
  STEP: Creating a kubernetes client @ 05/11/25 13:25:02.524
  I0511 13:25:02.524026 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/11/25 13:25:02.525
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:25:02.532
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:25:02.534
  I0511 13:25:02.536817 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 05/11/25 13:25:03.682
  I0511 13:25:03.682751 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-7887 --namespace=crd-publish-openapi-7887 create -f -'
  I0511 13:25:05.737848 26 builder.go:146] stderr: ""
  I0511 13:25:05.737902 26 builder.go:147] stdout: "e2e-test-crd-publish-openapi-261-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0511 13:25:05.737959 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-7887 --namespace=crd-publish-openapi-7887 delete e2e-test-crd-publish-openapi-261-crds test-cr'
  I0511 13:25:05.781963 26 builder.go:146] stderr: ""
  I0511 13:25:05.781990 26 builder.go:147] stdout: "e2e-test-crd-publish-openapi-261-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  I0511 13:25:05.782014 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-7887 --namespace=crd-publish-openapi-7887 apply -f -'
  I0511 13:25:05.822620 26 builder.go:146] stderr: ""
  I0511 13:25:05.822648 26 builder.go:147] stdout: "e2e-test-crd-publish-openapi-261-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0511 13:25:05.822675 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-7887 --namespace=crd-publish-openapi-7887 delete e2e-test-crd-publish-openapi-261-crds test-cr'
  I0511 13:25:05.865275 26 builder.go:146] stderr: ""
  I0511 13:25:05.865312 26 builder.go:147] stdout: "e2e-test-crd-publish-openapi-261-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 05/11/25 13:25:05.865
  I0511 13:25:05.865379 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-7887 explain e2e-test-crd-publish-openapi-261-crds'
  I0511 13:25:05.901743 26 builder.go:146] stderr: ""
  I0511 13:25:05.901798 26 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-261-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  I0511 13:25:07.057100 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7887" for this suite. @ 05/11/25 13:25:07.062
• [4.545 seconds]
------------------------------
S
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 05/11/25 13:25:07.068
  I0511 13:25:07.068745 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename secrets @ 05/11/25 13:25:07.069
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:25:07.077
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:25:07.079
  STEP: Creating secret with name s-test-opt-del-3815155e-874c-4b27-8e29-d490b08d2347 @ 05/11/25 13:25:07.163
  STEP: Creating secret with name s-test-opt-upd-3a48c83d-9aa8-432f-ae8f-79ec3ec17b52 @ 05/11/25 13:25:07.168
  STEP: Creating the pod @ 05/11/25 13:25:07.174
  STEP: Deleting secret s-test-opt-del-3815155e-874c-4b27-8e29-d490b08d2347 @ 05/11/25 13:25:09.222
  STEP: Updating secret s-test-opt-upd-3a48c83d-9aa8-432f-ae8f-79ec3ec17b52 @ 05/11/25 13:25:09.228
  STEP: Creating secret with name s-test-opt-create-71f879b3-22fe-43f8-b530-432d5b967a78 @ 05/11/25 13:25:09.232
  STEP: waiting to observe update in volume @ 05/11/25 13:25:09.235
  I0511 13:25:13.273037 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2581" for this suite. @ 05/11/25 13:25:13.275
• [6.213 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:189
  STEP: Creating a kubernetes client @ 05/11/25 13:25:13.281
  I0511 13:25:13.281725 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename emptydir @ 05/11/25 13:25:13.282
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:25:13.293
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:25:13.296
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 05/11/25 13:25:13.299
  STEP: Saw pod success @ 05/11/25 13:25:17.321
  I0511 13:25:17.324787 26 output.go:207] Trying to get logs from node k8sconformance pod pod-0e3fa554-aa7c-4bb7-b2f5-8d1466958b5f container test-container: <nil>
  STEP: delete the pod @ 05/11/25 13:25:17.331
  I0511 13:25:17.348081 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8917" for this suite. @ 05/11/25 13:25:17.351
• [4.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1861
  STEP: Creating a kubernetes client @ 05/11/25 13:25:17.358
  I0511 13:25:17.358393 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubectl @ 05/11/25 13:25:17.359
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:25:17.367
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:25:17.37
  STEP: Starting the proxy @ 05/11/25 13:25:17.372
  I0511 13:25:17.372483 26 util.go:541] Asynchronously running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-2989 proxy --unix-socket=/tmp/kubectl-proxy-unix1033332056/test'
  STEP: retrieving proxy /api/ output @ 05/11/25 13:25:17.405
  I0511 13:25:17.406386 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2989" for this suite. @ 05/11/25 13:25:17.451
• [0.100 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:168
  STEP: Creating a kubernetes client @ 05/11/25 13:25:17.458
  I0511 13:25:17.458552 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename cronjob @ 05/11/25 13:25:17.459
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:25:17.467
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:25:17.47
  STEP: Creating a ReplaceConcurrent cronjob @ 05/11/25 13:25:17.473
  STEP: Ensuring a job is scheduled @ 05/11/25 13:25:17.479
  STEP: Ensuring exactly one is scheduled @ 05/11/25 13:26:01.485
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 05/11/25 13:26:01.487
  STEP: Ensuring the job is replaced with a new one @ 05/11/25 13:26:01.489
  STEP: Removing cronjob @ 05/11/25 13:27:01.494
  I0511 13:27:01.499301 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-5700" for this suite. @ 05/11/25 13:27:01.502
• [104.049 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:175
  STEP: Creating a kubernetes client @ 05/11/25 13:27:01.507
  I0511 13:27:01.507609 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename configmap @ 05/11/25 13:27:01.508
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:27:01.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:27:01.52
  STEP: Creating configMap with name configmap-test-upd-bb3c1c41-c9c1-44b8-8526-0108aac0fb06 @ 05/11/25 13:27:01.604
  STEP: Creating the pod @ 05/11/25 13:27:01.61
  STEP: Waiting for pod with text data @ 05/11/25 13:27:03.625
  STEP: Waiting for pod with binary data @ 05/11/25 13:27:03.641
  I0511 13:27:03.647424 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3374" for this suite. @ 05/11/25 13:27:03.649
• [2.148 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:620
  STEP: Creating a kubernetes client @ 05/11/25 13:27:03.656
  I0511 13:27:03.656262 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename field-validation @ 05/11/25 13:27:03.657
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:27:03.665
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:27:03.668
  I0511 13:27:03.670972 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  I0511 13:27:06.212247      26 warnings.go:110] "Warning: unknown field \"alpha\""
  I0511 13:27:06.212279      26 warnings.go:110] "Warning: unknown field \"beta\""
  I0511 13:27:06.212290      26 warnings.go:110] "Warning: unknown field \"delta\""
  I0511 13:27:06.212302      26 warnings.go:110] "Warning: unknown field \"epsilon\""
  I0511 13:27:06.212313      26 warnings.go:110] "Warning: unknown field \"gamma\""
  I0511 13:27:06.746015 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5550" for this suite. @ 05/11/25 13:27:06.748
• [3.098 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1394
  STEP: Creating a kubernetes client @ 05/11/25 13:27:06.754
  I0511 13:27:06.754196 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubectl @ 05/11/25 13:27:06.755
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:27:06.765
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:27:06.768
  I0511 13:27:06.771748 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-379 create -f -'
  I0511 13:27:06.849572 26 builder.go:146] stderr: ""
  I0511 13:27:06.849605 26 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  I0511 13:27:06.849650 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-379 create -f -'
  I0511 13:27:06.938772 26 builder.go:146] stderr: ""
  I0511 13:27:06.938814 26 builder.go:147] stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 05/11/25 13:27:06.938
  I0511 13:27:07.942412 26 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0511 13:27:07.942472 26 framework.go:733] Found 1 / 1
  I0511 13:27:07.942511 26 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0511 13:27:07.945254 26 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0511 13:27:07.945286 26 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0511 13:27:07.945320 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-379 describe pod agnhost-primary-tflks'
  I0511 13:27:07.994505 26 builder.go:146] stderr: ""
  I0511 13:27:07.994606 26 builder.go:147] stdout: "Name:             agnhost-primary-tflks\nNamespace:        kubectl-379\nPriority:         0\nService Account:  default\nNode:             k8sconformance-m02/192.168.49.3\nStart Time:       Sun, 11 May 2025 13:27:06 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.244.1.62\nIPs:\n  IP:           10.244.1.62\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   docker://2ae992ff3c54c6bad4e421bc8e023364af5d644dbf2e5f13e36c98f3bf755833\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.53\n    Image ID:       docker-pullable://registry.k8s.io/e2e-test-images/agnhost@sha256:99c6b4bb4a1e1df3f0b3752168c89358794d02258ebebc26bf21c29399011a85\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sun, 11 May 2025 13:27:07 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-cw89p (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-cw89p:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    Optional:                false\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-379/agnhost-primary-tflks to k8sconformance-m02\n  Normal  Pulled     0s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.53\" already present on machine\n  Normal  Created    0s    kubelet            Created container: agnhost-primary\n  Normal  Started    0s    kubelet            Started container agnhost-primary\n"
  I0511 13:27:07.994690 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-379 describe rc agnhost-primary'
  I0511 13:27:08.036452 26 builder.go:146] stderr: ""
  I0511 13:27:08.036518 26 builder.go:147] stdout: "Name:         agnhost-primary\nNamespace:    kubectl-379\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:         registry.k8s.io/e2e-test-images/agnhost:2.53\n    Port:          6379/TCP\n    Host Port:     0/TCP\n    Environment:   <none>\n    Mounts:        <none>\n  Volumes:         <none>\n  Node-Selectors:  <none>\n  Tolerations:     <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-tflks\n"
  I0511 13:27:08.036558 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-379 describe service agnhost-primary'
  I0511 13:27:08.076800 26 builder.go:146] stderr: ""
  I0511 13:27:08.076847 26 builder.go:147] stdout: "Name:                     agnhost-primary\nNamespace:                kubectl-379\nLabels:                   app=agnhost\n                          role=primary\nAnnotations:              <none>\nSelector:                 app=agnhost,role=primary\nType:                     ClusterIP\nIP Family Policy:         SingleStack\nIP Families:              IPv4\nIP:                       10.104.34.153\nIPs:                      10.104.34.153\nPort:                     <unset>  6379/TCP\nTargetPort:               agnhost-server/TCP\nEndpoints:                10.244.1.62:6379\nSession Affinity:         None\nInternal Traffic Policy:  Cluster\nEvents:                   <none>\n"
  I0511 13:27:08.078638 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-379 describe node k8sconformance'
  I0511 13:27:08.126715 26 builder.go:146] stderr: ""
  I0511 13:27:08.126822 26 builder.go:147] stdout: "Name:               k8sconformance\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=k8sconformance\n                    kubernetes.io/os=linux\n                    minikube.k8s.io/commit=8575beea95e830054fe9a36513b8b24cb1ff7010\n                    minikube.k8s.io/name=k8sconformance\n                    minikube.k8s.io/primary=true\n                    minikube.k8s.io/updated_at=2025_05_11T09_00_03_0700\n                    minikube.k8s.io/version=v1.35.0\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sun, 11 May 2025 12:59:59 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  k8sconformance\n  AcquireTime:     <unset>\n  RenewTime:       Sun, 11 May 2025 13:27:05 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Sun, 11 May 2025 13:24:12 +0000   Sun, 11 May 2025 12:59:59 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sun, 11 May 2025 13:24:12 +0000   Sun, 11 May 2025 12:59:59 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sun, 11 May 2025 13:24:12 +0000   Sun, 11 May 2025 12:59:59 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sun, 11 May 2025 13:24:12 +0000   Sun, 11 May 2025 13:00:00 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.49.2\n  Hostname:    k8sconformance\nCapacity:\n  cpu:                12\n  ephemeral-storage:  954434220Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             31955748Ki\n  pods:               110\nAllocatable:\n  cpu:                12\n  ephemeral-storage:  954434220Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             31955748Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 377b5b8ee4ba4112b9e0bc9331922aaa\n  System UUID:                e799047b-aac0-4c81-a61b-f70af01252d7\n  Boot ID:                    62684619-bcf0-48f9-b962-153bf81fe38c\n  Kernel Version:             6.11.0-25-generic\n  OS Image:                   Ubuntu 22.04.5 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://28.1.1\n  Kubelet Version:            v1.33.0\n  Kube-Proxy Version:         \nPodCIDR:                      10.244.0.0/24\nPodCIDRs:                     10.244.0.0/24\nNon-terminated Pods:          (9 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 coredns-674b8bbfcf-68gnm                                   100m (0%)     0 (0%)      70Mi (0%)        170Mi (0%)     27m\n  kube-system                 etcd-k8sconformance                                        100m (0%)     0 (0%)      100Mi (0%)       0 (0%)         27m\n  kube-system                 kindnet-cs969                                              100m (0%)     100m (0%)   50Mi (0%)        50Mi (0%)      27m\n  kube-system                 kube-apiserver-k8sconformance                              250m (2%)     0 (0%)      0 (0%)           0 (0%)         27m\n  kube-system                 kube-controller-manager-k8sconformance                     200m (1%)     0 (0%)      0 (0%)           0 (0%)         27m\n  kube-system                 kube-proxy-ssjxm                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         27m\n  kube-system                 kube-scheduler-k8sconformance                              100m (0%)     0 (0%)      0 (0%)           0 (0%)         27m\n  kube-system                 storage-provisioner                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         27m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-3b1a685ddb394b60-rggfh    0 (0%)        0 (0%)      0 (0%)           0 (0%)         24m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                850m (7%)   100m (0%)\n  memory             220Mi (0%)  220Mi (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age                From             Message\n  ----    ------                   ----               ----             -------\n  Normal  Starting                 26m                kube-proxy       \n  Normal  Starting                 27m                kubelet          Starting kubelet.\n  Normal  NodeHasSufficientMemory  27m (x8 over 27m)  kubelet          Node k8sconformance status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    27m (x8 over 27m)  kubelet          Node k8sconformance status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     27m (x7 over 27m)  kubelet          Node k8sconformance status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  27m                kubelet          Updated Node Allocatable limit across pods\n  Normal  Starting                 27m                kubelet          Starting kubelet.\n  Normal  NodeAllocatableEnforced  27m                kubelet          Updated Node Allocatable limit across pods\n  Normal  NodeHasSufficientMemory  27m                kubelet          Node k8sconformance status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    27m                kubelet          Node k8sconformance status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     27m                kubelet          Node k8sconformance status is now: NodeHasSufficientPID\n  Normal  RegisteredNode           27m                node-controller  Node k8sconformance event: Registered Node k8sconformance in Controller\n"
  I0511 13:27:08.126885 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-379 describe namespace kubectl-379'
  I0511 13:27:08.167222 26 builder.go:146] stderr: ""
  I0511 13:27:08.167271 26 builder.go:147] stdout: "Name:         kubectl-379\nLabels:       e2e-framework=kubectl\n              e2e-run=01c2fc39-d9fb-41d9-b9dd-699f93ee27a7\n              kubernetes.io/metadata.name=kubectl-379\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  I0511 13:27:08.167370 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-379" for this suite. @ 05/11/25 13:27:08.168
• [1.419 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1070
  STEP: Creating a kubernetes client @ 05/11/25 13:27:08.173
  I0511 13:27:08.173599 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename resourcequota @ 05/11/25 13:27:08.174
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:27:08.178
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:27:08.18
  STEP: Creating resourceQuota "e2e-rq-status-v9pgm" @ 05/11/25 13:27:08.264
  I0511 13:27:08.273033 26 resource_quota.go:1106] Resource quota "e2e-rq-status-v9pgm" reports spec: hard cpu limit of 500m
  I0511 13:27:08.273090 26 resource_quota.go:1108] Resource quota "e2e-rq-status-v9pgm" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-v9pgm" /status @ 05/11/25 13:27:08.273
  STEP: Confirm /status for "e2e-rq-status-v9pgm" resourceQuota via watch @ 05/11/25 13:27:08.28
  I0511 13:27:08.281851 26 resource_quota.go:1135] observed resourceQuota "e2e-rq-status-v9pgm" in namespace "resourcequota-5821" with hard status: v1.ResourceList(nil)
  I0511 13:27:08.281963 26 resource_quota.go:1138] Found resourceQuota "e2e-rq-status-v9pgm" in namespace "resourcequota-5821" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0511 13:27:08.281991 26 resource_quota.go:1145] ResourceQuota "e2e-rq-status-v9pgm" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 05/11/25 13:27:08.284
  I0511 13:27:08.289506 26 resource_quota.go:1156] Resource quota "e2e-rq-status-v9pgm" reports spec: hard cpu limit of 1
  I0511 13:27:08.289550 26 resource_quota.go:1157] Resource quota "e2e-rq-status-v9pgm" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-v9pgm" /status @ 05/11/25 13:27:08.289
  STEP: Confirm /status for "e2e-rq-status-v9pgm" resourceQuota via watch @ 05/11/25 13:27:08.295
  I0511 13:27:08.297315 26 resource_quota.go:1179] observed resourceQuota "e2e-rq-status-v9pgm" in namespace "resourcequota-5821" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0511 13:27:08.297366 26 resource_quota.go:1182] Found resourceQuota "e2e-rq-status-v9pgm" in namespace "resourcequota-5821" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  I0511 13:27:08.297387 26 resource_quota.go:1189] ResourceQuota "e2e-rq-status-v9pgm" /status was patched
  STEP: Get "e2e-rq-status-v9pgm" /status @ 05/11/25 13:27:08.297
  I0511 13:27:08.299123 26 resource_quota.go:1200] Resourcequota "e2e-rq-status-v9pgm" reports status: hard cpu of 1
  I0511 13:27:08.299156 26 resource_quota.go:1202] Resourcequota "e2e-rq-status-v9pgm" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-v9pgm" /status before checking Spec is unchanged @ 05/11/25 13:27:08.3
  I0511 13:27:08.304207 26 resource_quota.go:1222] Resourcequota "e2e-rq-status-v9pgm" reports status: hard cpu of 2
  I0511 13:27:08.304261 26 resource_quota.go:1224] Resourcequota "e2e-rq-status-v9pgm" reports status: hard memory of 2Gi
  I0511 13:27:08.305582 26 resource_quota.go:1236] Found resourceQuota "e2e-rq-status-v9pgm" in namespace "resourcequota-5821" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  I0511 13:27:08.307727 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baea98), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baeac8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baeaf8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:27:13.309881 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661b440), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661b470), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661b4a0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:27:18.313023 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baec00), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baec30), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baec60), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:27:23.310878 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661b5a8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661b5d8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661b608), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:27:28.311631 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baed50), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baed98), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baedc8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:27:33.312884 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6e7f8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6e828), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6e858), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:27:38.311608 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6e918), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6e948), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6e978), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:27:43.312318 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6ea38), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6ea68), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6ea98), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:27:48.314043 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6eb58), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6eb88), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6ebb8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:27:53.313750 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baef18), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baef48), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baef78), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:27:58.312423 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baf038), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baf068), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baf098), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:28:03.310178 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661b7b8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661b7e8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661b818), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:28:08.311211 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661b8f0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661b920), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661b950), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:28:13.312197 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661ba58), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661ba88), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661bad0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:28:18.313604 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661bb90), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661bbc0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661bbf0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:28:23.310989 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baf1d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baf200), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baf230), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:28:28.313305 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baf2f0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baf320), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baf350), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:28:33.312961 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baf410), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baf440), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baf470), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:28:38.311810 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baf530), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baf560), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004baf590), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:28:43.314159 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6ed68), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6ed98), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6edc8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:28:48.313984 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6ee88), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6eeb8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6eee8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:28:53.312400 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661bd58), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661bd88), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661bdb8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:28:58.315509 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661bea8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661bed8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00661bf08), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:29:03.313259 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004636048), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004636090), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046360c0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:29:08.311351 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004bae090), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004bae0c0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004bae0f0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:29:13.312728 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d36048), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d36078), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d360c0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:29:18.312838 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004bae228), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004bae258), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004bae288), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:29:23.314473 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004bae348), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004bae378), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004bae3a8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:29:28.313317 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6e0f0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6e120), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6e150), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:29:33.313204 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004bae510), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004bae540), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004bae570), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:29:38.313491 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004bae630), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004bae660), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004bae690), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:29:43.314377 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d36228), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d36270), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d362b8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:29:48.313808 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d363a8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d363d8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d36408), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:29:53.311380 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d364e0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d36510), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d36540), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:29:58.312705 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6e2b8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6e2e8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004c6e318), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:30:03.313400 26 resource_quota.go:1267] ResourceQuota "e2e-rq-status-v9pgm" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v9pgm", GenerateName:"", Namespace:"resourcequota-5821", SelfLink:"", UID:"2c6cc0dd-d9e6-4656-8739-848146485fed", ResourceVersion:"4947", Generation:0, CreationTimestamp:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v9pgm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004bae7f8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004bae828), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.May, 11, 13, 27, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004bae858), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0511 13:30:08.313962 26 resource_quota.go:1264] ResourceQuota "e2e-rq-status-v9pgm" Spec was unchanged and /status reset
  I0511 13:30:08.314191 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5821" for this suite. @ 05/11/25 13:30:08.317
• [180.155 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:119
  STEP: Creating a kubernetes client @ 05/11/25 13:30:08.328
  I0511 13:30:08.328809 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename emptydir @ 05/11/25 13:30:08.329
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:30:08.341
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:30:08.344
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 05/11/25 13:30:08.348
  STEP: Saw pod success @ 05/11/25 13:30:12.37
  I0511 13:30:12.373583 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-a869d680-6138-4f1c-8016-db2c267739eb container test-container: <nil>
  STEP: delete the pod @ 05/11/25 13:30:12.39
  I0511 13:30:12.406517 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4657" for this suite. @ 05/11/25 13:30:12.41
• [4.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:246
  STEP: Creating a kubernetes client @ 05/11/25 13:30:12.415
  I0511 13:30:12.415829 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename namespaces @ 05/11/25 13:30:12.416
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:30:12.427
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:30:12.43
  STEP: Creating a test namespace @ 05/11/25 13:30:12.433
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:30:12.44
  STEP: Creating a pod in the namespace @ 05/11/25 13:30:12.443
  STEP: Waiting for the pod to have running status @ 05/11/25 13:30:12.449
  STEP: Deleting the namespace @ 05/11/25 13:30:14.457
  STEP: Waiting for the namespace to be removed. @ 05/11/25 13:30:14.463
  STEP: Recreating the namespace @ 05/11/25 13:30:25.469
  STEP: Verifying there are no pods in the namespace @ 05/11/25 13:30:25.481
  I0511 13:30:25.484208 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-3163" for this suite. @ 05/11/25 13:30:25.487
  STEP: Destroying namespace "nsdeletetest-829" for this suite. @ 05/11/25 13:30:25.492
  I0511 13:30:25.494716 26 framework.go:370] Namespace nsdeletetest-829 was already deleted
  STEP: Destroying namespace "nsdeletetest-3619" for this suite. @ 05/11/25 13:30:25.494
• [13.084 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 05/11/25 13:30:25.499
  I0511 13:30:25.499953 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename discovery @ 05/11/25 13:30:25.501
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:30:25.509
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:30:25.512
  STEP: Setting up server cert @ 05/11/25 13:30:25.515
  I0511 13:30:25.890207 26 discovery.go:139] Checking APIGroup: apiregistration.k8s.io
  I0511 13:30:25.890816 26 discovery.go:147] PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  I0511 13:30:25.890834 26 discovery.go:148] Versions found [{apiregistration.k8s.io/v1 v1}]
  I0511 13:30:25.890840 26 discovery.go:154] apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  I0511 13:30:25.890845 26 discovery.go:139] Checking APIGroup: apps
  I0511 13:30:25.891473 26 discovery.go:147] PreferredVersion.GroupVersion: apps/v1
  I0511 13:30:25.891486 26 discovery.go:148] Versions found [{apps/v1 v1}]
  I0511 13:30:25.891492 26 discovery.go:154] apps/v1 matches apps/v1
  I0511 13:30:25.891496 26 discovery.go:139] Checking APIGroup: events.k8s.io
  I0511 13:30:25.891990 26 discovery.go:147] PreferredVersion.GroupVersion: events.k8s.io/v1
  I0511 13:30:25.892005 26 discovery.go:148] Versions found [{events.k8s.io/v1 v1}]
  I0511 13:30:25.892012 26 discovery.go:154] events.k8s.io/v1 matches events.k8s.io/v1
  I0511 13:30:25.892017 26 discovery.go:139] Checking APIGroup: authentication.k8s.io
  I0511 13:30:25.892447 26 discovery.go:147] PreferredVersion.GroupVersion: authentication.k8s.io/v1
  I0511 13:30:25.892468 26 discovery.go:148] Versions found [{authentication.k8s.io/v1 v1}]
  I0511 13:30:25.892474 26 discovery.go:154] authentication.k8s.io/v1 matches authentication.k8s.io/v1
  I0511 13:30:25.892480 26 discovery.go:139] Checking APIGroup: authorization.k8s.io
  I0511 13:30:25.892944 26 discovery.go:147] PreferredVersion.GroupVersion: authorization.k8s.io/v1
  I0511 13:30:25.892958 26 discovery.go:148] Versions found [{authorization.k8s.io/v1 v1}]
  I0511 13:30:25.892964 26 discovery.go:154] authorization.k8s.io/v1 matches authorization.k8s.io/v1
  I0511 13:30:25.892969 26 discovery.go:139] Checking APIGroup: autoscaling
  I0511 13:30:25.893395 26 discovery.go:147] PreferredVersion.GroupVersion: autoscaling/v2
  I0511 13:30:25.893412 26 discovery.go:148] Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  I0511 13:30:25.893418 26 discovery.go:154] autoscaling/v2 matches autoscaling/v2
  I0511 13:30:25.893423 26 discovery.go:139] Checking APIGroup: batch
  I0511 13:30:25.893868 26 discovery.go:147] PreferredVersion.GroupVersion: batch/v1
  I0511 13:30:25.893882 26 discovery.go:148] Versions found [{batch/v1 v1}]
  I0511 13:30:25.893888 26 discovery.go:154] batch/v1 matches batch/v1
  I0511 13:30:25.893893 26 discovery.go:139] Checking APIGroup: certificates.k8s.io
  I0511 13:30:25.894296 26 discovery.go:147] PreferredVersion.GroupVersion: certificates.k8s.io/v1
  I0511 13:30:25.894309 26 discovery.go:148] Versions found [{certificates.k8s.io/v1 v1}]
  I0511 13:30:25.894314 26 discovery.go:154] certificates.k8s.io/v1 matches certificates.k8s.io/v1
  I0511 13:30:25.894319 26 discovery.go:139] Checking APIGroup: networking.k8s.io
  I0511 13:30:25.894770 26 discovery.go:147] PreferredVersion.GroupVersion: networking.k8s.io/v1
  I0511 13:30:25.894786 26 discovery.go:148] Versions found [{networking.k8s.io/v1 v1}]
  I0511 13:30:25.894792 26 discovery.go:154] networking.k8s.io/v1 matches networking.k8s.io/v1
  I0511 13:30:25.894797 26 discovery.go:139] Checking APIGroup: policy
  I0511 13:30:25.895217 26 discovery.go:147] PreferredVersion.GroupVersion: policy/v1
  I0511 13:30:25.895231 26 discovery.go:148] Versions found [{policy/v1 v1}]
  I0511 13:30:25.895236 26 discovery.go:154] policy/v1 matches policy/v1
  I0511 13:30:25.895241 26 discovery.go:139] Checking APIGroup: rbac.authorization.k8s.io
  I0511 13:30:25.895703 26 discovery.go:147] PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  I0511 13:30:25.895718 26 discovery.go:148] Versions found [{rbac.authorization.k8s.io/v1 v1}]
  I0511 13:30:25.895724 26 discovery.go:154] rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  I0511 13:30:25.895729 26 discovery.go:139] Checking APIGroup: storage.k8s.io
  I0511 13:30:25.896155 26 discovery.go:147] PreferredVersion.GroupVersion: storage.k8s.io/v1
  I0511 13:30:25.896168 26 discovery.go:148] Versions found [{storage.k8s.io/v1 v1}]
  I0511 13:30:25.896174 26 discovery.go:154] storage.k8s.io/v1 matches storage.k8s.io/v1
  I0511 13:30:25.896178 26 discovery.go:139] Checking APIGroup: admissionregistration.k8s.io
  I0511 13:30:25.896598 26 discovery.go:147] PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  I0511 13:30:25.896613 26 discovery.go:148] Versions found [{admissionregistration.k8s.io/v1 v1}]
  I0511 13:30:25.896621 26 discovery.go:154] admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  I0511 13:30:25.896627 26 discovery.go:139] Checking APIGroup: apiextensions.k8s.io
  I0511 13:30:25.897041 26 discovery.go:147] PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  I0511 13:30:25.897056 26 discovery.go:148] Versions found [{apiextensions.k8s.io/v1 v1}]
  I0511 13:30:25.897061 26 discovery.go:154] apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  I0511 13:30:25.897066 26 discovery.go:139] Checking APIGroup: scheduling.k8s.io
  I0511 13:30:25.897503 26 discovery.go:147] PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  I0511 13:30:25.897520 26 discovery.go:148] Versions found [{scheduling.k8s.io/v1 v1}]
  I0511 13:30:25.897526 26 discovery.go:154] scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  I0511 13:30:25.897532 26 discovery.go:139] Checking APIGroup: coordination.k8s.io
  I0511 13:30:25.897947 26 discovery.go:147] PreferredVersion.GroupVersion: coordination.k8s.io/v1
  I0511 13:30:25.897960 26 discovery.go:148] Versions found [{coordination.k8s.io/v1 v1}]
  I0511 13:30:25.897966 26 discovery.go:154] coordination.k8s.io/v1 matches coordination.k8s.io/v1
  I0511 13:30:25.897971 26 discovery.go:139] Checking APIGroup: node.k8s.io
  I0511 13:30:25.898382 26 discovery.go:147] PreferredVersion.GroupVersion: node.k8s.io/v1
  I0511 13:30:25.898395 26 discovery.go:148] Versions found [{node.k8s.io/v1 v1}]
  I0511 13:30:25.898401 26 discovery.go:154] node.k8s.io/v1 matches node.k8s.io/v1
  I0511 13:30:25.898406 26 discovery.go:139] Checking APIGroup: discovery.k8s.io
  I0511 13:30:25.898846 26 discovery.go:147] PreferredVersion.GroupVersion: discovery.k8s.io/v1
  I0511 13:30:25.898867 26 discovery.go:148] Versions found [{discovery.k8s.io/v1 v1}]
  I0511 13:30:25.898873 26 discovery.go:154] discovery.k8s.io/v1 matches discovery.k8s.io/v1
  I0511 13:30:25.898878 26 discovery.go:139] Checking APIGroup: flowcontrol.apiserver.k8s.io
  I0511 13:30:25.899533 26 discovery.go:147] PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  I0511 13:30:25.899551 26 discovery.go:148] Versions found [{flowcontrol.apiserver.k8s.io/v1 v1}]
  I0511 13:30:25.899558 26 discovery.go:154] flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  I0511 13:30:25.899628 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-623" for this suite. @ 05/11/25 13:30:25.901
• [0.405 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 05/11/25 13:30:25.905
  I0511 13:30:25.905848 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename podtemplate @ 05/11/25 13:30:25.906
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:30:25.912
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:30:25.913
  I0511 13:30:25.931214 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-4668" for this suite. @ 05/11/25 13:30:26.004
• [0.104 seconds]
------------------------------
S
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:116
  STEP: Creating a kubernetes client @ 05/11/25 13:30:26.009
  I0511 13:30:26.010017 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename var-expansion @ 05/11/25 13:30:26.011
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:30:26.02
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:30:26.024
  STEP: Creating a pod to test substitution in volume subpath @ 05/11/25 13:30:26.028
  STEP: Saw pod success @ 05/11/25 13:30:30.053
  I0511 13:30:30.056647 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod var-expansion-2ecac805-0466-4b6d-8f0b-1cb26ca5413e container dapi-container: <nil>
  STEP: delete the pod @ 05/11/25 13:30:30.063
  I0511 13:30:30.080734 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6149" for this suite. @ 05/11/25 13:30:30.084
• [4.079 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:69
  STEP: Creating a kubernetes client @ 05/11/25 13:30:30.089
  I0511 13:30:30.089494 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename emptydir-wrapper @ 05/11/25 13:30:30.09
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:30:30.101
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:30:30.104
  STEP: Cleaning up the secret @ 05/11/25 13:30:32.133
  STEP: Cleaning up the configmap @ 05/11/25 13:30:32.138
  STEP: Cleaning up the pod @ 05/11/25 13:30:32.145
  I0511 13:30:32.166574 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-4797" for this suite. @ 05/11/25 13:30:32.17
• [2.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:284
  STEP: Creating a kubernetes client @ 05/11/25 13:30:32.174
  I0511 13:30:32.174320 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename taint-single-pod @ 05/11/25 13:30:32.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:30:32.18
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:30:32.182
  I0511 13:30:32.184403 26 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  I0511 13:31:32.185914 26 util.go:390] Waiting for terminating namespaces to be deleted...
  I0511 13:31:32.190032 26 taints.go:144] Starting informer...
  STEP: Starting pod... @ 05/11/25 13:31:32.19
  I0511 13:31:32.403653 26 taints.go:294] Pod is running on k8sconformance-m02. Tainting Node
  STEP: Trying to apply a taint on the Node @ 05/11/25 13:31:32.403
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/11/25 13:31:32.415
  STEP: Waiting short time to make sure Pod is queued for deletion @ 05/11/25 13:31:32.42
  I0511 13:31:32.420206 26 taints.go:313] Pod wasn't evicted. Proceeding
  I0511 13:31:32.420222 26 taints.go:320] Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/11/25 13:31:32.429
  STEP: Waiting some time to make sure that toleration time passed. @ 05/11/25 13:31:32.437
  I0511 13:32:47.439830 26 taints.go:329] Pod wasn't evicted. Test successful
  I0511 13:32:47.440185 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-39" for this suite. @ 05/11/25 13:32:47.445
• [135.280 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:769
  STEP: Creating a kubernetes client @ 05/11/25 13:32:47.454
  I0511 13:32:47.454621 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename statefulset @ 05/11/25 13:32:47.455
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:32:47.469
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:32:47.473
  STEP: Creating service test in namespace statefulset-7127 @ 05/11/25 13:32:47.476
  STEP: Creating stateful set ss in namespace statefulset-7127 @ 05/11/25 13:32:47.48
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7127 @ 05/11/25 13:32:47.486
  I0511 13:32:47.489121 26 wait.go:44] Found 0 stateful pods, waiting for 1
  I0511 13:32:57.492810 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 05/11/25 13:32:57.492
  I0511 13:32:57.495645 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=statefulset-7127 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0511 13:32:57.608851 26 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0511 13:32:57.608885 26 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0511 13:32:57.608896 26 rest.go:280] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0511 13:32:57.610855 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  I0511 13:33:07.615652 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0511 13:33:07.615716 26 wait.go:109] Waiting for statefulset status.readyReplicas updated to 0
  I0511 13:33:07.633788 26 resource.go:168] POD   NODE                PHASE    GRACE  CONDITIONS
  I0511 13:33:07.633956 26 resource.go:175] ss-0  k8sconformance-m02  Running         [{PodReadyToStartContainers 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:32:49 +0000 UTC  } {Initialized 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:32:47 +0000 UTC  } {Ready 0 False 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:32:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady 0 False 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:32:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:32:47 +0000 UTC  }]
  I0511 13:33:07.633998 26 resource.go:175] ss-1                      Pending         []
  I0511 13:33:07.634015 26 resource.go:178] 
  I0511 13:33:07.634031 26 statefulset.go:2448] StatefulSet ss has not reached scale 3, at 2
  I0511 13:33:08.639663 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 3 for another 8.992747204s
  I0511 13:33:09.645765 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 3 for another 7.987110144s
  I0511 13:33:10.652705 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 3 for another 6.980266766s
  I0511 13:33:11.659599 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 3 for another 5.973446817s
  I0511 13:33:12.666418 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 3 for another 4.966357401s
  I0511 13:33:13.670625 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 3 for another 3.959463986s
  I0511 13:33:14.676500 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 3 for another 2.956170457s
  I0511 13:33:15.681678 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 3 for another 1.950341089s
  I0511 13:33:16.686166 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 3 for another 945.160295ms
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7127 @ 05/11/25 13:33:17.686
  I0511 13:33:17.690822 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=statefulset-7127 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0511 13:33:17.778060 26 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0511 13:33:17.778111 26 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0511 13:33:17.778132 26 rest.go:280] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0511 13:33:17.778192 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=statefulset-7127 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0511 13:33:17.868693 26 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I0511 13:33:17.868750 26 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0511 13:33:17.868771 26 rest.go:280] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0511 13:33:17.868834 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=statefulset-7127 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0511 13:33:17.952562 26 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I0511 13:33:17.952618 26 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0511 13:33:17.952638 26 rest.go:280] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0511 13:33:17.955926 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
  I0511 13:33:27.960818 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0511 13:33:27.960866 26 wait.go:54] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0511 13:33:27.960881 26 wait.go:54] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 05/11/25 13:33:27.96
  I0511 13:33:27.963755 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=statefulset-7127 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0511 13:33:28.055606 26 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0511 13:33:28.055663 26 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0511 13:33:28.055684 26 rest.go:280] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0511 13:33:28.055749 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=statefulset-7127 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0511 13:33:28.156952 26 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0511 13:33:28.156996 26 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0511 13:33:28.157011 26 rest.go:280] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0511 13:33:28.157059 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=statefulset-7127 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0511 13:33:28.268618 26 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0511 13:33:28.268675 26 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0511 13:33:28.268696 26 rest.go:280] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0511 13:33:28.268714 26 wait.go:109] Waiting for statefulset status.readyReplicas updated to 0
  I0511 13:33:28.271836 26 wait.go:122] Waiting for statefulset status.readyReplicas to become 0, currently 1
  I0511 13:33:38.280356 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0511 13:33:38.280401 26 wait.go:54] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0511 13:33:38.280416 26 wait.go:54] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I0511 13:33:38.295456 26 resource.go:168] POD   NODE                PHASE    GRACE  CONDITIONS
  I0511 13:33:38.295588 26 resource.go:175] ss-0  k8sconformance-m02  Running         [{PodReadyToStartContainers 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:32:49 +0000 UTC  } {Initialized 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:32:47 +0000 UTC  } {Ready 0 False 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:33:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady 0 False 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:33:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:32:47 +0000 UTC  }]
  I0511 13:33:38.295640 26 resource.go:175] ss-1  k8sconformance      Running         [{PodReadyToStartContainers 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:33:09 +0000 UTC  } {Initialized 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:33:07 +0000 UTC  } {Ready 0 False 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:33:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady 0 False 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:33:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:33:07 +0000 UTC  }]
  I0511 13:33:38.295688 26 resource.go:175] ss-2  k8sconformance-m02  Running  30s    [{PodReadyToStartContainers 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:33:08 +0000 UTC  } {Initialized 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:33:07 +0000 UTC  } {Ready 0 False 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:33:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady 0 False 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:33:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:33:07 +0000 UTC  }]
  I0511 13:33:38.295707 26 resource.go:178] 
  I0511 13:33:38.295723 26 statefulset.go:2448] StatefulSet ss has not reached scale 0, at 3
  I0511 13:33:39.300414 26 resource.go:168] POD   NODE            PHASE      GRACE  CONDITIONS
  I0511 13:33:39.300508 26 resource.go:175] ss-1  k8sconformance  Succeeded  30s    [{PodReadyToStartContainers 0 False 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:33:38 +0000 UTC  } {Initialized 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:33:07 +0000 UTC PodCompleted } {Ready 0 False 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:33:28 +0000 UTC PodCompleted } {ContainersReady 0 False 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:33:28 +0000 UTC PodCompleted } {PodScheduled 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 13:33:07 +0000 UTC  }]
  I0511 13:33:39.300523 26 resource.go:178] 
  I0511 13:33:39.300534 26 statefulset.go:2448] StatefulSet ss has not reached scale 0, at 1
  I0511 13:33:40.305411 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 0 for another 7.988457633s
  I0511 13:33:41.310329 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 0 for another 6.983282033s
  I0511 13:33:42.314770 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 0 for another 5.978382148s
  I0511 13:33:43.321347 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 0 for another 4.973256302s
  I0511 13:33:44.326188 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 0 for another 3.967554019s
  I0511 13:33:45.331292 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 0 for another 2.961865012s
  I0511 13:33:46.335986 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 0 for another 1.957466367s
  I0511 13:33:47.340715 26 statefulset.go:2453] Verifying statefulset ss doesn't scale past 0 for another 952.823171ms
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7127 @ 05/11/25 13:33:48.341
  I0511 13:33:48.346866 26 rest.go:153] Scaling statefulset ss to 0
  I0511 13:33:48.352488 26 wait.go:159] Waiting for statefulset status.replicas updated to 0
  I0511 13:33:48.354776 26 statefulset.go:138] Deleting all statefulset in ns statefulset-7127
  I0511 13:33:48.357748 26 rest.go:153] Scaling statefulset ss to 0
  I0511 13:33:48.362076 26 wait.go:159] Waiting for statefulset status.replicas updated to 0
  I0511 13:33:48.364226 26 rest.go:91] Deleting statefulset ss
  I0511 13:33:48.376001 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7127" for this suite. @ 05/11/25 13:33:48.378
• [60.928 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:196
  STEP: Creating a kubernetes client @ 05/11/25 13:33:48.382
  I0511 13:33:48.382881 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 13:33:48.383
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:33:48.393
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:33:48.395
  STEP: Setting up server cert @ 05/11/25 13:33:48.408
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 13:33:48.565
  STEP: Deploying the webhook pod @ 05/11/25 13:33:48.568
  STEP: Wait for the deployment to be ready @ 05/11/25 13:33:48.574
  I0511 13:33:48.578661 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/11/25 13:33:50.587
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 13:33:50.603
  I0511 13:33:51.604064 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 05/11/25 13:33:51.609
  STEP: create a pod that should be denied by the webhook @ 05/11/25 13:33:51.625
  STEP: create a pod that causes the webhook to hang @ 05/11/25 13:33:51.638
  STEP: create a configmap that should be denied by the webhook @ 05/11/25 13:34:01.646
  STEP: create a configmap that should be admitted by the webhook @ 05/11/25 13:34:01.667
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 05/11/25 13:34:01.674
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 05/11/25 13:34:01.677
  STEP: create a namespace that bypass the webhook @ 05/11/25 13:34:01.68
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 05/11/25 13:34:01.686
  I0511 13:34:01.724833 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2298" for this suite. @ 05/11/25 13:34:01.73
  STEP: Destroying namespace "webhook-markers-2531" for this suite. @ 05/11/25 13:34:01.733
  STEP: Destroying namespace "exempted-namespace-8311" for this suite. @ 05/11/25 13:34:01.737
• [13.360 seconds]
------------------------------
SS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:77
  STEP: Creating a kubernetes client @ 05/11/25 13:34:01.743
  I0511 13:34:01.743665 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename var-expansion @ 05/11/25 13:34:01.744
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:34:01.759
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:34:01.762
  STEP: Creating a pod to test substitution in container's command @ 05/11/25 13:34:01.764
  STEP: Saw pod success @ 05/11/25 13:34:05.792
  I0511 13:34:05.795139 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod var-expansion-34b06517-f774-44b5-9779-a6fd122bd400 container dapi-container: <nil>
  STEP: delete the pod @ 05/11/25 13:34:05.808
  I0511 13:34:05.824340 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4827" for this suite. @ 05/11/25 13:34:05.828
• [4.090 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 05/11/25 13:34:05.833
  I0511 13:34:05.833301 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/11/25 13:34:05.834
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:34:05.843
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:34:05.846
  I0511 13:34:05.849618 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  I0511 13:34:06.868421 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9524" for this suite. @ 05/11/25 13:34:06.872
• [1.044 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 05/11/25 13:34:06.877
  I0511 13:34:06.877327 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename lease-test @ 05/11/25 13:34:06.878
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:34:06.885
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:34:06.888
  I0511 13:34:06.927695 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-2611" for this suite. @ 05/11/25 13:34:06.974
• [0.105 seconds]
------------------------------
S
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:423
  STEP: Creating a kubernetes client @ 05/11/25 13:34:06.982
  I0511 13:34:06.982113 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename configmap @ 05/11/25 13:34:06.983
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:34:06.991
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:34:06.994
  STEP: Creating configMap with name configmap-test-volume-274f4d6c-50f0-4996-8064-e259b99afc50 @ 05/11/25 13:34:06.997
  STEP: Creating a pod to test consume configMaps @ 05/11/25 13:34:07.002
  STEP: Saw pod success @ 05/11/25 13:34:09.018
  I0511 13:34:09.020986 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-5fd05b77-d89f-493f-b5b5-e42dbb6e86d2 container configmap-volume-test: <nil>
  STEP: delete the pod @ 05/11/25 13:34:09.028
  I0511 13:34:09.044507 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5624" for this suite. @ 05/11/25 13:34:09.048
• [2.071 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:222
  STEP: Creating a kubernetes client @ 05/11/25 13:34:09.053
  I0511 13:34:09.053811 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 13:34:09.054
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:34:09.063
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:34:09.066
  STEP: Creating a pod to test downward API volume plugin @ 05/11/25 13:34:09.069
  STEP: Saw pod success @ 05/11/25 13:34:11.082
  I0511 13:34:11.085390 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-58826fbf-4970-4944-8888-02eb4af70bea container client-container: <nil>
  STEP: delete the pod @ 05/11/25 13:34:11.091
  I0511 13:34:11.106236 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9653" for this suite. @ 05/11/25 13:34:11.109
• [2.062 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 05/11/25 13:34:11.115
  I0511 13:34:11.115849 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename secrets @ 05/11/25 13:34:11.117
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:34:11.125
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:34:11.128
  STEP: Creating secret with name secret-test-679b08c2-5e21-43c3-9e85-364d04088fea @ 05/11/25 13:34:11.132
  STEP: Creating a pod to test consume secrets @ 05/11/25 13:34:11.137
  STEP: Saw pod success @ 05/11/25 13:34:13.152
  I0511 13:34:13.154709 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-secrets-f0ff4cb4-8d6b-4591-b2e1-c06bdb5d3cc1 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/11/25 13:34:13.161
  I0511 13:34:13.176589 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8548" for this suite. @ 05/11/25 13:34:13.179
• [2.070 seconds]
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:47
  STEP: Creating a kubernetes client @ 05/11/25 13:34:13.186
  I0511 13:34:13.186142 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 13:34:13.187
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:34:13.195
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:34:13.198
  STEP: Creating configMap with name projected-configmap-test-volume-7ab215b8-df8f-45fa-8c53-cfdbe2bd871b @ 05/11/25 13:34:13.201
  STEP: Creating a pod to test consume configMaps @ 05/11/25 13:34:13.205
  STEP: Saw pod success @ 05/11/25 13:34:15.222
  I0511 13:34:15.224776 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-projected-configmaps-615f6d5a-aa77-4321-a61e-4b14c56aacbe container agnhost-container: <nil>
  STEP: delete the pod @ 05/11/25 13:34:15.231
  I0511 13:34:15.245650 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7495" for this suite. @ 05/11/25 13:34:15.249
• [2.068 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:814
  STEP: Creating a kubernetes client @ 05/11/25 13:34:15.254
  I0511 13:34:15.254509 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename services @ 05/11/25 13:34:15.255
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:34:15.266
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:34:15.269
  STEP: creating service multi-endpoint-test in namespace services-4557 @ 05/11/25 13:34:15.272
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4557 to expose endpoints map[] @ 05/11/25 13:34:15.287
  I0511 13:34:15.291677      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 13:34:15.291804 26 service.go:4613] Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
  I0511 13:34:16.296913      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 13:34:16.301950 26 service.go:4645] successfully validated that service multi-endpoint-test in namespace services-4557 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-4557 @ 05/11/25 13:34:16.302
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4557 to expose endpoints map[pod1:[100]] @ 05/11/25 13:34:18.318
  I0511 13:34:18.323966      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 13:34:18.328778 26 service.go:4645] successfully validated that service multi-endpoint-test in namespace services-4557 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-4557 @ 05/11/25 13:34:18.328
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4557 to expose endpoints map[pod1:[100] pod2:[101]] @ 05/11/25 13:34:20.343
  I0511 13:34:20.348591      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 13:34:20.351501 26 service.go:4645] successfully validated that service multi-endpoint-test in namespace services-4557 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 05/11/25 13:34:20.351
  I0511 13:34:20.351562 26 resource.go:361] Creating new exec pod
  I0511 13:34:22.366490 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-4557 exec execpod54klw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  I0511 13:34:22.451453 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test (10.99.137.59) 80 port [tcp/http] succeeded!\n"
  I0511 13:34:22.451512 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 13:34:22.451598 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-4557 exec execpod54klw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.99.137.59 80'
  I0511 13:34:22.544032 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.99.137.59 80\nConnection to 10.99.137.59 80 port [tcp/http] succeeded!\n"
  I0511 13:34:22.544085 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 13:34:22.544177 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-4557 exec execpod54klw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  I0511 13:34:22.652674 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test (10.99.137.59) 81 port [tcp/*] succeeded!\n"
  I0511 13:34:22.652734 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 13:34:22.652828 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-4557 exec execpod54klw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.99.137.59 81'
  I0511 13:34:22.746160 26 builder.go:146] stderr: "+ + ncecho -v -t hostName -w 2 10.99.137.59\n 81\nConnection to 10.99.137.59 81 port [tcp/*] succeeded!\n"
  I0511 13:34:22.746220 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-4557 @ 05/11/25 13:34:22.746
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4557 to expose endpoints map[pod2:[101]] @ 05/11/25 13:34:22.757
  I0511 13:34:22.767914      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 13:34:22.775254 26 service.go:4645] successfully validated that service multi-endpoint-test in namespace services-4557 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-4557 @ 05/11/25 13:34:22.775
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4557 to expose endpoints map[] @ 05/11/25 13:34:22.789
  I0511 13:34:22.791799      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 13:34:22.795325 26 service.go:4645] successfully validated that service multi-endpoint-test in namespace services-4557 exposes endpoints map[]
  I0511 13:34:22.810865 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4557" for this suite. @ 05/11/25 13:34:22.814
• [7.565 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:303
  STEP: Creating a kubernetes client @ 05/11/25 13:34:22.819
  I0511 13:34:22.819633 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename aggregateddiscovery @ 05/11/25 13:34:22.82
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:34:22.83
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:34:22.832
  I0511 13:34:22.833709 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  I0511 13:34:25.884514 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-9673" for this suite. @ 05/11/25 13:34:25.887
• [3.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1794
  STEP: Creating a kubernetes client @ 05/11/25 13:34:25.894
  I0511 13:34:25.894889 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubectl @ 05/11/25 13:34:25.896
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:34:25.906
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:34:25.909
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/11/25 13:34:25.912
  I0511 13:34:25.912966 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-8038 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I0511 13:34:25.960561 26 builder.go:146] stderr: ""
  I0511 13:34:25.960592 26 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 05/11/25 13:34:25.96
  STEP: verifying the pod e2e-test-httpd-pod was created @ 05/11/25 13:34:31.012
  I0511 13:34:31.012677 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-8038 get pod e2e-test-httpd-pod -o json'
  I0511 13:34:31.049942 26 builder.go:146] stderr: ""
  I0511 13:34:31.050048 26 builder.go:147] stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2025-05-11T13:34:25Z\",\n        \"generation\": 1,\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-8038\",\n        \"resourceVersion\": \"6104\",\n        \"uid\": \"24af83c4-6e9a-40ed-9957-3a33df5e183f\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-64b47\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"k8sconformance-m02\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-64b47\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2025-05-11T13:34:27Z\",\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2025-05-11T13:34:25Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2025-05-11T13:34:27Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2025-05-11T13:34:27Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2025-05-11T13:34:25Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://4d91c7f864a42f275094cec445e043d4c37e3d5bb438e864e2051393139846ce\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"resources\": {},\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2025-05-11T13:34:26Z\"\n                    }\n                },\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-64b47\",\n                        \"readOnly\": true,\n                        \"recursiveReadOnly\": \"Disabled\"\n                    }\n                ]\n            }\n        ],\n        \"hostIP\": \"192.168.49.3\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"192.168.49.3\"\n            }\n        ],\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.1.78\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.1.78\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2025-05-11T13:34:25Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 05/11/25 13:34:31.05
  I0511 13:34:31.050142 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-8038 replace -f -'
  I0511 13:34:31.119820 26 builder.go:146] stderr: ""
  I0511 13:34:31.119863 26 builder.go:147] stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.36.1-1 @ 05/11/25 13:34:31.119
  I0511 13:34:31.121809 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-8038 delete pods e2e-test-httpd-pod'
  I0511 13:34:33.159617 26 builder.go:146] stderr: ""
  I0511 13:34:33.159655 26 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0511 13:34:33.159754 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8038" for this suite. @ 05/11/25 13:34:33.162
• [7.272 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:838
  STEP: Creating a kubernetes client @ 05/11/25 13:34:33.166
  I0511 13:34:33.166796 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename svcaccounts @ 05/11/25 13:34:33.167
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:34:33.178
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:34:33.181
  STEP: Creating ServiceAccount "e2e-sa-kkqk8"  @ 05/11/25 13:34:33.182
  I0511 13:34:33.185947 26 service_accounts.go:853] AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-kkqk8"  @ 05/11/25 13:34:33.185
  I0511 13:34:33.191093 26 service_accounts.go:867] AutomountServiceAccountToken: true
  I0511 13:34:33.191201 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2951" for this suite. @ 05/11/25 13:34:33.264
• [0.105 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:250
  STEP: Creating a kubernetes client @ 05/11/25 13:34:33.272
  I0511 13:34:33.272549 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 13:34:33.273
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:34:33.282
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:34:33.286
  STEP: Creating a pod to test downward API volume plugin @ 05/11/25 13:34:33.288
  STEP: Saw pod success @ 05/11/25 13:34:35.304
  I0511 13:34:35.307604 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-2055570e-72db-4156-894b-6742aacb6248 container client-container: <nil>
  STEP: delete the pod @ 05/11/25 13:34:35.315
  I0511 13:34:35.328832 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2921" for this suite. @ 05/11/25 13:34:35.332
• [2.064 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:282
  STEP: Creating a kubernetes client @ 05/11/25 13:34:35.336
  I0511 13:34:35.336805 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 13:34:35.337
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:34:35.345
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:34:35.347
  STEP: Setting up server cert @ 05/11/25 13:34:35.364
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 13:34:35.656
  STEP: Deploying the webhook pod @ 05/11/25 13:34:35.659
  STEP: Wait for the deployment to be ready @ 05/11/25 13:34:35.665
  I0511 13:34:35.669772 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/11/25 13:34:37.679
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 13:34:37.697
  I0511 13:34:38.697601 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0511 13:34:38.702973 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3217-crds.webhook.example.com via the AdmissionRegistration API @ 05/11/25 13:34:39.215
  STEP: Creating a custom resource that should be mutated by the webhook @ 05/11/25 13:34:39.234
  I0511 13:34:41.815608 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2909" for this suite. @ 05/11/25 13:34:41.82
  STEP: Destroying namespace "webhook-markers-7024" for this suite. @ 05/11/25 13:34:41.829
• [6.499 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:62
  STEP: Creating a kubernetes client @ 05/11/25 13:34:41.835
  I0511 13:34:41.835822 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename containers @ 05/11/25 13:34:41.836
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:34:41.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:34:41.853
  STEP: Creating a pod to test override arguments @ 05/11/25 13:34:41.856
  STEP: Saw pod success @ 05/11/25 13:34:45.878
  I0511 13:34:45.881316 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod client-containers-5a985ce5-4228-485d-a819-a24befe4d424 container agnhost-container: <nil>
  STEP: delete the pod @ 05/11/25 13:34:45.888
  I0511 13:34:45.901587 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-3352" for this suite. @ 05/11/25 13:34:45.905
• [4.074 seconds]
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:194
  STEP: Creating a kubernetes client @ 05/11/25 13:34:45.91
  I0511 13:34:45.910187 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename downward-api @ 05/11/25 13:34:45.911
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:34:45.918
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:34:45.921
  STEP: Creating a pod to test downward api env vars @ 05/11/25 13:34:45.923
  STEP: Saw pod success @ 05/11/25 13:34:49.945
  I0511 13:34:49.948061 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downward-api-013277c6-b42c-4c21-8b9b-29b771173f9e container dapi-container: <nil>
  STEP: delete the pod @ 05/11/25 13:34:49.955
  I0511 13:34:49.972648 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6813" for this suite. @ 05/11/25 13:34:49.976
• [4.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 05/11/25 13:34:49.981
  I0511 13:34:49.981832 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename subpath @ 05/11/25 13:34:49.982
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:34:49.992
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:34:49.995
  STEP: Setting up data @ 05/11/25 13:34:49.998
  STEP: Creating pod pod-subpath-test-downwardapi-82dl @ 05/11/25 13:34:50.006
  STEP: Creating a pod to test atomic-volume-subpath @ 05/11/25 13:34:50.006
  STEP: Saw pod success @ 05/11/25 13:35:14.083
  I0511 13:35:14.085646 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-subpath-test-downwardapi-82dl container test-container-subpath-downwardapi-82dl: <nil>
  STEP: delete the pod @ 05/11/25 13:35:14.096
  STEP: Deleting pod pod-subpath-test-downwardapi-82dl @ 05/11/25 13:35:14.111
  I0511 13:35:14.112038 26 delete.go:62] Deleting pod "pod-subpath-test-downwardapi-82dl" in namespace "subpath-1639"
  I0511 13:35:14.114931 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1639" for this suite. @ 05/11/25 13:35:14.118
• [24.142 seconds]
------------------------------
SSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 05/11/25 13:35:14.123
  I0511 13:35:14.123827 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename container-probe @ 05/11/25 13:35:14.124
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:35:14.134
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:35:14.137
  STEP: Creating pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602 @ 05/11/25 13:35:14.139
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/11/25 13:35:16.154
  I0511 13:35:16.157032 26 container_probe.go:1748] Initial restart count of pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 is 0
  I0511 13:35:16.159120 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:18.165159 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:20.170924 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:22.176207 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:24.180174 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:26.186421 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:28.192505 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:30.198079 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:32.202619 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:34.209282 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:36.214865 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:38.219584 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:40.224067 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:42.230614 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:44.235573 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:46.240665 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:48.245982 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:50.250129 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:52.254989 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:54.261136 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:56.267496 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:35:58.272332 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:00.277268 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:02.283122 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:04.288369 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:06.294028 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:08.299871 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:10.304811 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:12.311168 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:14.317009 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:16.323290 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:18.327420 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:20.331543 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:22.337340 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:24.343369 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:26.348548 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:28.351688 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:30.356549 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:32.362174 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:34.367817 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:36.374010 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:38.380067 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:40.385262 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:42.391048 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:44.397118 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:46.400594 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:48.404572 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:50.410185 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:52.414579 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:54.419652 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:56.425384 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:36:58.431642 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:00.436303 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:02.441489 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:04.446928 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:06.452374 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:08.457841 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:10.462381 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:12.467116 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:14.473141 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:16.478995 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:18.484375 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:20.489050 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:22.493974 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:24.500178 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:26.504674 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:28.510205 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:30.514825 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:32.520039 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:34.525078 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:36.531054 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:38.536242 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:40.540861 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:42.545121 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:44.551641 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:46.556365 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:48.561106 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:50.566714 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:52.571049 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:54.575333 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:56.580109 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:37:58.584711 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:00.589028 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:02.594852 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:04.600986 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:06.608708 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:08.613805 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:10.618869 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:12.624743 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:14.629070 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:16.633275 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:18.637590 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:20.642433 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:22.648058 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:24.654289 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:26.660380 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:28.665389 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:30.669654 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:32.675827 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:34.681920 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:36.685817 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:38.689919 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:40.695767 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:42.701410 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:44.706809 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:46.712687 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:48.718768 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:50.723914 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:52.728330 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:54.733595 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:56.739891 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:38:58.746616 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:39:00.752579 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:39:02.758289 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:39:04.764946 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:39:06.770296 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:39:08.774986 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:39:10.779852 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:39:12.785139 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  I0511 13:39:14.789524 26 container_probe.go:1758] Get pod liveness-aca9e932-5a50-4cc0-87f7-9d418fe30a27 in namespace container-probe-3602
  STEP: deleting the pod @ 05/11/25 13:39:16.79
  I0511 13:39:16.808148 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-3602" for this suite. @ 05/11/25 13:39:16.815
• [242.697 seconds]
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:305
  STEP: Creating a kubernetes client @ 05/11/25 13:39:16.82
  I0511 13:39:16.820717 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename svcaccounts @ 05/11/25 13:39:16.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:39:16.83
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:39:16.834
  STEP: Creating a pod to test service account token:  @ 05/11/25 13:39:16.836
  STEP: Saw pod success @ 05/11/25 13:39:20.854
  I0511 13:39:20.857131 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod test-pod-b05260a3-b9b7-4f33-bcd0-ee0f8eda1db4 container agnhost-container: <nil>
  STEP: delete the pod @ 05/11/25 13:39:20.873
  I0511 13:39:20.886216 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-1460" for this suite. @ 05/11/25 13:39:20.889
• [4.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 05/11/25 13:39:20.894
  I0511 13:39:20.894748 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename sysctl @ 05/11/25 13:39:20.895
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:39:20.905
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:39:20.908
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 05/11/25 13:39:20.91
  STEP: Watching for error events or started pod @ 05/11/25 13:39:20.917
  STEP: Waiting for pod completion @ 05/11/25 13:39:22.922
  STEP: Checking that the pod succeeded @ 05/11/25 13:39:24.933
  STEP: Getting logs from the pod @ 05/11/25 13:39:24.933
  STEP: Checking that the sysctl is actually updated @ 05/11/25 13:39:24.938
  I0511 13:39:24.938419 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-7791" for this suite. @ 05/11/25 13:39:24.94
• [4.051 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1836
  STEP: Creating a kubernetes client @ 05/11/25 13:39:24.945
  I0511 13:39:24.945626 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubectl @ 05/11/25 13:39:24.946
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:39:24.953
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:39:24.954
  STEP: starting the proxy server @ 05/11/25 13:39:24.956
  I0511 13:39:24.956145 26 util.go:541] Asynchronously running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-7853 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 05/11/25 13:39:24.983
  I0511 13:39:24.988537 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  I0511 13:39:24.990055 26 kubectl.go:2227] kubectl proxy stdout: Starting to serve on 127.0.0.1:46861

  I0511 13:39:24.990059 26 kubectl.go:2232] kubectl proxy stderr: W0511 13:39:24.983035     678 proxy.go:177] Request filter disabled, your proxy is vulnerable to XSRF attacks, please be cautious

  STEP: Destroying namespace "kubectl-7853" for this suite. @ 05/11/25 13:39:25.043
• [0.103 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 05/11/25 13:39:25.048
  I0511 13:39:25.048939 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename pod-network-test @ 05/11/25 13:39:25.049
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:39:25.061
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:39:25.065
  STEP: Performing setup for networking test in namespace pod-network-test-2555 @ 05/11/25 13:39:25.068
  STEP: creating a selector @ 05/11/25 13:39:25.068
  STEP: Creating the service pods in kubernetes @ 05/11/25 13:39:25.068
  I0511 13:39:25.068373 26 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 05/11/25 13:39:39.21
  I0511 13:39:41.239117 26 utils.go:802] Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  I0511 13:39:41.239161 26 utils.go:495] Going to poll 10.244.0.16 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  I0511 13:39:41.241354 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.16:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2555 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 13:39:41.241383 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 13:39:41.241439 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/pod-network-test-2555/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.0.16%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&stderr=true&stdout=true)
  I0511 13:39:41.303724 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 13:39:41.303767 26 utils.go:512] Found all 1 expected endpoints: [netserver-0]
  I0511 13:39:41.303785 26 utils.go:495] Going to poll 10.244.1.87 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  I0511 13:39:41.306089 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.87:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2555 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 13:39:41.306112 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 13:39:41.306170 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/pod-network-test-2555/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.1.87%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&stderr=true&stdout=true)
  I0511 13:39:41.363084 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 13:39:41.363141 26 utils.go:512] Found all 1 expected endpoints: [netserver-1]
  I0511 13:39:41.363289 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-2555" for this suite. @ 05/11/25 13:39:41.366
• [16.324 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3714
  STEP: Creating a kubernetes client @ 05/11/25 13:39:41.373
  I0511 13:39:41.373370 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename services @ 05/11/25 13:39:41.374
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:39:41.384
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:39:41.387
  STEP: creating service multiprotocol-test in namespace services-3086 @ 05/11/25 13:39:41.389
  STEP: creating pod pod1 in namespace services-3086 @ 05/11/25 13:39:41.402
  STEP: Creating pod pod1 in namespace services-3086 @ 05/11/25 13:39:41.402
  STEP: waiting up to 3m0s for service multiprotocol-test in namespace services-3086 to expose endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]] @ 05/11/25 13:39:43.426
  I0511 13:39:43.432301      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 13:39:43.436204 26 service.go:4729] successfully validated that service multiprotocol-test in namespace services-3086 exposes endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 05/11/25 13:39:43.436
  I0511 13:39:43.436294 26 resource.go:361] Creating new exec pod
  I0511 13:39:45.451258 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-3086 exec execpodj5whp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.111.243.186 80'
  I0511 13:39:45.553729 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.111.243.186 80\nConnection to 10.111.243.186 80 port [tcp/http] succeeded!\n"
  I0511 13:39:45.553790 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 13:39:45.553896 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-3086 exec execpodj5whp -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.111.243.186 80'
  I0511 13:39:47.670220 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.111.243.186 80\n"
  I0511 13:39:47.670284 26 builder.go:147] stdout: "pod1"
  STEP: Checking if the Service forwards traffic to TCP only @ 05/11/25 13:39:47.67
  I0511 13:39:47.680892 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-3086 exec execpodj5whp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.111.243.186 80'
  I0511 13:39:47.772648 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.111.243.186 80\nConnection to 10.111.243.186 80 port [tcp/http] succeeded!\n"
  I0511 13:39:47.772712 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 13:39:47.772849 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-3086 exec execpodj5whp -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.111.243.186 80'
  I0511 13:39:49.865802 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.111.243.186 80\n"
  I0511 13:39:49.865868 26 builder.go:147] stdout: ""
  I0511 13:39:49.865949 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-3086 exec execpodj5whp -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.111.243.186 80'
  I0511 13:39:51.962552 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.111.243.186 80\n"
  I0511 13:39:51.962621 26 builder.go:147] stdout: ""
  I0511 13:39:51.962725 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-3086 exec execpodj5whp -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.111.243.186 80'
  I0511 13:39:54.060305 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.111.243.186 80\n"
  I0511 13:39:54.060347 26 builder.go:147] stdout: ""
  STEP: Checking if the Service forwards traffic to UDP only @ 05/11/25 13:39:54.06
  I0511 13:39:54.069215 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-3086 exec execpodj5whp -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.111.243.186 80'
  I0511 13:39:54.163551 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.111.243.186 80\n"
  I0511 13:39:54.163611 26 builder.go:147] stdout: ""
  I0511 13:39:56.069867 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-3086 exec execpodj5whp -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.111.243.186 80'
  I0511 13:39:58.181358 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.111.243.186 80\n"
  I0511 13:39:58.181416 26 builder.go:147] stdout: "pod1"
  I0511 13:39:58.181563 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-3086 exec execpodj5whp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.111.243.186 80'
  I0511 13:40:00.399172 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.111.243.186 80\nConnection to 10.111.243.186 80 port [tcp/http] succeeded!\n"
  I0511 13:40:00.399239 26 builder.go:147] stdout: ""
  I0511 13:40:00.399321 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-3086 exec execpodj5whp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.111.243.186 80'
  I0511 13:40:02.530604 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.111.243.186 80\nConnection to 10.111.243.186 80 port [tcp/http] succeeded!\n"
  I0511 13:40:02.530695 26 builder.go:147] stdout: ""
  I0511 13:40:02.530798 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-3086 exec execpodj5whp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.111.243.186 80'
  I0511 13:40:04.700730 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.111.243.186 80\nConnection to 10.111.243.186 80 port [tcp/http] succeeded!\n"
  I0511 13:40:04.700804 26 builder.go:147] stdout: ""
  I0511 13:40:04.701037 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3086" for this suite. @ 05/11/25 13:40:04.705
• [23.338 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:944
  STEP: Creating a kubernetes client @ 05/11/25 13:40:04.714
  I0511 13:40:04.714876 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename resourcequota @ 05/11/25 13:40:04.715
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:40:04.725
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:40:04.729
  STEP: Creating a ResourceQuota @ 05/11/25 13:40:04.731
  STEP: Getting a ResourceQuota @ 05/11/25 13:40:04.736
  STEP: Updating a ResourceQuota @ 05/11/25 13:40:04.738
  STEP: Verifying a ResourceQuota was modified @ 05/11/25 13:40:04.745
  STEP: Deleting a ResourceQuota @ 05/11/25 13:40:04.747
  STEP: Verifying the deleted ResourceQuota @ 05/11/25 13:40:04.752
  I0511 13:40:04.754601 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3262" for this suite. @ 05/11/25 13:40:04.807
• [0.098 seconds]
------------------------------
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:170
  STEP: Creating a kubernetes client @ 05/11/25 13:40:04.813
  I0511 13:40:04.813156 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/11/25 13:40:04.814
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:40:04.822
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:40:04.825
  STEP: create the container to handle the HTTPGet hook request. @ 05/11/25 13:40:04.908
  STEP: create the pod with lifecycle hook @ 05/11/25 13:40:06.93
  STEP: check poststart hook @ 05/11/25 13:40:08.945
  STEP: delete the pod with lifecycle hook @ 05/11/25 13:40:08.961
  I0511 13:40:10.978930 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-8399" for this suite. @ 05/11/25 13:40:10.982
• [6.175 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:229
  STEP: Creating a kubernetes client @ 05/11/25 13:40:10.988
  I0511 13:40:10.988153 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename var-expansion @ 05/11/25 13:40:10.989
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:40:11
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:40:11.003
  STEP: creating the pod with failed condition @ 05/11/25 13:40:11.006
  STEP: updating the pod @ 05/11/25 13:42:11.014
  I0511 13:42:11.529935 26 pod_client.go:173] Successfully updated pod "var-expansion-c26d48dd-db9c-4be0-8932-c9fa40fd4f04"
  STEP: waiting for pod running @ 05/11/25 13:42:11.53
  STEP: deleting the pod gracefully @ 05/11/25 13:42:13.538
  I0511 13:42:13.538433 26 delete.go:62] Deleting pod "var-expansion-c26d48dd-db9c-4be0-8932-c9fa40fd4f04" in namespace "var-expansion-8364"
  I0511 13:42:13.546813 26 delete.go:70] Wait up to 5m0s for pod "var-expansion-c26d48dd-db9c-4be0-8932-c9fa40fd4f04" to be fully deleted
  I0511 13:42:45.627962 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8364" for this suite. @ 05/11/25 13:42:45.631
• [154.653 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 05/11/25 13:42:45.641
  I0511 13:42:45.641569 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename endpointslice @ 05/11/25 13:42:45.642
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:42:45.651
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:42:45.655
  STEP: referencing a single matching pod @ 05/11/25 13:42:47.744
  I0511 13:42:47.751687      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: referencing matching pods with named port @ 05/11/25 13:42:47.751
  I0511 13:42:47.756551      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 05/11/25 13:42:47.756
  I0511 13:42:47.760715      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: recreating EndpointSlices after they've been deleted @ 05/11/25 13:42:47.76
  I0511 13:42:47.774429 26 endpointslice.go:938] EndpointSlice for Service endpointslice-9584/example-named-port not found
  I0511 13:42:49.781287      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 13:42:49.781534 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-9584" for this suite. @ 05/11/25 13:42:49.784
• [4.147 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 05/11/25 13:42:49.789
  I0511 13:42:49.789093 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename daemonsets @ 05/11/25 13:42:49.79
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:42:49.8
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:42:49.803
  STEP: Creating a simple DaemonSet "daemon-set" @ 05/11/25 13:42:49.892
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/11/25 13:42:49.897
  I0511 13:42:49.990388 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 13:42:49.990479 26 fixtures.go:131] Node k8sconformance is running 0 daemon pod, expected 1
  I0511 13:42:50.905689 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 13:42:50.905733 26 fixtures.go:131] Node k8sconformance is running 0 daemon pod, expected 1
  I0511 13:42:51.905228 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0511 13:42:51.905276 26 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 05/11/25 13:42:51.907
  I0511 13:42:51.925650 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0511 13:42:51.925715 26 fixtures.go:131] Node k8sconformance is running 0 daemon pod, expected 1
  I0511 13:42:52.927384 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0511 13:42:52.927432 26 fixtures.go:131] Node k8sconformance is running 0 daemon pod, expected 1
  I0511 13:42:53.926023 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0511 13:42:53.926066 26 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 05/11/25 13:42:53.926
  STEP: Deleting DaemonSet "daemon-set" @ 05/11/25 13:42:53.93
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-962, will wait for the garbage collector to delete the pods @ 05/11/25 13:42:53.93
  I0511 13:42:53.991240 26 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 8.47194ms
  I0511 13:42:54.091896 26 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.657604ms
  I0511 13:42:55.197738 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 13:42:55.197811 26 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0511 13:42:55.201347 26 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"7227"},"items":null}

  I0511 13:42:55.203239 26 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"7227"},"items":null}

  I0511 13:42:55.210228 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-962" for this suite. @ 05/11/25 13:42:55.212
• [5.428 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 05/11/25 13:42:55.218
  I0511 13:42:55.218252 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename deployment @ 05/11/25 13:42:55.219
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:42:55.229
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:42:55.232
  I0511 13:42:55.234822 26 deployment.go:1664] Creating simple deployment test-new-deployment
  I0511 13:42:55.246270 26 deployment.go:223] deployment "test-new-deployment" doesn't have the required revision set
  STEP: getting scale subresource @ 05/11/25 13:42:57.258
  STEP: updating a scale subresource @ 05/11/25 13:42:57.26
  STEP: verifying the deployment Spec.Replicas was modified @ 05/11/25 13:42:57.269
  STEP: Patch a scale subresource @ 05/11/25 13:42:57.272
  I0511 13:42:57.288242 26 deployment.go:632] Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5801",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cd663e1e-23ae-4976-8a42-b711843b277e",
      ResourceVersion: (string) (len=4) "7259",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882567775,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882567775,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882567775,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-685b768f58\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0511 13:42:57.293897 26 deployment.go:40] New ReplicaSet "test-new-deployment-685b768f58" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-685b768f58",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5801",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "745e5499-8292-444b-8285-21591330abec",
      ResourceVersion: (string) (len=4) "7266",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882567775,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "cd663e1e-23ae-4976-8a42-b711843b277e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 63 64 36 36 33 65  31 65 2d 32 33 61 65 2d  |\"cd663e1e-23ae-|
              00000120  34 39 37 36 2d 38 61 34  32 2d 62 37 31 31 38 34  |4976-8a42-b71184|
              00000130  33 62 32 37 37 65 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |3b277e\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0511 13:42:57.298034 26 deployment.go:68] Pod "test-new-deployment-685b768f58-dnbf2" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-685b768f58-dnbf2",
      GenerateName: (string) (len=31) "test-new-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-5801",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "05eaa3ca-bb80-4bba-b583-bc1fe09bbe10",
      ResourceVersion: (string) (len=4) "7254",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882567775,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-685b768f58",
          UID: (types.UID) (len=36) "745e5499-8292-444b-8285-21591330abec",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882567775,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 34  35 65 35 34 39 39 2d 38  |d\":\"745e5499-8|
              00000090  32 39 32 2d 34 34 34 62  2d 38 32 38 35 2d 32 31  |292-444b-8285-21|
              000000a0  35 39 31 33 33 30 61 62  65 63 5c 22 7d 22 3a 7b  |591330abec\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 39  35 5c 22 7d 22 3a 7b 22  |.244.1.95\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jg947",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jg947",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882567775,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882567775,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.3"
        }
      },
      PodIP: (string) (len=11) "10.244.1.95",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.1.95"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882567775,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63882567775,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://35f5c712e843f6e39d9c83543fd8e26befab3302a009399c5bac6bfcd443ff8d",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-jg947",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 13:42:57.299004 26 deployment.go:68] Pod "test-new-deployment-685b768f58-k8pdk" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-685b768f58-k8pdk",
      GenerateName: (string) (len=31) "test-new-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-5801",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a91a9043-690f-434f-9d37-081b0d32c755",
      ResourceVersion: (string) (len=4) "7263",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882567777,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-685b768f58",
          UID: (types.UID) (len=36) "745e5499-8292-444b-8285-21591330abec",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 34  35 65 35 34 39 39 2d 38  |d\":\"745e5499-8|
              00000090  32 39 32 2d 34 34 34 62  2d 38 32 38 35 2d 32 31  |292-444b-8285-21|
              000000a0  35 39 31 33 33 30 61 62  65 63 5c 22 7d 22 3a 7b  |591330abec\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vtdkj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vtdkj",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 13:42:57.299957 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5801" for this suite. @ 05/11/25 13:42:57.306
• [2.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:366
  STEP: Creating a kubernetes client @ 05/11/25 13:42:57.312
  I0511 13:42:57.312620 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename cronjob @ 05/11/25 13:42:57.314
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:42:57.325
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:42:57.327
  STEP: Creating a cronjob @ 05/11/25 13:42:57.329
  STEP: creating @ 05/11/25 13:42:57.329
  STEP: getting @ 05/11/25 13:42:57.332
  STEP: listing @ 05/11/25 13:42:57.333
  STEP: watching @ 05/11/25 13:42:57.334
  I0511 13:42:57.334504 26 cronjob.go:395] starting watch
  STEP: cluster-wide listing @ 05/11/25 13:42:57.335
  STEP: cluster-wide watching @ 05/11/25 13:42:57.336
  I0511 13:42:57.336161 26 cronjob.go:407] starting watch
  STEP: patching @ 05/11/25 13:42:57.336
  STEP: updating @ 05/11/25 13:42:57.339
  I0511 13:42:57.344732 26 cronjob.go:431] waiting for watch events with expected annotations
  I0511 13:42:57.344768 26 cronjob.go:445] saw patched and updated annotations
  STEP: patching /status @ 05/11/25 13:42:57.344
  STEP: updating /status @ 05/11/25 13:42:57.348
  STEP: get /status @ 05/11/25 13:42:57.351
  STEP: deleting @ 05/11/25 13:42:57.353
  STEP: deleting a collection @ 05/11/25 13:42:57.363
  I0511 13:42:57.370309 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-7618" for this suite. @ 05/11/25 13:42:57.411
• [0.105 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:264
  STEP: Creating a kubernetes client @ 05/11/25 13:42:57.418
  I0511 13:42:57.418276 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename dns @ 05/11/25 13:42:57.419
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:42:57.43
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:42:57.433
  STEP: Creating a test headless service @ 05/11/25 13:42:57.437
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4373.svc.cluster.local)" && echo OK > /results/agnhost_hosts@dns-querier-2.dns-test-service-2.dns-4373.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/agnhost_hosts@dns-querier-2;sleep 1; done
   @ 05/11/25 13:42:57.441
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4373.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-4373.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 05/11/25 13:42:57.441
  STEP: creating a pod to probe DNS @ 05/11/25 13:42:57.441
  STEP: submitting the pod to kubernetes @ 05/11/25 13:42:57.441
  STEP: retrieving the pod @ 05/11/25 13:42:59.46
  STEP: looking for the results for each expected name from probers @ 05/11/25 13:42:59.462
  I0511 13:42:59.472522 26 dns_common.go:546] DNS probes using dns-4373/dns-test-3f6264e3-240e-4425-bde8-4d1dd1f0ddfe succeeded

  STEP: deleting the pod @ 05/11/25 13:42:59.472
  STEP: deleting the test headless service @ 05/11/25 13:42:59.483
  I0511 13:42:59.492029 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-4373" for this suite. @ 05/11/25 13:42:59.495
• [2.081 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:709
  STEP: Creating a kubernetes client @ 05/11/25 13:42:59.5
  I0511 13:42:59.500703 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 13:42:59.501
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:42:59.51
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:42:59.513
  STEP: Setting up server cert @ 05/11/25 13:42:59.525
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 13:42:59.771
  STEP: Deploying the webhook pod @ 05/11/25 13:42:59.774
  STEP: Wait for the deployment to be ready @ 05/11/25 13:42:59.781
  I0511 13:42:59.785325 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/11/25 13:43:01.793
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 13:43:01.806
  I0511 13:43:02.806808 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 05/11/25 13:43:02.812
  STEP: verifying the validating webhook match conditions @ 05/11/25 13:43:02.826
  STEP: updating the validating webhook match conditions @ 05/11/25 13:43:02.828
  STEP: verifying the validating webhook match conditions @ 05/11/25 13:43:02.836
  I0511 13:43:02.872131 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3793" for this suite. @ 05/11/25 13:43:02.874
  STEP: Destroying namespace "webhook-markers-3970" for this suite. @ 05/11/25 13:43:02.878
• [3.381 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:190
  STEP: Creating a kubernetes client @ 05/11/25 13:43:02.881
  I0511 13:43:02.881987 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename emptydir-wrapper @ 05/11/25 13:43:02.883
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:43:02.893
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:43:02.894
  STEP: Creating 50 configmaps @ 05/11/25 13:43:02.895
  STEP: Creating RC which spawns configmap-volume pods @ 05/11/25 13:43:03.14
  I0511 13:43:03.246357 26 resource.go:81] Pod name wrapped-volume-race-8e2128e5-4e68-4e5c-8672-0706740c6ea1: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 05/11/25 13:43:03.246
  STEP: Creating RC which spawns configmap-volume pods @ 05/11/25 13:43:05.309
  I0511 13:43:05.325980 26 resource.go:81] Pod name wrapped-volume-race-66488a7f-18f9-4f19-8b46-721c6e974ed6: Found 0 pods out of 5
  I0511 13:43:10.331951 26 resource.go:81] Pod name wrapped-volume-race-66488a7f-18f9-4f19-8b46-721c6e974ed6: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 05/11/25 13:43:10.331
  STEP: Creating RC which spawns configmap-volume pods @ 05/11/25 13:43:10.348
  I0511 13:43:10.364264 26 resource.go:81] Pod name wrapped-volume-race-7e3a7784-183b-442c-b1f0-f248488bea72: Found 1 pods out of 5
  I0511 13:43:15.371183 26 resource.go:81] Pod name wrapped-volume-race-7e3a7784-183b-442c-b1f0-f248488bea72: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 05/11/25 13:43:15.371
  STEP: deleting ReplicationController wrapped-volume-race-7e3a7784-183b-442c-b1f0-f248488bea72 in namespace emptydir-wrapper-3084, will wait for the garbage collector to delete the pods @ 05/11/25 13:43:15.385
  I0511 13:43:15.447608 26 resources.go:139] Deleting ReplicationController wrapped-volume-race-7e3a7784-183b-442c-b1f0-f248488bea72 took: 8.816202ms
  I0511 13:43:15.548025 26 resources.go:163] Terminating ReplicationController wrapped-volume-race-7e3a7784-183b-442c-b1f0-f248488bea72 pods took: 100.413862ms
  STEP: deleting ReplicationController wrapped-volume-race-66488a7f-18f9-4f19-8b46-721c6e974ed6 in namespace emptydir-wrapper-3084, will wait for the garbage collector to delete the pods @ 05/11/25 13:43:16.548
  I0511 13:43:16.614082 26 resources.go:139] Deleting ReplicationController wrapped-volume-race-66488a7f-18f9-4f19-8b46-721c6e974ed6 took: 9.519248ms
  I0511 13:43:16.714342 26 resources.go:163] Terminating ReplicationController wrapped-volume-race-66488a7f-18f9-4f19-8b46-721c6e974ed6 pods took: 100.256616ms
  STEP: deleting ReplicationController wrapped-volume-race-8e2128e5-4e68-4e5c-8672-0706740c6ea1 in namespace emptydir-wrapper-3084, will wait for the garbage collector to delete the pods @ 05/11/25 13:43:17.315
  I0511 13:43:17.380405 26 resources.go:139] Deleting ReplicationController wrapped-volume-race-8e2128e5-4e68-4e5c-8672-0706740c6ea1 took: 8.51637ms
  I0511 13:43:17.481163 26 resources.go:163] Terminating ReplicationController wrapped-volume-race-8e2128e5-4e68-4e5c-8672-0706740c6ea1 pods took: 100.762512ms
  STEP: Cleaning up the configMaps @ 05/11/25 13:43:18.382
  I0511 13:43:18.594618 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-3084" for this suite. @ 05/11/25 13:43:18.596
• [15.717 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1003
  STEP: Creating a kubernetes client @ 05/11/25 13:43:18.598
  I0511 13:43:18.599010 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename resourcequota @ 05/11/25 13:43:18.599
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:43:18.606
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:43:18.608
  STEP: Creating a ResourceQuota @ 05/11/25 13:43:18.609
  STEP: Getting a ResourceQuota @ 05/11/25 13:43:18.611
  STEP: Listing all ResourceQuotas with LabelSelector @ 05/11/25 13:43:18.612
  STEP: Patching the ResourceQuota @ 05/11/25 13:43:18.614
  STEP: Deleting a Collection of ResourceQuotas @ 05/11/25 13:43:18.618
  STEP: Verifying the deleted ResourceQuota @ 05/11/25 13:43:18.622
  I0511 13:43:18.623240 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3303" for this suite. @ 05/11/25 13:43:18.699
• [0.106 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:437
  STEP: Creating a kubernetes client @ 05/11/25 13:43:18.705
  I0511 13:43:18.705480 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename dns @ 05/11/25 13:43:18.706
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:43:18.714
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:43:18.717
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 05/11/25 13:43:18.72
  I0511 13:43:18.727621 26 dns.go:449] Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-1110  4c1b97e1-9c9b-4ea8-af2e-e29e5defdaf8 7855 1 2025-05-11 13:43:18 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2025-05-11 13:43:18 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dxgjk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,Image:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.53,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dxgjk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,RecursiveReadOnly:nil,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,AppArmorProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,AppArmorProfile:nil,SupplementalGroupsPolicy:nil,SELinuxChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},Resources:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},ObservedGeneration:0,},}
  STEP: Verifying customized DNS suffix list is configured on pod... @ 05/11/25 13:43:20.736
  I0511 13:43:20.736744 26 exec_util.go:63] ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-1110 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 13:43:20.736768 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 13:43:20.736834 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/dns-1110/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&stderr=true&stdout=true)
  I0511 13:43:20.803724 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  STEP: Verifying customized DNS server is configured on pod... @ 05/11/25 13:43:20.803
  I0511 13:43:20.803789 26 exec_util.go:63] ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-1110 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 13:43:20.803794 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 13:43:20.803837 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/dns-1110/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&stderr=true&stdout=true)
  I0511 13:43:20.858314 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 13:43:20.858392 26 dns.go:451] Deleting pod test-dns-nameservers...
  I0511 13:43:20.867894 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-1110" for this suite. @ 05/11/25 13:43:20.87
• [2.168 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:104
  STEP: Creating a kubernetes client @ 05/11/25 13:43:20.873
  I0511 13:43:20.873667 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 05/11/25 13:43:20.874
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:43:20.882
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:43:20.884
  STEP: creating a target pod @ 05/11/25 13:43:20.886
  STEP: adding an ephemeral container @ 05/11/25 13:43:22.904
  STEP: verifying the pod's generation is 2 @ 05/11/25 13:43:26.927
  STEP: checking pod container endpoints @ 05/11/25 13:43:26.929
  I0511 13:43:26.930013 26 exec_util.go:63] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-9617 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 13:43:26.930036 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 13:43:26.930102 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-9617/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&stderr=true&stdout=true)
  I0511 13:43:26.989689 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 13:43:26.989739 26 exec_util.go:112] Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 05/11/25 13:43:27.006
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 05/11/25 13:43:27.01
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 05/11/25 13:43:27.021
  I0511 13:43:27.026038 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-9617" for this suite. @ 05/11/25 13:43:27.03
• [6.164 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:90
  STEP: Creating a kubernetes client @ 05/11/25 13:43:27.038
  I0511 13:43:27.038435 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename containers @ 05/11/25 13:43:27.039
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:43:27.048
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:43:27.049
  STEP: Creating a pod to test override all @ 05/11/25 13:43:27.051
  STEP: Saw pod success @ 05/11/25 13:43:31.076
  I0511 13:43:31.079236 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod client-containers-176e416c-7a0c-4a11-9ffb-98b6c5f4835d container agnhost-container: <nil>
  STEP: delete the pod @ 05/11/25 13:43:31.086
  I0511 13:43:31.102036 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-2551" for this suite. @ 05/11/25 13:43:31.105
• [4.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 05/11/25 13:43:31.111
  I0511 13:43:31.111732 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename pods @ 05/11/25 13:43:31.112
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:43:31.118
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:43:31.12
  I0511 13:43:31.121924 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: creating the pod @ 05/11/25 13:43:31.122
  STEP: submitting the pod to kubernetes @ 05/11/25 13:43:31.122
  I0511 13:43:33.201971 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2448" for this suite. @ 05/11/25 13:43:33.203
• [2.098 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 05/11/25 13:43:33.209
  I0511 13:43:33.209596 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename replicaset @ 05/11/25 13:43:33.209
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:43:33.216
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:43:33.218
  I0511 13:43:33.225330 26 resource.go:81] Pod name sample-pod: Found 0 pods out of 1
  I0511 13:43:38.231735 26 resource.go:81] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/11/25 13:43:38.231
  STEP: Scaling up "test-rs" replicaset @ 05/11/25 13:43:38.231
  I0511 13:43:38.240438 26 replicaset.go:44] Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 05/11/25 13:43:38.24
  I0511 13:43:38.251403 26 replica_set.go:544] observed ReplicaSet test-rs in namespace replicaset-9245 with ReadyReplicas 1, AvailableReplicas 1
  I0511 13:43:38.259588 26 replica_set.go:544] observed ReplicaSet test-rs in namespace replicaset-9245 with ReadyReplicas 1, AvailableReplicas 1
  I0511 13:43:38.272403 26 replica_set.go:544] observed ReplicaSet test-rs in namespace replicaset-9245 with ReadyReplicas 1, AvailableReplicas 1
  I0511 13:43:38.280620 26 replica_set.go:544] observed ReplicaSet test-rs in namespace replicaset-9245 with ReadyReplicas 1, AvailableReplicas 1
  I0511 13:43:39.760674 26 replica_set.go:544] observed ReplicaSet test-rs in namespace replicaset-9245 with ReadyReplicas 2, AvailableReplicas 2
  I0511 13:43:39.792112 26 replica_set.go:547] observed Replicaset test-rs in namespace replicaset-9245 with ReadyReplicas 3 found true
  I0511 13:43:39.792321 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-9245" for this suite. @ 05/11/25 13:43:39.796
• [6.591 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:921
  STEP: Creating a kubernetes client @ 05/11/25 13:43:39.8
  I0511 13:43:39.801021 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename job @ 05/11/25 13:43:39.801
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:43:39.811
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:43:39.814
  STEP: Creating a job @ 05/11/25 13:43:39.817
  STEP: Ensuring active pods == parallelism @ 05/11/25 13:43:39.821
  STEP: Orphaning one of the Job's Pods @ 05/11/25 13:43:41.831
  I0511 13:43:42.349312 26 pod_client.go:173] Successfully updated pod "adopt-release-hv9fj"
  STEP: Checking that the Job readopts the Pod @ 05/11/25 13:43:42.349
  STEP: Removing the labels from the Job's Pod @ 05/11/25 13:43:44.357
  I0511 13:43:44.867343 26 pod_client.go:173] Successfully updated pod "adopt-release-hv9fj"
  STEP: Checking that the Job releases the Pod @ 05/11/25 13:43:44.867
  I0511 13:43:46.872962 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8813" for this suite. @ 05/11/25 13:43:46.876
• [7.083 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 05/11/25 13:43:46.883
  I0511 13:43:46.883886 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename chunking @ 05/11/25 13:43:46.884
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:43:46.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:43:46.896
  STEP: creating a large number of resources @ 05/11/25 13:43:46.898
  STEP: retrieving the first page @ 05/11/25 13:44:04.591
  I0511 13:44:04.642941 26 chunking.go:163] Retrieved 40/40 results with rv 8633 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODYzMywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0
  STEP: retrieving the second page until the token expires @ 05/11/25 13:44:04.642
  I0511 13:44:24.652162 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODYzMywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  I0511 13:44:44.654911 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODYzMywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  I0511 13:45:04.654736 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODYzMywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  I0511 13:45:24.649300 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODYzMywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  I0511 13:45:44.655282 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODYzMywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  I0511 13:46:04.652630 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODYzMywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  I0511 13:46:24.654981 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODYzMywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  I0511 13:46:44.653696 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODYzMywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  I0511 13:47:04.654332 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODYzMywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  I0511 13:47:24.649444 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODYzMywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  I0511 13:47:44.651858 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODYzMywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  I0511 13:48:04.653957 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODYzMywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  I0511 13:48:24.653888 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODYzMywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  I0511 13:48:44.654384 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODYzMywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  I0511 13:49:04.649981 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODYzMywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  I0511 13:49:24.651796 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODYzMywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  I0511 13:49:44.652681 26 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODYzMywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  I0511 13:50:04.652388 26 chunking.go:177] got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  I0511 13:50:04.652437 26 chunking.go:186] Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 05/11/25 13:50:04.652
  STEP: retrieving all remaining pages @ 05/11/25 13:50:04.656
  I0511 13:50:04.660423 26 chunking.go:221] Retrieved 40/40 results with rv 8981 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODk4MSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTE5XHUwMDAwIn0
  I0511 13:50:04.664056 26 chunking.go:221] Retrieved 40/40 results with rv 8981 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODk4MSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTU5XHUwMDAwIn0
  I0511 13:50:04.667345 26 chunking.go:221] Retrieved 40/40 results with rv 8981 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODk4MSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTk5XHUwMDAwIn0
  I0511 13:50:04.670882 26 chunking.go:221] Retrieved 40/40 results with rv 8981 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODk4MSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjM5XHUwMDAwIn0
  I0511 13:50:04.674207 26 chunking.go:221] Retrieved 40/40 results with rv 8981 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODk4MSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjc5XHUwMDAwIn0
  I0511 13:50:04.677655 26 chunking.go:221] Retrieved 40/40 results with rv 8981 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODk4MSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzE5XHUwMDAwIn0
  I0511 13:50:04.681515 26 chunking.go:221] Retrieved 40/40 results with rv 8981 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6ODk4MSwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzU5XHUwMDAwIn0
  I0511 13:50:04.685132 26 chunking.go:221] Retrieved 40/40 results with rv 8981 and continue 
  I0511 13:50:04.685327 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-1818" for this suite. @ 05/11/25 13:50:04.687
• [377.810 seconds]
------------------------------
SSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:527
  STEP: Creating a kubernetes client @ 05/11/25 13:50:04.693
  I0511 13:50:04.693979 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename container-probe @ 05/11/25 13:50:04.695
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:50:04.711
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:50:04.713
  STEP: Creating pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925 @ 05/11/25 13:50:04.715
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/11/25 13:50:06.727
  I0511 13:50:06.730235 26 container_probe.go:1748] Initial restart count of pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a is 0
  I0511 13:50:06.732754 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:08.737044 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:10.741166 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:12.744266 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:14.749613 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:16.755505 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:18.761263 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:20.766837 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:22.772338 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:24.777193 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:26.782380 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:28.787238 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:30.791798 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:32.797776 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:34.803588 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:36.808942 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:38.813063 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:40.818923 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:42.823959 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:44.829219 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:46.832743 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:48.837718 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:50.843949 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:52.850583 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:54.856013 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:56.860673 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:50:58.866476 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:00.872347 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:02.878348 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:04.881385 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:06.886573 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:08.892657 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:10.899198 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:12.905262 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:14.910287 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:16.916769 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:18.921806 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:20.927873 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:22.934020 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:24.940414 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:26.945794 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:28.950613 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:30.957184 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:32.963097 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:34.968224 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:36.973115 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:38.979147 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:40.985318 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:42.989858 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:44.995869 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:47.002003 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:49.006705 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:51.013033 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:53.019063 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:55.023855 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:57.029436 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:51:59.035674 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:01.041148 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:03.045503 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:05.051333 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:07.056143 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:09.061211 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:11.067779 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:13.073579 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:15.079183 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:17.084552 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:19.089502 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:21.095408 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:23.100336 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:25.106906 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:27.112727 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:29.118710 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:31.123991 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:33.129507 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:35.134839 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:37.137568 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:39.142191 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:41.148049 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:43.153402 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:45.158566 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:47.164446 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:49.169373 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:51.174050 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:53.178979 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:55.183845 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:57.187890 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:52:59.193754 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:01.200241 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:03.204256 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:05.210530 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:07.214388 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:09.218446 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:11.223644 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:13.227182 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:15.233205 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:17.239729 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:19.244640 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:21.250423 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:23.256568 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:25.262182 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:27.266797 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:29.273320 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:31.277757 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:33.283681 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:35.289308 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:37.295042 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:39.301511 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:41.307559 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:43.313170 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:45.317126 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:47.325036 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:49.328150 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:51.332764 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:53.337127 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:55.342265 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:57.346896 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:53:59.352632 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:54:01.359040 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:54:03.363257 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  I0511 13:54:05.368330 26 container_probe.go:1758] Get pod test-grpc-ef3c75d7-e07b-45f7-ae13-570fdc5f6a6a in namespace container-probe-9925
  STEP: deleting the pod @ 05/11/25 13:54:07.369
  I0511 13:54:07.383025 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9925" for this suite. @ 05/11/25 13:54:07.387
• [242.699 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 05/11/25 13:54:07.393
  I0511 13:54:07.393409 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename events @ 05/11/25 13:54:07.394
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:54:07.405
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:54:07.409
  STEP: creating a test event @ 05/11/25 13:54:07.411
  STEP: listing all events in all namespaces @ 05/11/25 13:54:07.414
  STEP: patching the test event @ 05/11/25 13:54:07.42
  STEP: fetching the test event @ 05/11/25 13:54:07.426
  STEP: updating the test event @ 05/11/25 13:54:07.429
  STEP: getting the test event @ 05/11/25 13:54:07.434
  STEP: deleting the test event @ 05/11/25 13:54:07.435
  STEP: listing all events in all namespaces @ 05/11/25 13:54:07.44
  I0511 13:54:07.443426 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-4663" for this suite. @ 05/11/25 13:54:07.488
• [0.100 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:129
  STEP: Creating a kubernetes client @ 05/11/25 13:54:07.493
  I0511 13:54:07.493501 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename emptydir @ 05/11/25 13:54:07.494
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:54:07.5
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:54:07.501
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 05/11/25 13:54:07.502
  STEP: Saw pod success @ 05/11/25 13:54:09.517
  I0511 13:54:09.519492 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-d3052600-39f7-46c0-a30f-dc14b051c0df container test-container: <nil>
  STEP: delete the pod @ 05/11/25 13:54:09.539
  I0511 13:54:09.552343 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-805" for this suite. @ 05/11/25 13:54:09.555
• [2.067 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:890
  STEP: Creating a kubernetes client @ 05/11/25 13:54:09.56
  I0511 13:54:09.560438 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename daemonsets @ 05/11/25 13:54:09.561
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:54:09.57
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:54:09.573
  STEP: Creating simple DaemonSet "daemon-set" @ 05/11/25 13:54:09.666
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/11/25 13:54:09.672
  I0511 13:54:09.762523 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 13:54:09.762597 26 fixtures.go:131] Node k8sconformance is running 0 daemon pod, expected 1
  I0511 13:54:10.681925 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0511 13:54:10.681972 26 fixtures.go:131] Node k8sconformance-m02 is running 0 daemon pod, expected 1
  I0511 13:54:11.680441 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0511 13:54:11.680507 26 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Getting /status @ 05/11/25 13:54:11.683
  I0511 13:54:11.685815 26 daemon_set.go:927] Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 05/11/25 13:54:11.685
  I0511 13:54:11.692882 26 daemon_set.go:947] updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 05/11/25 13:54:11.692
  I0511 13:54:11.694870 26 daemon_set.go:972] Observed &DaemonSet event: ADDED
  I0511 13:54:11.695019 26 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0511 13:54:11.695150 26 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0511 13:54:11.695268 26 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0511 13:54:11.695306 26 daemon_set.go:965] Found daemon set daemon-set in namespace daemonsets-9729 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0511 13:54:11.695327 26 daemon_set.go:976] Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 05/11/25 13:54:11.695
  STEP: watching for the daemon set status to be patched @ 05/11/25 13:54:11.702
  I0511 13:54:11.704881 26 daemon_set.go:1016] Observed &DaemonSet event: ADDED
  I0511 13:54:11.704964 26 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0511 13:54:11.705023 26 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0511 13:54:11.705246 26 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0511 13:54:11.705264 26 daemon_set.go:1012] Observed daemon set daemon-set in namespace daemonsets-9729 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0511 13:54:11.705325 26 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0511 13:54:11.705342 26 daemon_set.go:1009] Found daemon set daemon-set in namespace daemonsets-9729 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  I0511 13:54:11.705356 26 daemon_set.go:1020] Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 05/11/25 13:54:11.707
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9729, will wait for the garbage collector to delete the pods @ 05/11/25 13:54:11.707
  I0511 13:54:11.768865 26 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 8.093132ms
  I0511 13:54:11.869205 26 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.340013ms
  I0511 13:54:14.473906 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 13:54:14.473962 26 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0511 13:54:14.477086 26 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"9702"},"items":null}

  I0511 13:54:14.479303 26 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"9702"},"items":null}

  I0511 13:54:14.487192 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-9729" for this suite. @ 05/11/25 13:54:14.489
• [4.935 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 05/11/25 13:54:14.496
  I0511 13:54:14.496070 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename proxy @ 05/11/25 13:54:14.497
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:54:14.506
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:54:14.509
  STEP: starting an echo server on multiple ports @ 05/11/25 13:54:14.525
  I0511 13:54:14.537653 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  I0511 13:54:16.553294      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 13:54:16.553397 26 proxy.go:273] setup took 2.041496411s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 05/11/25 13:54:16.553
  I0511 13:54:16.559224 26 proxy.go:601] (0) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 5.633218ms)
  I0511 13:54:16.559262 26 proxy.go:601] (0) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 5.586673ms)
  I0511 13:54:16.559335 26 proxy.go:601] (0) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 5.639734ms)
  I0511 13:54:16.560896 26 proxy.go:601] (0) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 7.186993ms)
  I0511 13:54:16.560895 26 proxy.go:601] (0) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 7.218468ms)
  I0511 13:54:16.560942 26 proxy.go:601] (0) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 7.272075ms)
  I0511 13:54:16.560949 26 proxy.go:601] (0) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 7.33309ms)
  I0511 13:54:16.560982 26 proxy.go:601] (0) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 7.385301ms)
  I0511 13:54:16.560949 26 proxy.go:601] (0) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 7.332937ms)
  I0511 13:54:16.561031 26 proxy.go:601] (0) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 7.512264ms)
  I0511 13:54:16.562280 26 proxy.go:601] (0) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 8.582879ms)
  I0511 13:54:16.566807 26 proxy.go:601] (0) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 13.154035ms)
  I0511 13:54:16.569556 26 proxy.go:601] (0) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 15.891247ms)
  I0511 13:54:16.569609 26 proxy.go:601] (0) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 16.075404ms)
  I0511 13:54:16.570524 26 proxy.go:601] (0) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 16.897038ms)
  I0511 13:54:16.570639 26 proxy.go:601] (0) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 17.127868ms)
  I0511 13:54:16.577983 26 proxy.go:601] (1) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 7.228134ms)
  I0511 13:54:16.578131 26 proxy.go:601] (1) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 7.324355ms)
  I0511 13:54:16.578174 26 proxy.go:601] (1) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 7.178366ms)
  I0511 13:54:16.578202 26 proxy.go:601] (1) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 7.24537ms)
  I0511 13:54:16.578247 26 proxy.go:601] (1) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 7.225866ms)
  I0511 13:54:16.578248 26 proxy.go:601] (1) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 7.274313ms)
  I0511 13:54:16.578296 26 proxy.go:601] (1) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 7.542599ms)
  I0511 13:54:16.578304 26 proxy.go:601] (1) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 7.30351ms)
  I0511 13:54:16.578308 26 proxy.go:601] (1) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 7.365875ms)
  I0511 13:54:16.578319 26 proxy.go:601] (1) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 7.254076ms)
  I0511 13:54:16.579927 26 proxy.go:601] (1) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 8.867607ms)
  I0511 13:54:16.579948 26 proxy.go:601] (1) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 9.067785ms)
  I0511 13:54:16.580062 26 proxy.go:601] (1) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 9.334736ms)
  I0511 13:54:16.580099 26 proxy.go:601] (1) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 9.080531ms)
  I0511 13:54:16.580248 26 proxy.go:601] (1) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 9.356652ms)
  I0511 13:54:16.580660 26 proxy.go:601] (1) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 9.486506ms)
  I0511 13:54:16.587718 26 proxy.go:601] (2) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 6.721614ms)
  I0511 13:54:16.589183 26 proxy.go:601] (2) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 7.840656ms)
  I0511 13:54:16.589299 26 proxy.go:601] (2) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 7.961523ms)
  I0511 13:54:16.589364 26 proxy.go:601] (2) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 8.141236ms)
  I0511 13:54:16.589411 26 proxy.go:601] (2) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 8.378846ms)
  I0511 13:54:16.589446 26 proxy.go:601] (2) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 8.217094ms)
  I0511 13:54:16.589527 26 proxy.go:601] (2) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 8.537248ms)
  I0511 13:54:16.589557 26 proxy.go:601] (2) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 8.325499ms)
  I0511 13:54:16.589641 26 proxy.go:601] (2) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 8.457105ms)
  I0511 13:54:16.589625 26 proxy.go:601] (2) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 8.5551ms)
  I0511 13:54:16.589689 26 proxy.go:601] (2) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 8.603686ms)
  I0511 13:54:16.589739 26 proxy.go:601] (2) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 8.609931ms)
  I0511 13:54:16.589753 26 proxy.go:601] (2) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 8.587209ms)
  I0511 13:54:16.589804 26 proxy.go:601] (2) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 8.626578ms)
  I0511 13:54:16.589845 26 proxy.go:601] (2) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 8.65948ms)
  I0511 13:54:16.589886 26 proxy.go:601] (2) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 8.583442ms)
  I0511 13:54:16.595732 26 proxy.go:601] (3) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 5.694833ms)
  I0511 13:54:16.595754 26 proxy.go:601] (3) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 5.756662ms)
  I0511 13:54:16.596154 26 proxy.go:601] (3) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 6.011339ms)
  I0511 13:54:16.596261 26 proxy.go:601] (3) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 6.110676ms)
  I0511 13:54:16.596257 26 proxy.go:601] (3) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 6.206701ms)
  I0511 13:54:16.596316 26 proxy.go:601] (3) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 6.224838ms)
  I0511 13:54:16.596341 26 proxy.go:601] (3) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 6.13539ms)
  I0511 13:54:16.596375 26 proxy.go:601] (3) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 6.248112ms)
  I0511 13:54:16.596408 26 proxy.go:601] (3) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 6.429399ms)
  I0511 13:54:16.596750 26 proxy.go:601] (3) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 6.551776ms)
  I0511 13:54:16.597066 26 proxy.go:601] (3) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 6.954332ms)
  I0511 13:54:16.597066 26 proxy.go:601] (3) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 7.043746ms)
  I0511 13:54:16.597134 26 proxy.go:601] (3) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 7.064862ms)
  I0511 13:54:16.597159 26 proxy.go:601] (3) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 6.993343ms)
  I0511 13:54:16.597209 26 proxy.go:601] (3) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 7.046085ms)
  I0511 13:54:16.597247 26 proxy.go:601] (3) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 7.019577ms)
  I0511 13:54:16.601057 26 proxy.go:601] (4) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 3.744495ms)
  I0511 13:54:16.601062 26 proxy.go:601] (4) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 3.640916ms)
  I0511 13:54:16.601421 26 proxy.go:601] (4) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 4.070723ms)
  I0511 13:54:16.601517 26 proxy.go:601] (4) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 4.22548ms)
  I0511 13:54:16.602018 26 proxy.go:601] (4) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 4.635611ms)
  I0511 13:54:16.602031 26 proxy.go:601] (4) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 4.530002ms)
  I0511 13:54:16.602231 26 proxy.go:601] (4) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 4.792719ms)
  I0511 13:54:16.602253 26 proxy.go:601] (4) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 4.718861ms)
  I0511 13:54:16.602309 26 proxy.go:601] (4) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 4.752327ms)
  I0511 13:54:16.602317 26 proxy.go:601] (4) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 4.815364ms)
  I0511 13:54:16.602955 26 proxy.go:601] (4) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 5.422708ms)
  I0511 13:54:16.602959 26 proxy.go:601] (4) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 5.637338ms)
  I0511 13:54:16.602962 26 proxy.go:601] (4) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 5.548298ms)
  I0511 13:54:16.602999 26 proxy.go:601] (4) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 5.562447ms)
  I0511 13:54:16.603176 26 proxy.go:601] (4) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 5.721394ms)
  I0511 13:54:16.603176 26 proxy.go:601] (4) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 5.651759ms)
  I0511 13:54:16.607202 26 proxy.go:601] (5) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 3.863521ms)
  I0511 13:54:16.607232 26 proxy.go:601] (5) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 3.986888ms)
  I0511 13:54:16.607265 26 proxy.go:601] (5) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 3.917524ms)
  I0511 13:54:16.607290 26 proxy.go:601] (5) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 3.914885ms)
  I0511 13:54:16.607294 26 proxy.go:601] (5) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 3.98058ms)
  I0511 13:54:16.607308 26 proxy.go:601] (5) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 3.873109ms)
  I0511 13:54:16.607320 26 proxy.go:601] (5) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 3.975266ms)
  I0511 13:54:16.607323 26 proxy.go:601] (5) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 4.003374ms)
  I0511 13:54:16.607349 26 proxy.go:601] (5) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 3.981475ms)
  I0511 13:54:16.607567 26 proxy.go:601] (5) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 4.172251ms)
  I0511 13:54:16.607567 26 proxy.go:601] (5) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 4.139173ms)
  I0511 13:54:16.607728 26 proxy.go:601] (5) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 4.490664ms)
  I0511 13:54:16.607738 26 proxy.go:601] (5) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 4.343397ms)
  I0511 13:54:16.607887 26 proxy.go:601] (5) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 4.455085ms)
  I0511 13:54:16.607913 26 proxy.go:601] (5) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 4.498105ms)
  I0511 13:54:16.607997 26 proxy.go:601] (5) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 4.574361ms)
  I0511 13:54:16.610491 26 proxy.go:601] (6) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 2.459ms)
  I0511 13:54:16.610555 26 proxy.go:601] (6) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.434537ms)
  I0511 13:54:16.610575 26 proxy.go:601] (6) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 2.494343ms)
  I0511 13:54:16.610605 26 proxy.go:601] (6) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.538191ms)
  I0511 13:54:16.611328 26 proxy.go:601] (6) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 3.287025ms)
  I0511 13:54:16.611333 26 proxy.go:601] (6) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 3.202133ms)
  I0511 13:54:16.611369 26 proxy.go:601] (6) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 3.319223ms)
  I0511 13:54:16.611374 26 proxy.go:601] (6) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 3.349411ms)
  I0511 13:54:16.611382 26 proxy.go:601] (6) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 3.279034ms)
  I0511 13:54:16.611396 26 proxy.go:601] (6) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 3.264342ms)
  I0511 13:54:16.611404 26 proxy.go:601] (6) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 3.302584ms)
  I0511 13:54:16.611486 26 proxy.go:601] (6) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 3.316243ms)
  I0511 13:54:16.611500 26 proxy.go:601] (6) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 3.378974ms)
  I0511 13:54:16.611563 26 proxy.go:601] (6) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 3.475419ms)
  I0511 13:54:16.611707 26 proxy.go:601] (6) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 3.568827ms)
  I0511 13:54:16.612082 26 proxy.go:601] (6) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 3.967262ms)
  I0511 13:54:16.615141 26 proxy.go:601] (7) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.984982ms)
  I0511 13:54:16.615150 26 proxy.go:601] (7) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 3.024746ms)
  I0511 13:54:16.615157 26 proxy.go:601] (7) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 2.924879ms)
  I0511 13:54:16.615149 26 proxy.go:601] (7) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 2.946621ms)
  I0511 13:54:16.615178 26 proxy.go:601] (7) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 2.97027ms)
  I0511 13:54:16.615178 26 proxy.go:601] (7) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.938659ms)
  I0511 13:54:16.615189 26 proxy.go:601] (7) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 3.049773ms)
  I0511 13:54:16.615193 26 proxy.go:601] (7) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 2.977317ms)
  I0511 13:54:16.615207 26 proxy.go:601] (7) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 3.041965ms)
  I0511 13:54:16.615205 26 proxy.go:601] (7) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 2.999218ms)
  I0511 13:54:16.615150 26 proxy.go:601] (7) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 2.92671ms)
  I0511 13:54:16.615212 26 proxy.go:601] (7) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 2.977461ms)
  I0511 13:54:16.615223 26 proxy.go:601] (7) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 3.028932ms)
  I0511 13:54:16.615181 26 proxy.go:601] (7) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 2.995552ms)
  I0511 13:54:16.615195 26 proxy.go:601] (7) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 3.070484ms)
  I0511 13:54:16.615219 26 proxy.go:601] (7) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 3.000925ms)
  I0511 13:54:16.617356 26 proxy.go:601] (8) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 2.013057ms)
  I0511 13:54:16.617622 26 proxy.go:601] (8) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 2.242329ms)
  I0511 13:54:16.617658 26 proxy.go:601] (8) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 2.28232ms)
  I0511 13:54:16.618021 26 proxy.go:601] (8) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 2.662493ms)
  I0511 13:54:16.618032 26 proxy.go:601] (8) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 2.646536ms)
  I0511 13:54:16.618050 26 proxy.go:601] (8) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 2.727771ms)
  I0511 13:54:16.618124 26 proxy.go:601] (8) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 2.765579ms)
  I0511 13:54:16.618142 26 proxy.go:601] (8) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 2.809524ms)
  I0511 13:54:16.618156 26 proxy.go:601] (8) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 2.76629ms)
  I0511 13:54:16.618156 26 proxy.go:601] (8) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 2.784199ms)
  I0511 13:54:16.618161 26 proxy.go:601] (8) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 2.807351ms)
  I0511 13:54:16.618171 26 proxy.go:601] (8) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 2.889921ms)
  I0511 13:54:16.618174 26 proxy.go:601] (8) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 2.772375ms)
  I0511 13:54:16.618210 26 proxy.go:601] (8) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 2.947246ms)
  I0511 13:54:16.618312 26 proxy.go:601] (8) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.939876ms)
  I0511 13:54:16.618338 26 proxy.go:601] (8) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 3.026224ms)
  I0511 13:54:16.620326 26 proxy.go:601] (9) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 1.89079ms)
  I0511 13:54:16.620841 26 proxy.go:601] (9) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.455185ms)
  I0511 13:54:16.620871 26 proxy.go:601] (9) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 2.464145ms)
  I0511 13:54:16.620914 26 proxy.go:601] (9) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 2.502227ms)
  I0511 13:54:16.620934 26 proxy.go:601] (9) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 2.51586ms)
  I0511 13:54:16.620946 26 proxy.go:601] (9) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 2.502803ms)
  I0511 13:54:16.620958 26 proxy.go:601] (9) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 2.598437ms)
  I0511 13:54:16.620969 26 proxy.go:601] (9) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 2.578145ms)
  I0511 13:54:16.620983 26 proxy.go:601] (9) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 2.583154ms)
  I0511 13:54:16.620994 26 proxy.go:601] (9) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 2.616597ms)
  I0511 13:54:16.621147 26 proxy.go:601] (9) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 2.708209ms)
  I0511 13:54:16.621167 26 proxy.go:601] (9) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 2.813463ms)
  I0511 13:54:16.621170 26 proxy.go:601] (9) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 2.734081ms)
  I0511 13:54:16.621170 26 proxy.go:601] (9) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 2.729351ms)
  I0511 13:54:16.621181 26 proxy.go:601] (9) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 2.75135ms)
  I0511 13:54:16.621170 26 proxy.go:601] (9) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 2.739699ms)
  I0511 13:54:16.623327 26 proxy.go:601] (10) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 2.103027ms)
  I0511 13:54:16.623337 26 proxy.go:601] (10) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 2.087718ms)
  I0511 13:54:16.623371 26 proxy.go:601] (10) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 2.157526ms)
  I0511 13:54:16.623426 26 proxy.go:601] (10) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.203836ms)
  I0511 13:54:16.623430 26 proxy.go:601] (10) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 2.162926ms)
  I0511 13:54:16.623472 26 proxy.go:601] (10) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 2.183607ms)
  I0511 13:54:16.623541 26 proxy.go:601] (10) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 2.256467ms)
  I0511 13:54:16.623549 26 proxy.go:601] (10) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 2.325822ms)
  I0511 13:54:16.623568 26 proxy.go:601] (10) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 2.291806ms)
  I0511 13:54:16.623569 26 proxy.go:601] (10) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 2.295153ms)
  I0511 13:54:16.623657 26 proxy.go:601] (10) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 2.41375ms)
  I0511 13:54:16.623683 26 proxy.go:601] (10) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 2.420269ms)
  I0511 13:54:16.623700 26 proxy.go:601] (10) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.444747ms)
  I0511 13:54:16.623717 26 proxy.go:601] (10) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 2.454574ms)
  I0511 13:54:16.623839 26 proxy.go:601] (10) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 2.606846ms)
  I0511 13:54:16.623841 26 proxy.go:601] (10) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 2.565598ms)
  I0511 13:54:16.625928 26 proxy.go:601] (11) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 1.964519ms)
  I0511 13:54:16.625928 26 proxy.go:601] (11) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 1.983465ms)
  I0511 13:54:16.625955 26 proxy.go:601] (11) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 2.016858ms)
  I0511 13:54:16.625965 26 proxy.go:601] (11) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 2.014434ms)
  I0511 13:54:16.625986 26 proxy.go:601] (11) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 2.025472ms)
  I0511 13:54:16.625994 26 proxy.go:601] (11) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 2.063111ms)
  I0511 13:54:16.626024 26 proxy.go:601] (11) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 2.13687ms)
  I0511 13:54:16.626046 26 proxy.go:601] (11) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 2.155234ms)
  I0511 13:54:16.626036 26 proxy.go:601] (11) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 2.158534ms)
  I0511 13:54:16.626050 26 proxy.go:601] (11) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 2.13586ms)
  I0511 13:54:16.626077 26 proxy.go:601] (11) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.114445ms)
  I0511 13:54:16.626076 26 proxy.go:601] (11) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 2.154318ms)
  I0511 13:54:16.626085 26 proxy.go:601] (11) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.185485ms)
  I0511 13:54:16.626090 26 proxy.go:601] (11) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 2.209798ms)
  I0511 13:54:16.626095 26 proxy.go:601] (11) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 2.177469ms)
  I0511 13:54:16.626100 26 proxy.go:601] (11) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 2.170645ms)
  I0511 13:54:16.628096 26 proxy.go:601] (12) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 1.943941ms)
  I0511 13:54:16.628096 26 proxy.go:601] (12) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 1.921852ms)
  I0511 13:54:16.628124 26 proxy.go:601] (12) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 1.936994ms)
  I0511 13:54:16.628137 26 proxy.go:601] (12) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 1.979994ms)
  I0511 13:54:16.628138 26 proxy.go:601] (12) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 2.017891ms)
  I0511 13:54:16.628162 26 proxy.go:601] (12) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.024163ms)
  I0511 13:54:16.628168 26 proxy.go:601] (12) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 2.003089ms)
  I0511 13:54:16.628181 26 proxy.go:601] (12) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 2.052336ms)
  I0511 13:54:16.628184 26 proxy.go:601] (12) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 1.993105ms)
  I0511 13:54:16.628181 26 proxy.go:601] (12) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 2.053005ms)
  I0511 13:54:16.628192 26 proxy.go:601] (12) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.00564ms)
  I0511 13:54:16.628197 26 proxy.go:601] (12) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 2.011176ms)
  I0511 13:54:16.628711 26 proxy.go:601] (12) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 2.511609ms)
  I0511 13:54:16.629038 26 proxy.go:601] (12) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 2.86184ms)
  I0511 13:54:16.629036 26 proxy.go:601] (12) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 2.838719ms)
  I0511 13:54:16.629036 26 proxy.go:601] (12) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 2.82742ms)
  I0511 13:54:16.631404 26 proxy.go:601] (13) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 2.267888ms)
  I0511 13:54:16.631439 26 proxy.go:601] (13) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 2.313883ms)
  I0511 13:54:16.631447 26 proxy.go:601] (13) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 2.348761ms)
  I0511 13:54:16.631447 26 proxy.go:601] (13) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 2.362587ms)
  I0511 13:54:16.631481 26 proxy.go:601] (13) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 2.335361ms)
  I0511 13:54:16.631488 26 proxy.go:601] (13) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 2.41863ms)
  I0511 13:54:16.631485 26 proxy.go:601] (13) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 2.396762ms)
  I0511 13:54:16.631499 26 proxy.go:601] (13) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 2.359009ms)
  I0511 13:54:16.631502 26 proxy.go:601] (13) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 2.35215ms)
  I0511 13:54:16.631506 26 proxy.go:601] (13) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 2.364129ms)
  I0511 13:54:16.631508 26 proxy.go:601] (13) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.369279ms)
  I0511 13:54:16.631487 26 proxy.go:601] (13) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 2.423569ms)
  I0511 13:54:16.631486 26 proxy.go:601] (13) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 2.357082ms)
  I0511 13:54:16.631481 26 proxy.go:601] (13) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 2.374858ms)
  I0511 13:54:16.631509 26 proxy.go:601] (13) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.385695ms)
  I0511 13:54:16.631511 26 proxy.go:601] (13) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 2.395472ms)
  I0511 13:54:16.633394 26 proxy.go:601] (14) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 1.832395ms)
  I0511 13:54:16.633536 26 proxy.go:601] (14) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 1.945457ms)
  I0511 13:54:16.633545 26 proxy.go:601] (14) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 1.933385ms)
  I0511 13:54:16.633780 26 proxy.go:601] (14) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 2.165248ms)
  I0511 13:54:16.633795 26 proxy.go:601] (14) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 2.222686ms)
  I0511 13:54:16.634145 26 proxy.go:601] (14) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 2.560663ms)
  I0511 13:54:16.634172 26 proxy.go:601] (14) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 2.548804ms)
  I0511 13:54:16.634200 26 proxy.go:601] (14) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 2.59446ms)
  I0511 13:54:16.634207 26 proxy.go:601] (14) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 2.661001ms)
  I0511 13:54:16.634210 26 proxy.go:601] (14) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 2.605904ms)
  I0511 13:54:16.634219 26 proxy.go:601] (14) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 2.591308ms)
  I0511 13:54:16.634218 26 proxy.go:601] (14) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 2.592327ms)
  I0511 13:54:16.634231 26 proxy.go:601] (14) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 2.64634ms)
  I0511 13:54:16.634233 26 proxy.go:601] (14) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 2.671331ms)
  I0511 13:54:16.634236 26 proxy.go:601] (14) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 2.617438ms)
  I0511 13:54:16.634238 26 proxy.go:601] (14) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 2.637527ms)
  I0511 13:54:16.636370 26 proxy.go:601] (15) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 2.031811ms)
  I0511 13:54:16.636412 26 proxy.go:601] (15) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 2.129871ms)
  I0511 13:54:16.636418 26 proxy.go:601] (15) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 2.12278ms)
  I0511 13:54:16.636427 26 proxy.go:601] (15) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.147702ms)
  I0511 13:54:16.636423 26 proxy.go:601] (15) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 2.147825ms)
  I0511 13:54:16.636436 26 proxy.go:601] (15) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 2.079502ms)
  I0511 13:54:16.636429 26 proxy.go:601] (15) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.13007ms)
  I0511 13:54:16.636453 26 proxy.go:601] (15) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 2.116539ms)
  I0511 13:54:16.636446 26 proxy.go:601] (15) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 2.07475ms)
  I0511 13:54:16.636521 26 proxy.go:601] (15) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 2.182661ms)
  I0511 13:54:16.636526 26 proxy.go:601] (15) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 2.195252ms)
  I0511 13:54:16.636560 26 proxy.go:601] (15) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 2.237288ms)
  I0511 13:54:16.636580 26 proxy.go:601] (15) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 2.23268ms)
  I0511 13:54:16.636683 26 proxy.go:601] (15) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 2.365514ms)
  I0511 13:54:16.636684 26 proxy.go:601] (15) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 2.33757ms)
  I0511 13:54:16.636903 26 proxy.go:601] (15) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 2.595623ms)
  I0511 13:54:16.639200 26 proxy.go:601] (16) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 2.244749ms)
  I0511 13:54:16.639219 26 proxy.go:601] (16) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 2.299935ms)
  I0511 13:54:16.639226 26 proxy.go:601] (16) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 2.298939ms)
  I0511 13:54:16.639232 26 proxy.go:601] (16) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.222623ms)
  I0511 13:54:16.639234 26 proxy.go:601] (16) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 2.239249ms)
  I0511 13:54:16.639200 26 proxy.go:601] (16) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 2.231326ms)
  I0511 13:54:16.639246 26 proxy.go:601] (16) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.312925ms)
  I0511 13:54:16.639202 26 proxy.go:601] (16) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 2.258081ms)
  I0511 13:54:16.639200 26 proxy.go:601] (16) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 2.266692ms)
  I0511 13:54:16.639200 26 proxy.go:601] (16) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 2.225476ms)
  I0511 13:54:16.639222 26 proxy.go:601] (16) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 2.243633ms)
  I0511 13:54:16.639287 26 proxy.go:601] (16) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 2.278622ms)
  I0511 13:54:16.639434 26 proxy.go:601] (16) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 2.474401ms)
  I0511 13:54:16.639448 26 proxy.go:601] (16) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 2.457875ms)
  I0511 13:54:16.639453 26 proxy.go:601] (16) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 2.481699ms)
  I0511 13:54:16.639448 26 proxy.go:601] (16) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 2.438071ms)
  I0511 13:54:16.641495 26 proxy.go:601] (17) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 1.864671ms)
  I0511 13:54:16.641520 26 proxy.go:601] (17) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 1.908308ms)
  I0511 13:54:16.641495 26 proxy.go:601] (17) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 1.919308ms)
  I0511 13:54:16.641510 26 proxy.go:601] (17) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 1.884774ms)
  I0511 13:54:16.641534 26 proxy.go:601] (17) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 1.932663ms)
  I0511 13:54:16.641536 26 proxy.go:601] (17) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 1.938647ms)
  I0511 13:54:16.641597 26 proxy.go:601] (17) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 2.001985ms)
  I0511 13:54:16.641622 26 proxy.go:601] (17) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 2.122711ms)
  I0511 13:54:16.641627 26 proxy.go:601] (17) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 2.072612ms)
  I0511 13:54:16.641638 26 proxy.go:601] (17) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 2.087562ms)
  I0511 13:54:16.641880 26 proxy.go:601] (17) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 2.282612ms)
  I0511 13:54:16.641990 26 proxy.go:601] (17) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 2.387867ms)
  I0511 13:54:16.642012 26 proxy.go:601] (17) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 2.431659ms)
  I0511 13:54:16.642019 26 proxy.go:601] (17) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 2.416158ms)
  I0511 13:54:16.642023 26 proxy.go:601] (17) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 2.460218ms)
  I0511 13:54:16.642034 26 proxy.go:601] (17) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 2.473915ms)
  I0511 13:54:16.644195 26 proxy.go:601] (18) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 2.077794ms)
  I0511 13:54:16.644223 26 proxy.go:601] (18) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 2.125854ms)
  I0511 13:54:16.644313 26 proxy.go:601] (18) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 2.149153ms)
  I0511 13:54:16.644316 26 proxy.go:601] (18) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 2.186387ms)
  I0511 13:54:16.644308 26 proxy.go:601] (18) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 2.155018ms)
  I0511 13:54:16.644333 26 proxy.go:601] (18) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.200901ms)
  I0511 13:54:16.644402 26 proxy.go:601] (18) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 2.296446ms)
  I0511 13:54:16.644415 26 proxy.go:601] (18) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 2.245694ms)
  I0511 13:54:16.644652 26 proxy.go:601] (18) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 2.591498ms)
  I0511 13:54:16.644657 26 proxy.go:601] (18) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 2.497476ms)
  I0511 13:54:16.644653 26 proxy.go:601] (18) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 2.504757ms)
  I0511 13:54:16.644674 26 proxy.go:601] (18) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.515838ms)
  I0511 13:54:16.644700 26 proxy.go:601] (18) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 2.533665ms)
  I0511 13:54:16.644706 26 proxy.go:601] (18) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 2.576204ms)
  I0511 13:54:16.644706 26 proxy.go:601] (18) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 2.538858ms)
  I0511 13:54:16.644716 26 proxy.go:601] (18) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 2.568404ms)
  I0511 13:54:16.646368 26 proxy.go:601] (19) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/r... (200; 1.602541ms)
  I0511 13:54:16.646375 26 proxy.go:601] (19) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f/proxy/rewriteme">... (200; 1.58665ms)
  I0511 13:54:16.646727 26 proxy.go:601] (19) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 1.89815ms)
  I0511 13:54:16.646753 26 proxy.go:601] (19) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:1080/proxy/rewrit... (200; 1.959819ms)
  I0511 13:54:16.646767 26 proxy.go:601] (19) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 1.988774ms)
  I0511 13:54:16.646831 26 proxy.go:601] (19) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:460/proxy/: tls baz (200; 2.003758ms)
  I0511 13:54:16.647020 26 proxy.go:601] (19) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/: <a href="/api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:443/proxy/t... (200; 2.204034ms)
  I0511 13:54:16.647026 26 proxy.go:601] (19) /api/v1/namespaces/proxy-3149/pods/http:proxy-service-qbxdr-589bbbdd6-7gb5f:162/proxy/: bar (200; 2.20739ms)
  I0511 13:54:16.647035 26 proxy.go:601] (19) /api/v1/namespaces/proxy-3149/pods/https:proxy-service-qbxdr-589bbbdd6-7gb5f:462/proxy/: tls qux (200; 2.221139ms)
  I0511 13:54:16.647048 26 proxy.go:601] (19) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname2/proxy/: bar (200; 2.2419ms)
  I0511 13:54:16.647259 26 proxy.go:601] (19) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname2/proxy/: bar (200; 2.443259ms)
  I0511 13:54:16.647269 26 proxy.go:601] (19) /api/v1/namespaces/proxy-3149/services/proxy-service-qbxdr:portname1/proxy/: foo (200; 2.443517ms)
  I0511 13:54:16.647277 26 proxy.go:601] (19) /api/v1/namespaces/proxy-3149/pods/proxy-service-qbxdr-589bbbdd6-7gb5f:160/proxy/: foo (200; 2.510056ms)
  I0511 13:54:16.647267 26 proxy.go:601] (19) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname2/proxy/: tls qux (200; 2.449234ms)
  I0511 13:54:16.647287 26 proxy.go:601] (19) /api/v1/namespaces/proxy-3149/services/https:proxy-service-qbxdr:tlsportname1/proxy/: tls baz (200; 2.520472ms)
  I0511 13:54:16.647278 26 proxy.go:601] (19) /api/v1/namespaces/proxy-3149/services/http:proxy-service-qbxdr:portname1/proxy/: foo (200; 2.524676ms)
  I0511 13:54:16.652222 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-3149" for this suite. @ 05/11/25 13:54:16.654
• [2.161 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 05/11/25 13:54:16.657
  I0511 13:54:16.657567 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename deployment @ 05/11/25 13:54:16.658
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:54:16.668
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:54:16.67
  I0511 13:54:16.672852 26 deployment.go:798] Creating deployment "test-recreate-deployment"
  I0511 13:54:16.676941 26 deployment.go:804] Waiting deployment "test-recreate-deployment" to be updated to revision 1
  I0511 13:54:16.680399 26 deployment.go:223] deployment "test-recreate-deployment" doesn't have the required revision set
  I0511 13:54:18.687071 26 deployment.go:808] Waiting deployment "test-recreate-deployment" to complete
  I0511 13:54:18.689563 26 deployment.go:813] Triggering a new rollout for deployment "test-recreate-deployment"
  I0511 13:54:18.697773 26 deployment.go:314] Updating deployment test-recreate-deployment
  I0511 13:54:18.697826 26 deployment.go:820] Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  I0511 13:54:18.759993 26 deployment.go:632] Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2656",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "49ab9fa9-6bdd-4e4e-a09d-c5529717912e",
      ResourceVersion: (string) (len=4) "9799",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882568456,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568458,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568458,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      TerminatingReplicas: (*int32)(<nil>),
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568458,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568458,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568458,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568456,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=64) "ReplicaSet \"test-recreate-deployment-59cddbdd4b\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0511 13:54:18.788257 26 deployment.go:40] New ReplicaSet "test-recreate-deployment-59cddbdd4b" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-59cddbdd4b",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2656",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a6809c5c-47a6-46b0-8441-dfae09736005",
      ResourceVersion: (string) (len=4) "9798",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882568458,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "59cddbdd4b"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "49ab9fa9-6bdd-4e4e-a09d-c5529717912e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568458,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 34 39 61 62 39 66  61 39 2d 36 62 64 64 2d  |\"49ab9fa9-6bdd-|
              00000120  34 65 34 65 2d 61 30 39  64 2d 63 35 35 32 39 37  |4e4e-a09d-c55297|
              00000130  31 37 39 31 32 65 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |17912e\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568458,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "59cddbdd4b"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "59cddbdd4b"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0511 13:54:18.789079 26 deployment.go:45] All old ReplicaSets of Deployment "test-recreate-deployment":
  I0511 13:54:18.789428 26 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-db85869db",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2656",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b2cdf645-149d-4160-94ad-b7eca86d2c1b",
      ResourceVersion: (string) (len=4) "9788",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882568456,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "db85869db"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "49ab9fa9-6bdd-4e4e-a09d-c5529717912e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568458,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 34 39 61 62 39 66  61 39 2d 36 62 64 64 2d  |\"49ab9fa9-6bdd-|
              00000120  34 65 34 65 2d 61 30 39  64 2d 63 35 35 32 39 37  |4e4e-a09d-c55297|
              00000130  31 37 39 31 32 65 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |17912e\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568458,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "db85869db"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "db85869db"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0511 13:54:18.793483 26 deployment.go:68] Pod "test-recreate-deployment-59cddbdd4b-ls9mf" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-recreate-deployment-59cddbdd4b-ls9mf",
      GenerateName: (string) (len=36) "test-recreate-deployment-59cddbdd4b-",
      Namespace: (string) (len=15) "deployment-2656",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9f27fd2e-f9db-4482-8e10-2bc49c75bd34",
      ResourceVersion: (string) (len=4) "9800",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882568458,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "59cddbdd4b"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-recreate-deployment-59cddbdd4b",
          UID: (types.UID) (len=36) "a6809c5c-47a6-46b0-8441-dfae09736005",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568458,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 36  38 30 39 63 35 63 2d 34  |d\":\"a6809c5c-4|
              00000090  37 61 36 2d 34 36 62 30  2d 38 34 34 31 2d 64 66  |7a6-46b0-8441-df|
              000000a0  61 65 30 39 37 33 36 30  30 35 5c 22 7d 22 3a 7b  |ae09736005\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568458,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-c4m7n",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-c4m7n",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568458,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568458,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568458,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568458,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568458,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.3"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882568458,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-c4m7n",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 13:54:18.794848 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2656" for this suite. @ 05/11/25 13:54:18.797
• [2.144 seconds]
------------------------------
[sig-network] ServiceCIDR and IPAddress API should support IPAddress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_cidrs.go:223
  STEP: Creating a kubernetes client @ 05/11/25 13:54:18.802
  I0511 13:54:18.802079 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename servicecidr @ 05/11/25 13:54:18.802
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:54:18.813
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:54:18.815
  STEP: creating @ 05/11/25 13:54:18.816
  STEP: patching @ 05/11/25 13:54:18.823
  STEP: updating @ 05/11/25 13:54:18.826
  STEP: getting @ 05/11/25 13:54:18.83
  STEP: listing @ 05/11/25 13:54:18.831
  STEP: watching @ 05/11/25 13:54:18.832
  STEP: deleting @ 05/11/25 13:54:18.833
  STEP: deleting a collection @ 05/11/25 13:54:18.837
  I0511 13:54:18.845680 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "servicecidr-7315" for this suite. @ 05/11/25 13:54:18.899
• [0.102 seconds]
------------------------------
S
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 05/11/25 13:54:18.904
  I0511 13:54:18.904130 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename pods @ 05/11/25 13:54:18.904
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:54:18.914
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:54:18.917
  STEP: creating the pod @ 05/11/25 13:54:18.921
  STEP: submitting the pod to kubernetes @ 05/11/25 13:54:18.921
  I0511 13:54:18.928984      26 warnings.go:110] "Warning: metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]"
  STEP: verifying the pod is in kubernetes @ 05/11/25 13:54:20.94
  STEP: updating the pod @ 05/11/25 13:54:20.943
  I0511 13:54:21.457903 26 pod_client.go:173] Successfully updated pod "pod-update-activedeadlineseconds-85eecb61-c4d8-43a1-bb45-3b57424fd01b"
  I0511 13:54:25.469667 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2539" for this suite. @ 05/11/25 13:54:25.472
• [6.573 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 05/11/25 13:54:25.477
  I0511 13:54:25.477440 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename subpath @ 05/11/25 13:54:25.478
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:54:25.483
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:54:25.484
  STEP: Setting up data @ 05/11/25 13:54:25.486
  STEP: Creating pod pod-subpath-test-projected-6rpq @ 05/11/25 13:54:25.491
  STEP: Creating a pod to test atomic-volume-subpath @ 05/11/25 13:54:25.491
  STEP: Saw pod success @ 05/11/25 13:54:49.565
  I0511 13:54:49.567669 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-subpath-test-projected-6rpq container test-container-subpath-projected-6rpq: <nil>
  STEP: delete the pod @ 05/11/25 13:54:49.575
  STEP: Deleting pod pod-subpath-test-projected-6rpq @ 05/11/25 13:54:49.589
  I0511 13:54:49.589600 26 delete.go:62] Deleting pod "pod-subpath-test-projected-6rpq" in namespace "subpath-1352"
  I0511 13:54:49.592088 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1352" for this suite. @ 05/11/25 13:54:49.595
• [24.123 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:57
  STEP: Creating a kubernetes client @ 05/11/25 13:54:49.601
  I0511 13:54:49.601043 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename configmap @ 05/11/25 13:54:49.602
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:54:49.612
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:54:49.615
  STEP: Creating configMap with name configmap-test-volume-5ea6a279-2bb8-44a1-b6f1-ae79deb62779 @ 05/11/25 13:54:49.618
  STEP: Creating a pod to test consume configMaps @ 05/11/25 13:54:49.625
  STEP: Saw pod success @ 05/11/25 13:54:53.648
  I0511 13:54:53.651486 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-44519b66-92ed-49c1-a707-f85c2e796fde container agnhost-container: <nil>
  STEP: delete the pod @ 05/11/25 13:54:53.658
  I0511 13:54:53.677375 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7333" for this suite. @ 05/11/25 13:54:53.68
• [4.086 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:208
  STEP: Creating a kubernetes client @ 05/11/25 13:54:53.687
  I0511 13:54:53.687039 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 13:54:53.688
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:54:53.696
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:54:53.699
  STEP: Creating a pod to test downward API volume plugin @ 05/11/25 13:54:53.702
  STEP: Saw pod success @ 05/11/25 13:54:57.723
  I0511 13:54:57.725795 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-a6564e72-c476-448c-9685-46347cf1a596 container client-container: <nil>
  STEP: delete the pod @ 05/11/25 13:54:57.731
  I0511 13:54:57.745791 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9497" for this suite. @ 05/11/25 13:54:57.749
• [4.067 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:488
  STEP: Creating a kubernetes client @ 05/11/25 13:54:57.754
  I0511 13:54:57.754981 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename deployment @ 05/11/25 13:54:57.756
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:54:57.766
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:54:57.77
  STEP: creating a Deployment @ 05/11/25 13:54:57.775
  I0511 13:54:57.775931 26 deployment.go:506] Creating simple deployment test-deployment-5xdrv
  I0511 13:54:57.788116 26 deployment.go:223] deployment "test-deployment-5xdrv" doesn't have the required revision set
  STEP: Getting /status @ 05/11/25 13:54:59.801
  I0511 13:54:59.804803 26 deployment.go:531] Deployment test-deployment-5xdrv has Conditions: [{Available True 2025-05-11 13:54:58 +0000 UTC 2025-05-11 13:54:58 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2025-05-11 13:54:58 +0000 UTC 2025-05-11 13:54:57 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-5xdrv-6fb4c74686" has successfully progressed.}]
  STEP: updating Deployment Status @ 05/11/25 13:54:59.804
  I0511 13:54:59.816035 26 deployment.go:551] updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 54, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 54, 58, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 13, 54, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 13, 54, 57, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-5xdrv-6fb4c74686\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 05/11/25 13:54:59.816
  I0511 13:54:59.818062 26 deployment.go:578] Observed &Deployment event: ADDED
  I0511 13:54:59.818131 26 deployment.go:574] Observed Deployment test-deployment-5xdrv in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-05-11 13:54:57 +0000 UTC 2025-05-11 13:54:57 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-5xdrv-6fb4c74686"}
  I0511 13:54:59.818320 26 deployment.go:578] Observed &Deployment event: MODIFIED
  I0511 13:54:59.818355 26 deployment.go:574] Observed Deployment test-deployment-5xdrv in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-05-11 13:54:57 +0000 UTC 2025-05-11 13:54:57 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-5xdrv-6fb4c74686"}
  I0511 13:54:59.818375 26 deployment.go:574] Observed Deployment test-deployment-5xdrv in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2025-05-11 13:54:57 +0000 UTC 2025-05-11 13:54:57 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0511 13:54:59.818570 26 deployment.go:578] Observed &Deployment event: MODIFIED
  I0511 13:54:59.818603 26 deployment.go:574] Observed Deployment test-deployment-5xdrv in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2025-05-11 13:54:57 +0000 UTC 2025-05-11 13:54:57 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0511 13:54:59.818623 26 deployment.go:574] Observed Deployment test-deployment-5xdrv in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-05-11 13:54:57 +0000 UTC 2025-05-11 13:54:57 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-5xdrv-6fb4c74686" is progressing.}
  I0511 13:54:59.818769 26 deployment.go:578] Observed &Deployment event: MODIFIED
  I0511 13:54:59.818801 26 deployment.go:574] Observed Deployment test-deployment-5xdrv in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2025-05-11 13:54:58 +0000 UTC 2025-05-11 13:54:58 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0511 13:54:59.818820 26 deployment.go:574] Observed Deployment test-deployment-5xdrv in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-05-11 13:54:58 +0000 UTC 2025-05-11 13:54:57 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-5xdrv-6fb4c74686" has successfully progressed.}
  I0511 13:54:59.818959 26 deployment.go:578] Observed &Deployment event: MODIFIED
  I0511 13:54:59.818990 26 deployment.go:574] Observed Deployment test-deployment-5xdrv in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2025-05-11 13:54:58 +0000 UTC 2025-05-11 13:54:58 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0511 13:54:59.819009 26 deployment.go:574] Observed Deployment test-deployment-5xdrv in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-05-11 13:54:58 +0000 UTC 2025-05-11 13:54:57 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-5xdrv-6fb4c74686" has successfully progressed.}
  I0511 13:54:59.819032 26 deployment.go:571] Found Deployment test-deployment-5xdrv in namespace deployment-2202 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0511 13:54:59.819055 26 deployment.go:582] Deployment test-deployment-5xdrv has an updated status
  STEP: patching the Statefulset Status @ 05/11/25 13:54:59.819
  I0511 13:54:59.819105 26 deployment.go:586] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0511 13:54:59.827017 26 deployment.go:590] Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 05/11/25 13:54:59.827
  I0511 13:54:59.829014 26 deployment.go:615] Observed &Deployment event: ADDED
  I0511 13:54:59.829073 26 deployment.go:611] Observed deployment test-deployment-5xdrv in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-05-11 13:54:57 +0000 UTC 2025-05-11 13:54:57 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-5xdrv-6fb4c74686"}
  I0511 13:54:59.829244 26 deployment.go:615] Observed &Deployment event: MODIFIED
  I0511 13:54:59.829277 26 deployment.go:611] Observed deployment test-deployment-5xdrv in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-05-11 13:54:57 +0000 UTC 2025-05-11 13:54:57 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-5xdrv-6fb4c74686"}
  I0511 13:54:59.829299 26 deployment.go:611] Observed deployment test-deployment-5xdrv in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2025-05-11 13:54:57 +0000 UTC 2025-05-11 13:54:57 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0511 13:54:59.829456 26 deployment.go:615] Observed &Deployment event: MODIFIED
  I0511 13:54:59.829503 26 deployment.go:611] Observed deployment test-deployment-5xdrv in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2025-05-11 13:54:57 +0000 UTC 2025-05-11 13:54:57 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0511 13:54:59.829530 26 deployment.go:611] Observed deployment test-deployment-5xdrv in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-05-11 13:54:57 +0000 UTC 2025-05-11 13:54:57 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-5xdrv-6fb4c74686" is progressing.}
  I0511 13:54:59.829699 26 deployment.go:615] Observed &Deployment event: MODIFIED
  I0511 13:54:59.829730 26 deployment.go:611] Observed deployment test-deployment-5xdrv in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2025-05-11 13:54:58 +0000 UTC 2025-05-11 13:54:58 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0511 13:54:59.829752 26 deployment.go:611] Observed deployment test-deployment-5xdrv in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-05-11 13:54:58 +0000 UTC 2025-05-11 13:54:57 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-5xdrv-6fb4c74686" has successfully progressed.}
  I0511 13:54:59.829942 26 deployment.go:615] Observed &Deployment event: MODIFIED
  I0511 13:54:59.829976 26 deployment.go:611] Observed deployment test-deployment-5xdrv in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2025-05-11 13:54:58 +0000 UTC 2025-05-11 13:54:58 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0511 13:54:59.829997 26 deployment.go:611] Observed deployment test-deployment-5xdrv in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-05-11 13:54:58 +0000 UTC 2025-05-11 13:54:57 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-5xdrv-6fb4c74686" has successfully progressed.}
  I0511 13:54:59.830019 26 deployment.go:611] Observed deployment test-deployment-5xdrv in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0511 13:54:59.830220 26 deployment.go:615] Observed &Deployment event: MODIFIED
  I0511 13:54:59.830260 26 deployment.go:608] Found deployment test-deployment-5xdrv in namespace deployment-2202 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  I0511 13:54:59.830288 26 deployment.go:619] Deployment test-deployment-5xdrv has a patched status
  I0511 13:54:59.835026 26 deployment.go:632] Deployment "test-deployment-5xdrv":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-5xdrv",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2202",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3d347b8b-c8c8-4db7-9c8d-48d655d84a71",
      ResourceVersion: (string) (len=5) "10033",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882568497,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=3) "e2e": (string) (len=7) "testing"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568497,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568499,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568499,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=3) "e2e": (string) (len=7) "testing"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=3) "e2e": (string) (len=7) "testing"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568499,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568499,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=56) "Found new replica set \"test-deployment-5xdrv-6fb4c74686\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0511 13:54:59.898823 26 deployment.go:40] New ReplicaSet "test-deployment-5xdrv-6fb4c74686" of Deployment "test-deployment-5xdrv":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-5xdrv-6fb4c74686",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2202",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4588a8d7-b653-4f16-8885-d175b84cc2e7",
      ResourceVersion: (string) (len=5) "10026",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882568497,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fb4c74686"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-5xdrv",
          UID: (types.UID) (len=36) "3d347b8b-c8c8-4db7-9c8d-48d655d84a71",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568497,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 33 64 33  |k:{\"uid\":\"3d3|
              00000120  34 37 62 38 62 2d 63 38  63 38 2d 34 64 62 37 2d  |47b8b-c8c8-4db7-|
              00000130  39 63 38 64 2d 34 38 64  36 35 35 64 38 34 61 37  |9c8d-48d655d84a7|
              00000140  31 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |1\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568498,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6fb4c74686",
          (string) (len=3) "e2e": (string) (len=7) "testing"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6fb4c74686"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0511 13:54:59.904937 26 deployment.go:68] Pod "test-deployment-5xdrv-6fb4c74686-z5ftv" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=38) "test-deployment-5xdrv-6fb4c74686-z5ftv",
      GenerateName: (string) (len=33) "test-deployment-5xdrv-6fb4c74686-",
      Namespace: (string) (len=15) "deployment-2202",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "939dff25-5421-4cba-be27-4e079059f045",
      ResourceVersion: (string) (len=5) "10025",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882568497,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fb4c74686"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=32) "test-deployment-5xdrv-6fb4c74686",
          UID: (types.UID) (len=36) "4588a8d7-b653-4f16-8885-d175b84cc2e7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568497,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 34 35 38 38 61 38 64  37 2d 62 36 35 33 2d 34  |"4588a8d7-b653-4|
              000000a0  66 31 36 2d 38 38 38 35  2d 64 31 37 35 62 38 34  |f16-8885-d175b84|
              000000b0  63 63 32 65 37 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |cc2e7\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568498,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 31  32 35 5c 22 7d 22 3a 7b  |.244.1.125\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-hwhbz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-hwhbz",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568498,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568497,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568498,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568498,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882568497,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.3"
        }
      },
      PodIP: (string) (len=12) "10.244.1.125",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.1.125"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882568497,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63882568498,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://eb70a528d6a197d4800e03bfe1d449ffa84c069b7c0466a879dc1b32280fa3a4",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-hwhbz",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 13:54:59.907118 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2202" for this suite. @ 05/11/25 13:54:59.91
• [2.160 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:753
  STEP: Creating a kubernetes client @ 05/11/25 13:54:59.916
  I0511 13:54:59.916184 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename services @ 05/11/25 13:54:59.917
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:54:59.928
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:54:59.931
  STEP: creating service endpoint-test2 in namespace services-8669 @ 05/11/25 13:54:59.934
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8669 to expose endpoints map[] @ 05/11/25 13:54:59.949
  I0511 13:54:59.954252      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 13:54:59.958540 26 service.go:4645] successfully validated that service endpoint-test2 in namespace services-8669 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-8669 @ 05/11/25 13:54:59.958
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8669 to expose endpoints map[pod1:[80]] @ 05/11/25 13:55:01.974
  I0511 13:55:01.979079      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 13:55:01.982878 26 service.go:4645] successfully validated that service endpoint-test2 in namespace services-8669 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 05/11/25 13:55:01.982
  I0511 13:55:01.982945 26 resource.go:361] Creating new exec pod
  I0511 13:55:03.999887 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-8669 exec execpodxv4bf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0511 13:55:04.089533 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 (10.107.231.253) 80 port [tcp/http] succeeded!\n"
  I0511 13:55:04.089584 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 13:55:04.089672 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-8669 exec execpodxv4bf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.107.231.253 80'
  I0511 13:55:04.184876 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.107.231.253 80\nConnection to 10.107.231.253 80 port [tcp/http] succeeded!\n"
  I0511 13:55:04.184925 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-8669 @ 05/11/25 13:55:04.184
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8669 to expose endpoints map[pod1:[80] pod2:[80]] @ 05/11/25 13:55:06.201
  I0511 13:55:06.207292      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 13:55:06.211544 26 service.go:4645] successfully validated that service endpoint-test2 in namespace services-8669 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 05/11/25 13:55:06.211
  I0511 13:55:06.213855 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-8669 exec execpodxv4bf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0511 13:55:06.344513 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 (10.107.231.253) 80 port [tcp/http] succeeded!\n"
  I0511 13:55:06.344573 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 13:55:06.344683 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-8669 exec execpodxv4bf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.107.231.253 80'
  I0511 13:55:06.458725 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.107.231.253 80\nConnection to 10.107.231.253 80 port [tcp/http] succeeded!\n"
  I0511 13:55:06.458814 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-8669 @ 05/11/25 13:55:06.458
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8669 to expose endpoints map[pod2:[80]] @ 05/11/25 13:55:06.47
  I0511 13:55:06.481374      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 13:55:06.487557 26 service.go:4645] successfully validated that service endpoint-test2 in namespace services-8669 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 05/11/25 13:55:06.487
  I0511 13:55:06.492019 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-8669 exec execpodxv4bf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0511 13:55:06.592083 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 (10.107.231.253) 80 port [tcp/http] succeeded!\n"
  I0511 13:55:06.592160 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 13:55:06.592331 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-8669 exec execpodxv4bf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.107.231.253 80'
  I0511 13:55:06.697082 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.107.231.253 80\nConnection to 10.107.231.253 80 port [tcp/http] succeeded!\n"
  I0511 13:55:06.697165 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-8669 @ 05/11/25 13:55:06.697
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8669 to expose endpoints map[] @ 05/11/25 13:55:06.708
  I0511 13:55:06.712517      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 13:55:06.718309 26 service.go:4645] successfully validated that service endpoint-test2 in namespace services-8669 exposes endpoints map[]
  I0511 13:55:06.734138 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8669" for this suite. @ 05/11/25 13:55:06.737
• [6.826 seconds]
------------------------------
S
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:71
  STEP: Creating a kubernetes client @ 05/11/25 13:55:06.744
  I0511 13:55:06.744318 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename replication-controller @ 05/11/25 13:55:06.744
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:55:06.751
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:55:06.754
  STEP: Creating replication controller my-hostname-basic-c58f29ae-60dc-438a-a63d-debbb16d1116 @ 05/11/25 13:55:06.755
  I0511 13:55:06.763143 26 resource.go:81] Pod name my-hostname-basic-c58f29ae-60dc-438a-a63d-debbb16d1116: Found 0 pods out of 1
  I0511 13:55:11.767712 26 resource.go:81] Pod name my-hostname-basic-c58f29ae-60dc-438a-a63d-debbb16d1116: Found 1 pods out of 1
  I0511 13:55:11.767772 26 rc.go:509] Ensuring all pods for ReplicationController "my-hostname-basic-c58f29ae-60dc-438a-a63d-debbb16d1116" are running
  I0511 13:55:11.770621 26 rc.go:525] Pod "my-hostname-basic-c58f29ae-60dc-438a-a63d-debbb16d1116-k8bk5" is running and ready(conditions: [{Type:PodReadyToStartContainers ObservedGeneration:0 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-05-11 13:55:07 +0000 UTC Reason: Message:} {Type:Initialized ObservedGeneration:0 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-05-11 13:55:06 +0000 UTC Reason: Message:} {Type:Ready ObservedGeneration:0 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-05-11 13:55:07 +0000 UTC Reason: Message:} {Type:ContainersReady ObservedGeneration:0 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-05-11 13:55:07 +0000 UTC Reason: Message:} {Type:PodScheduled ObservedGeneration:0 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-05-11 13:55:06 +0000 UTC Reason: Message:}])
  I0511 13:55:11.770653 26 rc.go:533] Trying to dial the pod
  STEP: trying to dial each unique pod @ 05/11/25 13:55:11.77
  I0511 13:55:11.855084 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-4838" for this suite. @ 05/11/25 13:55:11.857
• [5.116 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:311
  STEP: Creating a kubernetes client @ 05/11/25 13:55:11.86
  I0511 13:55:11.860582 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/11/25 13:55:11.861
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:55:11.868
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:55:11.871
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 05/11/25 13:55:11.873
  I0511 13:55:11.873509 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 05/11/25 13:55:16.635
  I0511 13:55:16.635986 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  I0511 13:55:17.772245 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  I0511 13:55:22.408943 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4401" for this suite. @ 05/11/25 13:55:22.413
• [10.559 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 05/11/25 13:55:22.419
  I0511 13:55:22.419295 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename apf @ 05/11/25 13:55:22.42
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:55:22.426
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:55:22.428
  STEP: getting /apis @ 05/11/25 13:55:22.429
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 05/11/25 13:55:22.431
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 05/11/25 13:55:22.432
  STEP: creating @ 05/11/25 13:55:22.433
  STEP: getting @ 05/11/25 13:55:22.442
  STEP: listing @ 05/11/25 13:55:22.443
  STEP: watching @ 05/11/25 13:55:22.445
  I0511 13:55:22.445195 26 flowcontrol.go:620] starting watch
  STEP: patching @ 05/11/25 13:55:22.445
  STEP: updating @ 05/11/25 13:55:22.449
  I0511 13:55:22.454123 26 flowcontrol.go:648] waiting for watch events with expected annotations
  STEP: getting /status @ 05/11/25 13:55:22.454
  STEP: patching /status @ 05/11/25 13:55:22.456
  STEP: updating /status @ 05/11/25 13:55:22.46
  STEP: deleting @ 05/11/25 13:55:22.465
  STEP: deleting a collection @ 05/11/25 13:55:22.47
  I0511 13:55:22.481785 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-4245" for this suite. @ 05/11/25 13:55:22.514
• [0.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:258
  STEP: Creating a kubernetes client @ 05/11/25 13:55:22.518
  I0511 13:55:22.518455 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 13:55:22.519
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:55:22.526
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:55:22.529
  STEP: Setting up server cert @ 05/11/25 13:55:22.544
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 13:55:22.672
  STEP: Deploying the webhook pod @ 05/11/25 13:55:22.675
  STEP: Wait for the deployment to be ready @ 05/11/25 13:55:22.682
  I0511 13:55:22.685762 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/11/25 13:55:24.695
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 13:55:24.711
  I0511 13:55:25.712344 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 05/11/25 13:55:25.717
  STEP: create a pod that should be updated by the webhook @ 05/11/25 13:55:25.736
  I0511 13:55:25.790168 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2023" for this suite. @ 05/11/25 13:55:25.792
  STEP: Destroying namespace "webhook-markers-2779" for this suite. @ 05/11/25 13:55:25.796
• [3.282 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 05/11/25 13:55:25.8
  I0511 13:55:25.800067 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename cronjob @ 05/11/25 13:55:25.8
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:55:25.805
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:55:25.807
  STEP: Creating a cronjob @ 05/11/25 13:55:25.808
  STEP: Ensuring more than one job is running at a time @ 05/11/25 13:55:25.811
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 05/11/25 13:57:01.818
  STEP: Removing cronjob @ 05/11/25 13:57:01.821
  I0511 13:57:01.826350 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-6009" for this suite. @ 05/11/25 13:57:01.829
• [96.034 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:83
  STEP: Creating a kubernetes client @ 05/11/25 13:57:01.834
  I0511 13:57:01.834980 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename resourcequota @ 05/11/25 13:57:01.836
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:57:01.845
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:57:01.847
  STEP: Counting existing ResourceQuota @ 05/11/25 13:57:01.85
  STEP: Creating a ResourceQuota @ 05/11/25 13:57:06.853
  STEP: Ensuring resource quota status is calculated @ 05/11/25 13:57:06.857
  I0511 13:57:08.861913 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9415" for this suite. @ 05/11/25 13:57:08.864
• [7.036 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:179
  STEP: Creating a kubernetes client @ 05/11/25 13:57:08.871
  I0511 13:57:08.871102 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename emptydir @ 05/11/25 13:57:08.872
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:57:08.881
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:57:08.884
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 05/11/25 13:57:08.887
  STEP: Saw pod success @ 05/11/25 13:57:12.906
  I0511 13:57:12.909245 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-3eaba429-a916-4158-81c0-520bfde2cdde container test-container: <nil>
  STEP: delete the pod @ 05/11/25 13:57:12.925
  I0511 13:57:12.938022 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-262" for this suite. @ 05/11/25 13:57:12.94
• [4.072 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:69
  STEP: Creating a kubernetes client @ 05/11/25 13:57:12.943
  I0511 13:57:12.943241 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 13:57:12.944
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:57:12.949
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:57:12.95
  STEP: Creating a pod to test downward API volume plugin @ 05/11/25 13:57:12.952
  STEP: Saw pod success @ 05/11/25 13:57:16.969
  I0511 13:57:16.972203 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-5f7df5b5-7d8f-4398-bd82-5d058bf6e579 container client-container: <nil>
  STEP: delete the pod @ 05/11/25 13:57:16.978
  I0511 13:57:16.991257 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3263" for this suite. @ 05/11/25 13:57:16.994
• [4.056 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 05/11/25 13:57:17
  I0511 13:57:17.000583 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename init-container @ 05/11/25 13:57:17.001
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:57:17.009
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:57:17.013
  STEP: creating the pod @ 05/11/25 13:57:17.016
  I0511 13:57:17.016064 26 init_container.go:294] PodSpec: initContainers in spec.initContainers
  I0511 13:57:19.968272 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-9465" for this suite. @ 05/11/25 13:57:19.971
• [2.974 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:114
  STEP: Creating a kubernetes client @ 05/11/25 13:57:19.974
  I0511 13:57:19.974812 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename replication-controller @ 05/11/25 13:57:19.975
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:57:19.981
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:57:19.982
  STEP: creating a ReplicationController @ 05/11/25 13:57:19.985
  STEP: waiting for RC to be added @ 05/11/25 13:57:19.988
  STEP: waiting for available Replicas @ 05/11/25 13:57:19.988
  STEP: patching ReplicationController @ 05/11/25 13:57:20.995
  STEP: waiting for RC to be modified @ 05/11/25 13:57:21.005
  STEP: patching ReplicationController status @ 05/11/25 13:57:21.005
  STEP: waiting for RC to be modified @ 05/11/25 13:57:21.009
  STEP: waiting for available Replicas @ 05/11/25 13:57:21.009
  STEP: fetching ReplicationController status @ 05/11/25 13:57:21.013
  STEP: patching ReplicationController scale @ 05/11/25 13:57:21.014
  STEP: waiting for RC to be modified @ 05/11/25 13:57:21.018
  STEP: waiting for ReplicationController's scale to be the max amount @ 05/11/25 13:57:21.018
  STEP: fetching ReplicationController; ensuring that it's patched @ 05/11/25 13:57:21.983
  STEP: updating ReplicationController status @ 05/11/25 13:57:21.985
  STEP: waiting for RC to be modified @ 05/11/25 13:57:21.988
  STEP: listing all ReplicationControllers @ 05/11/25 13:57:21.989
  STEP: checking that ReplicationController has expected values @ 05/11/25 13:57:21.99
  STEP: deleting ReplicationControllers by collection @ 05/11/25 13:57:21.99
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 05/11/25 13:57:21.997
  I0511 13:57:22.036734 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0511 13:57:22.036874      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-9214" for this suite. @ 05/11/25 13:57:22.038
• [2.066 seconds]
------------------------------
SSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:215
  STEP: Creating a kubernetes client @ 05/11/25 13:57:22.041
  I0511 13:57:22.041150 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/11/25 13:57:22.042
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:57:22.048
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:57:22.05
  STEP: create the container to handle the HTTPGet hook request. @ 05/11/25 13:57:22.139
  E0511 13:57:23.038239      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:24.039161      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/11/25 13:57:24.245
  E0511 13:57:25.039086      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:26.039750      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 05/11/25 13:57:26.263
  E0511 13:57:27.040808      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:28.041733      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 05/11/25 13:57:28.278
  I0511 13:57:28.297677 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-8447" for this suite. @ 05/11/25 13:57:28.301
• [6.266 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 05/11/25 13:57:28.307
  I0511 13:57:28.307075 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename cronjob @ 05/11/25 13:57:28.308
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 13:57:28.319
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 13:57:28.321
  STEP: Creating a suspended cronjob @ 05/11/25 13:57:28.323
  STEP: Ensuring no jobs are scheduled @ 05/11/25 13:57:28.328
  E0511 13:57:29.042571      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:30.042610      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:31.042741      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:32.043907      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:33.044263      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:34.044735      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:35.045890      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:36.046264      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:37.046287      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:38.046899      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:39.046896      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:40.047051      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:41.047686      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:42.048085      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:43.049154      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:44.049773      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:45.049871      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:46.050455      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:47.051003      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:48.051554      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:49.052701      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:50.053548      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:51.053791      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:52.054256      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:53.054521      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:54.055119      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:55.055297      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:56.055804      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:57.056855      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:58.058038      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:57:59.058116      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:00.058605      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:01.059290      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:02.059604      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:03.060934      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:04.062042      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:05.062940      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:06.063594      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:07.064567      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:08.065088      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:09.065382      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:10.065539      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:11.065809      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:12.066834      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:13.067637      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:14.068184      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:15.068280      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:16.068788      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:17.069755      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:18.070280      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:19.070733      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:20.071071      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:21.071884      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:22.072246      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:23.072729      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:24.073188      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:25.073339      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:26.073864      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:27.074569      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:28.074873      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:29.075892      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:30.076054      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:31.076839      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:32.077331      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:33.077650      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:34.077942      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:35.078984      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:36.079505      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:37.080287      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:38.080716      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:39.080823      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:40.081636      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:41.081859      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:42.082408      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:43.083334      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:44.083907      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:45.084551      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:46.084842      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:47.084852      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:48.085276      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:49.085558      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:50.086058      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:51.086899      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:52.087418      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:53.087772      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:54.088297      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:55.089347      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:56.089810      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:57.089957      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:58.090443      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:58:59.090647      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:00.090897      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:01.091255      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:02.091577      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:03.091978      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:04.092649      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:05.092776      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:06.093204      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:07.093547      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:08.094137      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:09.095079      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:10.095427      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:11.095503      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:12.095787      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:13.096523      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:14.096908      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:15.097915      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:16.098306      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:17.098399      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:18.098703      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:19.099573      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:20.100050      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:21.100233      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:22.100635      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:23.101083      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:24.101593      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:25.101597      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:26.101775      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:27.102694      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:28.102878      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:29.103224      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:30.103844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:31.104976      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:32.105519      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:33.106662      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:34.107209      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:35.107899      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:36.108099      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:37.108182      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:38.108834      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:39.109819      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:40.110161      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:41.110694      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:42.111242      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:43.111626      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:44.112269      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:45.112856      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:46.113445      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:47.113641      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:48.114054      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:49.114200      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:50.114538      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:51.115586      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:52.116145      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:53.117139      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:54.117606      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:55.118868      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:56.119260      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:57.119762      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:58.119925      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 13:59:59.120039      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:00.120435      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:01.120658      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:02.120899      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:03.121355      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:04.121719      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:05.122580      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:06.122861      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:07.123346      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:08.123810      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:09.123909      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:10.125006      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:11.126046      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:12.126484      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:13.126667      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:14.127129      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:15.127425      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:16.127945      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:17.128251      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:18.128715      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:19.129036      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:20.129879      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:21.130921      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:22.131809      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:23.132505      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:24.132843      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:25.133615      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:26.134094      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:27.134528      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:28.134793      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:29.134907      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:30.135386      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:31.135650      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:32.136079      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:33.136944      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:34.137988      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:35.138201      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:36.138775      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:37.138917      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:38.139451      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:39.139627      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:40.139790      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:41.139987      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:42.140875      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:43.141887      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:44.142732      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:45.143531      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:46.143994      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:47.144062      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:48.144677      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:49.145627      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:50.145939      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:51.146810      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:52.147399      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:53.147636      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:54.148177      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:55.148434      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:56.149278      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:57.149597      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:58.149827      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:00:59.150085      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:00.150376      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:01.150668      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:02.151139      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:03.152192      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:04.152856      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:05.153899      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:06.154487      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:07.155099      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:08.155589      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:09.155811      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:10.156832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:11.157935      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:12.158538      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:13.159536      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:14.159731      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:15.160623      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:16.160741      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:17.161721      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:18.162297      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:19.162986      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:20.163341      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:21.163611      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:22.164056      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:23.164948      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:24.165105      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:25.165924      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:26.166776      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:27.167100      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:28.167688      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:29.168392      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:30.168587      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:31.168668      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:32.169102      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:33.169217      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:34.169737      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:35.169849      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:36.170368      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:37.171057      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:38.171649      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:39.171784      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:40.172356      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:41.173237      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:42.173913      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:43.174689      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:44.174772      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:45.175688      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:46.176268      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:47.177133      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:48.177685      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:49.178345      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:50.178696      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:51.179385      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:52.179784      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:53.180776      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:54.180977      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:55.182059      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:56.182841      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:57.183617      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:58.184093      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:01:59.185085      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:00.185368      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:01.185403      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:02.185815      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:03.186614      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:04.187153      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:05.187219      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:06.187652      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:07.188086      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:08.188417      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:09.188848      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:10.189144      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:11.189852      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:12.190111      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:13.190567      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:14.190777      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:15.191786      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:16.192946      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:17.193351      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:18.193720      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:19.194812      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:20.195314      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:21.195998      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:22.196446      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:23.197200      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:24.197910      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:25.198916      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:26.199352      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:27.200006      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:28.200802      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 05/11/25 14:02:28.328
  STEP: Removing cronjob @ 05/11/25 14:02:28.33
  I0511 14:02:28.334742 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-2171" for this suite. @ 05/11/25 14:02:28.336
• [300.034 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 05/11/25 14:02:28.341
  I0511 14:02:28.341788 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename container-runtime @ 05/11/25 14:02:28.342
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:02:28.348
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:02:28.35
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 05/11/25 14:02:28.358
  E0511 14:02:29.201793      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:30.202885      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:31.203316      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:32.204229      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:33.204278      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:34.204660      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:35.205711      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:36.205795      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:37.206444      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:38.206871      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:39.207786      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:40.208406      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:41.208626      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:42.209774      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:43.209980      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:44.210831      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:45.211094      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:46.211816      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 05/11/25 14:02:46.445
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 05/11/25 14:02:46.447
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 05/11/25 14:02:46.452
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 05/11/25 14:02:46.452
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 05/11/25 14:02:46.471
  E0511 14:02:47.211967      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:48.212762      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 05/11/25 14:02:48.482
  E0511 14:02:49.213590      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 05/11/25 14:02:49.49
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 05/11/25 14:02:49.496
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 05/11/25 14:02:49.496
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 05/11/25 14:02:49.515
  E0511 14:02:50.213758      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 05/11/25 14:02:50.522
  E0511 14:02:51.214353      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 05/11/25 14:02:51.53
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 05/11/25 14:02:51.535
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 05/11/25 14:02:51.535
  I0511 14:02:51.557111 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-9080" for this suite. @ 05/11/25 14:02:51.56
• [23.227 seconds]
------------------------------
S
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:99
  STEP: Creating a kubernetes client @ 05/11/25 14:02:51.568
  I0511 14:02:51.568567 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename configmap @ 05/11/25 14:02:51.569
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:02:51.578
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:02:51.581
  STEP: Creating configMap with name configmap-test-volume-map-356d6bb6-00eb-4015-a35e-3082dbfec3b5 @ 05/11/25 14:02:51.583
  STEP: Creating a pod to test consume configMaps @ 05/11/25 14:02:51.587
  E0511 14:02:52.214597      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:53.214938      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:02:53.602
  I0511 14:02:53.605496 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-fe0e2d07-0e8b-4f86-8ae4-a26bfd97b2b2 container agnhost-container: <nil>
  STEP: delete the pod @ 05/11/25 14:02:53.62
  I0511 14:02:53.634540 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7703" for this suite. @ 05/11/25 14:02:53.637
• [2.074 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:331
  STEP: Creating a kubernetes client @ 05/11/25 14:02:53.642
  I0511 14:02:53.642245 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename sched-pred @ 05/11/25 14:02:53.643
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:02:53.652
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:02:53.655
  I0511 14:02:53.657624 26 helper.go:125] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0511 14:02:53.743508 26 util.go:390] Waiting for terminating namespaces to be deleted...
  I0511 14:02:53.746510 26 predicates.go:118] 
  Logging pods the apiserver thinks is on node k8sconformance before test
  I0511 14:02:53.750420 26 predicates.go:956] coredns-674b8bbfcf-68gnm from kube-system started at 2025-05-11 13:00:07 +0000 UTC (1 container statuses recorded)
  I0511 14:02:53.750456 26 predicates.go:958] 	Container coredns ready: true, restart count 4
  I0511 14:02:53.750481 26 predicates.go:956] etcd-k8sconformance from kube-system started at 2025-05-11 13:00:02 +0000 UTC (1 container statuses recorded)
  I0511 14:02:53.750493 26 predicates.go:958] 	Container etcd ready: true, restart count 0
  I0511 14:02:53.750505 26 predicates.go:956] kindnet-cs969 from kube-system started at 2025-05-11 13:00:07 +0000 UTC (1 container statuses recorded)
  I0511 14:02:53.750516 26 predicates.go:958] 	Container kindnet-cni ready: true, restart count 0
  I0511 14:02:53.750527 26 predicates.go:956] kube-apiserver-k8sconformance from kube-system started at 2025-05-11 13:00:02 +0000 UTC (1 container statuses recorded)
  I0511 14:02:53.750537 26 predicates.go:958] 	Container kube-apiserver ready: true, restart count 0
  I0511 14:02:53.750548 26 predicates.go:956] kube-controller-manager-k8sconformance from kube-system started at 2025-05-11 13:00:02 +0000 UTC (1 container statuses recorded)
  I0511 14:02:53.750558 26 predicates.go:958] 	Container kube-controller-manager ready: true, restart count 0
  I0511 14:02:53.750568 26 predicates.go:956] kube-proxy-ssjxm from kube-system started at 2025-05-11 13:00:07 +0000 UTC (1 container statuses recorded)
  I0511 14:02:53.750577 26 predicates.go:958] 	Container kube-proxy ready: true, restart count 0
  I0511 14:02:53.750587 26 predicates.go:956] kube-scheduler-k8sconformance from kube-system started at 2025-05-11 13:00:02 +0000 UTC (1 container statuses recorded)
  I0511 14:02:53.750596 26 predicates.go:958] 	Container kube-scheduler ready: true, restart count 0
  I0511 14:02:53.750606 26 predicates.go:956] storage-provisioner from kube-system started at 2025-05-11 13:00:08 +0000 UTC (1 container statuses recorded)
  I0511 14:02:53.750615 26 predicates.go:958] 	Container storage-provisioner ready: true, restart count 0
  I0511 14:02:53.750625 26 predicates.go:956] sonobuoy-systemd-logs-daemon-set-3b1a685ddb394b60-rggfh from sonobuoy started at 2025-05-11 13:02:10 +0000 UTC (2 container statuses recorded)
  I0511 14:02:53.750635 26 predicates.go:958] 	Container sonobuoy-worker ready: true, restart count 0
  I0511 14:02:53.750644 26 predicates.go:958] 	Container systemd-logs ready: true, restart count 0
  I0511 14:02:53.750653 26 predicates.go:118] 
  Logging pods the apiserver thinks is on node k8sconformance-m02 before test
  I0511 14:02:53.753595 26 predicates.go:956] kindnet-5r7wn from kube-system started at 2025-05-11 13:31:32 +0000 UTC (1 container statuses recorded)
  I0511 14:02:53.753628 26 predicates.go:958] 	Container kindnet-cni ready: true, restart count 0
  I0511 14:02:53.753643 26 predicates.go:956] kube-proxy-wwbpc from kube-system started at 2025-05-11 13:00:19 +0000 UTC (1 container statuses recorded)
  I0511 14:02:53.753655 26 predicates.go:958] 	Container kube-proxy ready: true, restart count 0
  I0511 14:02:53.753666 26 predicates.go:956] sonobuoy from sonobuoy started at 2025-05-11 13:01:52 +0000 UTC (1 container statuses recorded)
  I0511 14:02:53.753675 26 predicates.go:958] 	Container kube-sonobuoy ready: true, restart count 0
  I0511 14:02:53.753688 26 predicates.go:956] sonobuoy-e2e-job-32c36e3a15c942ea from sonobuoy started at 2025-05-11 13:02:10 +0000 UTC (2 container statuses recorded)
  I0511 14:02:53.753699 26 predicates.go:958] 	Container e2e ready: true, restart count 0
  I0511 14:02:53.753708 26 predicates.go:958] 	Container sonobuoy-worker ready: true, restart count 0
  I0511 14:02:53.753719 26 predicates.go:956] sonobuoy-systemd-logs-daemon-set-3b1a685ddb394b60-t2p28 from sonobuoy started at 2025-05-11 13:02:10 +0000 UTC (2 container statuses recorded)
  I0511 14:02:53.753734 26 predicates.go:958] 	Container sonobuoy-worker ready: true, restart count 0
  I0511 14:02:53.753743 26 predicates.go:958] 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node k8sconformance @ 05/11/25 14:02:53.765
  STEP: verifying the node has the label node k8sconformance-m02 @ 05/11/25 14:02:53.777
  I0511 14:02:53.852721 26 predicates.go:371] Pod coredns-674b8bbfcf-68gnm requesting resource cpu=100m on Node k8sconformance
  I0511 14:02:53.852757 26 predicates.go:371] Pod etcd-k8sconformance requesting resource cpu=100m on Node k8sconformance
  I0511 14:02:53.852770 26 predicates.go:371] Pod kindnet-5r7wn requesting resource cpu=100m on Node k8sconformance-m02
  I0511 14:02:53.852780 26 predicates.go:371] Pod kindnet-cs969 requesting resource cpu=100m on Node k8sconformance
  I0511 14:02:53.852795 26 predicates.go:371] Pod kube-apiserver-k8sconformance requesting resource cpu=250m on Node k8sconformance
  I0511 14:02:53.852805 26 predicates.go:371] Pod kube-controller-manager-k8sconformance requesting resource cpu=200m on Node k8sconformance
  I0511 14:02:53.852815 26 predicates.go:371] Pod kube-proxy-ssjxm requesting resource cpu=0m on Node k8sconformance
  I0511 14:02:53.852827 26 predicates.go:371] Pod kube-proxy-wwbpc requesting resource cpu=0m on Node k8sconformance-m02
  I0511 14:02:53.852837 26 predicates.go:371] Pod kube-scheduler-k8sconformance requesting resource cpu=100m on Node k8sconformance
  I0511 14:02:53.852846 26 predicates.go:371] Pod storage-provisioner requesting resource cpu=0m on Node k8sconformance
  I0511 14:02:53.852856 26 predicates.go:371] Pod sonobuoy requesting resource cpu=0m on Node k8sconformance-m02
  I0511 14:02:53.852865 26 predicates.go:371] Pod sonobuoy-e2e-job-32c36e3a15c942ea requesting resource cpu=0m on Node k8sconformance-m02
  I0511 14:02:53.852875 26 predicates.go:371] Pod sonobuoy-systemd-logs-daemon-set-3b1a685ddb394b60-rggfh requesting resource cpu=0m on Node k8sconformance
  I0511 14:02:53.852890 26 predicates.go:371] Pod sonobuoy-systemd-logs-daemon-set-3b1a685ddb394b60-t2p28 requesting resource cpu=0m on Node k8sconformance-m02
  STEP: Starting Pods to consume most of the cluster CPU. @ 05/11/25 14:02:53.852
  I0511 14:02:53.852934 26 predicates.go:381] Creating a pod which consumes cpu=7805m on Node k8sconformance
  I0511 14:02:53.860706 26 predicates.go:381] Creating a pod which consumes cpu=8330m on Node k8sconformance-m02
  E0511 14:02:54.215420      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:55.215779      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 05/11/25 14:02:55.88
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-10543d88-3e56-4569-951d-575a2ff85c08.183e7defb03b1adb], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5390/filler-pod-10543d88-3e56-4569-951d-575a2ff85c08 to k8sconformance-m02] @ 05/11/25 14:02:55.883
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-10543d88-3e56-4569-951d-575a2ff85c08.183e7defccf8cbb8], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.10" already present on machine] @ 05/11/25 14:02:55.884
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-10543d88-3e56-4569-951d-575a2ff85c08.183e7defcf5addfa], Reason = [Created], Message = [Created container: filler-pod-10543d88-3e56-4569-951d-575a2ff85c08] @ 05/11/25 14:02:55.884
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-10543d88-3e56-4569-951d-575a2ff85c08.183e7defd4a6b73b], Reason = [Started], Message = [Started container filler-pod-10543d88-3e56-4569-951d-575a2ff85c08] @ 05/11/25 14:02:55.884
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-c9c2fa98-3fc3-4bb7-aada-445dad90e491.183e7defafcdd4ee], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5390/filler-pod-c9c2fa98-3fc3-4bb7-aada-445dad90e491 to k8sconformance] @ 05/11/25 14:02:55.884
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-c9c2fa98-3fc3-4bb7-aada-445dad90e491.183e7defcca0ffdc], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.10" already present on machine] @ 05/11/25 14:02:55.884
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-c9c2fa98-3fc3-4bb7-aada-445dad90e491.183e7defcf0733c7], Reason = [Created], Message = [Created container: filler-pod-c9c2fa98-3fc3-4bb7-aada-445dad90e491] @ 05/11/25 14:02:55.884
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-c9c2fa98-3fc3-4bb7-aada-445dad90e491.183e7defd46f761c], Reason = [Started], Message = [Started container filler-pod-c9c2fa98-3fc3-4bb7-aada-445dad90e491] @ 05/11/25 14:02:55.884
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.183e7df0288a19e7], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.] @ 05/11/25 14:02:55.897
  E0511 14:02:56.216673      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: removing the label node off the node k8sconformance @ 05/11/25 14:02:56.898
  STEP: verifying the node doesn't have the label node @ 05/11/25 14:02:56.909
  STEP: removing the label node off the node k8sconformance-m02 @ 05/11/25 14:02:56.913
  STEP: verifying the node doesn't have the label node @ 05/11/25 14:02:56.924
  I0511 14:02:56.928622 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-5390" for this suite. @ 05/11/25 14:02:56.932
• [3.297 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3220
  STEP: Creating a kubernetes client @ 05/11/25 14:02:56.94
  I0511 14:02:56.940051 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename services @ 05/11/25 14:02:56.941
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:02:56.954
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:02:56.959
  I0511 14:02:56.967057      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: creating an Endpoint @ 05/11/25 14:02:56.967
  I0511 14:02:56.971259      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: waiting for available Endpoint @ 05/11/25 14:02:56.971
  I0511 14:02:56.973409      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: listing all Endpoints @ 05/11/25 14:02:56.973
  I0511 14:02:56.976133      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: updating the Endpoint @ 05/11/25 14:02:56.976
  I0511 14:02:56.980114      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 14:02:56.981525      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: fetching the Endpoint @ 05/11/25 14:02:56.981
  I0511 14:02:56.983655      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: patching the Endpoint @ 05/11/25 14:02:56.983
  I0511 14:02:56.987921      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 14:02:56.988821      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: fetching the Endpoint @ 05/11/25 14:02:56.988
  I0511 14:02:56.990039      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: deleting the Endpoint by Collection @ 05/11/25 14:02:56.99
  I0511 14:02:56.993475      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: waiting for Endpoint deletion @ 05/11/25 14:02:56.993
  I0511 14:02:56.994114      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: fetching the Endpoint @ 05/11/25 14:02:56.994
  I0511 14:02:56.995593      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 14:02:56.995686 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-29" for this suite. @ 05/11/25 14:02:56.997
• [0.061 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:329
  STEP: Creating a kubernetes client @ 05/11/25 14:02:57
  I0511 14:02:57.000659 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename statefulset @ 05/11/25 14:02:57.001
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:02:57.007
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:02:57.008
  STEP: Creating service test in namespace statefulset-3225 @ 05/11/25 14:02:57.01
  STEP: Creating a new StatefulSet @ 05/11/25 14:02:57.014
  I0511 14:02:57.019586 26 wait.go:44] Found 0 stateful pods, waiting for 3
  E0511 14:02:57.217203      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:58.217708      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:02:59.217844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:00.218698      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:01.219157      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:02.219642      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:03.220093      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:04.220605      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:05.220916      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:06.221417      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:03:07.023255 26 wait.go:54] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0511 14:03:07.023299 26 wait.go:54] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0511 14:03:07.023315 26 wait.go:54] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  I0511 14:03:07.030607 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=statefulset-3225 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0511 14:03:07.129270 26 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0511 14:03:07.129330 26 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0511 14:03:07.129352 26 statefulset.go:2485] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0511 14:03:07.221867      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:08.221989      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:09.222576      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:10.222755      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:11.222884      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:12.224019      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:13.224498      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:14.224697      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:15.225698      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:16.226056      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 05/11/25 14:03:17.136
  I0511 14:03:17.144512 26 statefulset.go:2542] Updating stateful set ss2
  STEP: Creating a new revision @ 05/11/25 14:03:17.144
  E0511 14:03:17.226665      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:18.227232      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:19.227615      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:20.227761      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:21.228279      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:22.229007      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:23.229342      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:24.229881      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:25.230872      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:26.231264      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 05/11/25 14:03:27.151
  I0511 14:03:27.153823 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=statefulset-3225 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0511 14:03:27.231313      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:03:27.246669 26 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0511 14:03:27.246725 26 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0511 14:03:27.246743 26 statefulset.go:2509] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0511 14:03:28.232354      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:29.232864      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:30.233134      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:31.233589      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:32.234079      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:33.234633      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:34.234798      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:35.235073      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:36.235446      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:37.235551      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:03:37.262352 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:03:37.262443 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  I0511 14:03:37.262476 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:03:38.236580      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:39.236712      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:40.236898      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:41.237369      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:42.237722      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:43.237736      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:44.238278      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:45.238742      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:46.239096      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:47.240235      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:03:47.264306 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:03:47.264368 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  I0511 14:03:47.264384 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:03:48.241406      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:49.241914      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:50.242421      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:51.242765      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:52.243805      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:53.243886      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:54.244347      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:55.244838      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:56.245275      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:57.245701      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:03:57.266003 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:03:57.266067 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  I0511 14:03:57.266083 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:03:58.246197      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:03:59.246879      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:00.246983      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:01.247397      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:02.247771      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:03.248132      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:04.249248      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:05.249744      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:06.249971      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:07.250727      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:04:07.266975 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:04:07.267036 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  I0511 14:04:07.267053 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:04:08.251011      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:09.251582      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:10.251669      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:11.252110      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:12.252867      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:13.253893      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:14.254341      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:15.254861      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:16.255425      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:17.255933      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:04:17.264142 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:04:17.264210 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  I0511 14:04:17.264228 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:04:18.256242      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:19.256543      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:20.256751      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:21.257263      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:22.257500      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:23.257908      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:24.258358      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:25.258565      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:26.258618      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:27.258734      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:04:27.266319 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:04:27.266401 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  I0511 14:04:27.266424 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:04:28.259261      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:29.259734      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:30.260261      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:31.260782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:32.260998      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:33.261575      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:34.261979      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:35.262427      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:36.262979      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:37.263198      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:04:37.263516 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:04:37.263578 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  I0511 14:04:37.263596 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:04:38.263698      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:39.263733      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:40.263792      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:41.264186      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:42.264656      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:43.265753      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:44.265912      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:45.266075      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:46.266337      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:04:47.263263 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:04:47.263326 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  I0511 14:04:47.263342 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:04:47.266249      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:48.266740      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:49.267409      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:50.267699      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:51.268243      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:52.268715      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:53.268874      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:54.269229      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:55.269757      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:56.270199      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:04:57.266776 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:04:57.266839 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  I0511 14:04:57.266855 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:04:57.270877      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:58.271291      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:04:59.271786      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:00.272116      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:01.272630      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:02.272955      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:03.273584      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:04.274117      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:05.274650      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:06.275079      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:05:07.265730 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:05:07.265788 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  I0511 14:05:07.265804 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:05:07.275812      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:08.276370      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:09.276723      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:10.277102      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:11.277699      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:12.278198      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:13.278699      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:14.278653      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:15.279179      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:16.279804      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:05:17.264737 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:05:17.264804 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  I0511 14:05:17.264823 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:05:17.279743      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:18.279951      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:19.280223      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:20.280514      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:21.280719      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:22.281131      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:23.282680      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:24.281589      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:25.281788      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:26.282243      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:05:27.266406 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:05:27.266496 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:05:27.282383      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:28.282581      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:29.282789      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:30.283082      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:31.283277      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:32.283807      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:33.284076      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:34.284277      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:35.284755      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:36.285149      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:05:37.265030 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:05:37.265089 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:05:37.285193      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:38.285411      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:39.285949      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:40.286341      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:41.286750      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:42.287244      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:43.287867      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:44.288249      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:45.288511      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:46.288928      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:05:47.264584 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:05:47.264654 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:05:47.289883      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:48.291038      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:49.291801      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:50.291894      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:51.292823      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:52.293344      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:53.293797      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:54.294384      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:55.294889      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:56.295497      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:05:57.264314 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:05:57.264363 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:05:57.295539      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:58.295757      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:05:59.296086      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:00.296422      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:01.296851      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:02.297735      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:03.298073      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:04.298528      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:05.298778      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:06.298956      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:06:07.265525 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:06:07.265574 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:06:07.299770      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:08.300734      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:09.301176      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:10.301721      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:11.302673      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:12.303783      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:13.304603      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:14.304850      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:15.305782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:16.306206      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:06:17.263216 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:06:17.263267 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:06:17.306814      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:18.307945      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:19.308394      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:20.309069      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:21.309530      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:22.309926      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:23.310265      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:24.310691      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:25.310959      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:26.311431      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:06:27.264847 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:06:27.264909 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:06:27.312183      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:28.312666      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:29.313210      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:30.313774      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:31.314289      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:32.314769      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:33.315838      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:34.316305      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:35.316781      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:36.317889      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:06:37.265413 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:06:37.265486 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:06:37.318655      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:38.319147      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:39.319689      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:40.319821      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:41.320222      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:42.320766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:43.320793      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:44.321816      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:45.322766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:46.323004      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:06:47.264972 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:06:47.265036 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:06:47.324091      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:48.324264      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:49.324547      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:50.325519      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:51.325609      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:52.326740      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:53.327140      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:54.327845      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:55.328030      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:56.328704      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:06:57.265452 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:06:57.265527 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:06:57.329610      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:58.329806      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:06:59.330293      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:00.330798      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:01.331325      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:02.331742      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:03.332243      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:04.332897      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:05.333379      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:06.333756      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:07:07.266868 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:07:07.266934 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:07:07.334221      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:08.334430      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:09.334687      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:10.334664      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:11.335107      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:12.335391      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:13.335782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:14.336003      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:15.336912      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:16.337327      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:07:17.265053 26 wait.go:158] Waiting for StatefulSet statefulset-3225/ss2 to complete update
  I0511 14:07:17.265133 26 wait.go:165] Waiting for Pod statefulset-3225/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:07:17.338309      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:18.338832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:19.339329      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:20.339514      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:21.339771      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:22.340886      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:23.341210      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:24.341409      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:25.341956      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:26.342867      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 05/11/25 14:07:27.266
  I0511 14:07:27.267021 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=statefulset-3225 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0511 14:07:27.343469      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:07:27.375310 26 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0511 14:07:27.375371 26 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0511 14:07:27.375392 26 statefulset.go:2485] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0511 14:07:28.343928      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:29.344492      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:30.344953      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:31.345820      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:32.346764      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:33.347240      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:34.347915      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:35.348302      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:36.348913      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:37.349856      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:07:37.391880 26 statefulset.go:2542] Updating stateful set ss2
  E0511 14:07:38.350102      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:39.350598      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:40.350671      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:41.350835      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:42.351372      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:43.351799      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:44.352907      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:45.353873      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:46.353941      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:47.354832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 05/11/25 14:07:47.399
  I0511 14:07:47.401957 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=statefulset-3225 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0511 14:07:47.491669 26 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0511 14:07:47.491722 26 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0511 14:07:47.491741 26 statefulset.go:2509] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0511 14:07:48.355280      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:49.355844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:50.356155      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:51.356659      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:52.356745      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:53.357871      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:54.358751      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:55.359092      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:56.359702      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:57.360028      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:07:57.499678 26 statefulset.go:138] Deleting all statefulset in ns statefulset-3225
  I0511 14:07:57.502627 26 rest.go:153] Scaling statefulset ss2 to 0
  E0511 14:07:58.360772      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:07:59.361884      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:00.362926      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:01.363355      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:02.364025      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:03.364553      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:04.364644      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:05.365056      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:06.365561      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:07.365782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:08:07.512163 26 wait.go:159] Waiting for statefulset status.replicas updated to 0
  I0511 14:08:07.513487 26 rest.go:91] Deleting statefulset ss2
  I0511 14:08:07.520791 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3225" for this suite. @ 05/11/25 14:08:07.523
• [310.530 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 05/11/25 14:08:07.53
  I0511 14:08:07.530500 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename daemonsets @ 05/11/25 14:08:07.531
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:08:07.538
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:08:07.54
  I0511 14:08:07.633535 26 daemon_set.go:447] Create a RollingUpdate DaemonSet
  I0511 14:08:07.637933 26 daemon_set.go:454] Check that daemon pods launch on every node of the cluster
  I0511 14:08:07.729659 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 14:08:07.729709 26 fixtures.go:131] Node k8sconformance is running 0 daemon pod, expected 1
  E0511 14:08:08.366559      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:08:08.643794 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 14:08:08.643856 26 fixtures.go:131] Node k8sconformance is running 0 daemon pod, expected 1
  E0511 14:08:09.366731      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:08:09.643986 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0511 14:08:09.644010 26 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  I0511 14:08:09.644020 26 daemon_set.go:458] Update the DaemonSet to trigger a rollout
  I0511 14:08:09.652503 26 daemon_set.go:102] Updating DaemonSet daemon-set
  E0511 14:08:10.367529      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:11.368048      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:08:11.665207 26 daemon_set.go:493] Roll back the DaemonSet before rollout is complete
  I0511 14:08:11.673483 26 daemon_set.go:102] Updating DaemonSet daemon-set
  I0511 14:08:11.673543 26 daemon_set.go:499] Make sure DaemonSet rollback is complete
  I0511 14:08:11.676733 26 daemon_set.go:1193] Wrong image for pod: daemon-set-x6l9b. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  I0511 14:08:11.676770 26 daemon_set.go:1198] Pod daemon-set-x6l9b is not available
  E0511 14:08:12.368817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:13.369535      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:14.369988      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:15.370791      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:16.371685      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:08:16.676962 26 daemon_set.go:1198] Pod daemon-set-cvx8j is not available
  STEP: Deleting DaemonSet "daemon-set" @ 05/11/25 14:08:16.683
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4130, will wait for the garbage collector to delete the pods @ 05/11/25 14:08:16.683
  I0511 14:08:16.740961 26 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 4.861455ms
  I0511 14:08:16.841255 26 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.289665ms
  E0511 14:08:17.371986      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:08:18.346116 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 14:08:18.346176 26 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0511 14:08:18.349332 26 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"11924"},"items":null}

  I0511 14:08:18.351505 26 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"11924"},"items":null}

  I0511 14:08:18.359207 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4130" for this suite. @ 05/11/25 14:08:18.361
• [10.835 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 05/11/25 14:08:18.365
  I0511 14:08:18.366003 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename csistoragecapacity @ 05/11/25 14:08:18.366
  E0511 14:08:18.372311      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:08:18.376
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:08:18.38
  STEP: getting /apis @ 05/11/25 14:08:18.384
  STEP: getting /apis/storage.k8s.io @ 05/11/25 14:08:18.387
  STEP: getting /apis/storage.k8s.io/v1 @ 05/11/25 14:08:18.388
  STEP: creating @ 05/11/25 14:08:18.389
  STEP: watching @ 05/11/25 14:08:18.399
  I0511 14:08:18.399869 26 csistoragecapacity.go:143] starting watch
  STEP: getting @ 05/11/25 14:08:18.403
  STEP: listing in namespace @ 05/11/25 14:08:18.404
  STEP: listing across namespaces @ 05/11/25 14:08:18.406
  STEP: patching @ 05/11/25 14:08:18.407
  STEP: updating @ 05/11/25 14:08:18.411
  I0511 14:08:18.414676 26 csistoragecapacity.go:181] waiting for watch events with expected annotations in namespace
  I0511 14:08:18.414776 26 csistoragecapacity.go:181] waiting for watch events with expected annotations across namespace
  STEP: deleting @ 05/11/25 14:08:18.414
  STEP: deleting a collection @ 05/11/25 14:08:18.421
  I0511 14:08:18.430537 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-8190" for this suite. @ 05/11/25 14:08:18.456
• [0.096 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 05/11/25 14:08:18.462
  I0511 14:08:18.462747 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename watch @ 05/11/25 14:08:18.463
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:08:18.473
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:08:18.476
  STEP: creating a watch on configmaps with label A @ 05/11/25 14:08:18.479
  STEP: creating a watch on configmaps with label B @ 05/11/25 14:08:18.48
  STEP: creating a watch on configmaps with label A or B @ 05/11/25 14:08:18.481
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 05/11/25 14:08:18.482
  I0511 14:08:18.487960 26 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3238  3308646d-f845-41d9-89cf-0169af90c2c9 11941 0 2025-05-11 14:08:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-05-11 14:08:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0511 14:08:18.488060 26 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3238  3308646d-f845-41d9-89cf-0169af90c2c9 11941 0 2025-05-11 14:08:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-05-11 14:08:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 05/11/25 14:08:18.488
  I0511 14:08:18.494137 26 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3238  3308646d-f845-41d9-89cf-0169af90c2c9 11942 0 2025-05-11 14:08:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-05-11 14:08:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0511 14:08:18.494179 26 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3238  3308646d-f845-41d9-89cf-0169af90c2c9 11942 0 2025-05-11 14:08:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-05-11 14:08:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 05/11/25 14:08:18.494
  I0511 14:08:18.497662 26 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3238  3308646d-f845-41d9-89cf-0169af90c2c9 11943 0 2025-05-11 14:08:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-05-11 14:08:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0511 14:08:18.497736 26 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3238  3308646d-f845-41d9-89cf-0169af90c2c9 11943 0 2025-05-11 14:08:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-05-11 14:08:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 05/11/25 14:08:18.497
  I0511 14:08:18.501548 26 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3238  3308646d-f845-41d9-89cf-0169af90c2c9 11944 0 2025-05-11 14:08:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-05-11 14:08:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0511 14:08:18.501590 26 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3238  3308646d-f845-41d9-89cf-0169af90c2c9 11944 0 2025-05-11 14:08:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-05-11 14:08:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 05/11/25 14:08:18.501
  I0511 14:08:18.504023 26 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3238  6f539b9c-d26a-476f-beb7-f4956cb838dc 11945 0 2025-05-11 14:08:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2025-05-11 14:08:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0511 14:08:18.504090 26 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3238  6f539b9c-d26a-476f-beb7-f4956cb838dc 11945 0 2025-05-11 14:08:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2025-05-11 14:08:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0511 14:08:19.372711      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:20.373070      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:21.373903      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:22.374564      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:23.374644      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:24.375069      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:25.375528      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:26.375867      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:27.376288      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:28.376726      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 05/11/25 14:08:28.504
  I0511 14:08:28.513776 26 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3238  6f539b9c-d26a-476f-beb7-f4956cb838dc 11988 0 2025-05-11 14:08:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2025-05-11 14:08:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0511 14:08:28.513873 26 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3238  6f539b9c-d26a-476f-beb7-f4956cb838dc 11988 0 2025-05-11 14:08:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2025-05-11 14:08:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0511 14:08:29.377584      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:30.377926      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:31.378493      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:32.378854      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:33.379805      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:34.380813      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:35.381069      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:36.381498      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:37.381903      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:38.382260      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:08:38.514726 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3238" for this suite. @ 05/11/25 14:08:38.519
• [20.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 05/11/25 14:08:38.525
  I0511 14:08:38.525664 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename secrets @ 05/11/25 14:08:38.526
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:08:38.538
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:08:38.542
  STEP: Creating secret with name secret-test-c1cb5d87-f8e5-4e64-8e75-228ad5eaa951 @ 05/11/25 14:08:38.558
  STEP: Creating a pod to test consume secrets @ 05/11/25 14:08:38.562
  E0511 14:08:39.382511      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:40.382920      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:41.383223      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:42.383740      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:08:42.582
  I0511 14:08:42.585647 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-secrets-bb5f44bf-bc7e-432d-a0d2-8b9af23a6d2c container secret-volume-test: <nil>
  STEP: delete the pod @ 05/11/25 14:08:42.602
  I0511 14:08:42.616197 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7933" for this suite. @ 05/11/25 14:08:42.619
  STEP: Destroying namespace "secret-namespace-8761" for this suite. @ 05/11/25 14:08:42.624
• [4.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 05/11/25 14:08:42.629
  I0511 14:08:42.629704 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename controllerrevisions @ 05/11/25 14:08:42.63
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:08:42.637
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:08:42.639
  STEP: Creating DaemonSet "e2e-9jqjb-daemon-set" @ 05/11/25 14:08:42.727
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/11/25 14:08:42.732
  I0511 14:08:42.825973 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset e2e-9jqjb-daemon-set: 0
  I0511 14:08:42.826025 26 fixtures.go:131] Node k8sconformance is running 0 daemon pod, expected 1
  E0511 14:08:43.384631      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:08:43.741209 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset e2e-9jqjb-daemon-set: 1
  I0511 14:08:43.741257 26 fixtures.go:131] Node k8sconformance-m02 is running 0 daemon pod, expected 1
  E0511 14:08:44.385058      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:08:44.742225 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset e2e-9jqjb-daemon-set: 2
  I0511 14:08:44.742273 26 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset e2e-9jqjb-daemon-set
  STEP: Confirm DaemonSet "e2e-9jqjb-daemon-set" successfully created with "daemonset-name=e2e-9jqjb-daemon-set" label @ 05/11/25 14:08:44.744
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-9jqjb-daemon-set" @ 05/11/25 14:08:44.749
  I0511 14:08:44.751753 26 controller_revision.go:162] Located ControllerRevision: "e2e-9jqjb-daemon-set-f9bc47db6"
  STEP: Patching ControllerRevision "e2e-9jqjb-daemon-set-f9bc47db6" @ 05/11/25 14:08:44.753
  I0511 14:08:44.760911 26 controller_revision.go:173] e2e-9jqjb-daemon-set-f9bc47db6 has been patched
  STEP: Create a new ControllerRevision @ 05/11/25 14:08:44.76
  I0511 14:08:44.765414 26 controller_revision.go:191] Created ControllerRevision: e2e-9jqjb-daemon-set-745647f544
  STEP: Confirm that there are two ControllerRevisions @ 05/11/25 14:08:44.765
  I0511 14:08:44.765529 26 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0511 14:08:44.768013 26 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-9jqjb-daemon-set-f9bc47db6" @ 05/11/25 14:08:44.768
  STEP: Confirm that there is only one ControllerRevision @ 05/11/25 14:08:44.771
  I0511 14:08:44.771505 26 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0511 14:08:44.773240 26 controller_revision.go:265] Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-9jqjb-daemon-set-745647f544" @ 05/11/25 14:08:44.775
  I0511 14:08:44.780009 26 controller_revision.go:220] e2e-9jqjb-daemon-set-745647f544 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 05/11/25 14:08:44.78
  I0511 14:08:44.786784      26 warnings.go:110] "Warning: unknown field \"updateStrategy\""
  STEP: Confirm that there are two ControllerRevisions @ 05/11/25 14:08:44.786
  I0511 14:08:44.786900 26 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0511 14:08:44.800079 26 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-9jqjb-daemon-set-745647f544=updated" @ 05/11/25 14:08:44.8
  STEP: Confirm that there is only one ControllerRevision @ 05/11/25 14:08:44.806
  I0511 14:08:44.806638 26 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0511 14:08:44.853140 26 controller_revision.go:265] Found 1 ControllerRevisions
  I0511 14:08:44.856331 26 controller_revision.go:246] ControllerRevision "e2e-9jqjb-daemon-set-cf89c7c7" has revision 3
  STEP: Deleting DaemonSet "e2e-9jqjb-daemon-set" @ 05/11/25 14:08:44.858
  STEP: deleting DaemonSet.extensions e2e-9jqjb-daemon-set in namespace controllerrevisions-8337, will wait for the garbage collector to delete the pods @ 05/11/25 14:08:44.858
  I0511 14:08:44.918779 26 resources.go:139] Deleting DaemonSet.extensions e2e-9jqjb-daemon-set took: 7.008697ms
  I0511 14:08:45.019117 26 resources.go:163] Terminating DaemonSet.extensions e2e-9jqjb-daemon-set pods took: 100.325241ms
  E0511 14:08:45.385792      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:46.386539      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:47.386900      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:08:47.424016 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset e2e-9jqjb-daemon-set: 0
  I0511 14:08:47.424102 26 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset e2e-9jqjb-daemon-set
  I0511 14:08:47.427182 26 controller_revision.go:73] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"12081"},"items":null}

  I0511 14:08:47.429584 26 controller_revision.go:78] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"12081"},"items":null}

  I0511 14:08:47.437783 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-8337" for this suite. @ 05/11/25 14:08:47.44
• [4.815 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 05/11/25 14:08:47.445
  I0511 14:08:47.445232 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename secrets @ 05/11/25 14:08:47.446
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:08:47.453
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:08:47.455
  I0511 14:08:47.476840 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3358" for this suite. @ 05/11/25 14:08:47.534
• [0.095 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 05/11/25 14:08:47.54
  I0511 14:08:47.540682 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename deployment @ 05/11/25 14:08:47.541
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:08:47.551
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:08:47.555
  I0511 14:08:47.558559 26 deployment.go:1215] Creating deployment "webserver-deployment"
  I0511 14:08:47.563337 26 deployment.go:1219] Waiting for observed generation 1
  E0511 14:08:48.387647      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:49.387873      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:08:49.571550 26 deployment.go:1224] Waiting for all required pods to come up
  I0511 14:08:49.576678 26 resource.go:81] Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 05/11/25 14:08:49.576
  I0511 14:08:49.576866 26 deployment.go:1228] Waiting for deployment "webserver-deployment" to complete
  I0511 14:08:49.582695 26 deployment.go:1237] Updating deployment "webserver-deployment" with a non-existent image
  I0511 14:08:49.590874 26 deployment.go:314] Updating deployment webserver-deployment
  I0511 14:08:49.590933 26 deployment.go:1243] Waiting for observed generation 2
  E0511 14:08:50.388790      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:51.389321      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:08:51.597680 26 deployment.go:1253] Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  I0511 14:08:51.600540 26 deployment.go:1258] Waiting for the first rollout's replicaset to have .spec.replicas = 8
  I0511 14:08:51.602883 26 deployment.go:1263] Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0511 14:08:51.614403 26 deployment.go:1277] Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  I0511 14:08:51.614613 26 deployment.go:1282] Waiting for the second rollout's replicaset to have .spec.replicas = 5
  I0511 14:08:51.617326 26 deployment.go:1287] Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0511 14:08:51.625041 26 deployment.go:1294] Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  I0511 14:08:51.625129 26 deployment.go:1302] Scaling up the deployment "webserver-deployment" from 10 to 30
  I0511 14:08:51.634232 26 deployment.go:314] Updating deployment webserver-deployment
  I0511 14:08:51.634268 26 deployment.go:1308] Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  I0511 14:08:51.641152 26 deployment.go:1316] Verifying that first rollout's replicaset has .spec.replicas = 20
  I0511 14:08:51.650056 26 deployment.go:1322] Verifying that second rollout's replicaset has .spec.replicas = 13
  I0511 14:08:51.661586 26 deployment.go:632] Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9270514d-1ed3-4256-a079-fb10e45c4a8c",
      ResourceVersion: (string) (len=5) "12296",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 3,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      TerminatingReplicas: (*int32)(<nil>),
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=60) "ReplicaSet \"webserver-deployment-6fc69b9478\" is progressing."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0511 14:08:51.691011 26 deployment.go:40] New ReplicaSet "webserver-deployment-6fc69b9478" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-6fc69b9478",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "44141980-fa3a-4276-b77c-fd5a54c8d942",
      ResourceVersion: (string) (len=5) "12289",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569329,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "9270514d-1ed3-4256-a079-fb10e45c4a8c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 32 37 30 35 31  34 64 2d 31 65 64 33 2d  |\"9270514d-1ed3-|
              00000120  34 32 35 36 2d 61 30 37  39 2d 66 62 31 30 65 34  |4256-a079-fb10e4|
              00000130  35 63 34 61 38 63 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |5c4a8c\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0511 14:08:51.691585 26 deployment.go:45] All old ReplicaSets of Deployment "webserver-deployment":
  I0511 14:08:51.691866 26 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-685b768f58",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
      ResourceVersion: (string) (len=5) "12330",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "9270514d-1ed3-4256-a079-fb10e45c4a8c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 32 37 30 35 31  34 64 2d 31 65 64 33 2d  |\"9270514d-1ed3-|
              00000120  34 32 35 36 2d 61 30 37  39 2d 66 62 31 30 65 34  |4256-a079-fb10e4|
              00000130  35 63 34 61 38 63 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |5c4a8c\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 3,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0511 14:08:51.699100 26 deployment.go:68] Pod "webserver-deployment-685b768f58-48859" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-48859",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "517c053f-fc8c-4510-8397-47186e78e8ca",
      ResourceVersion: (string) (len=5) "12196",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 31  35 30 5c 22 7d 22 3a 7b  |.244.1.150\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-npfmp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-npfmp",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.3"
        }
      },
      PodIP: (string) (len=12) "10.244.1.150",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.1.150"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63882569328,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://52e7d45a554d24169d03d4814c625b3b4282843dff65e97f6c2f78ef1c1233f4",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-npfmp",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.700626 26 deployment.go:68] Pod "webserver-deployment-685b768f58-4bt6d" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-4bt6d",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0fd8ef36-02e5-4d61-8cc0-fdd0c5f3e7ca",
      ResourceVersion: (string) (len=5) "12218",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 34  35 5c 22 7d 22 3a 7b 22  |.244.0.45\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vxqqd",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vxqqd",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.2"
        }
      },
      PodIP: (string) (len=11) "10.244.0.45",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.45"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63882569328,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://d5b5f2d547cc76ebede7b582ac436414d9e0d02dc2077e2798145d4d94cf9b75",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-vxqqd",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.702123 26 deployment.go:68] Pod "webserver-deployment-685b768f58-5cdjp" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-5cdjp",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "10c7e691-8f65-4c38-8324-94c4a329b42a",
      ResourceVersion: (string) (len=5) "12213",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 34  31 5c 22 7d 22 3a 7b 22  |.244.0.41\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-tzjpp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-tzjpp",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.2"
        }
      },
      PodIP: (string) (len=11) "10.244.0.41",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.41"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63882569328,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://7ca0b217d438cd83953e2ab2d8c9be9140d00c01535af8f502e84aab4a70dece",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-tzjpp",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.703646 26 deployment.go:68] Pod "webserver-deployment-685b768f58-5l2tx" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-5l2tx",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fcfd848b-98fd-4fe2-86f6-938b0b3f47f8",
      ResourceVersion: (string) (len=5) "12313",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7jcg7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7jcg7",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.704787 26 deployment.go:68] Pod "webserver-deployment-685b768f58-64dhv" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-64dhv",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "29c7c4c3-ff49-4433-9f27-8a68291bf3ae",
      ResourceVersion: (string) (len=5) "12337",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6gtbl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6gtbl",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.705987 26 deployment.go:68] Pod "webserver-deployment-685b768f58-7w5d7" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-7w5d7",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b3362ce6-0c21-4e7a-8d65-1261df1dba51",
      ResourceVersion: (string) (len=5) "12327",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-kx6tq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-kx6tq",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.3"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-kx6tq",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.707388 26 deployment.go:68] Pod "webserver-deployment-685b768f58-frt22" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-frt22",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "95aa1b1f-0bf8-45b6-a152-8f63f9b26513",
      ResourceVersion: (string) (len=5) "12203",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 31  35 31 5c 22 7d 22 3a 7b  |.244.1.151\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-wmzvf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-wmzvf",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.3"
        }
      },
      PodIP: (string) (len=12) "10.244.1.151",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.1.151"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63882569328,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://d64e9d1fa7ee52bb942484a15f60a010ab4106a21404969bd7b4672c0d9ee6b3",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-wmzvf",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.709005 26 deployment.go:68] Pod "webserver-deployment-685b768f58-fxfss" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-fxfss",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "05b5e06a-8197-4441-9a1c-e6b6c267efaf",
      ResourceVersion: (string) (len=5) "12335",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mp7wf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mp7wf",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.710046 26 deployment.go:68] Pod "webserver-deployment-685b768f58-ghr8b" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-ghr8b",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c8827cc9-3dae-4e93-a41a-07535004ed4a",
      ResourceVersion: (string) (len=5) "12209",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 34  33 5c 22 7d 22 3a 7b 22  |.244.0.43\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-5znxr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-5znxr",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.2"
        }
      },
      PodIP: (string) (len=11) "10.244.0.43",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.43"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63882569328,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://1a36e72e9659e98290c738c001cfc63ba8654d2e2f60c654fd6e9332f1ef023a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-5znxr",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.711652 26 deployment.go:68] Pod "webserver-deployment-685b768f58-mhp9b" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-mhp9b",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8d2544da-2203-468e-b617-cb4fba9a7366",
      ResourceVersion: (string) (len=5) "12322",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-d8tpw",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-d8tpw",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.712727 26 deployment.go:68] Pod "webserver-deployment-685b768f58-mv89l" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-mv89l",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "239e3b75-1105-45ce-8204-bb20dc3d8f3f",
      ResourceVersion: (string) (len=5) "12207",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 34  32 5c 22 7d 22 3a 7b 22  |.244.0.42\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-kn294",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-kn294",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.2"
        }
      },
      PodIP: (string) (len=11) "10.244.0.42",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.42"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63882569328,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://9e81850dddd6543bd0bef196c33566dbe709f3b303ce2a789568a1c07f8bdd17",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-kn294",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.713990 26 deployment.go:68] Pod "webserver-deployment-685b768f58-mxg9w" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-mxg9w",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f6230996-ccea-4b5c-947e-29c84b4ad9e4",
      ResourceVersion: (string) (len=5) "12300",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-strb2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-strb2",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.714895 26 deployment.go:68] Pod "webserver-deployment-685b768f58-n77tm" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-n77tm",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6aba5b74-afed-4d66-a877-f77413c18456",
      ResourceVersion: (string) (len=5) "12314",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dp4tj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dp4tj",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.715820 26 deployment.go:68] Pod "webserver-deployment-685b768f58-ngf4x" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-ngf4x",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "60ff7535-6e22-4902-8ff6-f89d02e8d786",
      ResourceVersion: (string) (len=5) "12336",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-k7bst",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-k7bst",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.716691 26 deployment.go:68] Pod "webserver-deployment-685b768f58-nptw4" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-nptw4",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fc428581-0208-4b4d-901d-cfdadf2a9de1",
      ResourceVersion: (string) (len=5) "12332",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-5t2x9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-5t2x9",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.717817 26 deployment.go:68] Pod "webserver-deployment-685b768f58-pvvwx" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-pvvwx",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ed40022c-c41c-48a1-9aa4-66f4b552d944",
      ResourceVersion: (string) (len=5) "12201",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 31  35 33 5c 22 7d 22 3a 7b  |.244.1.153\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-p5lq2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-p5lq2",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.3"
        }
      },
      PodIP: (string) (len=12) "10.244.1.153",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.1.153"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63882569328,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://325f65be55f4e686589cd11526b272da3ffae227dc97501cce85f6985c7ce003",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-p5lq2",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.719258 26 deployment.go:68] Pod "webserver-deployment-685b768f58-rj9m6" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-rj9m6",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0515359e-0f24-493d-ac1f-53d86d04f182",
      ResourceVersion: (string) (len=5) "12310",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9rvt4",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9rvt4",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.719915 26 deployment.go:68] Pod "webserver-deployment-685b768f58-sbn6j" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-sbn6j",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "12f1cfdf-d260-4e4c-84ca-23fc2487a307",
      ResourceVersion: (string) (len=5) "12216",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 34  34 5c 22 7d 22 3a 7b 22  |.244.0.44\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-czjrb",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-czjrb",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569327,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.2"
        }
      },
      PodIP: (string) (len=11) "10.244.0.44",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.44"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569327,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63882569328,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://1f05d7b387baa450c8319dc5968a48002ec4dcc7828ec3bc93091d2d814c847f",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-czjrb",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.720703 26 deployment.go:68] Pod "webserver-deployment-685b768f58-wdjf7" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-wdjf7",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1d1b60a2-fd1c-4978-a191-aa24669b3c1d",
      ResourceVersion: (string) (len=5) "12299",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-zscs9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-zscs9",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.721206 26 deployment.go:68] Pod "webserver-deployment-685b768f58-zpxrq" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-zpxrq",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e79a58ce-6599-40b1-a4da-a8cd877da715",
      ResourceVersion: (string) (len=5) "12339",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "beeafa86-87b1-449a-bf8b-cd6b2da7a95c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 65  65 61 66 61 38 36 2d 38  |d\":\"beeafa86-8|
              00000090  37 62 31 2d 34 34 39 61  2d 62 66 38 62 2d 63 64  |7b1-449a-bf8b-cd|
              000000a0  36 62 32 64 61 37 61 39  35 63 5c 22 7d 22 3a 7b  |6b2da7a95c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-r8mdm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-r8mdm",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.721794 26 deployment.go:68] Pod "webserver-deployment-6fc69b9478-2d2hg" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-2d2hg",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "bb953fc6-de69-4e4d-9f62-72e6f86e6b72",
      ResourceVersion: (string) (len=5) "12254",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569329,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "44141980-fa3a-4276-b77c-fd5a54c8d942",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 34  31 34 31 39 38 30 2d 66  |d\":\"44141980-f|
              00000090  61 33 61 2d 34 32 37 36  2d 62 37 37 63 2d 66 64  |a3a-4276-b77c-fd|
              000000a0  35 61 35 34 63 38 64 39  34 32 5c 22 7d 22 3a 7b  |5a54c8d942\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6hk7w",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6hk7w",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.2"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569329,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-6hk7w",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.722581 26 deployment.go:68] Pod "webserver-deployment-6fc69b9478-4dtpt" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-4dtpt",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2b0070f6-bc0e-4e61-952d-ab6f1845fc5b",
      ResourceVersion: (string) (len=5) "12341",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "44141980-fa3a-4276-b77c-fd5a54c8d942",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 34  31 34 31 39 38 30 2d 66  |d\":\"44141980-f|
              00000090  61 33 61 2d 34 32 37 36  2d 62 37 37 63 2d 66 64  |a3a-4276-b77c-fd|
              000000a0  35 61 35 34 63 38 64 39  34 32 5c 22 7d 22 3a 7b  |5a54c8d942\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-db5rz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-db5rz",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.723522 26 deployment.go:68] Pod "webserver-deployment-6fc69b9478-5tz9n" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-5tz9n",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "990491be-84c5-4d9e-8566-cebb1d4b1dcb",
      ResourceVersion: (string) (len=5) "12329",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "44141980-fa3a-4276-b77c-fd5a54c8d942",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 34  31 34 31 39 38 30 2d 66  |d\":\"44141980-f|
              00000090  61 33 61 2d 34 32 37 36  2d 62 37 37 63 2d 66 64  |a3a-4276-b77c-fd|
              000000a0  35 61 35 34 63 38 64 39  34 32 5c 22 7d 22 3a 7b  |5a54c8d942\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-v8gck",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-v8gck",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.724334 26 deployment.go:68] Pod "webserver-deployment-6fc69b9478-6czs6" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-6czs6",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "64c32988-3788-4c0a-ac4b-a68255fa7f3c",
      ResourceVersion: (string) (len=5) "12334",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "44141980-fa3a-4276-b77c-fd5a54c8d942",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 34  31 34 31 39 38 30 2d 66  |d\":\"44141980-f|
              00000090  61 33 61 2d 34 32 37 36  2d 62 37 37 63 2d 66 64  |a3a-4276-b77c-fd|
              000000a0  35 61 35 34 63 38 64 39  34 32 5c 22 7d 22 3a 7b  |5a54c8d942\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-cj4gb",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-cj4gb",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.2"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-cj4gb",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.725208 26 deployment.go:68] Pod "webserver-deployment-6fc69b9478-h4kpz" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-h4kpz",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c64afe82-951f-468d-8c83-4107e241153d",
      ResourceVersion: (string) (len=5) "12338",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "44141980-fa3a-4276-b77c-fd5a54c8d942",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 34  31 34 31 39 38 30 2d 66  |d\":\"44141980-f|
              00000090  61 33 61 2d 34 32 37 36  2d 62 37 37 63 2d 66 64  |a3a-4276-b77c-fd|
              000000a0  35 61 35 34 63 38 64 39  34 32 5c 22 7d 22 3a 7b  |5a54c8d942\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-k78sf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-k78sf",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.725893 26 deployment.go:68] Pod "webserver-deployment-6fc69b9478-hbxx7" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-hbxx7",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "812606ba-0af2-4c5f-8aaf-399c3c205a64",
      ResourceVersion: (string) (len=5) "12253",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569329,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "44141980-fa3a-4276-b77c-fd5a54c8d942",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 34  31 34 31 39 38 30 2d 66  |d\":\"44141980-f|
              00000090  61 33 61 2d 34 32 37 36  2d 62 37 37 63 2d 66 64  |a3a-4276-b77c-fd|
              000000a0  35 61 35 34 63 38 64 39  34 32 5c 22 7d 22 3a 7b  |5a54c8d942\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-g6s2x",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-g6s2x",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.3"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569329,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-g6s2x",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.727024 26 deployment.go:68] Pod "webserver-deployment-6fc69b9478-l6bzq" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-l6bzq",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "acfd21a5-380f-4441-a33a-788afa076b6a",
      ResourceVersion: (string) (len=5) "12340",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "44141980-fa3a-4276-b77c-fd5a54c8d942",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 34  31 34 31 39 38 30 2d 66  |d\":\"44141980-f|
              00000090  61 33 61 2d 34 32 37 36  2d 62 37 37 63 2d 66 64  |a3a-4276-b77c-fd|
              000000a0  35 61 35 34 63 38 64 39  34 32 5c 22 7d 22 3a 7b  |5a54c8d942\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-zchhv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-zchhv",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.727814 26 deployment.go:68] Pod "webserver-deployment-6fc69b9478-mhqq2" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-mhqq2",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8a698d88-9f8d-4ed6-84f7-86d3da1aa970",
      ResourceVersion: (string) (len=5) "12275",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569329,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "44141980-fa3a-4276-b77c-fd5a54c8d942",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 34  31 34 31 39 38 30 2d 66  |d\":\"44141980-f|
              00000090  61 33 61 2d 34 32 37 36  2d 62 37 37 63 2d 66 64  |a3a-4276-b77c-fd|
              000000a0  35 61 35 34 63 38 64 39  34 32 5c 22 7d 22 3a 7b  |5a54c8d942\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-g4564",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-g4564",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.2"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569329,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-g4564",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.728637 26 deployment.go:68] Pod "webserver-deployment-6fc69b9478-s859v" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-s859v",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f51d6661-1fca-4071-9b1f-35f91513f5df",
      ResourceVersion: (string) (len=5) "12333",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "44141980-fa3a-4276-b77c-fd5a54c8d942",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 34  31 34 31 39 38 30 2d 66  |d\":\"44141980-f|
              00000090  61 33 61 2d 34 32 37 36  2d 62 37 37 63 2d 66 64  |a3a-4276-b77c-fd|
              000000a0  35 61 35 34 63 38 64 39  34 32 5c 22 7d 22 3a 7b  |5a54c8d942\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-n8522",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-n8522",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.729195 26 deployment.go:68] Pod "webserver-deployment-6fc69b9478-txjsx" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-txjsx",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "086a34a0-a4eb-4f47-8d79-67efb7be1781",
      ResourceVersion: (string) (len=5) "12318",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "44141980-fa3a-4276-b77c-fd5a54c8d942",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 34  31 34 31 39 38 30 2d 66  |d\":\"44141980-f|
              00000090  61 33 61 2d 34 32 37 36  2d 62 37 37 63 2d 66 64  |a3a-4276-b77c-fd|
              000000a0  35 61 35 34 63 38 64 39  34 32 5c 22 7d 22 3a 7b  |5a54c8d942\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-pkpnn",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-pkpnn",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.729794 26 deployment.go:68] Pod "webserver-deployment-6fc69b9478-vlzkq" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-vlzkq",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a6990649-acbc-47d6-8fac-355d8723283f",
      ResourceVersion: (string) (len=5) "12259",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569329,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "44141980-fa3a-4276-b77c-fd5a54c8d942",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 34  31 34 31 39 38 30 2d 66  |d\":\"44141980-f|
              00000090  61 33 61 2d 34 32 37 36  2d 62 37 37 63 2d 66 64  |a3a-4276-b77c-fd|
              000000a0  35 61 35 34 63 38 64 39  34 32 5c 22 7d 22 3a 7b  |5a54c8d942\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-kslqp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-kslqp",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.3"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569329,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-kslqp",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.730764 26 deployment.go:68] Pod "webserver-deployment-6fc69b9478-wjpgf" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-wjpgf",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b8cb2c3e-27d1-4a1b-a9a0-09b97298bb9d",
      ResourceVersion: (string) (len=5) "12277",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569329,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "44141980-fa3a-4276-b77c-fd5a54c8d942",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 34  31 34 31 39 38 30 2d 66  |d\":\"44141980-f|
              00000090  61 33 61 2d 34 32 37 36  2d 62 37 37 63 2d 66 64  |a3a-4276-b77c-fd|
              000000a0  35 61 35 34 63 38 64 39  34 32 5c 22 7d 22 3a 7b  |5a54c8d942\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-fxqql",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-fxqql",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.3"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569329,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-fxqql",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.731521 26 deployment.go:68] Pod "webserver-deployment-6fc69b9478-xd756" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-xd756",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=15) "deployment-3510",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b39ccbfc-1023-4b78-8cb3-650e34ddc8b7",
      ResourceVersion: (string) (len=5) "12312",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882569331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "44141980-fa3a-4276-b77c-fd5a54c8d942",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 34  31 34 31 39 38 30 2d 66  |d\":\"44141980-f|
              00000090  61 33 61 2d 34 32 37 36  2d 62 37 37 63 2d 66 64  |a3a-4276-b77c-fd|
              000000a0  35 61 35 34 63 38 64 39  34 32 5c 22 7d 22 3a 7b  |5a54c8d942\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-hx7md",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-hx7md",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882569331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:08:51.731964 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3510" for this suite. @ 05/11/25 14:08:51.734
• [4.199 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 05/11/25 14:08:51.74
  I0511 14:08:51.740100 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename pod-network-test @ 05/11/25 14:08:51.74
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:08:51.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:08:51.747
  STEP: Performing setup for networking test in namespace pod-network-test-8930 @ 05/11/25 14:08:51.748
  STEP: creating a selector @ 05/11/25 14:08:51.748
  STEP: Creating the service pods in kubernetes @ 05/11/25 14:08:51.748
  I0511 14:08:51.748986 26 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0511 14:08:52.390357      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:53.390768      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:54.391652      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:55.391694      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:56.392747      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:57.393767      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:58.393907      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:08:59.394447      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:00.394861      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:01.395354      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:02.395570      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:03.395800      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:04.396180      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:05.396925      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/11/25 14:09:05.892
  E0511 14:09:06.397632      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:07.398093      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:09:07.908986 26 utils.go:802] Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  I0511 14:09:07.909032 26 networking.go:42] Breadth first check of 10.244.0.48 on host 192.168.49.2...
  I0511 14:09:07.911403 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.159:9080/dial?request=hostname&protocol=http&host=10.244.0.48&port=8083&tries=1'] Namespace:pod-network-test-8930 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 14:09:07.911435 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 14:09:07.911507 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/pod-network-test-8930/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.159%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.0.48%26port%3D8083%26tries%3D1%27&container=webserver&stderr=true&stdout=true)
  I0511 14:09:07.970701 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 14:09:07.970794 26 utils.go:355] Waiting for responses: map[]
  I0511 14:09:07.970815 26 utils.go:359] reached 10.244.0.48 after 0/1 tries
  I0511 14:09:07.970862 26 networking.go:42] Breadth first check of 10.244.1.158 on host 192.168.49.3...
  I0511 14:09:07.973149 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.159:9080/dial?request=hostname&protocol=http&host=10.244.1.158&port=8083&tries=1'] Namespace:pod-network-test-8930 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 14:09:07.973171 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 14:09:07.973228 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/pod-network-test-8930/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.159%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.1.158%26port%3D8083%26tries%3D1%27&container=webserver&stderr=true&stdout=true)
  I0511 14:09:08.032867 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 14:09:08.032904 26 utils.go:355] Waiting for responses: map[]
  I0511 14:09:08.032912 26 utils.go:359] reached 10.244.1.158 after 0/1 tries
  I0511 14:09:08.032918 26 networking.go:53] Going to retry 0 out of 2 pods....
  I0511 14:09:08.033004 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-8930" for this suite. @ 05/11/25 14:09:08.035
• [16.302 seconds]
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1050
  STEP: Creating a kubernetes client @ 05/11/25 14:09:08.042
  I0511 14:09:08.042768 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubectl @ 05/11/25 14:09:08.043
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:09:08.052
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:09:08.054
  STEP: create deployment with httpd image @ 05/11/25 14:09:08.057
  I0511 14:09:08.057802 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-4829 create -f -'
  I0511 14:09:08.116398 26 builder.go:146] stderr: ""
  I0511 14:09:08.116424 26 builder.go:147] stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 05/11/25 14:09:08.116
  I0511 14:09:08.116487 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-4829 diff -f -'
  I0511 14:09:08.196674 26 builder.go:135] rc: 1
  I0511 14:09:08.196763 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-4829 delete -f -'
  I0511 14:09:08.239530 26 builder.go:146] stderr: ""
  I0511 14:09:08.239569 26 builder.go:147] stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  I0511 14:09:08.239695 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4829" for this suite. @ 05/11/25 14:09:08.242
• [0.203 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:194
  STEP: Creating a kubernetes client @ 05/11/25 14:09:08.245
  I0511 14:09:08.245691 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 14:09:08.246
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:09:08.253
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:09:08.254
  STEP: Creating a pod to test downward API volume plugin @ 05/11/25 14:09:08.256
  E0511 14:09:08.398508      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:09.398908      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:10.399102      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:11.399246      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:09:12.274
  I0511 14:09:12.277346 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-1ab50df5-a316-4a36-864a-a07aac103ae0 container client-container: <nil>
  STEP: delete the pod @ 05/11/25 14:09:12.284
  I0511 14:09:12.300959 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-100" for this suite. @ 05/11/25 14:09:12.304
• [4.063 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:74
  STEP: Creating a kubernetes client @ 05/11/25 14:09:12.309
  I0511 14:09:12.309368 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename configmap @ 05/11/25 14:09:12.31
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:09:12.321
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:09:12.324
  STEP: Creating configMap with name configmap-test-volume-511950a9-cb75-4939-b74e-731c032bb362 @ 05/11/25 14:09:12.326
  STEP: Creating a pod to test consume configMaps @ 05/11/25 14:09:12.33
  E0511 14:09:12.399801      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:13.399722      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:14.399944      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:15.400228      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:09:16.352
  I0511 14:09:16.354827 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-86a75d9f-ce55-4b2f-8418-62977eb428c7 container agnhost-container: <nil>
  STEP: delete the pod @ 05/11/25 14:09:16.361
  I0511 14:09:16.377225 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2482" for this suite. @ 05/11/25 14:09:16.38
• [4.076 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 05/11/25 14:09:16.385
  I0511 14:09:16.385947 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename replicaset @ 05/11/25 14:09:16.386
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:09:16.396
  E0511 14:09:16.400194      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:09:16.4
  I0511 14:09:16.403589 26 replica_set.go:192] Creating ReplicaSet my-hostname-basic-9ae4607b-09e2-4fdc-bab8-6312b7f42e87
  I0511 14:09:16.414350 26 resource.go:81] Pod name my-hostname-basic-9ae4607b-09e2-4fdc-bab8-6312b7f42e87: Found 0 pods out of 1
  E0511 14:09:17.400686      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:18.401090      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:19.401661      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:20.401747      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:21.402721      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:09:21.496203 26 resource.go:81] Pod name my-hostname-basic-9ae4607b-09e2-4fdc-bab8-6312b7f42e87: Found 1 pods out of 1
  I0511 14:09:21.496265 26 replica_set.go:205] Ensuring a pod for ReplicaSet "my-hostname-basic-9ae4607b-09e2-4fdc-bab8-6312b7f42e87" is running
  I0511 14:09:21.498822 26 replica_set.go:221] Pod "my-hostname-basic-9ae4607b-09e2-4fdc-bab8-6312b7f42e87-8jmjn" is running (conditions: [{Type:PodReadyToStartContainers ObservedGeneration:0 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-05-11 14:09:17 +0000 UTC Reason: Message:} {Type:Initialized ObservedGeneration:0 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-05-11 14:09:16 +0000 UTC Reason: Message:} {Type:Ready ObservedGeneration:0 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-05-11 14:09:17 +0000 UTC Reason: Message:} {Type:ContainersReady ObservedGeneration:0 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-05-11 14:09:17 +0000 UTC Reason: Message:} {Type:PodScheduled ObservedGeneration:0 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-05-11 14:09:16 +0000 UTC Reason: Message:}])
  I0511 14:09:21.498861 26 replica_set.go:229] Trying to dial the pod
  STEP: trying to dial each unique pod @ 05/11/25 14:09:21.498
  I0511 14:09:21.505634 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-885" for this suite. @ 05/11/25 14:09:21.507
• [5.125 seconds]
------------------------------
S
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:743
  STEP: Creating a kubernetes client @ 05/11/25 14:09:21.511
  I0511 14:09:21.511453 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename services @ 05/11/25 14:09:21.511
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:09:21.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:09:21.52
  I0511 14:09:21.522905 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2894" for this suite. @ 05/11/25 14:09:21.61
• [0.107 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2207
  STEP: Creating a kubernetes client @ 05/11/25 14:09:21.618
  I0511 14:09:21.618738 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename services @ 05/11/25 14:09:21.619
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:09:21.627
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:09:21.63
  STEP: creating service in namespace services-3473 @ 05/11/25 14:09:21.633
  STEP: creating service affinity-clusterip-transition in namespace services-3473 @ 05/11/25 14:09:21.633
  I0511 14:09:21.658157 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0511 14:09:22.403046      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:23.403592      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:09:23.672327 26 resource.go:361] Creating new exec pod
  E0511 14:09:24.404020      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:25.404496      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:09:25.689360 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-3473 exec execpod-affinity948lc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  I0511 14:09:25.783915 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition (10.108.18.5) 80 port [tcp/http] succeeded!\n"
  I0511 14:09:25.783984 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 14:09:25.784087 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-3473 exec execpod-affinity948lc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.108.18.5 80'
  I0511 14:09:25.881945 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.108.18.5 80\nConnection to 10.108.18.5 80 port [tcp/http] succeeded!\n"
  I0511 14:09:25.882004 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 14:09:25.890100 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-3473 exec execpod-affinity948lc -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/ ; done'
  I0511 14:09:26.047203 26 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n"
  I0511 14:09:26.047253 26 builder.go:147] stdout: "\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-8kg9b\naffinity-clusterip-transition-5cffb65545-lhmff\naffinity-clusterip-transition-5cffb65545-8kg9b\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-lhmff\naffinity-clusterip-transition-5cffb65545-8kg9b\naffinity-clusterip-transition-5cffb65545-8kg9b\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-8kg9b\naffinity-clusterip-transition-5cffb65545-8kg9b\naffinity-clusterip-transition-5cffb65545-8kg9b\naffinity-clusterip-transition-5cffb65545-lhmff\naffinity-clusterip-transition-5cffb65545-lhmff"
  I0511 14:09:26.047269 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.047280 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-8kg9b
  I0511 14:09:26.047288 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-lhmff
  I0511 14:09:26.047296 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-8kg9b
  I0511 14:09:26.047304 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.047316 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.047324 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.047331 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-lhmff
  I0511 14:09:26.047339 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-8kg9b
  I0511 14:09:26.047346 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-8kg9b
  I0511 14:09:26.047354 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.047361 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-8kg9b
  I0511 14:09:26.047369 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-8kg9b
  I0511 14:09:26.047376 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-8kg9b
  I0511 14:09:26.047384 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-lhmff
  I0511 14:09:26.047391 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-lhmff
  I0511 14:09:26.053264 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-3473 exec execpod-affinity948lc -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/ ; done'
  I0511 14:09:26.216656 26 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.108.18.5:80/\n"
  I0511 14:09:26.216718 26 builder.go:147] stdout: "\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-fhp8m\naffinity-clusterip-transition-5cffb65545-fhp8m"
  I0511 14:09:26.216742 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.216756 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.216768 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.216779 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.216790 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.216801 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.216810 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.216820 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.216836 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.216847 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.216857 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.216868 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.216881 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.216891 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.216901 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.216913 26 service.go:238] Received response from host: affinity-clusterip-transition-5cffb65545-fhp8m
  I0511 14:09:26.216990 26 service.go:4352] Cleaning up the exec pod
  I0511 14:09:26.276612 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3473" for this suite. @ 05/11/25 14:09:26.279
• [4.666 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 05/11/25 14:09:26.284
  I0511 14:09:26.284888 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename subpath @ 05/11/25 14:09:26.285
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:09:26.292
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:09:26.294
  STEP: Setting up data @ 05/11/25 14:09:26.296
  STEP: Creating pod pod-subpath-test-configmap-x9z2 @ 05/11/25 14:09:26.301
  STEP: Creating a pod to test atomic-volume-subpath @ 05/11/25 14:09:26.301
  E0511 14:09:26.405329      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:27.405716      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:28.405821      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:29.406798      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:30.407662      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:31.408742      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:32.409661      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:33.409947      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:34.410868      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:35.411940      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:36.412864      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:37.413213      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:38.413761      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:39.414131      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:40.415246      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:41.415790      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:42.416690      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:43.417685      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:44.418718      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:45.419090      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:46.419308      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:47.419876      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:09:48.365
  I0511 14:09:48.369008 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-subpath-test-configmap-x9z2 container test-container-subpath-configmap-x9z2: <nil>
  STEP: delete the pod @ 05/11/25 14:09:48.377
  STEP: Deleting pod pod-subpath-test-configmap-x9z2 @ 05/11/25 14:09:48.391
  I0511 14:09:48.391456 26 delete.go:62] Deleting pod "pod-subpath-test-configmap-x9z2" in namespace "subpath-576"
  I0511 14:09:48.394246 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-576" for this suite. @ 05/11/25 14:09:48.397
• [22.118 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:154
  STEP: Creating a kubernetes client @ 05/11/25 14:09:48.402
  I0511 14:09:48.402706 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/11/25 14:09:48.403
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:09:48.412
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:09:48.415
  E0511 14:09:48.419989      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: create the container to handle the HTTPGet hook request. @ 05/11/25 14:09:48.498
  E0511 14:09:49.420887      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:50.422111      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/11/25 14:09:50.521
  E0511 14:09:51.422508      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:52.422796      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 05/11/25 14:09:52.539
  E0511 14:09:53.423789      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:54.423760      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 05/11/25 14:09:54.554
  I0511 14:09:54.562395 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-2257" for this suite. @ 05/11/25 14:09:54.565
• [6.169 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:105
  STEP: Creating a kubernetes client @ 05/11/25 14:09:54.571
  I0511 14:09:54.571654 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename replication-controller @ 05/11/25 14:09:54.572
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:09:54.582
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:09:54.585
  STEP: Given a ReplicationController is created @ 05/11/25 14:09:54.589
  STEP: When the matched label of one of its pods change @ 05/11/25 14:09:54.593
  I0511 14:09:54.596861 26 resource.go:81] Pod name pod-release: Found 0 pods out of 1
  E0511 14:09:55.424846      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:56.426047      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:57.426717      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:58.427005      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:09:59.428034      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:09:59.601224 26 resource.go:81] Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 05/11/25 14:09:59.611
  E0511 14:10:00.428817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:10:00.621306 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-4102" for this suite. @ 05/11/25 14:10:00.624
• [6.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:466
  STEP: Creating a kubernetes client @ 05/11/25 14:10:00.631
  I0511 14:10:00.631413 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename sched-pred @ 05/11/25 14:10:00.632
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:10:00.643
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:10:00.646
  I0511 14:10:00.650089 26 helper.go:125] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0511 14:10:00.730393 26 util.go:390] Waiting for terminating namespaces to be deleted...
  I0511 14:10:00.733547 26 predicates.go:118] 
  Logging pods the apiserver thinks is on node k8sconformance before test
  I0511 14:10:00.737827 26 predicates.go:956] coredns-674b8bbfcf-68gnm from kube-system started at 2025-05-11 13:00:07 +0000 UTC (1 container statuses recorded)
  I0511 14:10:00.737853 26 predicates.go:958] 	Container coredns ready: true, restart count 4
  I0511 14:10:00.737868 26 predicates.go:956] etcd-k8sconformance from kube-system started at 2025-05-11 13:00:02 +0000 UTC (1 container statuses recorded)
  I0511 14:10:00.737877 26 predicates.go:958] 	Container etcd ready: true, restart count 0
  I0511 14:10:00.737886 26 predicates.go:956] kindnet-cs969 from kube-system started at 2025-05-11 13:00:07 +0000 UTC (1 container statuses recorded)
  I0511 14:10:00.737895 26 predicates.go:958] 	Container kindnet-cni ready: true, restart count 0
  I0511 14:10:00.737903 26 predicates.go:956] kube-apiserver-k8sconformance from kube-system started at 2025-05-11 13:00:02 +0000 UTC (1 container statuses recorded)
  I0511 14:10:00.737910 26 predicates.go:958] 	Container kube-apiserver ready: true, restart count 0
  I0511 14:10:00.737919 26 predicates.go:956] kube-controller-manager-k8sconformance from kube-system started at 2025-05-11 13:00:02 +0000 UTC (1 container statuses recorded)
  I0511 14:10:00.737926 26 predicates.go:958] 	Container kube-controller-manager ready: true, restart count 0
  I0511 14:10:00.737936 26 predicates.go:956] kube-proxy-ssjxm from kube-system started at 2025-05-11 13:00:07 +0000 UTC (1 container statuses recorded)
  I0511 14:10:00.737944 26 predicates.go:958] 	Container kube-proxy ready: true, restart count 0
  I0511 14:10:00.737952 26 predicates.go:956] kube-scheduler-k8sconformance from kube-system started at 2025-05-11 13:00:02 +0000 UTC (1 container statuses recorded)
  I0511 14:10:00.737960 26 predicates.go:958] 	Container kube-scheduler ready: true, restart count 0
  I0511 14:10:00.737969 26 predicates.go:956] storage-provisioner from kube-system started at 2025-05-11 13:00:08 +0000 UTC (1 container statuses recorded)
  I0511 14:10:00.737978 26 predicates.go:958] 	Container storage-provisioner ready: true, restart count 0
  I0511 14:10:00.737986 26 predicates.go:956] sonobuoy-systemd-logs-daemon-set-3b1a685ddb394b60-rggfh from sonobuoy started at 2025-05-11 13:02:10 +0000 UTC (2 container statuses recorded)
  I0511 14:10:00.737994 26 predicates.go:958] 	Container sonobuoy-worker ready: true, restart count 0
  I0511 14:10:00.738002 26 predicates.go:958] 	Container systemd-logs ready: true, restart count 0
  I0511 14:10:00.738010 26 predicates.go:118] 
  Logging pods the apiserver thinks is on node k8sconformance-m02 before test
  I0511 14:10:00.741199 26 predicates.go:956] kindnet-5r7wn from kube-system started at 2025-05-11 13:31:32 +0000 UTC (1 container statuses recorded)
  I0511 14:10:00.741234 26 predicates.go:958] 	Container kindnet-cni ready: true, restart count 0
  I0511 14:10:00.741251 26 predicates.go:956] kube-proxy-wwbpc from kube-system started at 2025-05-11 13:00:19 +0000 UTC (1 container statuses recorded)
  I0511 14:10:00.741265 26 predicates.go:958] 	Container kube-proxy ready: true, restart count 0
  I0511 14:10:00.741278 26 predicates.go:956] pod-release-5r6v4 from replication-controller-4102 started at 2025-05-11 14:09:54 +0000 UTC (1 container statuses recorded)
  I0511 14:10:00.741290 26 predicates.go:958] 	Container pod-release ready: true, restart count 0
  I0511 14:10:00.741302 26 predicates.go:956] pod-release-7hwb6 from replication-controller-4102 started at 2025-05-11 14:09:59 +0000 UTC (1 container statuses recorded)
  I0511 14:10:00.741321 26 predicates.go:958] 	Container pod-release ready: true, restart count 0
  I0511 14:10:00.741336 26 predicates.go:956] sonobuoy from sonobuoy started at 2025-05-11 13:01:52 +0000 UTC (1 container statuses recorded)
  I0511 14:10:00.741347 26 predicates.go:958] 	Container kube-sonobuoy ready: true, restart count 0
  I0511 14:10:00.741359 26 predicates.go:956] sonobuoy-e2e-job-32c36e3a15c942ea from sonobuoy started at 2025-05-11 13:02:10 +0000 UTC (2 container statuses recorded)
  I0511 14:10:00.741369 26 predicates.go:958] 	Container e2e ready: true, restart count 0
  I0511 14:10:00.741379 26 predicates.go:958] 	Container sonobuoy-worker ready: true, restart count 0
  I0511 14:10:00.741390 26 predicates.go:956] sonobuoy-systemd-logs-daemon-set-3b1a685ddb394b60-t2p28 from sonobuoy started at 2025-05-11 13:02:10 +0000 UTC (2 container statuses recorded)
  I0511 14:10:00.741399 26 predicates.go:958] 	Container sonobuoy-worker ready: true, restart count 0
  I0511 14:10:00.741409 26 predicates.go:958] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 05/11/25 14:10:00.741
  E0511 14:10:01.429843      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:02.430266      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 05/11/25 14:10:02.76
  STEP: Trying to apply a random label on the found node. @ 05/11/25 14:10:02.772
  STEP: verifying the node has the label kubernetes.io/e2e-a2e4d771-404d-48ee-845c-71d8a9c4bd78 42 @ 05/11/25 14:10:02.784
  STEP: Trying to relaunch the pod, now with labels. @ 05/11/25 14:10:02.789
  E0511 14:10:03.430339      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:04.431124      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-a2e4d771-404d-48ee-845c-71d8a9c4bd78 off the node k8sconformance-m02 @ 05/11/25 14:10:04.814
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-a2e4d771-404d-48ee-845c-71d8a9c4bd78 @ 05/11/25 14:10:04.825
  I0511 14:10:04.829274 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-5112" for this suite. @ 05/11/25 14:10:04.832
• [4.207 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:239
  STEP: Creating a kubernetes client @ 05/11/25 14:10:04.838
  I0511 14:10:04.838909 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename resourcequota @ 05/11/25 14:10:04.839
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:10:04.851
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:10:04.853
  STEP: Counting existing ResourceQuota @ 05/11/25 14:10:04.855
  E0511 14:10:05.431845      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:06.432398      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:07.432941      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:08.433736      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:09.434210      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/11/25 14:10:09.858
  STEP: Ensuring resource quota status is calculated @ 05/11/25 14:10:09.863
  E0511 14:10:10.434390      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:11.434825      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 05/11/25 14:10:11.868
  STEP: Ensuring ResourceQuota status captures the pod usage @ 05/11/25 14:10:11.883
  E0511 14:10:12.435913      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:13.436739      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 05/11/25 14:10:13.889
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 05/11/25 14:10:13.892
  STEP: Ensuring a pod cannot update its resource requirements @ 05/11/25 14:10:13.894
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 05/11/25 14:10:13.898
  E0511 14:10:14.437342      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:15.437805      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/11/25 14:10:15.904
  STEP: Ensuring resource quota status released the pod usage @ 05/11/25 14:10:15.913
  E0511 14:10:16.438888      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:17.439781      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:10:17.917927 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9694" for this suite. @ 05/11/25 14:10:17.921
• [13.088 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:935
  STEP: Creating a kubernetes client @ 05/11/25 14:10:17.927
  I0511 14:10:17.927542 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename sched-preemption @ 05/11/25 14:10:17.928
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:10:17.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:10:17.942
  I0511 14:10:17.955422 26 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  E0511 14:10:18.442658      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:19.442816      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:20.443765      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:21.444233      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:22.444517      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:23.444730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:24.445258      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:25.445714      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:26.445983      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:27.446426      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:28.447497      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:29.448034      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:30.448426      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:31.448814      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:32.449215      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:33.449788      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:34.450597      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:35.450878      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:36.451281      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:37.451896      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:38.451946      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:39.452791      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:40.453493      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:41.453828      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:42.454789      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:43.455891      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:44.456632      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:45.457058      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:46.457844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:47.458277      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:48.458367      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:49.458933      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:50.459038      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:51.459614      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:52.460098      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:53.460824      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:54.460985      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:55.461404      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:56.462364      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:57.462861      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:58.463789      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:10:59.464737      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:00.465058      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:01.465836      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:02.466892      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:03.467239      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:04.468438      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:05.468835      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:06.469210      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:07.469915      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:08.471006      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:09.471977      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:10.471963      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:11.472919      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:12.473741      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:13.473811      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:14.474264      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:15.474600      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:16.474656      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:17.475233      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:17.960954 26 util.go:390] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 05/11/25 14:11:17.964
  I0511 14:11:17.964046 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename sched-preemption-path @ 05/11/25 14:11:17.964
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:11:17.978
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:11:17.982
  I0511 14:11:17.999524 26 preemption.go:941] PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  I0511 14:11:18.002404 26 preemption.go:947] PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  STEP: Removing a custom resource @ 05/11/25 14:11:18.039
  STEP: Removing a custom resource @ 05/11/25 14:11:18.047
  I0511 14:11:18.054568 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-6314" for this suite. @ 05/11/25 14:11:18.06
  I0511 14:11:18.067637 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-2429" for this suite. @ 05/11/25 14:11:18.163
• [60.242 seconds]
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:133
  STEP: Creating a kubernetes client @ 05/11/25 14:11:18.169
  I0511 14:11:18.169701 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename runtimeclass @ 05/11/25 14:11:18.17
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:11:18.179
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:11:18.182
  E0511 14:11:18.475922      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:19.476515      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:20.212180 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8087" for this suite. @ 05/11/25 14:11:20.216
• [2.053 seconds]
------------------------------
SSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 05/11/25 14:11:20.223
  I0511 14:11:20.223186 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename limitrange @ 05/11/25 14:11:20.224
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:11:20.233
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:11:20.236
  STEP: Creating LimitRange "e2e-limitrange-tnk98" in namespace "limitrange-4264" @ 05/11/25 14:11:20.239
  STEP: Creating another limitRange in another namespace @ 05/11/25 14:11:20.246
  I0511 14:11:20.254699 26 limit_range.go:299] Namespace "e2e-limitrange-tnk98-6650" created
  I0511 14:11:20.254744 26 limit_range.go:300] Creating LimitRange "e2e-limitrange-tnk98" in namespace "e2e-limitrange-tnk98-6650"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-tnk98" @ 05/11/25 14:11:20.26
  I0511 14:11:20.263227 26 limit_range.go:309] Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-tnk98" in "limitrange-4264" namespace @ 05/11/25 14:11:20.263
  I0511 14:11:20.270280 26 limit_range.go:335] LimitRange "e2e-limitrange-tnk98" has been patched
  STEP: Delete LimitRange "e2e-limitrange-tnk98" by Collection with labelSelector: "e2e-limitrange-tnk98=patched" @ 05/11/25 14:11:20.27
  STEP: Confirm that the limitRange "e2e-limitrange-tnk98" has been deleted @ 05/11/25 14:11:20.275
  I0511 14:11:20.275572 26 limit_range.go:443] Requesting list of LimitRange to confirm quantity
  I0511 14:11:20.277170 26 limit_range.go:453] Found 0 LimitRange with label "e2e-limitrange-tnk98=patched"
  I0511 14:11:20.277187 26 limit_range.go:344] LimitRange "e2e-limitrange-tnk98" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-tnk98" @ 05/11/25 14:11:20.277
  I0511 14:11:20.278835 26 limit_range.go:350] Found 1 limitRange
  I0511 14:11:20.278933 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-4264" for this suite. @ 05/11/25 14:11:20.318
  STEP: Destroying namespace "e2e-limitrange-tnk98-6650" for this suite. @ 05/11/25 14:11:20.324
• [0.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:196
  STEP: Creating a kubernetes client @ 05/11/25 14:11:20.329
  I0511 14:11:20.329611 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/11/25 14:11:20.33
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:11:20.341
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:11:20.345
  I0511 14:11:20.348860 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  E0511 14:11:20.476684      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:21.476947      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 05/11/25 14:11:21.491
  I0511 14:11:21.491224 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-608 --namespace=crd-publish-openapi-608 create -f -'
  E0511 14:11:22.477901      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:23.477984      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:23.551813 26 builder.go:146] stderr: ""
  I0511 14:11:23.551877 26 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5171-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0511 14:11:23.551948 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-608 --namespace=crd-publish-openapi-608 delete e2e-test-crd-publish-openapi-5171-crds test-cr'
  I0511 14:11:23.595632 26 builder.go:146] stderr: ""
  I0511 14:11:23.595665 26 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5171-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  I0511 14:11:23.595703 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-608 --namespace=crd-publish-openapi-608 apply -f -'
  I0511 14:11:23.640388 26 builder.go:146] stderr: ""
  I0511 14:11:23.640438 26 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5171-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0511 14:11:23.640499 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-608 --namespace=crd-publish-openapi-608 delete e2e-test-crd-publish-openapi-5171-crds test-cr'
  I0511 14:11:23.681814 26 builder.go:146] stderr: ""
  I0511 14:11:23.681847 26 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5171-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 05/11/25 14:11:23.681
  I0511 14:11:23.681930 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-608 explain e2e-test-crd-publish-openapi-5171-crds'
  I0511 14:11:23.719866 26 builder.go:146] stderr: ""
  I0511 14:11:23.719916 26 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-5171-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0511 14:11:24.478891      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:24.858752 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-608" for this suite. @ 05/11/25 14:11:24.863
• [4.539 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 05/11/25 14:11:24.868
  I0511 14:11:24.868637 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename container-probe @ 05/11/25 14:11:24.869
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:11:24.876
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:11:24.878
  STEP: Creating pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862 @ 05/11/25 14:11:24.88
  E0511 14:11:25.479226      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:26.479589      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/11/25 14:11:26.895
  I0511 14:11:26.897732 26 container_probe.go:1748] Initial restart count of pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae is 0
  I0511 14:11:26.899888 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:11:27.479684      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:28.479807      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:28.905039 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:11:29.479784      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:30.480078      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:30.910635 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:11:31.480788      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:32.481794      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:32.915292 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:11:33.481966      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:34.482860      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:34.918550 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:11:35.483410      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:36.483839      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:36.924617 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:11:37.484256      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:38.484884      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:38.930532 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:11:39.485908      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:40.486160      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:40.935322 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:11:41.486862      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:42.487446      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:42.939551 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:11:43.488220      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:44.488790      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:44.944209 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:11:45.488873      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:46.490038      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:46.948534 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:11:47.490796      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:48.491241      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:48.953658 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:11:49.492361      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:50.492811      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:50.958755 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:11:51.493589      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:52.493721      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:52.963048 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:11:53.494786      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:54.495010      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:54.968077 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:11:55.495629      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:56.495958      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:56.973080 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:11:57.496942      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:11:58.497518      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:11:58.978498 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:11:59.497738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:00.498138      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:12:00.984807 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:12:01.499173      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:02.499634      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:12:02.990873 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:12:03.500613      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:04.501144      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:12:04.995562 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:12:05.502279      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:06.502853      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:12:07.001776 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:12:07.503879      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:08.504354      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:12:09.007809 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:12:09.504425      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:10.504810      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:12:11.011946 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:12:11.505530      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:12.505914      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:12:13.017366 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:12:13.506005      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:14.506379      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:12:15.022539 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  E0511 14:12:15.507087      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:16.507899      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:12:17.026706 26 container_probe.go:1758] Get pod busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae in namespace container-probe-4862
  I0511 14:12:17.026769 26 container_probe.go:1762] Restart count of pod container-probe-4862/busybox-2e878e41-5d7f-408a-bd86-e90a4211b7ae is now 1 (50.12900067s elapsed)
  STEP: deleting the pod @ 05/11/25 14:12:17.026
  I0511 14:12:17.040852 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4862" for this suite. @ 05/11/25 14:12:17.044
• [52.185 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:108
  STEP: Creating a kubernetes client @ 05/11/25 14:12:17.055
  I0511 14:12:17.055178 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename resourcequota @ 05/11/25 14:12:17.056
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:12:17.065
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:12:17.068
  STEP: Counting existing ResourceQuota @ 05/11/25 14:12:17.072
  E0511 14:12:17.508862      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:18.509844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:19.510621      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:20.511707      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:21.512543      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/11/25 14:12:22.076
  STEP: Ensuring resource quota status is calculated @ 05/11/25 14:12:22.081
  E0511 14:12:22.512757      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:23.513194      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 05/11/25 14:12:24.085
  STEP: Creating a NodePort Service @ 05/11/25 14:12:24.109
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 05/11/25 14:12:24.135
  STEP: Ensuring resource quota status captures service creation @ 05/11/25 14:12:24.165
  E0511 14:12:24.513266      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:25.513704      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 05/11/25 14:12:26.168
  STEP: Ensuring resource quota status released usage @ 05/11/25 14:12:26.204
  E0511 14:12:26.514869      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:27.515446      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:12:28.210825 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8300" for this suite. @ 05/11/25 14:12:28.215
• [11.166 seconds]
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 05/11/25 14:12:28.221
  I0511 14:12:28.221860 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename limitrange @ 05/11/25 14:12:28.223
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:12:28.233
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:12:28.236
  STEP: Creating a LimitRange @ 05/11/25 14:12:28.239
  STEP: Setting up watch @ 05/11/25 14:12:28.239
  STEP: Submitting a LimitRange @ 05/11/25 14:12:28.342
  STEP: Verifying LimitRange creation was observed @ 05/11/25 14:12:28.348
  STEP: Fetching the LimitRange to ensure it has proper values @ 05/11/25 14:12:28.348
  I0511 14:12:28.351784 26 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0511 14:12:28.351848 26 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 05/11/25 14:12:28.351
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 05/11/25 14:12:28.356
  I0511 14:12:28.359677 26 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0511 14:12:28.359731 26 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 05/11/25 14:12:28.359
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 05/11/25 14:12:28.365
  I0511 14:12:28.369028 26 limit_range.go:355] Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  I0511 14:12:28.369092 26 limit_range.go:360] Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 05/11/25 14:12:28.369
  STEP: Failing to create a Pod with more than max resources @ 05/11/25 14:12:28.371
  STEP: Updating a LimitRange @ 05/11/25 14:12:28.375
  STEP: Verifying LimitRange updating is effective @ 05/11/25 14:12:28.382
  E0511 14:12:28.516102      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:29.516901      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 05/11/25 14:12:30.387
  STEP: Failing to create a Pod with more than max resources @ 05/11/25 14:12:30.394
  STEP: Deleting a LimitRange @ 05/11/25 14:12:30.397
  STEP: Verifying the LimitRange was deleted @ 05/11/25 14:12:30.403
  E0511 14:12:30.517495      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:31.518070      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:32.518669      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:33.519067      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:34.519686      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:12:35.408578 26 limit_range.go:211] limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 05/11/25 14:12:35.408
  I0511 14:12:35.417592 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-6424" for this suite. @ 05/11/25 14:12:35.421
• [7.208 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
k8s.io/kubernetes/test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 05/11/25 14:12:35.434
  I0511 14:12:35.434780 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename conformance-tests @ 05/11/25 14:12:35.435
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:12:35.444
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:12:35.446
  STEP: Getting node addresses @ 05/11/25 14:12:35.449
  I0511 14:12:35.449172 26 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0511 14:12:35.520250      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:12:35.522962 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-5467" for this suite. @ 05/11/25 14:12:35.526
• [0.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:156
  STEP: Creating a kubernetes client @ 05/11/25 14:12:35.532
  I0511 14:12:35.532382 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename var-expansion @ 05/11/25 14:12:35.533
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:12:35.544
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:12:35.548
  E0511 14:12:36.520778      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:37.521297      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:12:37.567635 26 delete.go:62] Deleting pod "var-expansion-82326e81-0f6b-43e9-91f9-10b855e4e301" in namespace "var-expansion-3407"
  I0511 14:12:37.577663 26 delete.go:70] Wait up to 5m0s for pod "var-expansion-82326e81-0f6b-43e9-91f9-10b855e4e301" to be fully deleted
  E0511 14:12:38.522039      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:39.522720      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:12:39.586182 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3407" for this suite. @ 05/11/25 14:12:39.589
• [4.065 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 05/11/25 14:12:39.597
  I0511 14:12:39.597845 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 14:12:39.598
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:12:39.607
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:12:39.611
  STEP: Creating projection with secret that has name projected-secret-test-map-316b7545-7003-4982-bcd6-20079a4f2432 @ 05/11/25 14:12:39.613
  STEP: Creating a pod to test consume secrets @ 05/11/25 14:12:39.618
  E0511 14:12:40.523647      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:41.524040      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:42.524857      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:43.525357      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:12:43.635
  I0511 14:12:43.638783 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-projected-secrets-899d06a3-8be0-4fb0-b219-7ce7647cd986 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/11/25 14:12:43.657
  I0511 14:12:43.667446 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6156" for this suite. @ 05/11/25 14:12:43.669
• [4.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:458
  STEP: Creating a kubernetes client @ 05/11/25 14:12:43.672
  I0511 14:12:43.672719 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename resourcequota @ 05/11/25 14:12:43.673
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:12:43.678
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:12:43.68
  STEP: Counting existing ResourceQuota @ 05/11/25 14:12:43.682
  E0511 14:12:44.525693      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:45.526731      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:46.527832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:47.528282      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:48.528516      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/11/25 14:12:48.685
  STEP: Ensuring resource quota status is calculated @ 05/11/25 14:12:48.691
  E0511 14:12:49.528682      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:50.529193      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a ReplicaSet @ 05/11/25 14:12:50.695
  STEP: Ensuring resource quota status captures replicaset creation @ 05/11/25 14:12:50.707
  E0511 14:12:51.530166      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:52.530867      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicaSet @ 05/11/25 14:12:52.713
  STEP: Ensuring resource quota status released usage @ 05/11/25 14:12:52.721
  E0511 14:12:53.531212      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:54.531734      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:12:54.726959 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6750" for this suite. @ 05/11/25 14:12:54.73
• [11.066 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:866
  STEP: Creating a kubernetes client @ 05/11/25 14:12:54.738
  I0511 14:12:54.738670 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 14:12:54.739
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:12:54.749
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:12:54.752
  STEP: Setting up server cert @ 05/11/25 14:12:54.784
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 14:12:55.071
  STEP: Deploying the webhook pod @ 05/11/25 14:12:55.076
  STEP: Wait for the deployment to be ready @ 05/11/25 14:12:55.083
  I0511 14:12:55.088541 26 deployment.go:223] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0511 14:12:55.532108      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:56.532849      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/11/25 14:12:57.098
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 14:12:57.114
  E0511 14:12:57.533259      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:12:58.115589 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 05/11/25 14:12:58.118
  STEP: create the configmap with a random name @ 05/11/25 14:12:58.135
  STEP: verify the configmap is mutated @ 05/11/25 14:12:58.144
  STEP: create the configmap with 'skip-me' name @ 05/11/25 14:12:58.144
  I0511 14:12:58.185046 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-507" for this suite. @ 05/11/25 14:12:58.187
  STEP: Destroying namespace "webhook-markers-5" for this suite. @ 05/11/25 14:12:58.194
• [3.460 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:184
  STEP: Creating a kubernetes client @ 05/11/25 14:12:58.199
  I0511 14:12:58.199804 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubelet-test @ 05/11/25 14:12:58.2
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:12:58.213
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:12:58.215
  E0511 14:12:58.533645      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:12:59.534346      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:13:00.238517 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-5404" for this suite. @ 05/11/25 14:13:00.241
• [2.047 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:570
  STEP: Creating a kubernetes client @ 05/11/25 14:13:00.247
  I0511 14:13:00.247427 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename security-context-test @ 05/11/25 14:13:00.248
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:13:00.256
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:13:00.259
  E0511 14:13:00.534918      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:01.535456      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:02.536202      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:03.536639      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:13:04.280921 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-5326" for this suite. @ 05/11/25 14:13:04.284
• [4.043 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:330
  STEP: Creating a kubernetes client @ 05/11/25 14:13:04.29
  I0511 14:13:04.290995 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename gc @ 05/11/25 14:13:04.292
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:13:04.3
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:13:04.303
  STEP: create the rc @ 05/11/25 14:13:04.306
  I0511 14:13:04.310170      26 warnings.go:110] "Warning: metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]"
  E0511 14:13:04.536947      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:05.537129      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:06.537267      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:07.537942      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:08.538387      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the rc @ 05/11/25 14:13:09.312
  STEP: wait for all pods to be garbage collected @ 05/11/25 14:13:09.316
  E0511 14:13:09.538665      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:10.539207      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:11.539662      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:12.539955      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:13.540821      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/11/25 14:13:14.321
  I0511 14:13:14.415132 26 garbage_collector.go:273] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0511 14:13:14.415218 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-289" for this suite. @ 05/11/25 14:13:14.417
• [10.132 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 05/11/25 14:13:14.422
  I0511 14:13:14.422642 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename replicaset @ 05/11/25 14:13:14.423
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:13:14.429
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:13:14.431
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 05/11/25 14:13:14.432
  E0511 14:13:14.541982      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:15.543006      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 05/11/25 14:13:16.448
  STEP: Then the orphan pod is adopted @ 05/11/25 14:13:16.454
  E0511 14:13:16.544018      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 05/11/25 14:13:17.462
  I0511 14:13:17.465761 26 resource.go:81] Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 05/11/25 14:13:17.477
  E0511 14:13:17.544833      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:13:18.487600 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-5043" for this suite. @ 05/11/25 14:13:18.491
• [4.074 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Job with successPolicy should succeeded when all indexes succeeded [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:485
  STEP: Creating a kubernetes client @ 05/11/25 14:13:18.497
  I0511 14:13:18.497049 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename job @ 05/11/25 14:13:18.498
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:13:18.508
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:13:18.511
  STEP: Creating an indexed job with successPolicy @ 05/11/25 14:13:18.515
  STEP: Awaiting for the job to have the interim SuccessCriteriaMet with SuccessPolicy reason condition @ 05/11/25 14:13:18.52
  E0511 14:13:18.545513      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:19.545626      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:20.546544      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:21.546936      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensure that the job reaches completions @ 05/11/25 14:13:22.534
  STEP: Verifying that the job status to ensure correct final state @ 05/11/25 14:13:22.539
  I0511 14:13:22.541631 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-5199" for this suite. @ 05/11/25 14:13:22.544
  E0511 14:13:22.547716      26 retrywatcher.go:169] "Watch failed" err="context canceled"
• [4.055 seconds]
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts should create a serviceAccountToken and ensure a successful TokenReview [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:877
  STEP: Creating a kubernetes client @ 05/11/25 14:13:22.552
  I0511 14:13:22.552061 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename svcaccounts @ 05/11/25 14:13:22.553
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:13:22.564
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:13:22.567
  STEP: Creating a Serviceaccount "e2e-sa-87k8s" in namespace "svcaccounts-5175" @ 05/11/25 14:13:22.569
  STEP: Creating a ServiceaccountToken "e2e-sa-87k8s" in namespace "svcaccounts-5175" @ 05/11/25 14:13:22.575
  STEP: Creating a TokenReview for "e2e-sa-87k8s" in namespace "svcaccounts-5175" @ 05/11/25 14:13:22.579
  I0511 14:13:22.581359 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5175" for this suite. @ 05/11/25 14:13:22.647
• [0.101 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:62
  STEP: Creating a kubernetes client @ 05/11/25 14:13:22.653
  I0511 14:13:22.653144 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename field-validation @ 05/11/25 14:13:22.654
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:13:22.664
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:13:22.667
  STEP: apply creating a deployment @ 05/11/25 14:13:22.671
  I0511 14:13:22.681597 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-326" for this suite. @ 05/11/25 14:13:22.747
• [0.100 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/logs.go:167
  STEP: Creating a kubernetes client @ 05/11/25 14:13:22.753
  I0511 14:13:22.753828 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubectl-logs @ 05/11/25 14:13:22.755
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:13:22.765
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:13:22.768
  STEP: creating a pod @ 05/11/25 14:13:22.772
  I0511 14:13:22.772809 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-logs-7503 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.53 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  I0511 14:13:22.819823 26 builder.go:146] stderr: ""
  I0511 14:13:22.819885 26 builder.go:147] stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 05/11/25 14:13:22.819
  I0511 14:13:22.819959 26 resource.go:413] Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E0511 14:13:23.548694      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:24.549041      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:13:24.827446 26 resource.go:435] Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 05/11/25 14:13:24.827
  I0511 14:13:24.827600 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-logs-7503 logs logs-generator logs-generator'
  I0511 14:13:24.876369 26 builder.go:146] stderr: ""
  I0511 14:13:24.876410 26 builder.go:147] stdout: "I0511 14:13:23.433189       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/hqzg 276\nI0511 14:13:23.633592       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/2jjc 238\nI0511 14:13:23.834017       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/dlps 355\nI0511 14:13:24.033577       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/rk2p 379\nI0511 14:13:24.234105       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/tdn 230\nI0511 14:13:24.433673       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/cdk 545\nI0511 14:13:24.634169       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/gtrc 275\nI0511 14:13:24.833677       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/7pds 324\n"
  STEP: limiting log lines @ 05/11/25 14:13:24.876
  I0511 14:13:24.876496 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-logs-7503 logs logs-generator logs-generator --tail=1'
  I0511 14:13:24.923014 26 builder.go:146] stderr: ""
  I0511 14:13:24.923057 26 builder.go:147] stdout: "I0511 14:13:24.833677       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/7pds 324\n"
  I0511 14:13:24.923072 26 logs.go:180] got output "I0511 14:13:24.833677       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/7pds 324\n"
  STEP: limiting log bytes @ 05/11/25 14:13:24.923
  I0511 14:13:24.923157 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-logs-7503 logs logs-generator logs-generator --limit-bytes=1'
  I0511 14:13:24.965271 26 builder.go:146] stderr: ""
  I0511 14:13:24.965307 26 builder.go:147] stdout: "I"
  I0511 14:13:24.965316 26 logs.go:186] got output "I"
  STEP: exposing timestamps @ 05/11/25 14:13:24.965
  I0511 14:13:24.965409 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-logs-7503 logs logs-generator logs-generator --tail=1 --timestamps'
  I0511 14:13:25.007266 26 builder.go:146] stderr: ""
  I0511 14:13:25.007299 26 builder.go:147] stdout: "2025-05-11T14:13:24.833793335Z I0511 14:13:24.833677       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/7pds 324\n"
  I0511 14:13:25.007310 26 logs.go:192] got output "2025-05-11T14:13:24.833793335Z I0511 14:13:24.833677       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/7pds 324\n"
  STEP: restricting to a time range @ 05/11/25 14:13:25.007
  E0511 14:13:25.549253      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:26.549869      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:13:27.507677 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-logs-7503 logs logs-generator logs-generator --since=1s'
  E0511 14:13:27.550206      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:13:27.555882 26 builder.go:146] stderr: ""
  I0511 14:13:27.555920 26 builder.go:147] stdout: "I0511 14:13:26.634022       1 logs_generator.go:76] 16 GET /api/v1/namespaces/kube-system/pods/48h8 523\nI0511 14:13:26.833415       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/6lb 340\nI0511 14:13:27.034031       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/9fdx 510\nI0511 14:13:27.233484       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/nsk 465\nI0511 14:13:27.433943       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/wsjx 359\n"
  I0511 14:13:27.555968 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-logs-7503 logs logs-generator logs-generator --since=24h'
  I0511 14:13:27.608794 26 builder.go:146] stderr: ""
  I0511 14:13:27.608858 26 builder.go:147] stdout: "I0511 14:13:23.433189       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/hqzg 276\nI0511 14:13:23.633592       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/2jjc 238\nI0511 14:13:23.834017       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/dlps 355\nI0511 14:13:24.033577       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/rk2p 379\nI0511 14:13:24.234105       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/tdn 230\nI0511 14:13:24.433673       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/cdk 545\nI0511 14:13:24.634169       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/gtrc 275\nI0511 14:13:24.833677       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/7pds 324\nI0511 14:13:25.034038       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/bqc 593\nI0511 14:13:25.233547       1 logs_generator.go:76] 9 POST /api/v1/namespaces/kube-system/pods/qnct 257\nI0511 14:13:25.433949       1 logs_generator.go:76] 10 POST /api/v1/namespaces/kube-system/pods/s6jt 485\nI0511 14:13:25.633560       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/sr4j 584\nI0511 14:13:25.833994       1 logs_generator.go:76] 12 GET /api/v1/namespaces/ns/pods/cbml 234\nI0511 14:13:26.033530       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/nxxm 413\nI0511 14:13:26.234054       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/dgd 373\nI0511 14:13:26.433379       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/lb9 433\nI0511 14:13:26.634022       1 logs_generator.go:76] 16 GET /api/v1/namespaces/kube-system/pods/48h8 523\nI0511 14:13:26.833415       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/6lb 340\nI0511 14:13:27.034031       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/9fdx 510\nI0511 14:13:27.233484       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/nsk 465\nI0511 14:13:27.433943       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/wsjx 359\n"
  I0511 14:13:27.608968 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-logs-7503 delete pod logs-generator'
  I0511 14:13:28.163258 26 builder.go:146] stderr: ""
  I0511 14:13:28.163303 26 builder.go:147] stdout: "pod \"logs-generator\" deleted\n"
  I0511 14:13:28.163428 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-7503" for this suite. @ 05/11/25 14:13:28.165
• [5.415 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:335
  STEP: Creating a kubernetes client @ 05/11/25 14:13:28.168
  I0511 14:13:28.169002 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename resourcequota @ 05/11/25 14:13:28.169
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:13:28.179
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:13:28.182
  E0511 14:13:28.550758      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:29.551360      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:30.551961      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:31.552652      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:32.553610      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:33.554098      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:34.554941      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:35.555429      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:36.556442      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:37.556807      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:38.557622      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:39.557956      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:40.558072      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:41.558892      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:42.559940      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:43.560948      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:44.561894      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 05/11/25 14:13:45.189
  E0511 14:13:45.562647      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:46.562794      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:47.563783      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:48.565021      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:49.565999      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/11/25 14:13:50.195
  STEP: Ensuring resource quota status is calculated @ 05/11/25 14:13:50.203
  E0511 14:13:50.566715      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:51.567784      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 05/11/25 14:13:52.207
  STEP: Ensuring resource quota status captures configMap creation @ 05/11/25 14:13:52.223
  E0511 14:13:52.568434      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:53.568710      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 05/11/25 14:13:54.226
  STEP: Ensuring resource quota status released usage @ 05/11/25 14:13:54.233
  E0511 14:13:54.569086      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:55.569753      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:13:56.236790 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5654" for this suite. @ 05/11/25 14:13:56.239
• [28.076 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 05/11/25 14:13:56.244
  I0511 14:13:56.244992 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/11/25 14:13:56.245
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:13:56.256
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:13:56.259
  I0511 14:13:56.262138 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  E0511 14:13:56.570408      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:13:56.799767 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-3849" for this suite. @ 05/11/25 14:13:56.803
• [0.563 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:99
  STEP: Creating a kubernetes client @ 05/11/25 14:13:56.808
  I0511 14:13:56.808684 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename emptydir @ 05/11/25 14:13:56.809
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:13:56.818
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:13:56.821
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 05/11/25 14:13:56.824
  E0511 14:13:57.571278      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:13:58.571691      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:13:58.837
  I0511 14:13:58.840639 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-3f059311-311f-4562-95f6-246b8144e274 container test-container: <nil>
  STEP: delete the pod @ 05/11/25 14:13:58.849
  I0511 14:13:58.861220 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-907" for this suite. @ 05/11/25 14:13:58.864
• [2.061 seconds]
------------------------------
S
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:329
  STEP: Creating a kubernetes client @ 05/11/25 14:13:58.869
  I0511 14:13:58.869680 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename proxy @ 05/11/25 14:13:58.87
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:13:58.878
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:13:58.881
  I0511 14:13:58.883922 26 proxy.go:336] Creating pod...
  E0511 14:13:59.571753      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:00.572738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:00.898898 26 proxy.go:360] Creating service...
  I0511 14:14:00.914610 26 proxy.go:397] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7253/pods/agnhost/proxy/some/path/with/DELETE
  I0511 14:14:00.917973 26 proxy.go:573] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0511 14:14:00.918013 26 proxy.go:397] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7253/pods/agnhost/proxy/some/path/with/GET
  I0511 14:14:00.920532 26 proxy.go:573] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0511 14:14:00.920588 26 proxy.go:397] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7253/pods/agnhost/proxy/some/path/with/HEAD
  I0511 14:14:00.922955 26 proxy.go:560] http.Client request:HEAD | StatusCode:200
  I0511 14:14:00.923005 26 proxy.go:397] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7253/pods/agnhost/proxy/some/path/with/OPTIONS
  I0511 14:14:00.925741 26 proxy.go:573] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0511 14:14:00.925785 26 proxy.go:397] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7253/pods/agnhost/proxy/some/path/with/PATCH
  I0511 14:14:00.928117 26 proxy.go:573] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0511 14:14:00.928165 26 proxy.go:397] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7253/pods/agnhost/proxy/some/path/with/POST
  I0511 14:14:00.930772 26 proxy.go:573] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0511 14:14:00.930821 26 proxy.go:397] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7253/pods/agnhost/proxy/some/path/with/PUT
  I0511 14:14:00.933052 26 proxy.go:573] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0511 14:14:00.933094 26 proxy.go:408] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7253/services/test-service/proxy/some/path/with/DELETE
  I0511 14:14:00.935783 26 proxy.go:573] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0511 14:14:00.935832 26 proxy.go:408] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7253/services/test-service/proxy/some/path/with/GET
  I0511 14:14:00.938901 26 proxy.go:573] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0511 14:14:00.938940 26 proxy.go:408] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7253/services/test-service/proxy/some/path/with/HEAD
  I0511 14:14:00.942356 26 proxy.go:560] http.Client request:HEAD | StatusCode:200
  I0511 14:14:00.942398 26 proxy.go:408] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7253/services/test-service/proxy/some/path/with/OPTIONS
  I0511 14:14:00.945705 26 proxy.go:573] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0511 14:14:00.945744 26 proxy.go:408] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7253/services/test-service/proxy/some/path/with/PATCH
  I0511 14:14:00.948765 26 proxy.go:573] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0511 14:14:00.948812 26 proxy.go:408] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7253/services/test-service/proxy/some/path/with/POST
  I0511 14:14:00.951816 26 proxy.go:573] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0511 14:14:00.951870 26 proxy.go:408] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7253/services/test-service/proxy/some/path/with/PUT
  I0511 14:14:00.954405 26 proxy.go:573] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0511 14:14:00.954540 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-7253" for this suite. @ 05/11/25 14:14:00.957
• [2.092 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 05/11/25 14:14:00.961
  I0511 14:14:00.962012 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename container-probe @ 05/11/25 14:14:00.962
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:14:00.972
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:14:00.974
  STEP: Creating pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415 @ 05/11/25 14:14:00.976
  E0511 14:14:01.573292      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:02.573566      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/11/25 14:14:02.988
  I0511 14:14:02.991208 26 container_probe.go:1748] Initial restart count of pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d is 0
  I0511 14:14:02.993301 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:03.573984      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:04.574276      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:04.998373 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:05.574941      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:06.575765      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:07.004598 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:07.576304      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:08.576660      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:09.009727 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:09.577431      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:10.577678      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:11.013106 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:11.577750      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:12.578160      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:13.018202 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:13.578895      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:14.579317      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:15.023702 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:15.579581      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:16.580067      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:17.028475 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:17.580269      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:18.580886      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:19.033729 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:19.581571      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:20.581728      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:21.037760 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:21.582424      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:22.582929      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:23.043323 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:23.583738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:24.584388      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:25.046022 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:25.584908      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:26.585419      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:27.050983 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:27.585759      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:28.586234      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:29.055682 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:29.586362      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:30.587054      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:31.061137 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:31.588036      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:32.588205      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:33.063290 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:33.589070      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:34.589892      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:35.068437 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:35.590249      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:36.590855      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:37.076221 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:37.590844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:38.591352      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:39.080116 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:39.591915      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:40.592854      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:41.084191 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:41.593801      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:42.594777      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:43.087752 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:43.595703      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:44.596160      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:45.092906 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:45.596532      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:46.596720      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:47.098679 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:47.597106      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:48.597385      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:49.102342 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:49.598232      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:50.598570      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:51.107245 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:51.598762      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:52.599916      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:53.111802 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:53.600565      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:54.601169      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:55.116992 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:55.601668      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:56.601838      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:57.122630 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:57.602219      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:14:58.602772      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:14:59.126794 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:14:59.602988      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:00.603860      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:01.131571 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:01.604349      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:02.605017      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:03.136370 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:03.606093      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:04.606642      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:05.141452 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:05.607245      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:06.607642      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:07.148020 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:07.608831      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:08.609403      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:09.153447 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:09.610109      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:10.610883      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:11.159419 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:11.610978      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:12.611558      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:13.164667 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:13.612290      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:14.613456      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:15.169590 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:15.613993      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:16.614649      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:17.175670 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:17.614946      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:18.615528      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:19.180403 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:19.616036      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:20.616857      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:21.186704 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:21.617270      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:22.617777      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:23.192667 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:23.618299      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:24.618840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:25.196315 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:25.618916      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:26.619390      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:27.199988 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:27.620564      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:28.621034      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:29.205295 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:29.621833      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:30.622301      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:31.210501 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:31.623257      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:32.623733      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:33.216631 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:33.624196      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:34.624788      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:35.222916 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:35.625406      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:36.625747      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:37.228757 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:37.626753      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:38.627204      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:39.233301 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:39.627844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:40.628320      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:41.238087 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:41.628751      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:42.629250      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:43.243905 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:43.629702      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:44.630779      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:45.249278 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:45.631793      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:46.632379      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:47.252704 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:47.633348      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:48.633888      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:49.258667 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:49.634171      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:50.634662      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:51.263914 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:51.635324      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:52.635778      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:53.269661 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:53.635985      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:54.636832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:55.272744 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:55.637637      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:56.637688      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:57.278403 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:57.637777      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:15:58.638522      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:15:59.284384 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:15:59.638910      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:00.639265      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:01.289269 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:01.639906      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:02.640374      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:03.294634 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:03.640864      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:04.641426      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:05.298605 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:05.642373      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:06.642802      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:07.304768 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:07.643120      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:08.643826      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:09.310089 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:09.644738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:10.645153      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:11.313273 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:11.645971      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:12.646519      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:13.318585 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:13.646729      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:14.647936      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:15.324123 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:15.648858      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:16.649942      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:17.327515 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:17.651038      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:18.651552      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:19.332389 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:19.651917      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:20.652184      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:21.337378 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:21.652931      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:22.653906      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:23.341619 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:23.654273      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:24.654929      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:25.346029 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:25.655719      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:26.656232      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:27.351666 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:27.656985      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:28.657143      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:29.356746 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:29.657907      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:30.658345      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:31.362212 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:31.658548      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:32.658574      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:33.365620 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:33.658763      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:34.659016      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:35.369702 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:35.659946      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:36.660254      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:37.373521 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:37.660866      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:38.661730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:39.379062 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:39.662428      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:40.662987      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:41.385091 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:41.663433      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:42.664081      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:43.391383 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:43.665770      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:44.666315      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:45.395916 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:45.666401      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:46.667047      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:47.400710 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:47.667229      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:48.667805      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:49.405840 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:49.668662      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:50.669054      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:51.410606 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:51.669968      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:52.670561      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:53.417084 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:53.671287      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:54.672374      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:55.421287 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:55.672796      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:56.673251      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:57.425623 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:57.674145      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:16:58.674788      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:16:59.430077 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:16:59.675773      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:00.676659      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:01.433936 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:01.677591      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:02.678016      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:03.440116 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:03.678701      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:04.678728      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:05.444784 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:05.678995      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:06.679272      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:07.450176 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:07.679515      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:08.679688      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:09.455382 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:09.680752      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:10.682088      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:11.461060 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:11.682264      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:12.682618      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:13.466625 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:13.682648      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:14.683230      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:15.471128 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:15.683756      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:16.684033      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:17.476424 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:17.684581      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:18.684623      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:19.481411 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:19.685685      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:20.685728      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:21.486977 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:21.686050      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:22.686678      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:23.490100 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:23.687291      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:24.687724      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:25.495631 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:25.688754      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:26.689817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:27.500996 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:27.690413      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:28.690695      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:29.506556 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:29.691853      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:30.692166      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:31.511553 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:31.693022      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:32.693570      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:33.514842 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:33.694294      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:34.695036      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:35.518953 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:35.695386      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:36.695882      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:37.523714 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:37.696876      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:38.697337      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:39.527327 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:39.697610      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:40.697802      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:41.532541 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:41.697897      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:42.698382      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:43.538029 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:43.699235      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:44.700145      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:45.543451 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:45.700956      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:46.701558      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:47.548730 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:47.701915      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:48.702411      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:49.553263 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:49.703281      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:50.704122      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:51.558691 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:51.705151      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:52.705881      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:53.563852 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:53.706106      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:54.707129      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:55.567505 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:55.707808      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:56.708245      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:57.573591 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:57.708742      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:17:58.709182      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:17:59.578664 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:17:59.710118      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:00.710973      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:18:01.583066 26 container_probe.go:1758] Get pod test-webserver-d1edbb69-5669-49ee-910b-23dd4db3a37d in namespace container-probe-4415
  E0511 14:18:01.711308      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:02.711759      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 05/11/25 14:18:03.583
  I0511 14:18:03.600852 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4415" for this suite. @ 05/11/25 14:18:03.605
• [242.649 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:863
  STEP: Creating a kubernetes client @ 05/11/25 14:18:03.611
  I0511 14:18:03.611242 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename resourcequota @ 05/11/25 14:18:03.612
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:18:03.621
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:18:03.623
  STEP: Creating a ResourceQuota with best effort scope @ 05/11/25 14:18:03.625
  STEP: Ensuring ResourceQuota status is calculated @ 05/11/25 14:18:03.627
  E0511 14:18:03.712009      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:04.712783      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 05/11/25 14:18:05.632
  STEP: Ensuring ResourceQuota status is calculated @ 05/11/25 14:18:05.639
  E0511 14:18:05.713838      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:06.714398      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 05/11/25 14:18:07.645
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 05/11/25 14:18:07.658
  E0511 14:18:07.715024      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:08.715708      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 05/11/25 14:18:09.664
  E0511 14:18:09.716307      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:10.716829      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/11/25 14:18:11.669
  STEP: Ensuring resource quota status released the pod usage @ 05/11/25 14:18:11.682
  E0511 14:18:11.717115      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:12.717654      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 05/11/25 14:18:13.685
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 05/11/25 14:18:13.695
  E0511 14:18:13.718417      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:14.719424      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 05/11/25 14:18:15.7
  E0511 14:18:15.720574      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:16.721028      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/11/25 14:18:17.704
  STEP: Ensuring resource quota status released the pod usage @ 05/11/25 14:18:17.713
  E0511 14:18:17.721719      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:18.722240      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:18:19.718365 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2259" for this suite. @ 05/11/25 14:18:19.722
  E0511 14:18:19.722312      26 retrywatcher.go:169] "Watch failed" err="context canceled"
• [16.117 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:170
  STEP: Creating a kubernetes client @ 05/11/25 14:18:19.728
  I0511 14:18:19.728413 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename security-context @ 05/11/25 14:18:19.729
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:18:19.74
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:18:19.743
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 05/11/25 14:18:19.746
  E0511 14:18:20.723086      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:21.723822      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:22.724364      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:23.724814      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:18:23.766
  I0511 14:18:23.768945 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod security-context-7f6b4e62-6ef7-496d-b0e0-0ede69939132 container test-container: <nil>
  STEP: delete the pod @ 05/11/25 14:18:23.782
  I0511 14:18:23.795857 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-2444" for this suite. @ 05/11/25 14:18:23.798
• [4.075 seconds]
------------------------------
SSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 05/11/25 14:18:23.803
  I0511 14:18:23.803659 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename events @ 05/11/25 14:18:23.804
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:18:23.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:18:23.815
  STEP: Create set of events @ 05/11/25 14:18:23.818
  STEP: get a list of Events with a label in the current namespace @ 05/11/25 14:18:23.832
  STEP: delete a list of events @ 05/11/25 14:18:23.835
  I0511 14:18:23.835040 26 events.go:224] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 05/11/25 14:18:23.847
  I0511 14:18:23.850107 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-3930" for this suite. @ 05/11/25 14:18:23.9
• [0.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 05/11/25 14:18:23.906
  I0511 14:18:23.907003 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename podtemplate @ 05/11/25 14:18:23.908
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:18:23.917
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:18:23.92
  STEP: Create a pod template @ 05/11/25 14:18:23.923
  STEP: Replace a pod template @ 05/11/25 14:18:23.926
  I0511 14:18:23.933046 26 podtemplates.go:210] Found updated podtemplate annotation: "true"

  I0511 14:18:23.933192 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-8496" for this suite. @ 05/11/25 14:18:24
• [0.099 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 05/11/25 14:18:24.006
  I0511 14:18:24.006403 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 14:18:24.007
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:18:24.015
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:18:24.017
  STEP: Creating secret with name projected-secret-test-9322b9b4-81a0-4818-89b5-316061c6508d @ 05/11/25 14:18:24.019
  STEP: Creating a pod to test consume secrets @ 05/11/25 14:18:24.024
  E0511 14:18:24.725808      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:25.725884      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:26.726829      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:27.728043      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:18:28.048
  I0511 14:18:28.051082 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-projected-secrets-4c4d3c5f-1f7a-420a-b396-674ba38e1206 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/11/25 14:18:28.058
  I0511 14:18:28.071425 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1627" for this suite. @ 05/11/25 14:18:28.074
• [4.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:550
  STEP: Creating a kubernetes client @ 05/11/25 14:18:28.08
  I0511 14:18:28.080264 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename container-probe @ 05/11/25 14:18:28.081
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:18:28.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:18:28.093
  STEP: Creating pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623 @ 05/11/25 14:18:28.096
  E0511 14:18:28.728649      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:29.729269      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/11/25 14:18:30.11
  I0511 14:18:30.113205 26 container_probe.go:1748] Initial restart count of pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 is 0
  I0511 14:18:30.115437 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:18:30.730291      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:31.730771      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:18:32.123631 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:18:32.730890      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:33.731946      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:18:34.128736 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:18:34.732732      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:35.732935      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:18:36.133588 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:18:36.733287      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:37.734019      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:18:38.139371 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:18:38.734313      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:39.734863      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:18:40.145435 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:18:40.735178      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:41.735852      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:18:42.150425 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:18:42.736039      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:43.736623      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:18:44.155070 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:18:44.737001      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:45.737958      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:18:46.160274 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:18:46.738058      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:47.738635      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:18:48.165592 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:18:48.739199      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:49.739485      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:18:50.169925 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:18:50.739708      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:51.739945      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:18:52.173632 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:18:52.741015      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:53.741601      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:18:54.177074 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:18:54.742198      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:55.742778      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:18:56.182314 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:18:56.743146      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:57.743823      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:18:58.188411 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:18:58.744192      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:18:59.745327      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:00.193720 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:19:00.745455      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:01.746048      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:02.196403 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:19:02.746885      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:03.747801      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:04.202626 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:19:04.748155      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:05.748736      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:06.206746 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:19:06.749390      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:07.749878      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:08.211917 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:19:08.750866      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:09.751315      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:10.216548 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:19:10.751452      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:11.751784      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:12.222436 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:19:12.751973      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:13.752319      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:14.226224 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:19:14.752673      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:15.753132      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:16.230675 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:19:16.753385      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:17.753919      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:18.235520 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:19:18.754144      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:19.755321      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:20.240668 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:19:20.755264      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:21.755317      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:22.246234 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:19:22.755912      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:23.756521      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:24.252695 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:19:24.756851      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:25.757374      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:26.257638 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:19:26.758384      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:27.758578      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:28.263705 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:19:28.759804      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:29.760177      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:30.268151 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:19:30.760879      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:31.761201      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:32.273137 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  E0511 14:19:32.761780      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:33.762355      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:34.278355 26 container_probe.go:1758] Get pod test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 in namespace container-probe-623
  I0511 14:19:34.278411 26 container_probe.go:1762] Restart count of pod container-probe-623/test-grpc-f643b36f-e10e-4290-9c40-9aca6647d1c4 is now 1 (1m4.165164961s elapsed)
  STEP: deleting the pod @ 05/11/25 14:19:34.278
  I0511 14:19:34.288079 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-623" for this suite. @ 05/11/25 14:19:34.292
• [66.218 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 05/11/25 14:19:34.299
  I0511 14:19:34.299112 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename certificates @ 05/11/25 14:19:34.3
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:19:34.311
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:19:34.315
  STEP: getting /apis @ 05/11/25 14:19:34.668
  STEP: getting /apis/certificates.k8s.io @ 05/11/25 14:19:34.671
  STEP: getting /apis/certificates.k8s.io/v1 @ 05/11/25 14:19:34.671
  STEP: creating @ 05/11/25 14:19:34.672
  STEP: getting @ 05/11/25 14:19:34.682
  STEP: listing @ 05/11/25 14:19:34.683
  STEP: watching @ 05/11/25 14:19:34.684
  I0511 14:19:34.684983 26 certificates.go:316] starting watch
  STEP: patching @ 05/11/25 14:19:34.685
  STEP: updating @ 05/11/25 14:19:34.689
  I0511 14:19:34.693929 26 certificates.go:332] waiting for watch events with expected annotations
  I0511 14:19:34.693961 26 certificates.go:345] saw patched and updated annotations
  STEP: getting /approval @ 05/11/25 14:19:34.694
  STEP: patching /approval @ 05/11/25 14:19:34.695
  STEP: updating /approval @ 05/11/25 14:19:34.698
  STEP: getting /status @ 05/11/25 14:19:34.703
  STEP: patching /status @ 05/11/25 14:19:34.704
  STEP: updating /status @ 05/11/25 14:19:34.71
  STEP: deleting @ 05/11/25 14:19:34.716
  STEP: deleting a collection @ 05/11/25 14:19:34.723
  I0511 14:19:34.731869 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-1560" for this suite. @ 05/11/25 14:19:34.734
• [0.440 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:811
  STEP: Creating a kubernetes client @ 05/11/25 14:19:34.739
  I0511 14:19:34.739390 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename statefulset @ 05/11/25 14:19:34.74
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:19:34.747
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:19:34.749
  STEP: Creating service test in namespace statefulset-3384 @ 05/11/25 14:19:34.752
  STEP: Looking for a node to schedule stateful set and pod @ 05/11/25 14:19:34.756
  E0511 14:19:34.762585      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating pod with conflicting port in namespace statefulset-3384 @ 05/11/25 14:19:34.839
  STEP: Waiting until pod test-pod will start running in namespace statefulset-3384 @ 05/11/25 14:19:34.85
  E0511 14:19:35.762774      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:36.762889      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-3384 @ 05/11/25 14:19:36.859
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3384 @ 05/11/25 14:19:36.868
  I0511 14:19:36.879351 26 statefulset.go:884] Observed stateful pod in namespace: statefulset-3384, name: ss-0, uid: afa51290-82ba-4e1f-bdd1-2bceb80b1e8c, status phase: Pending. Waiting for statefulset controller to delete.
  I0511 14:19:36.894127 26 statefulset.go:884] Observed stateful pod in namespace: statefulset-3384, name: ss-0, uid: afa51290-82ba-4e1f-bdd1-2bceb80b1e8c, status phase: Failed. Waiting for statefulset controller to delete.
  I0511 14:19:36.902690 26 statefulset.go:884] Observed stateful pod in namespace: statefulset-3384, name: ss-0, uid: afa51290-82ba-4e1f-bdd1-2bceb80b1e8c, status phase: Failed. Waiting for statefulset controller to delete.
  I0511 14:19:36.905150 26 statefulset.go:878] Observed delete event for stateful pod ss-0 in namespace statefulset-3384
  STEP: Removing pod with conflicting port in namespace statefulset-3384 @ 05/11/25 14:19:36.905
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3384 and will be in running state @ 05/11/25 14:19:36.919
  E0511 14:19:37.763537      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:38.763955      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:38.929071 26 statefulset.go:138] Deleting all statefulset in ns statefulset-3384
  I0511 14:19:38.932211 26 rest.go:153] Scaling statefulset ss to 0
  E0511 14:19:39.764136      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:40.764870      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:41.765194      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:42.765951      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:43.766486      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:44.767304      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:45.767730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:46.768235      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:47.768703      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:48.769091      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:48.948963 26 wait.go:159] Waiting for statefulset status.replicas updated to 0
  I0511 14:19:48.951421 26 rest.go:91] Deleting statefulset ss
  I0511 14:19:48.965873 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3384" for this suite. @ 05/11/25 14:19:48.968
• [14.235 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:338
  STEP: Creating a kubernetes client @ 05/11/25 14:19:48.974
  I0511 14:19:48.974937 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubectl @ 05/11/25 14:19:48.976
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:19:48.986
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:19:48.989
  STEP: creating a replication controller @ 05/11/25 14:19:48.992
  I0511 14:19:48.992793 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 create -f -'
  I0511 14:19:49.065594 26 builder.go:146] stderr: ""
  I0511 14:19:49.065626 26 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/11/25 14:19:49.065
  I0511 14:19:49.065699 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:19:49.114667 26 builder.go:146] stderr: ""
  I0511 14:19:49.114703 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:19:49.114745 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:19:49.154647 26 builder.go:146] stderr: ""
  I0511 14:19:49.154684 26 builder.go:147] stdout: ""
  I0511 14:19:49.154696 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:19:49.770120      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:50.770808      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:51.771360      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:52.771785      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:53.772144      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:54.155575 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:19:54.200626 26 builder.go:146] stderr: ""
  I0511 14:19:54.200666 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:19:54.200711 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:19:54.237004 26 builder.go:146] stderr: ""
  I0511 14:19:54.237036 26 builder.go:147] stdout: ""
  I0511 14:19:54.237045 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:19:54.773266      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:55.773741      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:56.774415      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:57.774701      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:19:58.775154      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:19:59.237752 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:19:59.287883 26 builder.go:146] stderr: ""
  I0511 14:19:59.287908 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:19:59.287942 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:19:59.333229 26 builder.go:146] stderr: ""
  I0511 14:19:59.333264 26 builder.go:147] stdout: ""
  I0511 14:19:59.333274 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:19:59.776080      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:00.776640      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:01.776736      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:02.777302      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:03.777745      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:20:04.334027 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:20:04.377006 26 builder.go:146] stderr: ""
  I0511 14:20:04.377039 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:20:04.377085 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:20:04.426507 26 builder.go:146] stderr: ""
  I0511 14:20:04.426543 26 builder.go:147] stdout: ""
  I0511 14:20:04.426556 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:20:04.778702      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:05.779361      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:06.779970      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:07.780349      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:08.780790      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:20:09.427656 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:20:09.477344 26 builder.go:146] stderr: ""
  I0511 14:20:09.477383 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:20:09.477426 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:20:09.514271 26 builder.go:146] stderr: ""
  I0511 14:20:09.514307 26 builder.go:147] stdout: ""
  I0511 14:20:09.514317 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:20:09.781587      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:10.782169      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:11.782768      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:12.782848      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:13.783421      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:20:14.515579 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:20:14.561668 26 builder.go:146] stderr: ""
  I0511 14:20:14.561701 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:20:14.561746 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:20:14.605057 26 builder.go:146] stderr: ""
  I0511 14:20:14.605090 26 builder.go:147] stdout: ""
  I0511 14:20:14.605099 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:20:14.784242      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:15.784342      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:16.784767      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:17.785421      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:18.785766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:20:19.605961 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:20:19.649235 26 builder.go:146] stderr: ""
  I0511 14:20:19.649267 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:20:19.649319 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:20:19.693471 26 builder.go:146] stderr: ""
  I0511 14:20:19.693512 26 builder.go:147] stdout: ""
  I0511 14:20:19.693526 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:20:19.786030      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:20.786877      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:21.787398      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:22.787775      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:23.788337      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:20:24.694322 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:20:24.747255 26 builder.go:146] stderr: ""
  I0511 14:20:24.747281 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:20:24.747313 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:20:24.782490 26 builder.go:146] stderr: ""
  I0511 14:20:24.782522 26 builder.go:147] stdout: ""
  I0511 14:20:24.782538 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:20:24.788692      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:25.789065      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:26.789580      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:27.790276      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:28.790914      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:20:29.783608 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0511 14:20:29.791149      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:20:29.825665 26 builder.go:146] stderr: ""
  I0511 14:20:29.825704 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:20:29.825747 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:20:29.860639 26 builder.go:146] stderr: ""
  I0511 14:20:29.860674 26 builder.go:147] stdout: ""
  I0511 14:20:29.860685 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:20:30.792021      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:31.792547      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:32.793293      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:33.793515      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:34.794308      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:20:34.861631 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:20:34.911739 26 builder.go:146] stderr: ""
  I0511 14:20:34.911766 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:20:34.911799 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:20:34.947991 26 builder.go:146] stderr: ""
  I0511 14:20:34.948026 26 builder.go:147] stdout: ""
  I0511 14:20:34.948037 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:20:35.795185      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:36.795809      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:37.796393      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:38.796751      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:39.797202      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:20:39.948414 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:20:39.995714 26 builder.go:146] stderr: ""
  I0511 14:20:39.995756 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:20:39.995799 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:20:40.032195 26 builder.go:146] stderr: ""
  I0511 14:20:40.032231 26 builder.go:147] stdout: ""
  I0511 14:20:40.032240 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:20:40.797801      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:41.798012      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:42.798867      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:43.799332      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:44.800148      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:20:45.033286 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:20:45.077981 26 builder.go:146] stderr: ""
  I0511 14:20:45.078007 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:20:45.078039 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:20:45.117167 26 builder.go:146] stderr: ""
  I0511 14:20:45.117198 26 builder.go:147] stdout: ""
  I0511 14:20:45.117208 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:20:45.800281      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:46.800834      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:47.801284      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:48.801841      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:49.802020      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:20:50.117400 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:20:50.159597 26 builder.go:146] stderr: ""
  I0511 14:20:50.159633 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:20:50.159675 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:20:50.193537 26 builder.go:146] stderr: ""
  I0511 14:20:50.193570 26 builder.go:147] stdout: ""
  I0511 14:20:50.193583 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:20:50.803005      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:51.803838      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:52.804314      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:53.804682      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:54.805127      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:20:55.193723 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:20:55.245734 26 builder.go:146] stderr: ""
  I0511 14:20:55.245769 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:20:55.245812 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:20:55.280142 26 builder.go:146] stderr: ""
  I0511 14:20:55.280175 26 builder.go:147] stdout: ""
  I0511 14:20:55.280186 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:20:55.805919      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:56.806386      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:57.806957      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:58.807420      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:20:59.807904      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:21:00.280673 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:21:00.322673 26 builder.go:146] stderr: ""
  I0511 14:21:00.322709 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:21:00.322748 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:21:00.357315 26 builder.go:146] stderr: ""
  I0511 14:21:00.357348 26 builder.go:147] stdout: ""
  I0511 14:21:00.357359 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:21:00.808202      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:01.808895      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:02.809800      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:03.809864      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:04.810011      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:21:05.357648 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:21:05.402353 26 builder.go:146] stderr: ""
  I0511 14:21:05.402386 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:21:05.402432 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:21:05.444090 26 builder.go:146] stderr: ""
  I0511 14:21:05.444128 26 builder.go:147] stdout: ""
  I0511 14:21:05.444141 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:21:05.810875      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:06.811638      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:07.812122      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:08.813085      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:09.813165      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:21:10.444949 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:21:10.488617 26 builder.go:146] stderr: ""
  I0511 14:21:10.488655 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:21:10.488695 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:21:10.523307 26 builder.go:146] stderr: ""
  I0511 14:21:10.523339 26 builder.go:147] stdout: ""
  I0511 14:21:10.523349 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:21:10.814012      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:11.814220      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:12.814789      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:13.815835      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:14.816647      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:21:15.523562 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:21:15.571671 26 builder.go:146] stderr: ""
  I0511 14:21:15.571700 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:21:15.571731 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:21:15.605528 26 builder.go:146] stderr: ""
  I0511 14:21:15.605572 26 builder.go:147] stdout: ""
  I0511 14:21:15.605584 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:21:15.817299      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:16.817963      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:17.818545      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:18.819136      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:19.820042      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:21:20.605790 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:21:20.653235 26 builder.go:146] stderr: ""
  I0511 14:21:20.653268 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:21:20.653311 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:21:20.690544 26 builder.go:146] stderr: ""
  I0511 14:21:20.690582 26 builder.go:147] stdout: ""
  I0511 14:21:20.690593 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:21:20.820910      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:21.821765      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:22.822855      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:23.823871      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:24.824315      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:21:25.691266 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:21:25.733717 26 builder.go:146] stderr: ""
  I0511 14:21:25.733753 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:21:25.733795 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:21:25.775756 26 builder.go:146] stderr: ""
  I0511 14:21:25.775789 26 builder.go:147] stdout: ""
  I0511 14:21:25.775799 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:21:25.825252      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:26.825743      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:27.826222      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:28.826803      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:29.827656      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:21:30.776638 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:21:30.820755 26 builder.go:146] stderr: ""
  I0511 14:21:30.820790 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:21:30.820832 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0511 14:21:30.828135      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:21:30.854594 26 builder.go:146] stderr: ""
  I0511 14:21:30.854625 26 builder.go:147] stdout: ""
  I0511 14:21:30.854635 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:21:31.828680      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:32.828796      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:33.829522      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:34.829988      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:35.830688      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:21:35.855912 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:21:35.894582 26 builder.go:146] stderr: ""
  I0511 14:21:35.894620 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:21:35.894670 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:21:35.929481 26 builder.go:146] stderr: ""
  I0511 14:21:35.929515 26 builder.go:147] stdout: ""
  I0511 14:21:35.929524 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:21:36.831711      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:37.832253      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:38.832840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:39.833547      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:40.833725      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:21:40.930169 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:21:40.973384 26 builder.go:146] stderr: ""
  I0511 14:21:40.973424 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:21:40.973479 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:21:41.008027 26 builder.go:146] stderr: ""
  I0511 14:21:41.008058 26 builder.go:147] stdout: ""
  I0511 14:21:41.008068 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:21:41.833805      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:42.834336      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:43.834902      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:44.835108      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:45.835529      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:21:46.008858 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:21:46.052718 26 builder.go:146] stderr: ""
  I0511 14:21:46.052753 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:21:46.052794 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:21:46.087102 26 builder.go:146] stderr: ""
  I0511 14:21:46.087126 26 builder.go:147] stdout: ""
  I0511 14:21:46.087131 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:21:46.835782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:47.836231      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:48.836662      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:49.837269      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:50.837672      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:21:51.088270 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:21:51.131818 26 builder.go:146] stderr: ""
  I0511 14:21:51.131851 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:21:51.131894 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:21:51.169705 26 builder.go:146] stderr: ""
  I0511 14:21:51.169751 26 builder.go:147] stdout: ""
  I0511 14:21:51.169762 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:21:51.838867      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:52.839350      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:53.839841      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:54.839939      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:55.840453      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:21:56.170113 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:21:56.221915 26 builder.go:146] stderr: ""
  I0511 14:21:56.221961 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:21:56.222003 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:21:56.256918 26 builder.go:146] stderr: ""
  I0511 14:21:56.256954 26 builder.go:147] stdout: ""
  I0511 14:21:56.256966 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:21:56.840752      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:57.841135      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:58.841749      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:21:59.842321      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:00.842852      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:22:01.257318 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:22:01.314114 26 builder.go:146] stderr: ""
  I0511 14:22:01.314148 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:22:01.314188 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:22:01.354344 26 builder.go:146] stderr: ""
  I0511 14:22:01.354371 26 builder.go:147] stdout: ""
  I0511 14:22:01.354380 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:22:01.843948      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:02.844918      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:03.845452      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:04.845940      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:05.846437      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:22:06.354746 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:22:06.403949 26 builder.go:146] stderr: ""
  I0511 14:22:06.403983 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:22:06.404015 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:22:06.442552 26 builder.go:146] stderr: ""
  I0511 14:22:06.442578 26 builder.go:147] stdout: ""
  I0511 14:22:06.442585 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:22:06.846980      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:07.847793      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:08.848319      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:09.849083      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:10.849760      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:22:11.443582 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:22:11.486745 26 builder.go:146] stderr: ""
  I0511 14:22:11.486785 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:22:11.486830 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:22:11.522785 26 builder.go:146] stderr: ""
  I0511 14:22:11.522830 26 builder.go:147] stdout: ""
  I0511 14:22:11.522840 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:22:11.850526      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:12.850862      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:13.851827      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:14.851980      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:15.852839      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:22:16.523635 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:22:16.566773 26 builder.go:146] stderr: ""
  I0511 14:22:16.566798 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:22:16.566826 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:22:16.604808 26 builder.go:146] stderr: ""
  I0511 14:22:16.604839 26 builder.go:147] stdout: ""
  I0511 14:22:16.604854 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:22:16.853435      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:17.853895      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:18.854841      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:19.855414      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:20.855602      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:22:21.605398 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:22:21.645799 26 builder.go:146] stderr: ""
  I0511 14:22:21.645834 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:22:21.645880 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:22:21.683397 26 builder.go:146] stderr: ""
  I0511 14:22:21.683438 26 builder.go:147] stdout: ""
  I0511 14:22:21.683450 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:22:21.856061      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:22.856999      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:23.858179      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:24.859094      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:25.859572      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:22:26.683610 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:22:26.730595 26 builder.go:146] stderr: ""
  I0511 14:22:26.730620 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:22:26.730648 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:22:26.762211 26 builder.go:146] stderr: ""
  I0511 14:22:26.762243 26 builder.go:147] stdout: ""
  I0511 14:22:26.762253 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:22:26.859670      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:27.859707      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:28.860198      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:29.860583      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:30.861189      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:22:31.763266 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:22:31.806580 26 builder.go:146] stderr: ""
  I0511 14:22:31.806618 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:22:31.806669 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:22:31.849234 26 builder.go:146] stderr: ""
  I0511 14:22:31.849261 26 builder.go:147] stdout: ""
  I0511 14:22:31.849269 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:22:31.861469      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:32.861888      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:33.862350      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:34.862636      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:35.863273      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:22:36.850379 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0511 14:22:36.864008      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:22:36.905676 26 builder.go:146] stderr: ""
  I0511 14:22:36.905717 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:22:36.905759 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:22:36.940314 26 builder.go:146] stderr: ""
  I0511 14:22:36.940348 26 builder.go:147] stdout: ""
  I0511 14:22:36.940357 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:22:37.864704      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:38.865319      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:39.865824      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:40.866760      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:41.867270      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:22:41.941475 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:22:41.989914 26 builder.go:146] stderr: ""
  I0511 14:22:41.989946 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:22:41.989994 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:22:42.026357 26 builder.go:146] stderr: ""
  I0511 14:22:42.026387 26 builder.go:147] stdout: ""
  I0511 14:22:42.026400 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:22:42.867563      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:43.868083      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:44.868386      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:45.868956      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:46.869090      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:22:47.027554 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:22:47.085340 26 builder.go:146] stderr: ""
  I0511 14:22:47.085374 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:22:47.085414 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:22:47.125846 26 builder.go:146] stderr: ""
  I0511 14:22:47.125879 26 builder.go:147] stdout: ""
  I0511 14:22:47.125888 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:22:47.869337      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:48.869951      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:49.870230      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:50.870817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:51.870951      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:22:52.126444 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:22:52.174717 26 builder.go:146] stderr: ""
  I0511 14:22:52.174750 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:22:52.174793 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:22:52.208911 26 builder.go:146] stderr: ""
  I0511 14:22:52.208947 26 builder.go:147] stdout: ""
  I0511 14:22:52.208955 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:22:52.872013      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:53.872839      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:54.872692      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:55.873227      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:56.873911      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:22:57.209231 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:22:57.253695 26 builder.go:146] stderr: ""
  I0511 14:22:57.253729 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:22:57.253772 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:22:57.285027 26 builder.go:146] stderr: ""
  I0511 14:22:57.285057 26 builder.go:147] stdout: ""
  I0511 14:22:57.285066 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:22:57.874763      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:58.875228      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:22:59.876280      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:00.876735      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:01.877232      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:23:02.285923 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:23:02.332650 26 builder.go:146] stderr: ""
  I0511 14:23:02.332676 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:23:02.332704 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:23:02.365986 26 builder.go:146] stderr: ""
  I0511 14:23:02.366018 26 builder.go:147] stdout: ""
  I0511 14:23:02.366027 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:23:02.877529      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:03.877834      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:04.878078      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:05.878553      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:06.879003      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:23:07.366377 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:23:07.412939 26 builder.go:146] stderr: ""
  I0511 14:23:07.412975 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:23:07.413013 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:23:07.449226 26 builder.go:146] stderr: ""
  I0511 14:23:07.449258 26 builder.go:147] stdout: ""
  I0511 14:23:07.449268 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:23:07.880266      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:08.880576      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:09.880987      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:10.881409      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:11.881881      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:23:12.449594 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:23:12.495510 26 builder.go:146] stderr: ""
  I0511 14:23:12.495557 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:23:12.495605 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:23:12.531784 26 builder.go:146] stderr: ""
  I0511 14:23:12.531819 26 builder.go:147] stdout: ""
  I0511 14:23:12.531829 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:23:12.882819      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:13.883355      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:14.883874      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:15.884318      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:16.884692      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:23:17.532537 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:23:17.576606 26 builder.go:146] stderr: ""
  I0511 14:23:17.576651 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:23:17.576697 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:23:17.620683 26 builder.go:146] stderr: ""
  I0511 14:23:17.620721 26 builder.go:147] stdout: ""
  I0511 14:23:17.620732 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:23:17.885844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:18.886360      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:19.887153      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:20.887605      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:21.888052      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:23:22.621095 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:23:22.668822 26 builder.go:146] stderr: ""
  I0511 14:23:22.668861 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:23:22.668909 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:23:22.705061 26 builder.go:146] stderr: ""
  I0511 14:23:22.705096 26 builder.go:147] stdout: ""
  I0511 14:23:22.705107 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:23:22.888664      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:23.889227      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:24.889238      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:25.889960      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:26.890580      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:23:27.706024 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:23:27.753336 26 builder.go:146] stderr: ""
  I0511 14:23:27.753369 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:23:27.753412 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:23:27.789315 26 builder.go:146] stderr: ""
  I0511 14:23:27.789356 26 builder.go:147] stdout: ""
  I0511 14:23:27.789368 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:23:27.890955      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:28.891554      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:29.891963      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:30.892532      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:31.893354      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:23:32.790363 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:23:32.834584 26 builder.go:146] stderr: ""
  I0511 14:23:32.834620 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:23:32.834662 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:23:32.870128 26 builder.go:146] stderr: ""
  I0511 14:23:32.870167 26 builder.go:147] stdout: ""
  I0511 14:23:32.870177 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:23:32.893402      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:33.893987      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:34.894406      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:35.894950      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:36.895916      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:23:37.870613 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0511 14:23:37.896101      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:23:37.913488 26 builder.go:146] stderr: ""
  I0511 14:23:37.913523 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:23:37.913549 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:23:37.953712 26 builder.go:146] stderr: ""
  I0511 14:23:37.953750 26 builder.go:147] stdout: ""
  I0511 14:23:37.953772 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:23:38.896776      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:39.897095      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:40.897643      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:41.898164      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:42.898906      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:23:42.954006 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:23:42.999794 26 builder.go:146] stderr: ""
  I0511 14:23:42.999836 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:23:42.999893 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:23:43.034838 26 builder.go:146] stderr: ""
  I0511 14:23:43.034874 26 builder.go:147] stdout: ""
  I0511 14:23:43.034881 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:23:43.899917      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:44.900149      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:45.901057      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:46.901809      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:47.902865      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:23:48.035221 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:23:48.083171 26 builder.go:146] stderr: ""
  I0511 14:23:48.083195 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:23:48.083221 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:23:48.121578 26 builder.go:146] stderr: ""
  I0511 14:23:48.121612 26 builder.go:147] stdout: ""
  I0511 14:23:48.121623 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:23:48.903681      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:49.903818      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:50.904445      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:51.904717      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:52.905077      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:23:53.122510 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:23:53.165699 26 builder.go:146] stderr: ""
  I0511 14:23:53.165735 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:23:53.165781 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:23:53.205425 26 builder.go:146] stderr: ""
  I0511 14:23:53.205464 26 builder.go:147] stdout: ""
  I0511 14:23:53.205476 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:23:53.905667      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:54.906818      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:55.907540      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:56.907781      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:57.908702      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:23:58.206066 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:23:58.245365 26 builder.go:146] stderr: ""
  I0511 14:23:58.245398 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:23:58.245440 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:23:58.286385 26 builder.go:146] stderr: ""
  I0511 14:23:58.286417 26 builder.go:147] stdout: ""
  I0511 14:23:58.286428 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:23:58.909902      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:23:59.909924      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:00.910385      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:01.910809      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:02.911393      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:24:03.286944 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:24:03.330975 26 builder.go:146] stderr: ""
  I0511 14:24:03.331001 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:24:03.331030 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:24:03.365161 26 builder.go:146] stderr: ""
  I0511 14:24:03.365196 26 builder.go:147] stdout: ""
  I0511 14:24:03.365207 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:24:03.911998      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:04.912129      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:05.912864      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:06.913571      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:07.914193      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:24:08.365621 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:24:08.409846 26 builder.go:146] stderr: ""
  I0511 14:24:08.409875 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:24:08.409901 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:24:08.441648 26 builder.go:146] stderr: ""
  I0511 14:24:08.441681 26 builder.go:147] stdout: ""
  I0511 14:24:08.441697 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:24:08.914531      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:09.915020      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:10.915618      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:11.916230      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:12.916947      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:24:13.442661 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:24:13.490153 26 builder.go:146] stderr: ""
  I0511 14:24:13.490191 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:24:13.490234 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:24:13.524977 26 builder.go:146] stderr: ""
  I0511 14:24:13.525014 26 builder.go:147] stdout: ""
  I0511 14:24:13.525023 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:24:13.917863      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:14.918289      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:15.918668      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:16.919134      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:17.919865      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:24:18.525591 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:24:18.571186 26 builder.go:146] stderr: ""
  I0511 14:24:18.571225 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:24:18.571263 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:24:18.606923 26 builder.go:146] stderr: ""
  I0511 14:24:18.606955 26 builder.go:147] stdout: ""
  I0511 14:24:18.606964 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:24:18.920938      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:19.921282      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:20.921785      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:21.922294      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:22.922955      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:24:23.607885 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:24:23.666033 26 builder.go:146] stderr: ""
  I0511 14:24:23.666068 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:24:23.666110 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:24:23.701448 26 builder.go:146] stderr: ""
  I0511 14:24:23.701486 26 builder.go:147] stdout: ""
  I0511 14:24:23.701500 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:24:23.923767      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:24.924558      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:25.924893      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:26.925495      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:27.925707      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:24:28.702573 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:24:28.748643 26 builder.go:146] stderr: ""
  I0511 14:24:28.748690 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:24:28.748734 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:24:28.784088 26 builder.go:146] stderr: ""
  I0511 14:24:28.784124 26 builder.go:147] stdout: ""
  I0511 14:24:28.784134 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:24:28.926873      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:29.927621      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:30.928161      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:31.928609      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:32.928659      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:24:33.784698 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:24:33.832901 26 builder.go:146] stderr: ""
  I0511 14:24:33.832943 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:24:33.832984 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:24:33.872621 26 builder.go:146] stderr: ""
  I0511 14:24:33.872658 26 builder.go:147] stdout: ""
  I0511 14:24:33.872667 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:24:33.928957      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:34.929236      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:35.929760      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:36.930287      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:37.930718      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:24:38.873735 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:24:38.917494 26 builder.go:146] stderr: ""
  I0511 14:24:38.917528 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:24:38.917569 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0511 14:24:38.930877      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:24:38.950593 26 builder.go:146] stderr: ""
  I0511 14:24:38.950626 26 builder.go:147] stdout: ""
  I0511 14:24:38.950639 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:24:39.931161      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:40.931866      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:41.932341      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:42.932935      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:43.933420      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:24:43.951660 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:24:44.003644 26 builder.go:146] stderr: ""
  I0511 14:24:44.003683 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:24:44.003725 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:24:44.038004 26 builder.go:146] stderr: ""
  I0511 14:24:44.038033 26 builder.go:147] stdout: ""
  I0511 14:24:44.038042 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:24:44.934338      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:45.934890      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:46.935173      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:47.936047      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:48.936581      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:24:49.038883 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:24:49.081366 26 builder.go:146] stderr: ""
  I0511 14:24:49.081403 26 builder.go:147] stdout: "update-demo-nautilus-clmsn update-demo-nautilus-nmlf6 "
  I0511 14:24:49.081445 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-clmsn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:24:49.114478 26 builder.go:146] stderr: ""
  I0511 14:24:49.114511 26 builder.go:147] stdout: ""
  I0511 14:24:49.114520 26 kubectl.go:2505] update-demo-nautilus-clmsn is created but not running
  E0511 14:24:49.937327      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:50.937957      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:51.938555      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:52.939144      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:53.940023      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: using delete to clean up resources @ 05/11/25 14:24:54.115
  I0511 14:24:54.115841 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 delete --grace-period=0 --force -f -'
  I0511 14:24:54.159796 26 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0511 14:24:54.159830 26 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I0511 14:24:54.159874 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get rc,svc -l name=update-demo --no-headers'
  I0511 14:24:54.208538 26 builder.go:146] stderr: "No resources found in kubectl-473 namespace.\n"
  I0511 14:24:54.208577 26 builder.go:147] stdout: ""
  I0511 14:24:54.208623 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0511 14:24:54.247018 26 builder.go:146] stderr: ""
  I0511 14:24:54.247057 26 builder.go:147] stdout: ""
  [FAILED] in [It] - k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:2532 @ 05/11/25 14:24:54.247
  I0511 14:24:54.247294 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: dump namespace information after failure @ 05/11/25 14:24:54.253
  STEP: Collecting events from namespace "kubectl-473". @ 05/11/25 14:24:54.253
  STEP: Found 16 events. @ 05/11/25 14:24:54.255
  I0511 14:24:54.255518 26 dump.go:53] At 2025-05-11 14:19:49 +0000 UTC - event for update-demo-nautilus: {replication-controller } SuccessfulCreate: Created pod: update-demo-nautilus-clmsn
  I0511 14:24:54.255536 26 dump.go:53] At 2025-05-11 14:19:49 +0000 UTC - event for update-demo-nautilus: {replication-controller } SuccessfulCreate: Created pod: update-demo-nautilus-nmlf6
  I0511 14:24:54.255548 26 dump.go:53] At 2025-05-11 14:19:49 +0000 UTC - event for update-demo-nautilus-clmsn: {kubelet k8sconformance} Pulling: Pulling image "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0511 14:24:54.255560 26 dump.go:53] At 2025-05-11 14:19:49 +0000 UTC - event for update-demo-nautilus-clmsn: {default-scheduler } Scheduled: Successfully assigned kubectl-473/update-demo-nautilus-clmsn to k8sconformance
  I0511 14:24:54.255571 26 dump.go:53] At 2025-05-11 14:19:49 +0000 UTC - event for update-demo-nautilus-nmlf6: {kubelet k8sconformance-m02} Pulling: Pulling image "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0511 14:24:54.255584 26 dump.go:53] At 2025-05-11 14:19:49 +0000 UTC - event for update-demo-nautilus-nmlf6: {default-scheduler } Scheduled: Successfully assigned kubectl-473/update-demo-nautilus-nmlf6 to k8sconformance-m02
  I0511 14:24:54.255594 26 dump.go:53] At 2025-05-11 14:22:18 +0000 UTC - event for update-demo-nautilus-clmsn: {kubelet k8sconformance} Failed: Failed to pull image "registry.k8s.io/e2e-test-images/nautilus:1.7": rpc error: code = Canceled desc = context canceled
  I0511 14:24:54.255604 26 dump.go:53] At 2025-05-11 14:22:18 +0000 UTC - event for update-demo-nautilus-clmsn: {kubelet k8sconformance} Failed: Error: ErrImagePull
  I0511 14:24:54.255613 26 dump.go:53] At 2025-05-11 14:22:19 +0000 UTC - event for update-demo-nautilus-clmsn: {kubelet k8sconformance} BackOff: Back-off pulling image "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0511 14:24:54.255658 26 dump.go:53] At 2025-05-11 14:22:19 +0000 UTC - event for update-demo-nautilus-clmsn: {kubelet k8sconformance} Failed: Error: ImagePullBackOff
  I0511 14:24:54.255669 26 dump.go:53] At 2025-05-11 14:22:39 +0000 UTC - event for update-demo-nautilus-nmlf6: {kubelet k8sconformance-m02} Failed: Failed to pull image "registry.k8s.io/e2e-test-images/nautilus:1.7": rpc error: code = Canceled desc = context canceled
  I0511 14:24:54.255677 26 dump.go:53] At 2025-05-11 14:22:39 +0000 UTC - event for update-demo-nautilus-nmlf6: {kubelet k8sconformance-m02} Failed: Error: ErrImagePull
  I0511 14:24:54.255689 26 dump.go:53] At 2025-05-11 14:22:40 +0000 UTC - event for update-demo-nautilus-nmlf6: {kubelet k8sconformance-m02} BackOff: Back-off pulling image "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0511 14:24:54.255696 26 dump.go:53] At 2025-05-11 14:22:40 +0000 UTC - event for update-demo-nautilus-nmlf6: {kubelet k8sconformance-m02} Failed: Error: ImagePullBackOff
  I0511 14:24:54.255705 26 dump.go:53] At 2025-05-11 14:22:45 +0000 UTC - event for update-demo-nautilus-clmsn: {kubelet k8sconformance} Failed: Failed to pull image "registry.k8s.io/e2e-test-images/nautilus:1.7": Error response from daemon: Get "https://registry.k8s.io/v2/": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
  I0511 14:24:54.255712 26 dump.go:53] At 2025-05-11 14:23:06 +0000 UTC - event for update-demo-nautilus-nmlf6: {kubelet k8sconformance-m02} Failed: Failed to pull image "registry.k8s.io/e2e-test-images/nautilus:1.7": Error response from daemon: Get "https://registry.k8s.io/v2/": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
  I0511 14:24:54.257307 26 resource.go:168] POD                         NODE                PHASE    GRACE  CONDITIONS
  I0511 14:24:54.257354 26 resource.go:175] update-demo-nautilus-clmsn  k8sconformance      Pending  30s    [{PodReadyToStartContainers 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:22:19 +0000 UTC  } {Initialized 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:19:49 +0000 UTC  } {Ready 0 False 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:19:49 +0000 UTC ContainersNotReady containers with unready status: [update-demo]} {ContainersReady 0 False 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:19:49 +0000 UTC ContainersNotReady containers with unready status: [update-demo]} {PodScheduled 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:19:49 +0000 UTC  }]
  I0511 14:24:54.257378 26 resource.go:175] update-demo-nautilus-nmlf6  k8sconformance-m02  Pending  30s    [{PodReadyToStartContainers 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:22:40 +0000 UTC  } {Initialized 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:19:49 +0000 UTC  } {Ready 0 False 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:19:49 +0000 UTC ContainersNotReady containers with unready status: [update-demo]} {ContainersReady 0 False 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:19:49 +0000 UTC ContainersNotReady containers with unready status: [update-demo]} {PodScheduled 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:19:49 +0000 UTC  }]
  I0511 14:24:54.257388 26 resource.go:178] 
  I0511 14:24:54.267273 26 resource.go:231] Unable to fetch kubectl-473/update-demo-nautilus-clmsn/update-demo logs: the server rejected our request for an unknown reason (get pods update-demo-nautilus-clmsn)
  I0511 14:24:54.275501 26 resource.go:231] Unable to fetch kubectl-473/update-demo-nautilus-nmlf6/update-demo logs: the server rejected our request for an unknown reason (get pods update-demo-nautilus-nmlf6)
  I0511 14:24:54.276926 26 dump.go:109] 
  Logging node info for node k8sconformance
  I0511 14:24:54.278477 26 dump.go:114] Node Info: &Node{ObjectMeta:{k8sconformance    0d6a5478-8548-44c5-8c74-42cb07407d14 14874 0 2025-05-11 12:59:59 +0000 UTC <nil> <nil> map[beta.kubernetes.io/arch:amd64 beta.kubernetes.io/os:linux kubernetes.io/arch:amd64 kubernetes.io/hostname:k8sconformance kubernetes.io/os:linux minikube.k8s.io/commit:8575beea95e830054fe9a36513b8b24cb1ff7010 minikube.k8s.io/name:k8sconformance minikube.k8s.io/primary:true minikube.k8s.io/updated_at:2025_05_11T09_00_03_0700 minikube.k8s.io/version:v1.35.0 node-role.kubernetes.io/control-plane: node.kubernetes.io/exclude-from-external-load-balancers:] map[kubeadm.alpha.kubernetes.io/cri-socket:unix:///var/run/cri-dockerd.sock node.alpha.kubernetes.io/ttl:0 volumes.kubernetes.io/controller-managed-attach-detach:true] [] [] [{kubelet Update v1 2025-05-11 12:59:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:volumes.kubernetes.io/controller-managed-attach-detach":{}},"f:labels":{".":{},"f:beta.kubernetes.io/arch":{},"f:beta.kubernetes.io/os":{},"f:kubernetes.io/arch":{},"f:kubernetes.io/hostname":{},"f:kubernetes.io/os":{}}}} } {kubeadm Update v1 2025-05-11 13:00:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:kubeadm.alpha.kubernetes.io/cri-socket":{}},"f:labels":{"f:node-role.kubernetes.io/control-plane":{},"f:node.kubernetes.io/exclude-from-external-load-balancers":{}}}} } {kubectl-label Update v1 2025-05-11 13:00:03 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{"f:minikube.k8s.io/commit":{},"f:minikube.k8s.io/name":{},"f:minikube.k8s.io/primary":{},"f:minikube.k8s.io/updated_at":{},"f:minikube.k8s.io/version":{}}}} } {kube-controller-manager Update v1 2025-05-11 13:00:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:node.alpha.kubernetes.io/ttl":{}}},"f:spec":{"f:podCIDR":{},"f:podCIDRs":{".":{},"v:\"10.244.0.0/24\"":{}}}} } {kubelet Update v1 2025-05-11 14:22:52 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"DiskPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"MemoryPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"PIDPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"Ready\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}}},"f:images":{}}} status}]},Spec:NodeSpec{PodCIDR:10.244.0.0/24,DoNotUseExternalID:,ProviderID:,Unschedulable:false,Taints:[]Taint{},ConfigSource:nil,PodCIDRs:[10.244.0.0/24],},Status:NodeStatus{Capacity:ResourceList{cpu: {{12 0} {<nil>} 12 DecimalSI},ephemeral-storage: {{977340641280 0} {<nil>} 954434220Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{32722685952 0} {<nil>} 31955748Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{12 0} {<nil>} 12 DecimalSI},ephemeral-storage: {{977340641280 0} {<nil>} 954434220Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{32722685952 0} {<nil>} 31955748Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2025-05-11 14:22:52 +0000 UTC,LastTransitionTime:2025-05-11 12:59:59 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2025-05-11 14:22:52 +0000 UTC,LastTransitionTime:2025-05-11 12:59:59 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2025-05-11 14:22:52 +0000 UTC,LastTransitionTime:2025-05-11 12:59:59 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2025-05-11 14:22:52 +0000 UTC,LastTransitionTime:2025-05-11 13:00:00 +0000 UTC,Reason:KubeletReady,Message:kubelet is posting ready status,},},Addresses:[]NodeAddress{NodeAddress{Type:InternalIP,Address:192.168.49.2,},NodeAddress{Type:Hostname,Address:k8sconformance,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:377b5b8ee4ba4112b9e0bc9331922aaa,SystemUUID:e799047b-aac0-4c81-a61b-f70af01252d7,BootID:62684619-bcf0-48f9-b962-153bf81fe38c,KernelVersion:6.11.0-25-generic,OSImage:Ubuntu 22.04.5 LTS,ContainerRuntimeVersion:docker://28.1.1,KubeletVersion:v1.33.0,KubeProxyVersion:,OperatingSystem:linux,Architecture:amd64,Swap:nil,},Images:[]ContainerImage{ContainerImage{Names:[sonobuoy/systemd-logs@sha256:0b8b2b7b43b03f7db26e7e4b99be402495b77b496f5a5b0425b3c226bc1e9cbd sonobuoy/systemd-logs:v0.4],SizeBytes:314096343,},ContainerImage{Names:[registry.k8s.io/etcd@sha256:d58c035df557080a27387d687092e3fc2b64c6d0e3162dc51453a115f847d121 registry.k8s.io/etcd:3.5.21-0],SizeBytes:153121922,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/agnhost@sha256:99c6b4bb4a1e1df3f0b3752168c89358794d02258ebebc26bf21c29399011a85 registry.k8s.io/e2e-test-images/agnhost:2.53],SizeBytes:139374622,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/httpd@sha256:3fe7acf013d1264ffded116b80a73dc129a449b0fccdb8d21af8279f2233f36e registry.k8s.io/e2e-test-images/httpd:2.4.39-4],SizeBytes:126894770,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22 registry.k8s.io/e2e-test-images/httpd:2.4.38-4],SizeBytes:123781643,},ContainerImage{Names:[registry.k8s.io/kube-apiserver@sha256:6679a9970a8b2f18647b33bf02e5e9895d286689256e2f7172481b4096e46a32 registry.k8s.io/kube-apiserver:v1.33.0],SizeBytes:101797831,},ContainerImage{Names:[registry.k8s.io/kube-proxy@sha256:05f8984642d05b1b1a6c37605a4a566e46e7290f9291d17885f096c36861095b registry.k8s.io/kube-proxy:v1.33.0],SizeBytes:97885254,},ContainerImage{Names:[registry.k8s.io/kube-controller-manager@sha256:f0b32ab11fd06504608cdb9084f7284106b4f5f07f35eb8823e70ea0eaaf252a registry.k8s.io/kube-controller-manager:v1.33.0],SizeBytes:94593318,},ContainerImage{Names:[kindest/kindnetd@sha256:e3c42406b0806c1f7e8a66838377936cbd2cdfd94d9b26a3eefedada8713d495 kindest/kindnetd:v20250214-acbabc1a],SizeBytes:94322874,},ContainerImage{Names:[registry.k8s.io/kube-scheduler@sha256:8dd2fbeb7f711da53a89ded239e54133f34110d98de887a39a9021e651b51f1f registry.k8s.io/kube-scheduler:v1.33.0],SizeBytes:73441574,},ContainerImage{Names:[registry.k8s.io/coredns/coredns@sha256:40384aa1f5ea6bfdc77997d243aec73da05f27aed0c5e9d65bfa98933c519d97 registry.k8s.io/coredns/coredns:v1.12.0],SizeBytes:70112656,},ContainerImage{Names:[sonobuoy/sonobuoy@sha256:69d1ddf7bf84deb02807a415c0ff469358046aaf9c69409ef4c4a943d663201f sonobuoy/sonobuoy:v0.57.3],SizeBytes:54447235,},ContainerImage{Names:[gcr.io/k8s-minikube/storage-provisioner@sha256:18eb69d1418e854ad5a19e399310e52808a8321e4c441c1dddad8977a0d7a944 gcr.io/k8s-minikube/storage-provisioner:v5],SizeBytes:31465472,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/nginx@sha256:5c99cf6a02adda929b10321dbf4ecfa00d87be9ba4fb456006237d530ab4baa1 registry.k8s.io/e2e-test-images/nginx:1.14-4],SizeBytes:16032814,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9 registry.k8s.io/e2e-test-images/busybox:1.36.1-1],SizeBytes:4261566,},ContainerImage{Names:[registry.k8s.io/pause@sha256:ee6521f290b2168b6e0935a181d4cff9be1ac3f505666ef0e3c98fae8199917a registry.k8s.io/pause:3.10],SizeBytes:735760,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,RuntimeHandlers:[]NodeRuntimeHandler{},Features:nil,},}
  I0511 14:24:54.278511 26 dump.go:116] 
  Logging kubelet events for node k8sconformance
  I0511 14:24:54.279855 26 dump.go:121] 
  Logging pods the kubelet thinks are on node k8sconformance
  I0511 14:24:54.285032 26 dump.go:128] kubectl-473/update-demo-nautilus-clmsn started at 2025-05-11 14:19:49 +0000 UTC (0+1 container statuses recorded)
  I0511 14:24:54.285051 26 dump.go:134] 	Container update-demo ready: false, restart count 0
  I0511 14:24:54.285058 26 dump.go:128] kube-system/etcd-k8sconformance started at 2025-05-11 13:00:02 +0000 UTC (0+1 container statuses recorded)
  I0511 14:24:54.285064 26 dump.go:134] 	Container etcd ready: true, restart count 0
  I0511 14:24:54.285072 26 dump.go:128] kube-system/kube-controller-manager-k8sconformance started at 2025-05-11 13:00:02 +0000 UTC (0+1 container statuses recorded)
  I0511 14:24:54.285077 26 dump.go:134] 	Container kube-controller-manager ready: true, restart count 0
  I0511 14:24:54.285083 26 dump.go:128] kube-system/kube-scheduler-k8sconformance started at 2025-05-11 13:00:02 +0000 UTC (0+1 container statuses recorded)
  I0511 14:24:54.285089 26 dump.go:134] 	Container kube-scheduler ready: true, restart count 0
  I0511 14:24:54.285095 26 dump.go:128] sonobuoy/sonobuoy-systemd-logs-daemon-set-3b1a685ddb394b60-rggfh started at 2025-05-11 13:02:10 +0000 UTC (0+2 container statuses recorded)
  I0511 14:24:54.285101 26 dump.go:134] 	Container sonobuoy-worker ready: true, restart count 0
  I0511 14:24:54.285106 26 dump.go:134] 	Container systemd-logs ready: true, restart count 0
  I0511 14:24:54.285114 26 dump.go:128] kube-system/storage-provisioner started at 2025-05-11 13:00:08 +0000 UTC (0+1 container statuses recorded)
  I0511 14:24:54.285120 26 dump.go:134] 	Container storage-provisioner ready: true, restart count 0
  I0511 14:24:54.285125 26 dump.go:128] kube-system/kindnet-cs969 started at 2025-05-11 13:00:07 +0000 UTC (0+1 container statuses recorded)
  I0511 14:24:54.285131 26 dump.go:134] 	Container kindnet-cni ready: true, restart count 0
  I0511 14:24:54.285138 26 dump.go:128] kube-system/kube-apiserver-k8sconformance started at 2025-05-11 13:00:02 +0000 UTC (0+1 container statuses recorded)
  I0511 14:24:54.285144 26 dump.go:134] 	Container kube-apiserver ready: true, restart count 0
  I0511 14:24:54.285150 26 dump.go:128] kube-system/coredns-674b8bbfcf-68gnm started at 2025-05-11 13:00:07 +0000 UTC (0+1 container statuses recorded)
  I0511 14:24:54.285155 26 dump.go:134] 	Container coredns ready: true, restart count 4
  I0511 14:24:54.285160 26 dump.go:128] kube-system/kube-proxy-ssjxm started at 2025-05-11 13:00:07 +0000 UTC (0+1 container statuses recorded)
  I0511 14:24:54.285166 26 dump.go:134] 	Container kube-proxy ready: true, restart count 0
  I0511 14:24:54.321655 26 kubelet_metrics.go:206] 
  Latency metrics for node k8sconformance
  I0511 14:24:54.321687 26 dump.go:109] 
  Logging node info for node k8sconformance-m02
  I0511 14:24:54.323195 26 dump.go:114] Node Info: &Node{ObjectMeta:{k8sconformance-m02    62b787f7-3860-4963-837b-b010217cb0d3 14762 0 2025-05-11 13:00:17 +0000 UTC <nil> <nil> map[beta.kubernetes.io/arch:amd64 beta.kubernetes.io/os:linux kubernetes.io/arch:amd64 kubernetes.io/hostname:k8sconformance-m02 kubernetes.io/os:linux minikube.k8s.io/commit:8575beea95e830054fe9a36513b8b24cb1ff7010 minikube.k8s.io/name:k8sconformance minikube.k8s.io/primary:false minikube.k8s.io/updated_at:2025_05_11T09_00_17_0700 minikube.k8s.io/version:v1.35.0] map[kubeadm.alpha.kubernetes.io/cri-socket:unix:///var/run/cri-dockerd.sock node.alpha.kubernetes.io/ttl:0 volumes.kubernetes.io/controller-managed-attach-detach:true] [] [] [{kube-controller-manager Update v1 2025-05-11 13:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:node.alpha.kubernetes.io/ttl":{}}},"f:spec":{"f:podCIDR":{},"f:podCIDRs":{".":{},"v:\"10.244.1.0/24\"":{}}}} } {kubeadm Update v1 2025-05-11 13:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:kubeadm.alpha.kubernetes.io/cri-socket":{}}}} } {kubectl-label Update v1 2025-05-11 13:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{"f:minikube.k8s.io/commit":{},"f:minikube.k8s.io/name":{},"f:minikube.k8s.io/primary":{},"f:minikube.k8s.io/updated_at":{},"f:minikube.k8s.io/version":{}}}} } {kubelet Update v1 2025-05-11 13:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:volumes.kubernetes.io/controller-managed-attach-detach":{}},"f:labels":{".":{},"f:beta.kubernetes.io/arch":{},"f:beta.kubernetes.io/os":{},"f:kubernetes.io/arch":{},"f:kubernetes.io/hostname":{},"f:kubernetes.io/os":{}}}} } {kubelet Update v1 2025-05-11 14:21:08 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"DiskPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"MemoryPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"PIDPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"Ready\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}}},"f:images":{}}} status}]},Spec:NodeSpec{PodCIDR:10.244.1.0/24,DoNotUseExternalID:,ProviderID:,Unschedulable:false,Taints:[]Taint{},ConfigSource:nil,PodCIDRs:[10.244.1.0/24],},Status:NodeStatus{Capacity:ResourceList{cpu: {{12 0} {<nil>} 12 DecimalSI},ephemeral-storage: {{977340641280 0} {<nil>} 954434220Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{32722685952 0} {<nil>} 31955748Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{12 0} {<nil>} 12 DecimalSI},ephemeral-storage: {{977340641280 0} {<nil>} 954434220Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{32722685952 0} {<nil>} 31955748Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2025-05-11 14:21:08 +0000 UTC,LastTransitionTime:2025-05-11 13:00:17 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2025-05-11 14:21:08 +0000 UTC,LastTransitionTime:2025-05-11 13:00:17 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2025-05-11 14:21:08 +0000 UTC,LastTransitionTime:2025-05-11 13:00:17 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2025-05-11 14:21:08 +0000 UTC,LastTransitionTime:2025-05-11 13:00:18 +0000 UTC,Reason:KubeletReady,Message:kubelet is posting ready status,},},Addresses:[]NodeAddress{NodeAddress{Type:InternalIP,Address:192.168.49.3,},NodeAddress{Type:Hostname,Address:k8sconformance-m02,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:8c5a8740e2624faba2a6ef4cd8ec4415,SystemUUID:ea151e56-d5a5-451f-bee4-dbfc4d9209dd,BootID:62684619-bcf0-48f9-b962-153bf81fe38c,KernelVersion:6.11.0-25-generic,OSImage:Ubuntu 22.04.5 LTS,ContainerRuntimeVersion:docker://28.1.1,KubeletVersion:v1.33.0,KubeProxyVersion:,OperatingSystem:linux,Architecture:amd64,Swap:nil,},Images:[]ContainerImage{ContainerImage{Names:[sonobuoy/systemd-logs@sha256:0b8b2b7b43b03f7db26e7e4b99be402495b77b496f5a5b0425b3c226bc1e9cbd sonobuoy/systemd-logs:v0.4],SizeBytes:314096343,},ContainerImage{Names:[registry.k8s.io/conformance@sha256:8e8418f17d2a77f004edbcb2c853df2326da9ecff57bf42264652f14620cd54f registry.k8s.io/conformance:v1.33.0],SizeBytes:265839740,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/jessie-dnsutils@sha256:24aaf2626d6b27864c29de2097e8bbb840b3a414271bf7c8995e431e47d8408e registry.k8s.io/e2e-test-images/jessie-dnsutils:1.7],SizeBytes:253371792,},ContainerImage{Names:[registry.k8s.io/etcd@sha256:d58c035df557080a27387d687092e3fc2b64c6d0e3162dc51453a115f847d121 registry.k8s.io/etcd:3.5.21-0],SizeBytes:153121922,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/agnhost@sha256:99c6b4bb4a1e1df3f0b3752168c89358794d02258ebebc26bf21c29399011a85 registry.k8s.io/e2e-test-images/agnhost:2.53],SizeBytes:139374622,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/httpd@sha256:3fe7acf013d1264ffded116b80a73dc129a449b0fccdb8d21af8279f2233f36e registry.k8s.io/e2e-test-images/httpd:2.4.39-4],SizeBytes:126894770,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22 registry.k8s.io/e2e-test-images/httpd:2.4.38-4],SizeBytes:123781643,},ContainerImage{Names:[registry.k8s.io/kube-apiserver@sha256:6679a9970a8b2f18647b33bf02e5e9895d286689256e2f7172481b4096e46a32 registry.k8s.io/kube-apiserver:v1.33.0],SizeBytes:101797831,},ContainerImage{Names:[registry.k8s.io/kube-proxy@sha256:05f8984642d05b1b1a6c37605a4a566e46e7290f9291d17885f096c36861095b registry.k8s.io/kube-proxy:v1.33.0],SizeBytes:97885254,},ContainerImage{Names:[registry.k8s.io/kube-controller-manager@sha256:f0b32ab11fd06504608cdb9084f7284106b4f5f07f35eb8823e70ea0eaaf252a registry.k8s.io/kube-controller-manager:v1.33.0],SizeBytes:94593318,},ContainerImage{Names:[kindest/kindnetd@sha256:e3c42406b0806c1f7e8a66838377936cbd2cdfd94d9b26a3eefedada8713d495 kindest/kindnetd:v20250214-acbabc1a],SizeBytes:94322874,},ContainerImage{Names:[registry.k8s.io/kube-scheduler@sha256:8dd2fbeb7f711da53a89ded239e54133f34110d98de887a39a9021e651b51f1f registry.k8s.io/kube-scheduler:v1.33.0],SizeBytes:73441574,},ContainerImage{Names:[registry.k8s.io/coredns/coredns@sha256:40384aa1f5ea6bfdc77997d243aec73da05f27aed0c5e9d65bfa98933c519d97 registry.k8s.io/coredns/coredns:v1.12.0],SizeBytes:70112656,},ContainerImage{Names:[sonobuoy/sonobuoy@sha256:69d1ddf7bf84deb02807a415c0ff469358046aaf9c69409ef4c4a943d663201f sonobuoy/sonobuoy:v0.57.3],SizeBytes:54447235,},ContainerImage{Names:[gcr.io/k8s-minikube/storage-provisioner@sha256:18eb69d1418e854ad5a19e399310e52808a8321e4c441c1dddad8977a0d7a944 gcr.io/k8s-minikube/storage-provisioner:v5],SizeBytes:31465472,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/nginx@sha256:5c99cf6a02adda929b10321dbf4ecfa00d87be9ba4fb456006237d530ab4baa1 registry.k8s.io/e2e-test-images/nginx:1.14-4],SizeBytes:16032814,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9 registry.k8s.io/e2e-test-images/busybox:1.36.1-1],SizeBytes:4261566,},ContainerImage{Names:[registry.k8s.io/pause@sha256:ee6521f290b2168b6e0935a181d4cff9be1ac3f505666ef0e3c98fae8199917a registry.k8s.io/pause:3.10],SizeBytes:735760,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,RuntimeHandlers:[]NodeRuntimeHandler{},Features:nil,},}
  I0511 14:24:54.323224 26 dump.go:116] 
  Logging kubelet events for node k8sconformance-m02
  I0511 14:24:54.324740 26 dump.go:121] 
  Logging pods the kubelet thinks are on node k8sconformance-m02
  I0511 14:24:54.329332 26 dump.go:128] kubectl-473/update-demo-nautilus-nmlf6 started at 2025-05-11 14:19:49 +0000 UTC (0+1 container statuses recorded)
  I0511 14:24:54.329354 26 dump.go:134] 	Container update-demo ready: false, restart count 0
  I0511 14:24:54.329361 26 dump.go:128] kube-system/kube-proxy-wwbpc started at 2025-05-11 13:00:19 +0000 UTC (0+1 container statuses recorded)
  I0511 14:24:54.329366 26 dump.go:134] 	Container kube-proxy ready: true, restart count 0
  I0511 14:24:54.329371 26 dump.go:128] sonobuoy/sonobuoy-systemd-logs-daemon-set-3b1a685ddb394b60-t2p28 started at 2025-05-11 13:02:10 +0000 UTC (0+2 container statuses recorded)
  I0511 14:24:54.329376 26 dump.go:134] 	Container sonobuoy-worker ready: true, restart count 0
  I0511 14:24:54.329381 26 dump.go:134] 	Container systemd-logs ready: true, restart count 0
  I0511 14:24:54.329386 26 dump.go:128] sonobuoy/sonobuoy-e2e-job-32c36e3a15c942ea started at 2025-05-11 13:02:10 +0000 UTC (0+2 container statuses recorded)
  I0511 14:24:54.329392 26 dump.go:134] 	Container e2e ready: true, restart count 0
  I0511 14:24:54.329396 26 dump.go:134] 	Container sonobuoy-worker ready: true, restart count 0
  I0511 14:24:54.329401 26 dump.go:128] kube-system/kindnet-5r7wn started at 2025-05-11 13:31:32 +0000 UTC (0+1 container statuses recorded)
  I0511 14:24:54.329406 26 dump.go:134] 	Container kindnet-cni ready: true, restart count 0
  I0511 14:24:54.329411 26 dump.go:128] sonobuoy/sonobuoy started at 2025-05-11 13:01:52 +0000 UTC (0+1 container statuses recorded)
  I0511 14:24:54.329415 26 dump.go:134] 	Container kube-sonobuoy ready: true, restart count 0
  I0511 14:24:54.392037 26 kubelet_metrics.go:206] 
  Latency metrics for node k8sconformance-m02
  STEP: Destroying namespace "kubectl-473" for this suite. @ 05/11/25 14:24:54.392
• [FAILED] [305.421 seconds]
[sig-cli] Kubectl client Update Demo [It] should create and stop a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:338

  [FAILED] Timed out after 300 seconds waiting for name=update-demo pods to reach valid state
  In [It] at: k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:2532 @ 05/11/25 14:24:54.247
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1627
  STEP: Creating a kubernetes client @ 05/11/25 14:24:54.396
  I0511 14:24:54.396449 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubectl @ 05/11/25 14:24:54.396
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:24:54.402
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:24:54.404
  STEP: creating the pod @ 05/11/25 14:24:54.405
  I0511 14:24:54.405848 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-5191 create -f -'
  I0511 14:24:54.479421 26 builder.go:146] stderr: ""
  I0511 14:24:54.479456 26 builder.go:147] stdout: "pod/pause created\n"
  E0511 14:24:54.940595      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:55.940846      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 05/11/25 14:24:56.486
  I0511 14:24:56.486867 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-5191 label pods pause testing-label=testing-label-value'
  I0511 14:24:56.533964 26 builder.go:146] stderr: ""
  I0511 14:24:56.534000 26 builder.go:147] stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 05/11/25 14:24:56.534
  I0511 14:24:56.534080 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-5191 get pod pause -L testing-label'
  I0511 14:24:56.572931 26 builder.go:146] stderr: ""
  I0511 14:24:56.572971 26 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 05/11/25 14:24:56.572
  I0511 14:24:56.573055 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-5191 label pods pause testing-label-'
  I0511 14:24:56.615502 26 builder.go:146] stderr: ""
  I0511 14:24:56.615541 26 builder.go:147] stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 05/11/25 14:24:56.615
  I0511 14:24:56.615638 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-5191 get pod pause -L testing-label'
  I0511 14:24:56.651315 26 builder.go:146] stderr: ""
  I0511 14:24:56.651351 26 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
  STEP: using delete to clean up resources @ 05/11/25 14:24:56.651
  I0511 14:24:56.651502 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-5191 delete --grace-period=0 --force -f -'
  I0511 14:24:56.695127 26 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0511 14:24:56.695159 26 builder.go:147] stdout: "pod \"pause\" force deleted\n"
  I0511 14:24:56.695202 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-5191 get rc,svc -l name=pause --no-headers'
  I0511 14:24:56.741053 26 builder.go:146] stderr: "No resources found in kubectl-5191 namespace.\n"
  I0511 14:24:56.741086 26 builder.go:147] stdout: ""
  I0511 14:24:56.741124 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-5191 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0511 14:24:56.778078 26 builder.go:146] stderr: ""
  I0511 14:24:56.778118 26 builder.go:147] stdout: ""
  I0511 14:24:56.778222 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5191" for this suite. @ 05/11/25 14:24:56.78
• [2.386 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:131
  STEP: Creating a kubernetes client @ 05/11/25 14:24:56.782
  I0511 14:24:56.782808 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 14:24:56.783
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:24:56.789
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:24:56.791
  STEP: Creating the pod @ 05/11/25 14:24:56.792
  E0511 14:24:56.941888      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:57.941936      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:24:58.942951      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:24:59.331986 26 pod_client.go:173] Successfully updated pod "labelsupdateaad1b326-efe3-47cc-944e-08ada864f793"
  E0511 14:24:59.943280      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:00.943880      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:01.944729      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:02.945915      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:25:03.361013 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5889" for this suite. @ 05/11/25 14:25:03.363
• [6.587 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:375
  STEP: Creating a kubernetes client @ 05/11/25 14:25:03.37
  I0511 14:25:03.370684 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 14:25:03.371
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:25:03.382
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:25:03.385
  STEP: Creating configMap with name projected-configmap-test-volume-e5350ba6-f765-42bc-9039-e4c1fbfd5765 @ 05/11/25 14:25:03.388
  STEP: Creating a pod to test consume configMaps @ 05/11/25 14:25:03.392
  E0511 14:25:03.946872      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:04.947997      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:05.948189      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:06.948940      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:25:07.416
  I0511 14:25:07.419152 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-projected-configmaps-02d5c484-6c22-4ae3-95de-ef54a7fbbad6 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 05/11/25 14:25:07.425
  I0511 14:25:07.442591 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8645" for this suite. @ 05/11/25 14:25:07.446
• [4.080 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:900
  STEP: Creating a kubernetes client @ 05/11/25 14:25:07.451
  I0511 14:25:07.451228 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename pods @ 05/11/25 14:25:07.452
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:25:07.462
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:25:07.465
  STEP: creating a Pod with a static label @ 05/11/25 14:25:07.47
  STEP: watching for Pod to be ready @ 05/11/25 14:25:07.477
  I0511 14:25:07.479756 26 pods.go:947] observed Pod pod-test in namespace pods-3746 in phase Pending with labels: map[test-pod-static:true] & conditions []
  I0511 14:25:07.484726 26 pods.go:947] observed Pod pod-test in namespace pods-3746 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:25:07 +0000 UTC  }]
  I0511 14:25:07.498601 26 pods.go:947] observed Pod pod-test in namespace pods-3746 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers 0 False 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:25:07 +0000 UTC  } {Initialized 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:25:07 +0000 UTC  } {Ready 0 False 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:25:07 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady 0 False 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:25:07 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:25:07 +0000 UTC  }]
  E0511 14:25:07.949055      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:25:08.571439 26 pods.go:950] Found Pod pod-test in namespace pods-3746 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:25:08 +0000 UTC  } {Initialized 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:25:07 +0000 UTC  } {Ready 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:25:08 +0000 UTC  } {ContainersReady 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:25:08 +0000 UTC  } {PodScheduled 0 True 0001-01-01 00:00:00 +0000 UTC 2025-05-11 14:25:07 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 05/11/25 14:25:08.575
  STEP: getting the Pod and ensuring that it's patched @ 05/11/25 14:25:08.583
  STEP: replacing the Pod's status Ready condition to False @ 05/11/25 14:25:08.585
  STEP: check the Pod again to ensure its Ready conditions are False @ 05/11/25 14:25:08.592
  STEP: deleting the Pod via a Collection with a LabelSelector @ 05/11/25 14:25:08.592
  STEP: watching for the Pod to be deleted @ 05/11/25 14:25:08.598
  I0511 14:25:08.600248 26 pods.go:1060] observed event type MODIFIED
  E0511 14:25:08.950166      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:09.950249      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:25:10.611822 26 pods.go:1060] observed event type MODIFIED
  I0511 14:25:10.710217 26 pods.go:1060] observed event type MODIFIED
  E0511 14:25:10.950690      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:25:11.623634 26 pods.go:1060] observed event type MODIFIED
  I0511 14:25:11.630178 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3746" for this suite. @ 05/11/25 14:25:11.633
• [4.186 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:229
  STEP: Creating a kubernetes client @ 05/11/25 14:25:11.637
  I0511 14:25:11.637659 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename emptydir @ 05/11/25 14:25:11.638
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:25:11.648
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:25:11.651
  STEP: Creating Pod @ 05/11/25 14:25:11.654
  E0511 14:25:11.951774      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:12.952370      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 05/11/25 14:25:13.667
  I0511 14:25:13.667849 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-6103 PodName:pod-sharedvolume-4b1d3188-2937-44ac-b0b2-95380a06de2d ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 14:25:13.667865 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 14:25:13.667906 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/emptydir-6103/pods/pod-sharedvolume-4b1d3188-2937-44ac-b0b2-95380a06de2d/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&stderr=true&stdout=true)
  I0511 14:25:13.719828 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 14:25:13.719859 26 exec_util.go:112] Exec stderr: ""
  I0511 14:25:13.719977 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6103" for this suite. @ 05/11/25 14:25:13.722
• [2.087 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 05/11/25 14:25:13.725
  I0511 14:25:13.725071 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename deployment @ 05/11/25 14:25:13.725
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:25:13.73
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:25:13.731
  I0511 14:25:13.738070 26 resource.go:81] Pod name cleanup-pod: Found 0 pods out of 1
  E0511 14:25:13.952394      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:14.953229      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:15.953700      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:16.954260      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:17.954835      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:25:18.741853 26 resource.go:81] Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/11/25 14:25:18.741
  I0511 14:25:18.741968 26 deployment.go:854] Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 05/11/25 14:25:18.755
  I0511 14:25:18.767108 26 deployment.go:632] Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1176",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0a599828-0a1d-45e7-91a4-01213f7c3a48",
      ResourceVersion: (string) (len=5) "15174",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882570318,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570318,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 0,
      Replicas: (int32) 0,
      UpdatedReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      Conditions: ([]v1.DeploymentCondition) <nil>,
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0511 14:25:18.773140 26 deployment.go:42] New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
  I0511 14:25:18.773226 26 deployment.go:45] All old ReplicaSets of Deployment "test-cleanup-deployment":
  I0511 14:25:18.773782 26 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1176",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4a0dc39d-0243-43c8-aee9-fb0b2b7f3d2d",
      ResourceVersion: (string) (len=5) "15175",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882570313,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "0a599828-0a1d-45e7-91a4-01213f7c3a48",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570313,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=483) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000050  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000060  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000070  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000080  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000090  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              000000a0  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000b0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000c0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000d0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000e0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000f0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000100  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000110  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000120  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000130  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000140  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000160  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000170  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000180  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000190  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000001a0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001b0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001c0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001d0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001e0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570318,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=103) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000020  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              00000030  22 75 69 64 5c 22 3a 5c  22 30 61 35 39 39 38 32  |"uid\":\"0a59982|
              00000040  38 2d 30 61 31 64 2d 34  35 65 37 2d 39 31 61 34  |8-0a1d-45e7-91a4|
              00000050  2d 30 31 32 31 33 66 37  63 33 61 34 38 5c 22 7d  |-01213f7c3a48\"}|
              00000060  22 3a 7b 7d 7d 7d 7d                              |":{}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0511 14:25:18.783857 26 deployment.go:68] Pod "test-cleanup-controller-r2qpf" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=29) "test-cleanup-controller-r2qpf",
      GenerateName: (string) (len=24) "test-cleanup-controller-",
      Namespace: (string) (len=15) "deployment-1176",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "aaa77bc8-88e2-4f25-a434-4fc85f6381c3",
      ResourceVersion: (string) (len=5) "15157",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882570313,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=23) "test-cleanup-controller",
          UID: (types.UID) (len=36) "4a0dc39d-0243-43c8-aee9-fb0b2b7f3d2d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570313,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=500) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 2c 22 66  |},"f:pod":{}},"f|
              00000050  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000060  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000070  75 69 64 5c 22 3a 5c 22  34 61 30 64 63 33 39 64  |uid\":\"4a0dc39d|
              00000080  2d 30 32 34 33 2d 34 33  63 38 2d 61 65 65 39 2d  |-0243-43c8-aee9-|
              00000090  66 62 30 62 32 62 37 66  33 64 32 64 5c 22 7d 22  |fb0b2b7f3d2d\"}"|
              000000a0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000b0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000c0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              000000d0  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              000000e0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              000000f0  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000100  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000110  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000120  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000130  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000140  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000150  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000160  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              00000170  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              00000180  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              00000190  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001a0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001b0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001c0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              000001d0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              000001e0  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              000001f0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 31  39 38 5c 22 7d 22 3a 7b  |.244.1.198\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-rdsfz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-rdsfz",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)(<nil>),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570313,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570313,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.3"
        }
      },
      PodIP: (string) (len=12) "10.244.1.198",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.1.198"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882570313,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63882570314,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://67f74e7d6965d0980ea7db3399e37a02aab20c1b0d555a003822258d0004992d",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-rdsfz",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:25:18.787034 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1176" for this suite. @ 05/11/25 14:25:18.796
• [5.078 seconds]
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 05/11/25 14:25:18.803
  I0511 14:25:18.803517 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename runtimeclass @ 05/11/25 14:25:18.804
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:25:18.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:25:18.813
  I0511 14:25:18.821557 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-9856" for this suite. @ 05/11/25 14:25:18.895
• [0.100 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 05/11/25 14:25:18.903
  I0511 14:25:18.903381 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename secrets @ 05/11/25 14:25:18.904
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:25:18.914
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:25:18.916
  STEP: Creating secret with name secret-test-6414baa9-172d-4ce5-977b-7512d0228f5a @ 05/11/25 14:25:18.918
  STEP: Creating a pod to test consume secrets @ 05/11/25 14:25:18.921
  E0511 14:25:18.955854      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:19.956201      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:20.956745      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:25:21.033
  I0511 14:25:21.035936 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-secrets-35c96318-879e-4eff-ba44-134aa37bd9fb container secret-volume-test: <nil>
  STEP: delete the pod @ 05/11/25 14:25:21.044
  I0511 14:25:21.060559 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4379" for this suite. @ 05/11/25 14:25:21.064
• [2.165 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:504
  STEP: Creating a kubernetes client @ 05/11/25 14:25:21.069
  I0511 14:25:21.069319 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename configmap @ 05/11/25 14:25:21.07
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:25:21.078
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:25:21.08
  I0511 14:25:21.104551 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2472" for this suite. @ 05/11/25 14:25:21.165
• [0.102 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 05/11/25 14:25:21.171
  I0511 14:25:21.171838 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename endpointslice @ 05/11/25 14:25:21.172
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:25:21.183
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:25:21.186
  I0511 14:25:21.193979      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 14:25:21.196597 26 endpointslice.go:1045] Endpoints addresses: [192.168.49.2] , ports: [8443]
  I0511 14:25:21.196630 26 endpointslice.go:1075] EndpointSlices addresses: [192.168.49.2] , ports: [8443]
  I0511 14:25:21.196755 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-57" for this suite. @ 05/11/25 14:25:21.266
• [0.101 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 05/11/25 14:25:21.272
  I0511 14:25:21.272917 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/11/25 14:25:21.273
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:25:21.285
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:25:21.288
  I0511 14:25:21.291108 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  E0511 14:25:21.957553      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:22.958240      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:23.958708      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:24.959938      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:25.960131      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:26.960931      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:25:27.469305 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-3568" for this suite. @ 05/11/25 14:25:27.473
• [6.208 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:841
  STEP: Creating a kubernetes client @ 05/11/25 14:25:27.481
  I0511 14:25:27.481326 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 14:25:27.482
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:25:27.491
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:25:27.494
  STEP: Setting up server cert @ 05/11/25 14:25:27.509
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 14:25:27.773
  STEP: Deploying the webhook pod @ 05/11/25 14:25:27.776
  STEP: Wait for the deployment to be ready @ 05/11/25 14:25:27.784
  I0511 14:25:27.787605 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0511 14:25:27.962017      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:28.962630      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/11/25 14:25:29.794
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 14:25:29.809
  E0511 14:25:29.963180      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:25:30.810585 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 05/11/25 14:25:30.814
  I0511 14:25:30.857872 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7690" for this suite. @ 05/11/25 14:25:30.861
  STEP: Destroying namespace "webhook-markers-5493" for this suite. @ 05/11/25 14:25:30.869
• [3.393 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:411
  STEP: Creating a kubernetes client @ 05/11/25 14:25:30.874
  I0511 14:25:30.874500 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename validating-admission-policy @ 05/11/25 14:25:30.875
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:25:30.882
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:25:30.884
  STEP: getting /apis @ 05/11/25 14:25:30.89
  STEP: getting /apis/admissionregistration.k8s.io @ 05/11/25 14:25:30.893
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 05/11/25 14:25:30.894
  STEP: creating @ 05/11/25 14:25:30.895
  STEP: getting @ 05/11/25 14:25:30.913
  STEP: listing @ 05/11/25 14:25:30.917
  STEP: watching @ 05/11/25 14:25:30.92
  I0511 14:25:30.920623 26 validatingadmissionpolicy.go:528] starting watch
  STEP: patching @ 05/11/25 14:25:30.922
  STEP: updating @ 05/11/25 14:25:30.927
  I0511 14:25:30.932835 26 validatingadmissionpolicy.go:557] waiting for watch events with expected annotations
  I0511 14:25:30.932873 26 validatingadmissionpolicy.go:573] missing expected annotations, waiting: map[string]string(nil)
  I0511 14:25:30.932967 26 validatingadmissionpolicy.go:573] missing expected annotations, waiting: map[string]string(nil)
  STEP: getting /status @ 05/11/25 14:25:30.933
  STEP: patching /status @ 05/11/25 14:25:30.934
  STEP: updating /status @ 05/11/25 14:25:30.94
  E0511 14:25:30.963557      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting @ 05/11/25 14:25:30.967
  STEP: deleting a collection @ 05/11/25 14:25:30.979
  I0511 14:25:30.993308 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-48" for this suite. @ 05/11/25 14:25:30.996
• [0.126 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 05/11/25 14:25:31
  I0511 14:25:31.000953 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename deployment @ 05/11/25 14:25:31.001
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:25:31.009
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:25:31.012
  I0511 14:25:31.015571 26 deployment.go:754] Creating replica set "test-rolling-update-controller" (going to be adopted)
  I0511 14:25:31.022417 26 resource.go:81] Pod name sample-pod: Found 0 pods out of 1
  E0511 14:25:31.963669      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:32.964700      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:33.965043      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:34.966080      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:35.966371      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:25:36.109547 26 resource.go:81] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/11/25 14:25:36.109
  I0511 14:25:36.109674 26 deployment.go:769] Creating deployment "test-rolling-update-deployment"
  I0511 14:25:36.114353 26 deployment.go:775] Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  I0511 14:25:36.120757 26 deployment.go:223] new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  E0511 14:25:36.967113      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:37.967332      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:25:38.129787 26 deployment.go:779] Ensuring status for deployment "test-rolling-update-deployment" is the expected
  I0511 14:25:38.131900 26 deployment.go:784] Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  I0511 14:25:38.138669 26 deployment.go:632] Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1704",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "44205963-3489-45af-9048-3770a0d9742c",
      ResourceVersion: (string) (len=5) "15482",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882570336,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570336,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570336,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570336,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570336,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570336,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570336,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-6ff565599d\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0511 14:25:38.141948 26 deployment.go:40] New ReplicaSet "test-rolling-update-deployment-6ff565599d" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-6ff565599d",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1704",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4730f44d-913c-4ced-b015-5b58a2cb795d",
      ResourceVersion: (string) (len=5) "15472",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882570336,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6ff565599d"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "44205963-3489-45af-9048-3770a0d9742c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570336,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 34 34 32 30 35 39  36 33 2d 33 34 38 39 2d  |\"44205963-3489-|
              00000120  34 35 61 66 2d 39 30 34  38 2d 33 37 37 30 61 30  |45af-9048-3770a0|
              00000130  64 39 37 34 32 63 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |d9742c\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570336,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6ff565599d"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6ff565599d"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0511 14:25:38.142618 26 deployment.go:45] All old ReplicaSets of Deployment "test-rolling-update-deployment":
  I0511 14:25:38.142789 26 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1704",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d279c91c-acc8-4580-9bce-ab7dc0cafcfd",
      ResourceVersion: (string) (len=5) "15481",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882570331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "44205963-3489-45af-9048-3770a0d9742c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570336,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 34 34 32 30 35 39 36  |"uid\":\"4420596|
              000000b0  33 2d 33 34 38 39 2d 34  35 61 66 2d 39 30 34 38  |3-3489-45af-9048|
              000000c0  2d 33 37 37 30 61 30 64  39 37 34 32 63 5c 22 7d  |-3770a0d9742c\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570336,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "pod": (string) (len=5) "httpd",
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0511 14:25:38.145126 26 deployment.go:68] Pod "test-rolling-update-deployment-6ff565599d-tcg6v" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-6ff565599d-tcg6v",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-6ff565599d-",
      Namespace: (string) (len=15) "deployment-1704",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0fda3b45-3dd9-4a07-97a4-958b6ba18984",
      ResourceVersion: (string) (len=5) "15471",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882570336,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6ff565599d"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-6ff565599d",
          UID: (types.UID) (len=36) "4730f44d-913c-4ced-b015-5b58a2cb795d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570336,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 37  33 30 66 34 34 64 2d 39  |d\":\"4730f44d-9|
              00000090  31 33 63 2d 34 63 65 64  2d 62 30 31 35 2d 35 62  |13c-4ced-b015-5b|
              000000a0  35 38 61 32 63 62 37 39  35 64 5c 22 7d 22 3a 7b  |58a2cb795d\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570336,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 32  30 32 5c 22 7d 22 3a 7b  |.244.1.202\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-nj52m",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-nj52m",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570336,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570336,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570336,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570336,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63882570336,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.49.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.49.3"
        }
      },
      PodIP: (string) (len=12) "10.244.1.202",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.1.202"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63882570336,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63882570336,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
          ImageID: (string) (len=129) "docker-pullable://registry.k8s.io/e2e-test-images/agnhost@sha256:99c6b4bb4a1e1df3f0b3752168c89358794d02258ebebc26bf21c29399011a85",
          ContainerID: (string) (len=73) "docker://a7866685be6a68b6a2fe9efd5e1f0241054a0aadb67fd6456a8143c497a3818d",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-nj52m",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0511 14:25:38.145853 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1704" for this suite. @ 05/11/25 14:25:38.147
• [7.151 seconds]
------------------------------
SS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingress.go:55
  STEP: Creating a kubernetes client @ 05/11/25 14:25:38.152
  I0511 14:25:38.152137 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename ingress @ 05/11/25 14:25:38.152
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:25:38.161
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:25:38.163
  STEP: getting /apis @ 05/11/25 14:25:38.165
  STEP: getting /apis/networking.k8s.io @ 05/11/25 14:25:38.169
  STEP: getting /apis/networking.k8s.iov1 @ 05/11/25 14:25:38.17
  STEP: creating @ 05/11/25 14:25:38.171
  STEP: getting @ 05/11/25 14:25:38.181
  STEP: listing @ 05/11/25 14:25:38.182
  STEP: watching @ 05/11/25 14:25:38.184
  I0511 14:25:38.184474 26 ingress.go:186] starting watch
  STEP: cluster-wide listing @ 05/11/25 14:25:38.184
  STEP: cluster-wide watching @ 05/11/25 14:25:38.186
  I0511 14:25:38.186318 26 ingress.go:198] starting watch
  STEP: patching @ 05/11/25 14:25:38.186
  STEP: updating @ 05/11/25 14:25:38.19
  I0511 14:25:38.197373 26 ingress.go:221] waiting for watch events with expected annotations
  I0511 14:25:38.197432 26 ingress.go:234] saw patched and updated annotations
  STEP: patching /status @ 05/11/25 14:25:38.197
  STEP: updating /status @ 05/11/25 14:25:38.202
  STEP: get /status @ 05/11/25 14:25:38.207
  STEP: deleting @ 05/11/25 14:25:38.209
  STEP: deleting a collection @ 05/11/25 14:25:38.216
  I0511 14:25:38.225971 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-6665" for this suite. @ 05/11/25 14:25:38.249
• [0.106 seconds]
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 05/11/25 14:25:38.258
  I0511 14:25:38.258219 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename pod-network-test @ 05/11/25 14:25:38.259
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:25:38.272
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:25:38.274
  STEP: Performing setup for networking test in namespace pod-network-test-9597 @ 05/11/25 14:25:38.277
  STEP: creating a selector @ 05/11/25 14:25:38.277
  STEP: Creating the service pods in kubernetes @ 05/11/25 14:25:38.277
  I0511 14:25:38.277489 26 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0511 14:25:38.967758      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:39.968862      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:40.969933      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:41.970603      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:42.970656      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:43.970844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:44.970987      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:45.971436      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:46.972128      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:47.972546      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:48.972618      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:49.973556      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:50.973852      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:51.974328      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/11/25 14:25:52.415
  E0511 14:25:52.974686      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:53.975207      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:25:54.430361 26 utils.go:802] Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  I0511 14:25:54.430404 26 networking.go:42] Breadth first check of 10.244.0.56 on host 192.168.49.2...
  I0511 14:25:54.432448 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.204:9080/dial?request=hostname&protocol=udp&host=10.244.0.56&port=8081&tries=1'] Namespace:pod-network-test-9597 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 14:25:54.432497 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 14:25:54.432559 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9597/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.204%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.0.56%26port%3D8081%26tries%3D1%27&container=webserver&stderr=true&stdout=true)
  I0511 14:25:54.503126 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 14:25:54.503180 26 utils.go:355] Waiting for responses: map[]
  I0511 14:25:54.503193 26 utils.go:359] reached 10.244.0.56 after 0/1 tries
  I0511 14:25:54.503205 26 networking.go:42] Breadth first check of 10.244.1.203 on host 192.168.49.3...
  I0511 14:25:54.506208 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.204:9080/dial?request=hostname&protocol=udp&host=10.244.1.203&port=8081&tries=1'] Namespace:pod-network-test-9597 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 14:25:54.506250 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 14:25:54.506329 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9597/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.204%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.1.203%26port%3D8081%26tries%3D1%27&container=webserver&stderr=true&stdout=true)
  I0511 14:25:54.570022 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 14:25:54.570125 26 utils.go:355] Waiting for responses: map[]
  I0511 14:25:54.570283 26 utils.go:359] reached 10.244.1.203 after 0/1 tries
  I0511 14:25:54.570303 26 networking.go:53] Going to retry 0 out of 2 pods....
  I0511 14:25:54.570546 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-9597" for this suite. @ 05/11/25 14:25:54.573
• [16.320 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3195
  STEP: Creating a kubernetes client @ 05/11/25 14:25:54.578
  I0511 14:25:54.578144 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename services @ 05/11/25 14:25:54.579
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:25:54.585
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:25:54.588
  STEP: fetching services @ 05/11/25 14:25:54.589
  I0511 14:25:54.591353 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-88" for this suite. @ 05/11/25 14:25:54.675
• [0.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 05/11/25 14:25:54.681
  I0511 14:25:54.681394 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename discovery @ 05/11/25 14:25:54.682
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:25:54.692
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:25:54.696
  STEP: Setting up server cert @ 05/11/25 14:25:54.7
  STEP: Requesting APIResourceList from "/api/v1" @ 05/11/25 14:25:54.945
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 05/11/25 14:25:54.946
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 05/11/25 14:25:54.947
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 05/11/25 14:25:54.948
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 05/11/25 14:25:54.948
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 05/11/25 14:25:54.949
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 05/11/25 14:25:54.95
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 05/11/25 14:25:54.95
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 05/11/25 14:25:54.951
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 05/11/25 14:25:54.952
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 05/11/25 14:25:54.952
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 05/11/25 14:25:54.953
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 05/11/25 14:25:54.953
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 05/11/25 14:25:54.954
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 05/11/25 14:25:54.954
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 05/11/25 14:25:54.955
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 05/11/25 14:25:54.956
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 05/11/25 14:25:54.956
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 05/11/25 14:25:54.957
  I0511 14:25:54.957489 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-3453" for this suite. @ 05/11/25 14:25:54.959
• [0.280 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 05/11/25 14:25:54.961
  I0511 14:25:54.961671 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 14:25:54.962
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:25:54.968
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:25:54.97
  STEP: Creating configMap with name configmap-projected-all-test-volume-73b01cab-21c0-483d-9f63-57d80c06eb31 @ 05/11/25 14:25:54.971
  STEP: Creating secret with name secret-projected-all-test-volume-04aa956d-52f4-430d-a147-28800ff02f55 @ 05/11/25 14:25:54.974
  E0511 14:25:54.975250      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 05/11/25 14:25:54.976
  I0511 14:25:54.981385      26 warnings.go:110] "Warning: volume \"podinfo\" (Projected): overlapping paths: \"podname\" (DownwardAPI) with \"podname\" (DownwardAPI)"
  E0511 14:25:55.975745      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:56.976750      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:57.977033      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:25:58.977817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:25:58.995
  I0511 14:25:58.998445 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod projected-volume-1c94aa9c-4f69-492e-94ac-490d90cede36 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 05/11/25 14:25:59.005
  I0511 14:25:59.019759 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2216" for this suite. @ 05/11/25 14:25:59.022
• [4.066 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:259
  STEP: Creating a kubernetes client @ 05/11/25 14:25:59.028
  I0511 14:25:59.028315 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename aggregateddiscovery @ 05/11/25 14:25:59.029
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:25:59.038
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:25:59.041
  I0511 14:25:59.047724 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-4043" for this suite. @ 05/11/25 14:25:59.124
• [0.102 seconds]
------------------------------
SSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 05/11/25 14:25:59.13
  I0511 14:25:59.130220 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename container-probe @ 05/11/25 14:25:59.131
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:25:59.142
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:25:59.145
  STEP: Creating pod liveness-8d9a0ee9-18b6-4822-b37f-40b7e06b6442 in namespace container-probe-8382 @ 05/11/25 14:25:59.149
  E0511 14:25:59.978695      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:00.979198      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/11/25 14:26:01.165
  I0511 14:26:01.168633 26 container_probe.go:1748] Initial restart count of pod liveness-8d9a0ee9-18b6-4822-b37f-40b7e06b6442 is 0
  I0511 14:26:01.170719 26 container_probe.go:1758] Get pod liveness-8d9a0ee9-18b6-4822-b37f-40b7e06b6442 in namespace container-probe-8382
  E0511 14:26:01.979848      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:02.979854      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:26:03.176093 26 container_probe.go:1758] Get pod liveness-8d9a0ee9-18b6-4822-b37f-40b7e06b6442 in namespace container-probe-8382
  E0511 14:26:03.980189      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:04.980881      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:26:05.181707 26 container_probe.go:1758] Get pod liveness-8d9a0ee9-18b6-4822-b37f-40b7e06b6442 in namespace container-probe-8382
  E0511 14:26:05.981729      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:06.982199      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:26:07.186912 26 container_probe.go:1758] Get pod liveness-8d9a0ee9-18b6-4822-b37f-40b7e06b6442 in namespace container-probe-8382
  E0511 14:26:07.982662      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:08.983066      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:26:09.192180 26 container_probe.go:1758] Get pod liveness-8d9a0ee9-18b6-4822-b37f-40b7e06b6442 in namespace container-probe-8382
  E0511 14:26:09.983392      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:10.983861      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:26:11.198909 26 container_probe.go:1758] Get pod liveness-8d9a0ee9-18b6-4822-b37f-40b7e06b6442 in namespace container-probe-8382
  E0511 14:26:11.983936      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:12.984341      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:26:13.204833 26 container_probe.go:1758] Get pod liveness-8d9a0ee9-18b6-4822-b37f-40b7e06b6442 in namespace container-probe-8382
  E0511 14:26:13.984560      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:14.985367      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:26:15.209494 26 container_probe.go:1758] Get pod liveness-8d9a0ee9-18b6-4822-b37f-40b7e06b6442 in namespace container-probe-8382
  E0511 14:26:15.985661      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:16.986301      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:26:17.214836 26 container_probe.go:1758] Get pod liveness-8d9a0ee9-18b6-4822-b37f-40b7e06b6442 in namespace container-probe-8382
  E0511 14:26:17.986937      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:18.986811      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:26:19.219923 26 container_probe.go:1758] Get pod liveness-8d9a0ee9-18b6-4822-b37f-40b7e06b6442 in namespace container-probe-8382
  E0511 14:26:19.987173      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:20.987851      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:26:21.226872 26 container_probe.go:1758] Get pod liveness-8d9a0ee9-18b6-4822-b37f-40b7e06b6442 in namespace container-probe-8382
  I0511 14:26:21.226960 26 container_probe.go:1762] Restart count of pod container-probe-8382/liveness-8d9a0ee9-18b6-4822-b37f-40b7e06b6442 is now 1 (20.058282727s elapsed)
  STEP: deleting the pod @ 05/11/25 14:26:21.227
  I0511 14:26:21.239085 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8382" for this suite. @ 05/11/25 14:26:21.241
• [22.115 seconds]
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Serial] [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:388
  STEP: Creating a kubernetes client @ 05/11/25 14:26:21.244
  I0511 14:26:21.245002 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename gc @ 05/11/25 14:26:21.245
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:26:21.253
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:26:21.255
  STEP: create the rc @ 05/11/25 14:26:21.343
  I0511 14:26:21.349669      26 warnings.go:110] "Warning: metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]"
  E0511 14:26:21.987951      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:22.991722      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:23.991876      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:24.991936      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:25.993207      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:26.993717      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the rc @ 05/11/25 14:26:27.354
  STEP: wait for the rc to be deleted @ 05/11/25 14:26:27.361
  E0511 14:26:27.994057      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:28.994576      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:29.995347      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:30.995832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:31.996941      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 05/11/25 14:26:32.368
  E0511 14:26:32.997974      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:33.998411      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:34.998743      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:35.999756      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:37.000199      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:38.000714      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:39.000767      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:40.001624      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:41.002133      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:42.003080      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:43.003793      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:44.003924      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:45.004137      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:46.004950      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:47.005546      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:48.005999      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:49.006771      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:50.007739      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:51.008115      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:52.008784      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:53.009061      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:54.009894      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:55.010227      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:56.010950      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:57.011545      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:58.012111      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:26:59.012784      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:00.013015      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:01.013367      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:02.014124      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/11/25 14:27:02.381
  I0511 14:27:02.477519 26 garbage_collector.go:273] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0511 14:27:02.477556 26 delete.go:95] Deleting pod "simpletest.rc-2jnv5" in namespace "gc-6973"
  I0511 14:27:02.486837 26 delete.go:95] Deleting pod "simpletest.rc-2n4p7" in namespace "gc-6973"
  I0511 14:27:02.498367 26 delete.go:95] Deleting pod "simpletest.rc-2vdc4" in namespace "gc-6973"
  I0511 14:27:02.509691 26 delete.go:95] Deleting pod "simpletest.rc-458cp" in namespace "gc-6973"
  I0511 14:27:02.522912 26 delete.go:95] Deleting pod "simpletest.rc-4dslh" in namespace "gc-6973"
  I0511 14:27:02.539859 26 delete.go:95] Deleting pod "simpletest.rc-4ktm9" in namespace "gc-6973"
  I0511 14:27:02.551639 26 delete.go:95] Deleting pod "simpletest.rc-54cq8" in namespace "gc-6973"
  I0511 14:27:02.563555 26 delete.go:95] Deleting pod "simpletest.rc-5bb49" in namespace "gc-6973"
  I0511 14:27:02.575407 26 delete.go:95] Deleting pod "simpletest.rc-5dbqw" in namespace "gc-6973"
  I0511 14:27:02.586301 26 delete.go:95] Deleting pod "simpletest.rc-5jwjj" in namespace "gc-6973"
  I0511 14:27:02.596175 26 delete.go:95] Deleting pod "simpletest.rc-5tpgx" in namespace "gc-6973"
  I0511 14:27:02.618195 26 delete.go:95] Deleting pod "simpletest.rc-5xbll" in namespace "gc-6973"
  I0511 14:27:02.628366 26 delete.go:95] Deleting pod "simpletest.rc-68xs8" in namespace "gc-6973"
  I0511 14:27:02.638967 26 delete.go:95] Deleting pod "simpletest.rc-6f286" in namespace "gc-6973"
  I0511 14:27:02.656448 26 delete.go:95] Deleting pod "simpletest.rc-6f9rt" in namespace "gc-6973"
  I0511 14:27:02.673417 26 delete.go:95] Deleting pod "simpletest.rc-6jjmb" in namespace "gc-6973"
  I0511 14:27:02.688975 26 delete.go:95] Deleting pod "simpletest.rc-6lqzp" in namespace "gc-6973"
  I0511 14:27:02.701887 26 delete.go:95] Deleting pod "simpletest.rc-6n286" in namespace "gc-6973"
  I0511 14:27:02.715172 26 delete.go:95] Deleting pod "simpletest.rc-6p8zw" in namespace "gc-6973"
  I0511 14:27:02.731858 26 delete.go:95] Deleting pod "simpletest.rc-77s64" in namespace "gc-6973"
  I0511 14:27:02.754790 26 delete.go:95] Deleting pod "simpletest.rc-7cxgq" in namespace "gc-6973"
  I0511 14:27:02.768796 26 delete.go:95] Deleting pod "simpletest.rc-7tw59" in namespace "gc-6973"
  I0511 14:27:02.784314 26 delete.go:95] Deleting pod "simpletest.rc-82856" in namespace "gc-6973"
  I0511 14:27:02.796438 26 delete.go:95] Deleting pod "simpletest.rc-8k98n" in namespace "gc-6973"
  I0511 14:27:02.810723 26 delete.go:95] Deleting pod "simpletest.rc-8wg46" in namespace "gc-6973"
  I0511 14:27:02.832153 26 delete.go:95] Deleting pod "simpletest.rc-95ddm" in namespace "gc-6973"
  I0511 14:27:02.849281 26 delete.go:95] Deleting pod "simpletest.rc-9c4tl" in namespace "gc-6973"
  I0511 14:27:02.862061 26 delete.go:95] Deleting pod "simpletest.rc-9s9dw" in namespace "gc-6973"
  I0511 14:27:02.883852 26 delete.go:95] Deleting pod "simpletest.rc-9tcv5" in namespace "gc-6973"
  I0511 14:27:02.903115 26 delete.go:95] Deleting pod "simpletest.rc-bg57r" in namespace "gc-6973"
  I0511 14:27:02.918656 26 delete.go:95] Deleting pod "simpletest.rc-bmk5d" in namespace "gc-6973"
  I0511 14:27:02.940754 26 delete.go:95] Deleting pod "simpletest.rc-bt47z" in namespace "gc-6973"
  I0511 14:27:02.957652 26 delete.go:95] Deleting pod "simpletest.rc-c6vwm" in namespace "gc-6973"
  I0511 14:27:02.974676 26 delete.go:95] Deleting pod "simpletest.rc-c77pk" in namespace "gc-6973"
  I0511 14:27:02.994624 26 delete.go:95] Deleting pod "simpletest.rc-cgls7" in namespace "gc-6973"
  I0511 14:27:03.008454 26 delete.go:95] Deleting pod "simpletest.rc-cxzk6" in namespace "gc-6973"
  E0511 14:27:03.014844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:27:03.032164 26 delete.go:95] Deleting pod "simpletest.rc-dclqj" in namespace "gc-6973"
  I0511 14:27:03.052340 26 delete.go:95] Deleting pod "simpletest.rc-dffd8" in namespace "gc-6973"
  I0511 14:27:03.074151 26 delete.go:95] Deleting pod "simpletest.rc-dzt46" in namespace "gc-6973"
  I0511 14:27:03.086109 26 delete.go:95] Deleting pod "simpletest.rc-f56xc" in namespace "gc-6973"
  I0511 14:27:03.103981 26 delete.go:95] Deleting pod "simpletest.rc-f66ms" in namespace "gc-6973"
  I0511 14:27:03.130604 26 delete.go:95] Deleting pod "simpletest.rc-fbqfz" in namespace "gc-6973"
  I0511 14:27:03.153029 26 delete.go:95] Deleting pod "simpletest.rc-fcc5g" in namespace "gc-6973"
  I0511 14:27:03.169683 26 delete.go:95] Deleting pod "simpletest.rc-fgh9w" in namespace "gc-6973"
  I0511 14:27:03.188112 26 delete.go:95] Deleting pod "simpletest.rc-fj8v5" in namespace "gc-6973"
  I0511 14:27:03.197859 26 delete.go:95] Deleting pod "simpletest.rc-fpt6f" in namespace "gc-6973"
  I0511 14:27:03.213712 26 delete.go:95] Deleting pod "simpletest.rc-frlv2" in namespace "gc-6973"
  I0511 14:27:03.227434 26 delete.go:95] Deleting pod "simpletest.rc-fsbwc" in namespace "gc-6973"
  I0511 14:27:03.246256 26 delete.go:95] Deleting pod "simpletest.rc-fzf6x" in namespace "gc-6973"
  I0511 14:27:03.263419 26 delete.go:95] Deleting pod "simpletest.rc-g8p69" in namespace "gc-6973"
  I0511 14:27:03.274020 26 delete.go:95] Deleting pod "simpletest.rc-g99j4" in namespace "gc-6973"
  I0511 14:27:03.294665 26 delete.go:95] Deleting pod "simpletest.rc-gb5d6" in namespace "gc-6973"
  I0511 14:27:03.308570 26 delete.go:95] Deleting pod "simpletest.rc-gczcs" in namespace "gc-6973"
  I0511 14:27:03.324164 26 delete.go:95] Deleting pod "simpletest.rc-gkbkf" in namespace "gc-6973"
  I0511 14:27:03.336639 26 delete.go:95] Deleting pod "simpletest.rc-h5xhd" in namespace "gc-6973"
  I0511 14:27:03.356009 26 delete.go:95] Deleting pod "simpletest.rc-hgtgj" in namespace "gc-6973"
  I0511 14:27:03.370210 26 delete.go:95] Deleting pod "simpletest.rc-hj62r" in namespace "gc-6973"
  I0511 14:27:03.383628 26 delete.go:95] Deleting pod "simpletest.rc-hrrlz" in namespace "gc-6973"
  I0511 14:27:03.401674 26 delete.go:95] Deleting pod "simpletest.rc-hvqwn" in namespace "gc-6973"
  I0511 14:27:03.422822 26 delete.go:95] Deleting pod "simpletest.rc-kfcnr" in namespace "gc-6973"
  I0511 14:27:03.436243 26 delete.go:95] Deleting pod "simpletest.rc-kgdrn" in namespace "gc-6973"
  I0511 14:27:03.456907 26 delete.go:95] Deleting pod "simpletest.rc-m22n4" in namespace "gc-6973"
  I0511 14:27:03.472754 26 delete.go:95] Deleting pod "simpletest.rc-m7rsd" in namespace "gc-6973"
  I0511 14:27:03.486741 26 delete.go:95] Deleting pod "simpletest.rc-m8nrg" in namespace "gc-6973"
  I0511 14:27:03.506975 26 delete.go:95] Deleting pod "simpletest.rc-mq828" in namespace "gc-6973"
  I0511 14:27:03.522519 26 delete.go:95] Deleting pod "simpletest.rc-mvn56" in namespace "gc-6973"
  I0511 14:27:03.534826 26 delete.go:95] Deleting pod "simpletest.rc-pdgrb" in namespace "gc-6973"
  I0511 14:27:03.548876 26 delete.go:95] Deleting pod "simpletest.rc-phpxw" in namespace "gc-6973"
  I0511 14:27:03.564683 26 delete.go:95] Deleting pod "simpletest.rc-ppnlk" in namespace "gc-6973"
  I0511 14:27:03.576331 26 delete.go:95] Deleting pod "simpletest.rc-pq598" in namespace "gc-6973"
  I0511 14:27:03.597063 26 delete.go:95] Deleting pod "simpletest.rc-pxrlw" in namespace "gc-6973"
  I0511 14:27:03.635766 26 delete.go:95] Deleting pod "simpletest.rc-q9skm" in namespace "gc-6973"
  I0511 14:27:03.680132 26 delete.go:95] Deleting pod "simpletest.rc-qbzjc" in namespace "gc-6973"
  I0511 14:27:03.729326 26 delete.go:95] Deleting pod "simpletest.rc-qkl7j" in namespace "gc-6973"
  I0511 14:27:03.784657 26 delete.go:95] Deleting pod "simpletest.rc-qkptj" in namespace "gc-6973"
  I0511 14:27:03.832522 26 delete.go:95] Deleting pod "simpletest.rc-qrhx4" in namespace "gc-6973"
  I0511 14:27:03.884442 26 delete.go:95] Deleting pod "simpletest.rc-s6jhl" in namespace "gc-6973"
  I0511 14:27:03.937428 26 delete.go:95] Deleting pod "simpletest.rc-shlvn" in namespace "gc-6973"
  I0511 14:27:03.979051 26 delete.go:95] Deleting pod "simpletest.rc-sj7w5" in namespace "gc-6973"
  E0511 14:27:04.015580      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:27:04.029435 26 delete.go:95] Deleting pod "simpletest.rc-spwrj" in namespace "gc-6973"
  I0511 14:27:04.078313 26 delete.go:95] Deleting pod "simpletest.rc-t5wwr" in namespace "gc-6973"
  I0511 14:27:04.127106 26 delete.go:95] Deleting pod "simpletest.rc-tjjzl" in namespace "gc-6973"
  I0511 14:27:04.178148 26 delete.go:95] Deleting pod "simpletest.rc-tnwvq" in namespace "gc-6973"
  I0511 14:27:04.229174 26 delete.go:95] Deleting pod "simpletest.rc-v4lvj" in namespace "gc-6973"
  I0511 14:27:04.278251 26 delete.go:95] Deleting pod "simpletest.rc-v5cq5" in namespace "gc-6973"
  I0511 14:27:04.328780 26 delete.go:95] Deleting pod "simpletest.rc-v9226" in namespace "gc-6973"
  I0511 14:27:04.382509 26 delete.go:95] Deleting pod "simpletest.rc-vwqhd" in namespace "gc-6973"
  I0511 14:27:04.427777 26 delete.go:95] Deleting pod "simpletest.rc-w2qdj" in namespace "gc-6973"
  I0511 14:27:04.483007 26 delete.go:95] Deleting pod "simpletest.rc-w4t8w" in namespace "gc-6973"
  I0511 14:27:04.529959 26 delete.go:95] Deleting pod "simpletest.rc-w6mhr" in namespace "gc-6973"
  I0511 14:27:04.580210 26 delete.go:95] Deleting pod "simpletest.rc-wbhvk" in namespace "gc-6973"
  I0511 14:27:04.631599 26 delete.go:95] Deleting pod "simpletest.rc-wvps6" in namespace "gc-6973"
  I0511 14:27:04.679099 26 delete.go:95] Deleting pod "simpletest.rc-xl8hk" in namespace "gc-6973"
  I0511 14:27:04.730098 26 delete.go:95] Deleting pod "simpletest.rc-xmc2p" in namespace "gc-6973"
  I0511 14:27:04.779545 26 delete.go:95] Deleting pod "simpletest.rc-xzttk" in namespace "gc-6973"
  I0511 14:27:04.827916 26 delete.go:95] Deleting pod "simpletest.rc-z5pkb" in namespace "gc-6973"
  I0511 14:27:04.880992 26 delete.go:95] Deleting pod "simpletest.rc-z5pxk" in namespace "gc-6973"
  I0511 14:27:04.927828 26 delete.go:95] Deleting pod "simpletest.rc-zcbnl" in namespace "gc-6973"
  I0511 14:27:04.976646 26 delete.go:95] Deleting pod "simpletest.rc-zhbzq" in namespace "gc-6973"
  E0511 14:27:05.015434      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:27:05.031742 26 delete.go:95] Deleting pod "simpletest.rc-ztltc" in namespace "gc-6973"
  I0511 14:27:05.079253 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-6973" for this suite. @ 05/11/25 14:27:05.123
• [43.929 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:429
  STEP: Creating a kubernetes client @ 05/11/25 14:27:05.173
  I0511 14:27:05.173878 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename pv @ 05/11/25 14:27:05.174
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:27:05.182
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:27:05.184
  STEP: Creating initial PV and PVC @ 05/11/25 14:27:05.185
  I0511 14:27:05.185761 26 pv.go:394] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-4204" @ 05/11/25 14:27:05.193
  STEP: Listing PVCs in namespace "pv-4204" @ 05/11/25 14:27:05.195
  STEP: Patching the PV "pv-4204-vknnk" @ 05/11/25 14:27:05.199
  STEP: Patching the PVC "pvc-b6rmp" @ 05/11/25 14:27:05.206
  STEP: Getting PV "pv-4204-vknnk" @ 05/11/25 14:27:05.215
  STEP: Getting PVC "pvc-b6rmp" @ 05/11/25 14:27:05.216
  STEP: Deleting PVC "pvc-b6rmp" @ 05/11/25 14:27:05.219
  STEP: Confirm deletion of PVC "pvc-b6rmp" @ 05/11/25 14:27:05.224
  E0511 14:27:06.015991      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:07.016190      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-4204-vknnk" @ 05/11/25 14:27:07.233
  STEP: Confirm deletion of PV "pv-4204-vknnk" @ 05/11/25 14:27:07.239
  E0511 14:27:08.016842      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:09.017253      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Recreating another PV & PVC @ 05/11/25 14:27:09.248
  I0511 14:27:09.248908 26 pv.go:394] Creating a PV followed by a PVC
  STEP: Updating the PV "pv-4204-btqt8" @ 05/11/25 14:27:09.263
  STEP: Updating the PVC "pvc-g2g5f" @ 05/11/25 14:27:09.287
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-g2g5f=updated" @ 05/11/25 14:27:09.293
  STEP: Deleting PVC "pvc-g2g5f" via DeleteCollection @ 05/11/25 14:27:09.297
  STEP: Confirm deletion of PVC "pvc-g2g5f" @ 05/11/25 14:27:09.3
  E0511 14:27:10.017534      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:11.017706      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-4204-btqt8" via DeleteCollection @ 05/11/25 14:27:11.306
  STEP: Confirm deletion of PV "pv-4204-btqt8" @ 05/11/25 14:27:11.312
  I0511 14:27:11.321497 26 persistent_volumes.go:406] AfterEach: deleting 1 PVCs and 1 PVs...
  I0511 14:27:11.321535 26 pv.go:205] Deleting PersistentVolumeClaim "pvc-g2g5f"
  I0511 14:27:11.323163 26 pv.go:193] Deleting PersistentVolume "pv-4204-btqt8"
  I0511 14:27:11.324686 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-4204" for this suite. @ 05/11/25 14:27:11.327
• [6.156 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 05/11/25 14:27:11.33
  I0511 14:27:11.330273 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 14:27:11.331
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:27:11.338
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:27:11.34
  STEP: Creating projection with secret that has name projected-secret-test-9c92ab03-9303-4ba5-b86b-295edcca8e7c @ 05/11/25 14:27:11.342
  STEP: Creating a pod to test consume secrets @ 05/11/25 14:27:11.344
  E0511 14:27:12.018942      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:13.019417      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:14.020432      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:15.021152      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:27:15.362
  I0511 14:27:15.364772 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-projected-secrets-67a2f8be-229c-4a11-ad6e-53e3ea6f7e9d container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/11/25 14:27:15.371
  I0511 14:27:15.389418 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3454" for this suite. @ 05/11/25 14:27:15.393
• [4.068 seconds]
------------------------------
S
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 05/11/25 14:27:15.398
  I0511 14:27:15.398052 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename events @ 05/11/25 14:27:15.399
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:27:15.409
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:27:15.412
  STEP: Create set of events @ 05/11/25 14:27:15.415
  I0511 14:27:15.420218 26 core_events.go:198] created test-event-1
  I0511 14:27:15.424343 26 core_events.go:198] created test-event-2
  I0511 14:27:15.430413 26 core_events.go:198] created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 05/11/25 14:27:15.43
  STEP: delete collection of events @ 05/11/25 14:27:15.433
  I0511 14:27:15.433076 26 core_events.go:213] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 05/11/25 14:27:15.446
  I0511 14:27:15.446681 26 core_events.go:230] requesting list of events to confirm quantity
  I0511 14:27:15.449394 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-1481" for this suite. @ 05/11/25 14:27:15.494
• [0.101 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:124
  STEP: Creating a kubernetes client @ 05/11/25 14:27:15.499
  I0511 14:27:15.499627 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename configmap @ 05/11/25 14:27:15.5
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:27:15.51
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:27:15.513
  STEP: Creating configMap with name configmap-test-upd-d001a325-aead-4ff8-b15d-52b494caa4f7 @ 05/11/25 14:27:15.595
  STEP: Creating the pod @ 05/11/25 14:27:15.599
  E0511 14:27:16.021693      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:17.021942      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Updating configmap configmap-test-upd-d001a325-aead-4ff8-b15d-52b494caa4f7 @ 05/11/25 14:27:17.623
  STEP: waiting to observe update in volume @ 05/11/25 14:27:17.629
  E0511 14:27:18.022513      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:19.022822      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:20.023027      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:21.023924      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:22.023956      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:23.025279      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:24.026190      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:25.026874      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:26.026954      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:27.027447      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:28.028292      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:29.029018      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:30.029092      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:31.029859      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:32.030280      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:33.030536      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:34.031619      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:35.032282      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:36.033216      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:37.033555      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:38.034451      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:39.034957      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:40.035966      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:41.036454      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:42.036709      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:43.036812      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:44.037761      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:45.038005      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:46.038448      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:47.039134      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:48.039526      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:49.040084      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:50.040829      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:51.041391      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:52.041591      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:53.042006      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:54.042191      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:55.042936      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:56.043680      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:57.044261      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:58.045349      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:27:59.046018      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:00.046840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:01.047322      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:02.047773      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:03.048050      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:04.048687      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:05.049021      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:06.049800      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:07.049851      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:08.050953      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:09.051349      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:10.051623      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:11.052563      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:12.053361      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:13.053442      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:14.053576      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:15.053775      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:16.053900      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:17.054436      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:18.055005      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:19.055508      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:20.056245      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:21.056671      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:22.057180      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:23.057491      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:24.058156      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:25.058311      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:26.059032      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:27.059363      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:28.059495      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:29.060130      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:30.060848      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:31.061693      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:32.062328      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:33.062427      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:34.062918      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:35.063243      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:36.063934      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:37.064538      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:38.064891      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:39.065104      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:40.065910      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:41.066837      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:42.067380      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:43.067624      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:44.068278      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:28:44.097330 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-191" for this suite. @ 05/11/25 14:28:44.101
• [88.608 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:235
  STEP: Creating a kubernetes client @ 05/11/25 14:28:44.108
  I0511 14:28:44.108591 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 14:28:44.109
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:28:44.12
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:28:44.123
  STEP: Setting up server cert @ 05/11/25 14:28:44.14
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 14:28:44.561
  STEP: Deploying the webhook pod @ 05/11/25 14:28:44.564
  STEP: Wait for the deployment to be ready @ 05/11/25 14:28:44.571
  I0511 14:28:44.576225 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0511 14:28:45.068738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:46.069165      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/11/25 14:28:46.585
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 14:28:46.599
  E0511 14:28:47.069265      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:28:47.600646 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 05/11/25 14:28:47.605
  STEP: create a namespace for the webhook @ 05/11/25 14:28:47.622
  STEP: create a configmap should be unconditionally rejected by the webhook @ 05/11/25 14:28:47.633
  I0511 14:28:47.671808 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8717" for this suite. @ 05/11/25 14:28:47.675
  STEP: Destroying namespace "webhook-markers-7138" for this suite. @ 05/11/25 14:28:47.678
  STEP: Destroying namespace "fail-closed-namespace-5788" for this suite. @ 05/11/25 14:28:47.681
• [3.577 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:163
  STEP: Creating a kubernetes client @ 05/11/25 14:28:47.686
  I0511 14:28:47.686313 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 14:28:47.687
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:28:47.694
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:28:47.696
  STEP: Creating the pod @ 05/11/25 14:28:47.697
  E0511 14:28:48.069312      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:49.069967      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:50.070782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:28:50.238823 26 pod_client.go:173] Successfully updated pod "annotationupdate7eb8391f-3e56-44bc-b7c0-9e8a543ac540"
  E0511 14:28:51.071356      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:52.071979      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:53.072792      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:54.073356      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:28:54.266873 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-498" for this suite. @ 05/11/25 14:28:54.269
• [6.590 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:115
  STEP: Creating a kubernetes client @ 05/11/25 14:28:54.28
  I0511 14:28:54.280702 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename field-validation @ 05/11/25 14:28:54.281
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:28:54.289
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:28:54.291
  STEP: apply creating a deployment @ 05/11/25 14:28:54.294
  I0511 14:28:54.301313 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8617" for this suite. @ 05/11/25 14:28:54.37
• [0.096 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3630
  STEP: Creating a kubernetes client @ 05/11/25 14:28:54.376
  I0511 14:28:54.376496 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename services @ 05/11/25 14:28:54.377
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:28:54.385
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:28:54.387
  STEP: creating a collection of services @ 05/11/25 14:28:54.389
  I0511 14:28:54.389435 26 service.go:3666] Creating e2e-svc-a-9pdk8
  I0511 14:28:54.401698 26 service.go:3666] Creating e2e-svc-b-xrrw7
  I0511 14:28:54.415391 26 service.go:3666] Creating e2e-svc-c-69x2g
  STEP: deleting service collection @ 05/11/25 14:28:54.434
  I0511 14:28:54.469907 26 service.go:3701] Collection of services has been deleted
  I0511 14:28:54.470141 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3600" for this suite. @ 05/11/25 14:28:54.472
• [0.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:353
  STEP: Creating a kubernetes client @ 05/11/25 14:28:54.476
  I0511 14:28:54.476540 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename dns @ 05/11/25 14:28:54.477
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:28:54.486
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:28:54.489
  STEP: Creating a test externalName service @ 05/11/25 14:28:54.491
  STEP: Running these commands on agnhost: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4673.svc.cluster.local CNAME > /results/agnhost_udp@dns-test-service-3.dns-4673.svc.cluster.local; sleep 1; done
   @ 05/11/25 14:28:54.494
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4673.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4673.svc.cluster.local; sleep 1; done
   @ 05/11/25 14:28:54.494
  STEP: creating a pod to probe DNS @ 05/11/25 14:28:54.494
  STEP: submitting the pod to kubernetes @ 05/11/25 14:28:54.494
  E0511 14:28:55.073291      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:56.073645      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/11/25 14:28:56.507
  STEP: looking for the results for each expected name from probers @ 05/11/25 14:28:56.51
  I0511 14:28:56.516260 26 dns_common.go:571] DNS probes using dns-test-3ce5e77f-0d53-4c13-bc37-13b973539a79 succeeded

  STEP: changing the externalName to bar.example.com @ 05/11/25 14:28:56.516
  STEP: Running these commands on agnhost: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4673.svc.cluster.local CNAME > /results/agnhost_udp@dns-test-service-3.dns-4673.svc.cluster.local; sleep 1; done
   @ 05/11/25 14:28:56.523
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4673.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4673.svc.cluster.local; sleep 1; done
   @ 05/11/25 14:28:56.523
  STEP: creating a second pod to probe DNS @ 05/11/25 14:28:56.523
  STEP: submitting the pod to kubernetes @ 05/11/25 14:28:56.523
  E0511 14:28:57.074590      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:28:58.075057      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/11/25 14:28:58.54
  STEP: looking for the results for each expected name from probers @ 05/11/25 14:28:58.543
  I0511 14:28:58.550685 26 dns_common.go:571] DNS probes using dns-test-427cc387-8517-450f-bb40-e2116ec90dec succeeded

  STEP: changing the service to type=ClusterIP @ 05/11/25 14:28:58.55
  I0511 14:28:58.570386      26 warnings.go:110] "Warning: spec.externalName is ignored when spec.type is not \"ExternalName\""
  STEP: Running these commands on agnhost: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4673.svc.cluster.local A > /results/agnhost_udp@dns-test-service-3.dns-4673.svc.cluster.local; sleep 1; done
   @ 05/11/25 14:28:58.57
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4673.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-4673.svc.cluster.local; sleep 1; done
   @ 05/11/25 14:28:58.57
  STEP: creating a third pod to probe DNS @ 05/11/25 14:28:58.57
  STEP: submitting the pod to kubernetes @ 05/11/25 14:28:58.574
  E0511 14:28:59.075482      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:00.075775      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/11/25 14:29:00.589
  STEP: looking for the results for each expected name from probers @ 05/11/25 14:29:00.592
  I0511 14:29:00.598608 26 dns_common.go:571] DNS probes using dns-test-d9dd7ca5-7719-459c-ab36-3158a7b2ae89 succeeded

  STEP: deleting the pod @ 05/11/25 14:29:00.598
  STEP: deleting the pod @ 05/11/25 14:29:00.609
  STEP: deleting the pod @ 05/11/25 14:29:00.623
  STEP: deleting the test externalName service @ 05/11/25 14:29:00.638
  I0511 14:29:00.662158 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-4673" for this suite. @ 05/11/25 14:29:00.665
• [6.194 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 05/11/25 14:29:00.67
  I0511 14:29:00.670797 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename secrets @ 05/11/25 14:29:00.671
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:29:00.678
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:29:00.68
  STEP: Creating secret with name secret-test-5ffee79e-0309-4fc7-a18a-cb6789208004 @ 05/11/25 14:29:00.682
  STEP: Creating a pod to test consume secrets @ 05/11/25 14:29:00.687
  E0511 14:29:01.076736      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:02.077015      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:29:02.699
  I0511 14:29:02.701126 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-secrets-9e9f041a-ee84-4af7-9f28-1b7a9622c8a0 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/11/25 14:29:02.707
  I0511 14:29:02.719828 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-157" for this suite. @ 05/11/25 14:29:02.721
• [2.054 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1426
  STEP: Creating a kubernetes client @ 05/11/25 14:29:02.725
  I0511 14:29:02.725814 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename services @ 05/11/25 14:29:02.726
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:29:02.734
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:29:02.736
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-6890 @ 05/11/25 14:29:02.738
  STEP: changing the ExternalName service to type=NodePort @ 05/11/25 14:29:02.74
  I0511 14:29:02.766404 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0511 14:29:03.077700      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:04.078238      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:29:04.772050 26 resource.go:361] Creating new exec pod
  E0511 14:29:05.078885      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:06.079455      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:29:06.791134 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-6890 exec execpodw9l8h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0511 14:29:06.884746 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service (10.102.0.172) 80 port [tcp/http] succeeded!\n"
  I0511 14:29:06.884788 26 builder.go:147] stdout: "externalname-service-56b5774759-49tpp"
  I0511 14:29:06.884873 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-6890 exec execpodw9l8h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.102.0.172 80'
  I0511 14:29:06.992145 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.102.0.172 80\nConnection to 10.102.0.172 80 port [tcp/http] succeeded!\n"
  I0511 14:29:06.992199 26 builder.go:147] stdout: "externalname-service-56b5774759-9gg2w"
  I0511 14:29:06.992298 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-6890 exec execpodw9l8h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.49.2 32484'
  E0511 14:29:07.079828      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:29:07.093731 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.49.2 32484\nConnection to 192.168.49.2 32484 port [tcp/*] succeeded!\n"
  I0511 14:29:07.093778 26 builder.go:147] stdout: "externalname-service-56b5774759-49tpp"
  I0511 14:29:07.093880 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-6890 exec execpodw9l8h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.49.3 32484'
  I0511 14:29:07.191544 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.49.3 32484\nConnection to 192.168.49.3 32484 port [tcp/*] succeeded!\n"
  I0511 14:29:07.191606 26 builder.go:147] stdout: "externalname-service-56b5774759-49tpp"
  I0511 14:29:07.191723 26 service.go:1435] Cleaning up the ExternalName to NodePort test service
  I0511 14:29:07.211862 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6890" for this suite. @ 05/11/25 14:29:07.213
• [4.491 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:255
  STEP: Creating a kubernetes client @ 05/11/25 14:29:07.217
  I0511 14:29:07.217454 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename namespaces @ 05/11/25 14:29:07.218
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:29:07.228
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:29:07.229
  STEP: Creating a test namespace @ 05/11/25 14:29:07.231
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:29:07.238
  STEP: Creating a service in the namespace @ 05/11/25 14:29:07.239
  STEP: Deleting the namespace @ 05/11/25 14:29:07.251
  STEP: Waiting for the namespace to be removed. @ 05/11/25 14:29:07.256
  E0511 14:29:08.080747      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:09.080884      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:10.081932      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:11.082155      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:12.082837      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:13.083722      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 05/11/25 14:29:13.261
  STEP: Verifying there is no service in the namespace @ 05/11/25 14:29:13.272
  I0511 14:29:13.275200 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-5714" for this suite. @ 05/11/25 14:29:13.278
  STEP: Destroying namespace "nsdeletetest-1879" for this suite. @ 05/11/25 14:29:13.283
  I0511 14:29:13.286144 26 framework.go:370] Namespace nsdeletetest-1879 was already deleted
  STEP: Destroying namespace "nsdeletetest-1414" for this suite. @ 05/11/25 14:29:13.286
• [6.073 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:208
  STEP: Creating a kubernetes client @ 05/11/25 14:29:13.291
  I0511 14:29:13.291148 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename downward-api @ 05/11/25 14:29:13.292
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:29:13.301
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:29:13.303
  STEP: Creating a pod to test downward API volume plugin @ 05/11/25 14:29:13.305
  E0511 14:29:14.084029      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:15.085182      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:16.085139      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:17.085755      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:29:17.324
  I0511 14:29:17.326763 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-a1411b23-b49d-465b-b1a6-79dd056d92ea container client-container: <nil>
  STEP: delete the pod @ 05/11/25 14:29:17.333
  I0511 14:29:17.352414 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1563" for this suite. @ 05/11/25 14:29:17.355
• [4.069 seconds]
------------------------------
S
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:245
  STEP: Creating a kubernetes client @ 05/11/25 14:29:17.36
  I0511 14:29:17.360748 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename downward-api @ 05/11/25 14:29:17.361
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:29:17.371
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:29:17.374
  STEP: Creating a pod to test downward api env vars @ 05/11/25 14:29:17.376
  E0511 14:29:18.086120      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:19.086664      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:20.087359      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:21.087807      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:29:21.395
  I0511 14:29:21.398509 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downward-api-6d68dc88-59a7-47c5-ace2-83d1c4647705 container dapi-container: <nil>
  STEP: delete the pod @ 05/11/25 14:29:21.405
  I0511 14:29:21.422532 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-334" for this suite. @ 05/11/25 14:29:21.427
• [4.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:166
  STEP: Creating a kubernetes client @ 05/11/25 14:29:21.433
  I0511 14:29:21.433257 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename pods @ 05/11/25 14:29:21.434
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:29:21.443
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:29:21.445
  STEP: creating the pod @ 05/11/25 14:29:21.448
  STEP: submitting the pod to kubernetes @ 05/11/25 14:29:21.448
  STEP: verifying QOS class is set on the pod @ 05/11/25 14:29:21.457
  I0511 14:29:21.460549 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2413" for this suite. @ 05/11/25 14:29:21.528
• [0.101 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:407
  STEP: Creating a kubernetes client @ 05/11/25 14:29:21.533
  I0511 14:29:21.533924 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename job @ 05/11/25 14:29:21.534
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:29:21.546
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:29:21.548
  STEP: Creating Indexed job @ 05/11/25 14:29:21.552
  STEP: Ensuring job reaches completions @ 05/11/25 14:29:21.558
  E0511 14:29:22.088862      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:23.089092      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:24.089890      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:25.090833      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:26.091149      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:27.091934      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:28.092293      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:29.092885      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 05/11/25 14:29:29.583
  I0511 14:29:29.586997 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-716" for this suite. @ 05/11/25 14:29:29.59
• [8.063 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:99
  STEP: Creating a kubernetes client @ 05/11/25 14:29:29.597
  I0511 14:29:29.597654 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename aggregator @ 05/11/25 14:29:29.598
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:29:29.609
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:29:29.613
  I0511 14:29:29.616047 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Registering the sample API server. @ 05/11/25 14:29:29.616
  I0511 14:29:29.784889 26 helpers.go:184] Found ClusterRoles; assuming RBAC is enabled.
  I0511 14:29:29.802305 26 deployment.go:223] deployment "sample-apiserver-deployment" doesn't have the required revision set
  E0511 14:29:30.093799      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:31.094213      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:29:31.843358 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:29:32.094592      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:33.094646      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:29:33.847901 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:29:34.095319      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:35.096432      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:29:35.846791 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:29:36.097244      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:37.097752      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:29:37.847380 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:29:38.098680      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:39.098781      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:29:39.848527 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:29:40.099894      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:41.100869      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:29:41.848072 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:29:42.101641      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:43.101774      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:29:43.847825 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:29:44.102063      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:45.102288      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:29:45.847430 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:29:46.103372      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:47.103524      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:29:47.847114 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:29:48.104646      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:49.104694      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:29:49.847319 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:29:50.105992      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:51.106662      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:29:51.851194 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:29:52.107418      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:53.108262      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:29:53.848755 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:29:54.109166      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:55.109524      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:29:55.847490 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:29:56.109756      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:57.110297      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:29:57.848272 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:29:58.110745      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:29:59.110757      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:29:59.847246 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:00.111755      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:01.112821      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:01.846633 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:02.112941      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:03.113231      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:03.847180 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:04.113389      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:05.113498      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:05.847818 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:06.114168      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:07.114632      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:07.848082 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:08.115540      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:09.115731      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:09.848256 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:10.116703      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:11.116817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:11.846763 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:12.117293      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:13.117878      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:13.848982 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:14.118522      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:15.119060      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:15.848430 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:16.119642      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:17.119870      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:17.848575 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:18.120008      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:19.120663      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:19.848570 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:20.120777      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:21.121331      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:21.848101 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:22.121405      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:23.121749      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:23.847482 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:24.121913      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:25.122925      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:25.849134 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:26.123705      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:27.123963      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:27.848983 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:28.124260      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:29.124901      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:29.848534 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:30.124945      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:31.125642      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:31.848746 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:32.125695      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:33.126102      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:33.847744 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:34.126231      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:35.126480      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:35.848056 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:36.127760      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:37.128501      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:37.849267 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:38.128792      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:39.129190      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:39.849763 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:40.130034      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:41.130526      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:41.849199 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:42.130604      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:43.131042      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:43.848612 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:44.131637      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:45.132037      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:45.848096 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:46.132597      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:47.132931      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:47.848541 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:48.133977      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:49.134487      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:49.849931 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:50.135727      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:51.136317      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:51.848553 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:52.137069      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:53.137611      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:53.848938 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:54.138403      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:55.138625      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:55.847800 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:56.139035      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:57.139423      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:57.849389 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:30:58.139655      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:30:59.139921      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:30:59.848085 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:00.140804      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:01.141342      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:01.847795 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:02.142249      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:03.143120      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:03.847683 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:04.144101      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:05.144516      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:05.847715 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:06.145141      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:07.145572      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:07.848268 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:08.145744      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:09.146168      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:09.848573 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:10.146272      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:11.146836      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:11.848249 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:12.147698      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:13.147883      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:13.847854 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:14.148289      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:15.149475      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:15.848392 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:16.149341      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:17.149852      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:17.848478 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:18.150048      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:19.150570      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:19.848697 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:20.150841      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:21.151268      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:21.847862 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:22.152030      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:23.152164      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:23.848536 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:24.152749      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:25.153319      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:25.848382 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:26.153640      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:27.153698      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:27.849517 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:28.153915      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:29.154890      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:29.848565 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:30.155791      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:31.156081      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:31.848600 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:32.156844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:33.157346      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:33.847878 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:34.158392      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:35.158748      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:35.848411 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:36.158885      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:37.159848      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:37.848577 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:38.160041      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:39.160675      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:39.848267 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:40.161825      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:41.162362      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:41.848982 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:42.163528      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:43.164053      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:43.848583 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:44.164937      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:45.164988      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:45.848627 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:46.165056      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:47.165747      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:47.849054 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:48.166413      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:49.167085      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:49.846962 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:50.167323      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:51.167743      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:51.848839 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:52.168381      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:53.168648      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:53.849533 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:54.168966      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:55.169374      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:55.847993 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:56.170348      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:57.170852      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:57.848163 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:31:58.171968      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:31:59.172491      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:31:59.846904 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:00.173820      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:01.174543      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:01.849195 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:02.174670      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:03.174845      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:03.848640 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:04.175048      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:05.175515      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:05.848306 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:06.175818      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:07.176094      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:07.848389 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:08.176955      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:09.177268      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:09.847447 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:10.178048      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:11.178742      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:11.849653 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:12.179061      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:13.179615      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:13.849241 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:14.180664      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:15.180817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:15.848651 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:16.181087      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:17.181692      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:17.848715 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:18.182073      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:19.182997      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:19.847660 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:20.184051      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:21.184398      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:21.849582 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:22.185066      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:23.185700      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:23.849039 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:24.186360      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:25.187169      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:25.847565 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:26.188044      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:27.188561      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:27.849782 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:28.188819      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:29.189266      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:29.846984 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:30.189525      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:31.189830      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:31.848900 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:32.189966      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:33.190771      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:33.847751 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:34.191034      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:35.191833      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:35.847042 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:36.192886      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:37.193404      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:37.848202 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:38.193743      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:39.194238      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:39.848963 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:40.194328      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:41.194855      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:41.848226 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:42.195920      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:43.196505      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:43.848520 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:44.197115      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:45.197359      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:45.848052 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:46.197622      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:47.198036      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:47.848641 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:48.198907      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:49.199336      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:49.849743 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:50.199799      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:51.200016      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:51.848518 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:52.200809      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:53.201200      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:53.848146 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:54.201601      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:55.202003      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:55.847611 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:56.202789      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:57.203224      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:57.847664 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:32:58.204043      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:32:59.204419      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:32:59.848295 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:33:00.204798      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:01.204983      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:33:01.848479 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:33:02.205802      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:03.206169      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:33:03.848858 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:33:04.206853      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:05.207332      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:33:05.847452 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:33:06.208030      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:07.208659      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:33:07.848196 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:33:08.208741      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:09.209318      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:33:09.848560 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:33:10.210311      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:11.210791      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:33:11.849825 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:33:12.210796      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:13.211254      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:33:13.848437 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:33:14.211697      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:15.212693      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:33:15.848087 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:33:16.212617      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:17.213069      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:33:17.847361 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:33:18.213888      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:19.214334      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:33:19.849134 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:33:20.214595      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:21.215170      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:33:21.847790 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:33:22.215290      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:23.215735      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:33:23.848931 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:33:24.216605      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:25.216689      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:33:25.848917 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:33:26.217374      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:27.217708      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:33:27.848778 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:33:28.218285      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:29.218832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:33:29.849251 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:33:30.219766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:31.220045      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:33:31.848242 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), LastTransitionTime:time.Date(2025, time.May, 11, 14, 29, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6fc8d58968\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0511 14:33:32.220757      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:33.221857      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:33:33.969217 26 aggregator.go:756] Waited 112.837576ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 05/11/25 14:33:34.009
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 05/11/25 14:33:34.015
  STEP: List APIServices @ 05/11/25 14:33:34.019
  I0511 14:33:34.023097 26 aggregator.go:557] Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 05/11/25 14:33:34.023
  I0511 14:33:34.030629 26 aggregator.go:582] APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 05/11/25 14:33:34.03
  I0511 14:33:34.036730 26 aggregator.go:608] updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2025, time.May, 11, 14, 33, 33, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 05/11/25 14:33:34.036
  I0511 14:33:34.038917 26 aggregator.go:626] Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2025-05-11 14:33:33 +0000 UTC Passed all checks passed}
  I0511 14:33:34.038948 26 aggregator.go:622] Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0511 14:33:34.038959 26 aggregator.go:632] Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 05/11/25 14:33:34.038
  I0511 14:33:34.044322 26 aggregator.go:648] Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-476280051" @ 05/11/25 14:33:34.044
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 05/11/25 14:33:34.051
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 05/11/25 14:33:34.055
  STEP: Patch APIService Status @ 05/11/25 14:33:34.057
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 05/11/25 14:33:34.061
  I0511 14:33:34.064020 26 aggregator.go:726] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2025-05-11 14:33:33 +0000 UTC Passed all checks passed}
  I0511 14:33:34.064060 26 aggregator.go:726] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0511 14:33:34.064076 26 aggregator.go:722] Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  I0511 14:33:34.064092 26 aggregator.go:732] Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 05/11/25 14:33:34.064
  STEP: Confirm that the generated APIService has been deleted @ 05/11/25 14:33:34.069
  I0511 14:33:34.069217 26 aggregator.go:793] Requesting list of APIServices to confirm quantity
  I0511 14:33:34.070588 26 aggregator.go:803] Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  I0511 14:33:34.070612 26 aggregator.go:745] APIService v1alpha1.wardle.example.com has been deleted.
  I0511 14:33:34.125591 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-5731" for this suite. @ 05/11/25 14:33:34.127
• [244.533 seconds]
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1081
  STEP: Creating a kubernetes client @ 05/11/25 14:33:34.13
  I0511 14:33:34.130351 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubectl @ 05/11/25 14:33:34.13
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:33:34.139
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:33:34.14
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/11/25 14:33:34.142
  I0511 14:33:34.142288 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-679 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I0511 14:33:34.180705 26 builder.go:146] stderr: ""
  I0511 14:33:34.180739 26 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 05/11/25 14:33:34.18
  I0511 14:33:34.180805 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-679 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.36.1-1"}]}} --dry-run=server'
  I0511 14:33:34.220648 26 builder.go:146] stderr: ""
  I0511 14:33:34.220686 26 builder.go:147] stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/11/25 14:33:34.22
  E0511 14:33:34.222087      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:33:34.222176 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-679 delete pods e2e-test-httpd-pod'
  E0511 14:33:35.222974      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:33:35.815494 26 builder.go:146] stderr: ""
  I0511 14:33:35.815532 26 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0511 14:33:35.815679 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-679" for this suite. @ 05/11/25 14:33:35.818
• [1.694 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 05/11/25 14:33:35.824
  I0511 14:33:35.824443 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename secrets @ 05/11/25 14:33:35.825
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:33:35.83
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:33:35.833
  STEP: Creating secret with name secret-test-84d33411-b889-4608-b094-84752809fb4c @ 05/11/25 14:33:35.835
  STEP: Creating a pod to test consume secrets @ 05/11/25 14:33:35.839
  E0511 14:33:36.223115      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:37.223358      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:38.224389      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:39.224681      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:33:39.857
  I0511 14:33:39.859905 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-secrets-43cbff15-313b-40a3-905b-cb050a8879df container secret-volume-test: <nil>
  STEP: delete the pod @ 05/11/25 14:33:39.874
  I0511 14:33:39.887582 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8764" for this suite. @ 05/11/25 14:33:39.89
• [4.070 seconds]
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:54
  STEP: Creating a kubernetes client @ 05/11/25 14:33:39.894
  I0511 14:33:39.894753 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 14:33:39.895
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:33:39.903
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:33:39.905
  STEP: Creating a pod to test downward API volume plugin @ 05/11/25 14:33:39.907
  E0511 14:33:40.224911      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:41.225520      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:42.226048      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:43.226608      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:33:43.924
  I0511 14:33:43.926681 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-e67773d9-4714-4945-9482-db3525f39fe8 container client-container: <nil>
  STEP: delete the pod @ 05/11/25 14:33:43.933
  I0511 14:33:43.948928 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1077" for this suite. @ 05/11/25 14:33:43.952
• [4.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 05/11/25 14:33:43.959
  I0511 14:33:43.959395 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename sysctl @ 05/11/25 14:33:43.96
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:33:43.972
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:33:43.975
  STEP: Creating a pod with one valid and two invalid sysctls @ 05/11/25 14:33:43.977
  I0511 14:33:43.981748 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-9265" for this suite. @ 05/11/25 14:33:44.052
• [0.097 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:693
  STEP: Creating a kubernetes client @ 05/11/25 14:33:44.057
  I0511 14:33:44.057062 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename security-context-test @ 05/11/25 14:33:44.058
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:33:44.066
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:33:44.068
  E0511 14:33:44.227550      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:45.227924      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:46.228249      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:47.228882      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:48.228840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:49.229732      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:50.230064      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:51.230840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:52.231004      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:53.231708      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:54.232448      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:55.232743      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:56.233113      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:57.233653      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:58.234314      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:33:59.234996      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:00.236062      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:01.236547      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:02.237045      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:03.237688      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:04.238447      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:05.238766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:06.239556      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:07.239803      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:08.240523      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:09.240984      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:10.241942      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:11.242782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:12.243555      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:13.243967      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:14.244857      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:15.245142      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:16.245818      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:17.246574      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:18.247004      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:19.247614      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:20.248117      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:21.248524      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:22.248549      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:23.249072      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:24.249070      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:25.249336      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:26.249864      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:27.250789      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:28.251113      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:29.251730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:34:30.212349 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-1142" for this suite. @ 05/11/25 14:34:30.215
• [46.165 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:678
  STEP: Creating a kubernetes client @ 05/11/25 14:34:30.222
  I0511 14:34:30.222395 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename validating-admission-policy @ 05/11/25 14:34:30.223
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:34:30.234
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:34:30.238
  STEP: getting /apis @ 05/11/25 14:34:30.246
  STEP: getting /apis/admissionregistration.k8s.io @ 05/11/25 14:34:30.251
  E0511 14:34:30.252351      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 05/11/25 14:34:30.252
  STEP: creating @ 05/11/25 14:34:30.253
  STEP: getting @ 05/11/25 14:34:30.266
  STEP: listing @ 05/11/25 14:34:30.268
  STEP: watching @ 05/11/25 14:34:30.271
  I0511 14:34:30.271176 26 validatingadmissionpolicy.go:773] starting watch
  STEP: patching @ 05/11/25 14:34:30.272
  STEP: updating @ 05/11/25 14:34:30.275
  I0511 14:34:30.281630 26 validatingadmissionpolicy.go:801] waiting for watch events with expected annotations
  STEP: deleting @ 05/11/25 14:34:30.281
  STEP: deleting a collection @ 05/11/25 14:34:30.291
  I0511 14:34:30.305161 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-969" for this suite. @ 05/11/25 14:34:30.317
• [0.104 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 05/11/25 14:34:30.326
  I0511 14:34:30.326866 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename subjectreview @ 05/11/25 14:34:30.327
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:34:30.338
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:34:30.34
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-6246" @ 05/11/25 14:34:30.342
  I0511 14:34:30.346162 26 subjectreviews.go:66] saUsername: "system:serviceaccount:subjectreview-6246:e2e"
  I0511 14:34:30.346213 26 subjectreviews.go:69] saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-6246"}
  I0511 14:34:30.346230 26 subjectreviews.go:71] saUID: "e0ac7e77-9bf4-4580-aef5-9a8a1ff1c948"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-6246:e2e" @ 05/11/25 14:34:30.346
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-6246:e2e" @ 05/11/25 14:34:30.346
  I0511 14:34:30.348740 26 subjectreviews.go:102] sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-6246:e2e" api 'list' configmaps in "subjectreview-6246" namespace @ 05/11/25 14:34:30.348
  I0511 14:34:30.350294 26 subjectreviews.go:121] SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-6246:e2e" @ 05/11/25 14:34:30.35
  I0511 14:34:30.352437 26 subjectreviews.go:144] lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  I0511 14:34:30.352476 26 subjectreviews.go:150] LocalSubjectAccessReview has been verified
  I0511 14:34:30.352606 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-6246" for this suite. @ 05/11/25 14:34:30.418
• [0.101 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 05/11/25 14:34:30.428
  I0511 14:34:30.428389 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename pod-network-test @ 05/11/25 14:34:30.429
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:34:30.438
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:34:30.442
  STEP: Performing setup for networking test in namespace pod-network-test-5145 @ 05/11/25 14:34:30.445
  STEP: creating a selector @ 05/11/25 14:34:30.445
  STEP: Creating the service pods in kubernetes @ 05/11/25 14:34:30.445
  I0511 14:34:30.445101 26 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0511 14:34:31.253570      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:32.254046      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:33.254387      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:34.254851      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:35.255743      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:36.256157      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:37.256918      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:38.257823      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:39.258585      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:40.258771      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:41.259525      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:42.259921      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/11/25 14:34:42.57
  E0511 14:34:43.260906      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:44.261540      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:34:44.597098 26 utils.go:802] Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  I0511 14:34:44.597148 26 utils.go:495] Going to poll 10.244.0.108 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  I0511 14:34:44.599431 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.0.108 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5145 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 14:34:44.599482 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 14:34:44.599549 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5145/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.0.108+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&stderr=true&stdout=true)
  E0511 14:34:45.261750      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:34:45.672664 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 14:34:45.672742 26 utils.go:512] Found all 1 expected endpoints: [netserver-0]
  I0511 14:34:45.672771 26 utils.go:495] Going to poll 10.244.1.26 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  I0511 14:34:45.675930 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.26 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5145 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 14:34:45.675975 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 14:34:45.676056 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5145/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.1.26+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&stderr=true&stdout=true)
  E0511 14:34:46.262783      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:34:46.743600 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 14:34:46.743691 26 utils.go:512] Found all 1 expected endpoints: [netserver-1]
  I0511 14:34:46.743854 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-5145" for this suite. @ 05/11/25 14:34:46.747
• [16.326 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:402
  STEP: Creating a kubernetes client @ 05/11/25 14:34:46.754
  I0511 14:34:46.754981 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename resourcequota @ 05/11/25 14:34:46.756
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:34:46.769
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:34:46.772
  STEP: Counting existing ResourceQuota @ 05/11/25 14:34:46.775
  E0511 14:34:47.263767      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:48.264194      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:49.264400      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:50.264821      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:51.265286      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/11/25 14:34:51.779
  STEP: Ensuring resource quota status is calculated @ 05/11/25 14:34:51.787
  E0511 14:34:52.266099      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:53.266737      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 05/11/25 14:34:53.792
  STEP: Ensuring resource quota status captures replication controller creation @ 05/11/25 14:34:53.804
  E0511 14:34:54.267092      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:55.267600      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 05/11/25 14:34:55.812
  STEP: Ensuring resource quota status released usage @ 05/11/25 14:34:55.817
  E0511 14:34:56.267663      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:34:57.268306      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:34:57.822970 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2548" for this suite. @ 05/11/25 14:34:57.826
• [11.078 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:77
  STEP: Creating a kubernetes client @ 05/11/25 14:34:57.833
  I0511 14:34:57.833594 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename validating-admission-policy @ 05/11/25 14:34:57.834
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:34:57.844
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:34:57.848
  STEP: creating the policy @ 05/11/25 14:34:57.857
  STEP: waiting until the marker is denied @ 05/11/25 14:34:57.867
  E0511 14:34:58.268713      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: testing a replicated Deployment to be allowed @ 05/11/25 14:34:58.477
  STEP: testing a non-replicated ReplicaSet not to be denied @ 05/11/25 14:34:58.489
  I0511 14:34:58.532104 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-2225" for this suite. @ 05/11/25 14:34:58.535
• [0.707 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:373
  STEP: Creating a kubernetes client @ 05/11/25 14:34:58.54
  I0511 14:34:58.540695 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename namespaces @ 05/11/25 14:34:58.541
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:34:58.548
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:34:58.55
  STEP: Updating Namespace "namespaces-1919" @ 05/11/25 14:34:58.551
  I0511 14:34:58.555440 26 namespace.go:390] Namespace "namespaces-1919" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"01c2fc39-d9fb-41d9-b9dd-699f93ee27a7", "kubernetes.io/metadata.name":"namespaces-1919", "namespaces-1919":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  I0511 14:34:58.555564 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1919" for this suite. @ 05/11/25 14:34:58.636
• [0.101 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 05/11/25 14:34:58.642
  I0511 14:34:58.642236 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename pods @ 05/11/25 14:34:58.643
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:34:58.654
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:34:58.657
  STEP: creating the pod @ 05/11/25 14:34:58.66
  STEP: setting up watch @ 05/11/25 14:34:58.66
  STEP: submitting the pod to kubernetes @ 05/11/25 14:34:58.766
  STEP: verifying the pod is in kubernetes @ 05/11/25 14:34:58.778
  STEP: verifying pod creation was observed @ 05/11/25 14:34:58.781
  E0511 14:34:59.268880      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:00.270051      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 05/11/25 14:35:00.794
  STEP: verifying pod deletion was observed @ 05/11/25 14:35:00.803
  E0511 14:35:01.270866      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:35:01.586715 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9667" for this suite. @ 05/11/25 14:35:01.589
• [2.954 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:401
  STEP: Creating a kubernetes client @ 05/11/25 14:35:01.597
  I0511 14:35:01.597052 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename namespaces @ 05/11/25 14:35:01.598
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:35:01.607
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:35:01.61
  STEP: Creating namespace "e2e-ns-6m4jj" @ 05/11/25 14:35:01.613
  I0511 14:35:01.621041 26 namespace.go:412] Namespace "e2e-ns-6m4jj-2908" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-6m4jj-2908" @ 05/11/25 14:35:01.621
  I0511 14:35:01.627622 26 namespace.go:435] Namespace "e2e-ns-6m4jj-2908" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-6m4jj-2908" @ 05/11/25 14:35:01.627
  I0511 14:35:01.633217 26 namespace.go:464] Namespace "e2e-ns-6m4jj-2908" has []v1.FinalizerName{"kubernetes"}
  I0511 14:35:01.633351 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-9804" for this suite. @ 05/11/25 14:35:01.69
  STEP: Destroying namespace "e2e-ns-6m4jj-2908" for this suite. @ 05/11/25 14:35:01.694
• [0.102 seconds]
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:42
  STEP: Creating a kubernetes client @ 05/11/25 14:35:01.699
  I0511 14:35:01.699263 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename containers @ 05/11/25 14:35:01.7
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:35:01.707
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:35:01.71
  E0511 14:35:02.271167      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:03.271778      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:35:03.729946 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-6465" for this suite. @ 05/11/25 14:35:03.731
• [2.037 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:763
  STEP: Creating a kubernetes client @ 05/11/25 14:35:03.736
  I0511 14:35:03.736501 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 14:35:03.737
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:35:03.741
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:35:03.743
  STEP: Setting up server cert @ 05/11/25 14:35:03.754
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 14:35:04.25
  STEP: Deploying the webhook pod @ 05/11/25 14:35:04.253
  STEP: Wait for the deployment to be ready @ 05/11/25 14:35:04.261
  I0511 14:35:04.265049 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0511 14:35:04.272222      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:05.272582      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:06.273261      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/11/25 14:35:06.277
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 14:35:06.292
  E0511 14:35:07.273601      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:35:07.293718 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 05/11/25 14:35:07.299
  STEP: verifying the mutating webhook match conditions @ 05/11/25 14:35:07.306
  STEP: updating the mutating webhook match conditions @ 05/11/25 14:35:07.312
  STEP: verifying the mutating webhook match conditions @ 05/11/25 14:35:07.323
  I0511 14:35:07.361061 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5051" for this suite. @ 05/11/25 14:35:07.363
  STEP: Destroying namespace "webhook-markers-55" for this suite. @ 05/11/25 14:35:07.367
• [3.635 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:155
  STEP: Creating a kubernetes client @ 05/11/25 14:35:07.371
  I0511 14:35:07.371771 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/11/25 14:35:07.372
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:35:07.379
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:35:07.38
  I0511 14:35:07.382086 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  E0511 14:35:08.274408      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 05/11/25 14:35:08.543
  I0511 14:35:08.543718 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-7363 --namespace=crd-publish-openapi-7363 create -f -'
  E0511 14:35:09.275325      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:10.275417      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:35:10.602810 26 builder.go:146] stderr: ""
  I0511 14:35:10.602864 26 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2505-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0511 14:35:10.602920 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-7363 --namespace=crd-publish-openapi-7363 delete e2e-test-crd-publish-openapi-2505-crds test-cr'
  I0511 14:35:10.646818 26 builder.go:146] stderr: ""
  I0511 14:35:10.646854 26 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2505-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  I0511 14:35:10.646906 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-7363 --namespace=crd-publish-openapi-7363 apply -f -'
  I0511 14:35:10.691687 26 builder.go:146] stderr: ""
  I0511 14:35:10.691723 26 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2505-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0511 14:35:10.691764 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-7363 --namespace=crd-publish-openapi-7363 delete e2e-test-crd-publish-openapi-2505-crds test-cr'
  I0511 14:35:10.732677 26 builder.go:146] stderr: ""
  I0511 14:35:10.732710 26 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2505-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 05/11/25 14:35:10.732
  I0511 14:35:10.732779 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-7363 explain e2e-test-crd-publish-openapi-2505-crds'
  I0511 14:35:10.768956 26 builder.go:146] stderr: ""
  I0511 14:35:10.768996 26 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-2505-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0511 14:35:11.275826      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:35:11.925496 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7363" for this suite. @ 05/11/25 14:35:11.932
• [4.565 seconds]
------------------------------
SSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 05/11/25 14:35:11.936
  I0511 14:35:11.936878 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename csiinlinevolumes @ 05/11/25 14:35:11.937
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:35:11.944
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:35:11.947
  STEP: Creating two CSIDrivers @ 05/11/25 14:35:11.949
  STEP: Getting "inline-driver-cb4f987d-080a-4fb7-b452-78c8ec3f3338" & "inline-driver-c4e06cb2-534e-4c3b-aa80-3d1141aabf21" @ 05/11/25 14:35:11.961
  STEP: Patching the CSIDriver "inline-driver-c4e06cb2-534e-4c3b-aa80-3d1141aabf21" @ 05/11/25 14:35:11.964
  STEP: Updating the CSIDriver "inline-driver-c4e06cb2-534e-4c3b-aa80-3d1141aabf21" @ 05/11/25 14:35:11.97
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-419" @ 05/11/25 14:35:11.977
  STEP: Deleting CSIDriver "inline-driver-cb4f987d-080a-4fb7-b452-78c8ec3f3338" @ 05/11/25 14:35:11.98
  STEP: Confirm deletion of CSIDriver "inline-driver-cb4f987d-080a-4fb7-b452-78c8ec3f3338" @ 05/11/25 14:35:11.983
  STEP: Deleting CSIDriver "inline-driver-c4e06cb2-534e-4c3b-aa80-3d1141aabf21" via DeleteCollection @ 05/11/25 14:35:11.985
  STEP: Confirm deletion of CSIDriver "inline-driver-c4e06cb2-534e-4c3b-aa80-3d1141aabf21" @ 05/11/25 14:35:11.99
  I0511 14:35:11.992837 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-419" for this suite. @ 05/11/25 14:35:12.035
• [0.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:199
  STEP: Creating a kubernetes client @ 05/11/25 14:35:12.041
  I0511 14:35:12.041385 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename emptydir @ 05/11/25 14:35:12.042
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:35:12.052
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:35:12.054
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 05/11/25 14:35:12.057
  E0511 14:35:12.276756      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:13.277210      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:35:14.072
  I0511 14:35:14.075224 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-0b6b8f3f-6321-4686-b2aa-0956e84647b7 container test-container: <nil>
  STEP: delete the pod @ 05/11/25 14:35:14.081
  I0511 14:35:14.093790 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5667" for this suite. @ 05/11/25 14:35:14.095
• [2.057 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:174
  STEP: Creating a kubernetes client @ 05/11/25 14:35:14.098
  I0511 14:35:14.098428 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename crd-webhook @ 05/11/25 14:35:14.099
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:35:14.105
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:35:14.106
  STEP: Setting up server cert @ 05/11/25 14:35:14.108
  E0511 14:35:14.277488      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 05/11/25 14:35:14.373
  STEP: Deploying the custom resource conversion webhook pod @ 05/11/25 14:35:14.376
  STEP: Wait for the deployment to be ready @ 05/11/25 14:35:14.382
  I0511 14:35:14.386965 26 deployment.go:223] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0511 14:35:15.277882      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:16.278403      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/11/25 14:35:16.396
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 14:35:16.41
  E0511 14:35:17.278755      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:35:17.412054 26 util.go:418] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I0511 14:35:17.415856 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  E0511 14:35:18.279931      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:19.279976      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 05/11/25 14:35:19.975
  STEP: Create a v2 custom resource @ 05/11/25 14:35:19.991
  STEP: List CRs in v1 @ 05/11/25 14:35:20.016
  STEP: List CRs in v2 @ 05/11/25 14:35:20.018
  E0511 14:35:20.280369      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:35:20.564290 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-1884" for this suite. @ 05/11/25 14:35:20.566
• [6.475 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:668
  STEP: Creating a kubernetes client @ 05/11/25 14:35:20.574
  I0511 14:35:20.574163 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename pv @ 05/11/25 14:35:20.575
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:35:20.585
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:35:20.589
  STEP: Creating initial PV and PVC @ 05/11/25 14:35:20.594
  I0511 14:35:20.594227 26 pv.go:394] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-832" @ 05/11/25 14:35:20.604
  STEP: Listing PVCs in namespace "pv-832" @ 05/11/25 14:35:20.607
  STEP: Reading "pvc-7bmdz" Status @ 05/11/25 14:35:20.611
  STEP: Reading "pv-832-cz8ws" Status @ 05/11/25 14:35:20.616
  STEP: Patching "pvc-7bmdz" Status @ 05/11/25 14:35:20.618
  STEP: Patching "pv-832-cz8ws" Status @ 05/11/25 14:35:20.624
  STEP: Updating "pvc-7bmdz" Status @ 05/11/25 14:35:20.628
  STEP: Updating "pv-832-cz8ws" Status @ 05/11/25 14:35:20.635
  I0511 14:35:20.641291 26 persistent_volumes.go:406] AfterEach: deleting 1 PVCs and 1 PVs...
  I0511 14:35:20.641331 26 pv.go:205] Deleting PersistentVolumeClaim "pvc-7bmdz"
  I0511 14:35:20.644709 26 pv.go:193] Deleting PersistentVolume "pv-832-cz8ws"
  I0511 14:35:20.647526 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-832" for this suite. @ 05/11/25 14:35:20.666
• [0.096 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:69
  STEP: Creating a kubernetes client @ 05/11/25 14:35:20.669
  I0511 14:35:20.669861 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename downward-api @ 05/11/25 14:35:20.67
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:35:20.675
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:35:20.676
  STEP: Creating a pod to test downward API volume plugin @ 05/11/25 14:35:20.679
  E0511 14:35:21.280603      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:22.280672      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:23.281309      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:24.281788      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:35:24.718
  I0511 14:35:24.720721 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-d0871bf1-29f1-44e1-bbe2-0b7eccc3ba82 container client-container: <nil>
  STEP: delete the pod @ 05/11/25 14:35:24.727
  I0511 14:35:24.744076 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9361" for this suite. @ 05/11/25 14:35:24.747
• [4.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:139
  STEP: Creating a kubernetes client @ 05/11/25 14:35:24.752
  I0511 14:35:24.752928 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename crd-webhook @ 05/11/25 14:35:24.753
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:35:24.764
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:35:24.767
  STEP: Setting up server cert @ 05/11/25 14:35:24.77
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 05/11/25 14:35:24.865
  STEP: Deploying the custom resource conversion webhook pod @ 05/11/25 14:35:24.868
  STEP: Wait for the deployment to be ready @ 05/11/25 14:35:24.874
  I0511 14:35:24.879319 26 deployment.go:223] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0511 14:35:25.282710      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:26.282882      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/11/25 14:35:26.89
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 14:35:26.905
  E0511 14:35:27.284018      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:35:27.905580 26 util.go:418] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I0511 14:35:27.909700 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  E0511 14:35:28.284899      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:29.285027      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:30.285282      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 05/11/25 14:35:30.464
  STEP: v2 custom resource should be converted @ 05/11/25 14:35:30.471
  I0511 14:35:31.023140 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-6457" for this suite. @ 05/11/25 14:35:31.026
• [6.279 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:262
  STEP: Creating a kubernetes client @ 05/11/25 14:35:31.032
  I0511 14:35:31.032816 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename downward-api @ 05/11/25 14:35:31.034
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:35:31.044
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:35:31.046
  STEP: Creating a pod to test downward API volume plugin @ 05/11/25 14:35:31.05
  E0511 14:35:31.285590      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:32.285885      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:35:33.065
  I0511 14:35:33.067071 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-a3e6a097-3a23-4838-97ec-939c33028ea8 container client-container: <nil>
  STEP: delete the pod @ 05/11/25 14:35:33.071
  I0511 14:35:33.080280 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4810" for this suite. @ 05/11/25 14:35:33.082
• [2.052 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:802
  STEP: Creating a kubernetes client @ 05/11/25 14:35:33.085
  I0511 14:35:33.085127 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename job @ 05/11/25 14:35:33.085
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:35:33.091
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:35:33.093
  STEP: Creating a job @ 05/11/25 14:35:33.094
  STEP: Ensuring job reaches completions @ 05/11/25 14:35:33.098
  E0511 14:35:33.287018      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:34.287738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:35.288007      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:36.288589      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:37.289409      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:38.289868      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:39.290653      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:40.290797      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:41.290899      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:42.291723      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:35:43.127214 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-6938" for this suite. @ 05/11/25 14:35:43.13
• [10.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:340
  STEP: Creating a kubernetes client @ 05/11/25 14:35:43.137
  I0511 14:35:43.137848 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename statefulset @ 05/11/25 14:35:43.139
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:35:43.149
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:35:43.152
  STEP: Creating service test in namespace statefulset-7614 @ 05/11/25 14:35:43.155
  STEP: Creating a new StatefulSet @ 05/11/25 14:35:43.16
  I0511 14:35:43.169637 26 wait.go:44] Found 0 stateful pods, waiting for 3
  E0511 14:35:43.292144      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:44.292829      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:45.293844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:46.294041      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:47.294910      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:48.295672      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:49.295967      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:50.296719      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:51.296849      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:52.297863      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:35:53.172147 26 wait.go:54] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0511 14:35:53.172200 26 wait.go:54] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0511 14:35:53.172217 26 wait.go:54] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 05/11/25 14:35:53.179
  I0511 14:35:53.190134 26 statefulset.go:2542] Updating stateful set ss2
  STEP: Creating a new revision @ 05/11/25 14:35:53.19
  E0511 14:35:53.298593      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:54.299200      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:55.299597      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:56.300115      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:57.300752      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:58.301314      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:35:59.301834      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:00.301804      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:01.302190      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:02.303250      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 05/11/25 14:36:03.2
  STEP: Performing a canary update @ 05/11/25 14:36:03.2
  I0511 14:36:03.209811 26 statefulset.go:2542] Updating stateful set ss2
  I0511 14:36:03.219353 26 wait.go:74] Waiting for Pod statefulset-7614/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:36:03.303216      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:04.303598      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:05.304121      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:06.304535      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:07.305144      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:08.305537      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:09.306080      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:10.306439      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:11.307184      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:12.307718      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 05/11/25 14:36:13.214
  I0511 14:36:13.249668 26 wait.go:44] Found 2 stateful pods, waiting for 3
  E0511 14:36:13.308097      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:14.308450      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:15.308618      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:16.309075      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:17.309436      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:18.309960      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:19.310761      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:20.311824      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:21.312168      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:22.312774      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:36:23.250239 26 wait.go:54] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0511 14:36:23.250287 26 wait.go:54] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0511 14:36:23.250302 26 wait.go:54] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 05/11/25 14:36:23.255
  I0511 14:36:23.263946 26 statefulset.go:2542] Updating stateful set ss2
  I0511 14:36:23.272712 26 wait.go:74] Waiting for Pod statefulset-7614/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:36:23.313811      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:24.314408      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:25.314789      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:26.315382      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:27.315917      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:28.316233      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:29.316600      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:30.316751      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:31.317186      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:32.317894      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:36:33.279670 26 statefulset.go:2542] Updating stateful set ss2
  I0511 14:36:33.288284 26 wait.go:56] Waiting for StatefulSet statefulset-7614/ss2 to complete update
  I0511 14:36:33.288373 26 wait.go:63] Waiting for Pod statefulset-7614/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0511 14:36:33.318054      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:34.318717      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:35.318832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:36.319335      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:37.319361      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:38.319733      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:39.320334      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:40.320628      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:41.320689      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:42.321635      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:36:43.288561 26 statefulset.go:138] Deleting all statefulset in ns statefulset-7614
  I0511 14:36:43.291417 26 rest.go:153] Scaling statefulset ss2 to 0
  E0511 14:36:43.321722      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:44.322744      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:45.323005      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:46.323149      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:47.323187      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:48.323452      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:49.323632      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:50.324661      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:51.325711      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:36:52.325728      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:36:53.306131 26 wait.go:159] Waiting for statefulset status.replicas updated to 0
  I0511 14:36:53.308477 26 rest.go:91] Deleting statefulset ss2
  I0511 14:36:53.321945 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7614" for this suite. @ 05/11/25 14:36:53.325
  E0511 14:36:53.325780      26 retrywatcher.go:169] "Watch failed" err="context canceled"
• [70.193 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 05/11/25 14:36:53.33
  I0511 14:36:53.331033 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename csiinlinevolumes @ 05/11/25 14:36:53.332
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:36:53.341
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:36:53.344
  STEP: creating @ 05/11/25 14:36:53.347
  STEP: getting @ 05/11/25 14:36:53.362
  STEP: listing in namespace @ 05/11/25 14:36:53.365
  STEP: patching @ 05/11/25 14:36:53.368
  STEP: deleting @ 05/11/25 14:36:53.376
  I0511 14:36:53.382586 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-9564" for this suite. @ 05/11/25 14:36:53.426
• [0.102 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 05/11/25 14:36:53.433
  I0511 14:36:53.433326 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename daemonsets @ 05/11/25 14:36:53.434
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:36:53.443
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:36:53.446
  I0511 14:36:53.535661 26 daemon_set.go:388] Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/11/25 14:36:53.541
  I0511 14:36:53.632533 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 14:36:53.632587 26 fixtures.go:131] Node k8sconformance is running 0 daemon pod, expected 1
  E0511 14:36:54.326811      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:36:54.550093 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 14:36:54.550141 26 fixtures.go:131] Node k8sconformance is running 0 daemon pod, expected 1
  E0511 14:36:55.327771      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:36:55.550768 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0511 14:36:55.550819 26 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Update daemon pods image. @ 05/11/25 14:36:55.56
  STEP: Check that daemon pods images are updated. @ 05/11/25 14:36:55.648
  I0511 14:36:55.653608 26 daemon_set.go:1193] Wrong image for pod: daemon-set-28gd5. Expected: registry.k8s.io/e2e-test-images/agnhost:2.53, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0511 14:36:56.328381      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:36:56.654046 26 daemon_set.go:1193] Wrong image for pod: daemon-set-28gd5. Expected: registry.k8s.io/e2e-test-images/agnhost:2.53, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0511 14:36:56.654096 26 daemon_set.go:1198] Pod daemon-set-7f98q is not available
  E0511 14:36:57.328683      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:36:57.651291 26 daemon_set.go:1198] Pod daemon-set-zng22 is not available
  STEP: Check that daemon pods are still running on every node of the cluster. @ 05/11/25 14:36:57.652
  I0511 14:36:57.654942 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0511 14:36:57.654968 26 fixtures.go:131] Node k8sconformance-m02 is running 0 daemon pod, expected 1
  E0511 14:36:58.328714      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:36:58.658629 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0511 14:36:58.658683 26 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 05/11/25 14:36:58.671
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3589, will wait for the garbage collector to delete the pods @ 05/11/25 14:36:58.671
  I0511 14:36:58.731452 26 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 6.436571ms
  I0511 14:36:58.832645 26 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 101.19371ms
  E0511 14:36:59.329013      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:37:00.038212 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 14:37:00.038282 26 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0511 14:37:00.041727 26 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20128"},"items":null}

  I0511 14:37:00.044062 26 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20128"},"items":null}

  I0511 14:37:00.051934 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3589" for this suite. @ 05/11/25 14:37:00.054
• [6.626 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:423
  STEP: Creating a kubernetes client @ 05/11/25 14:37:00.059
  I0511 14:37:00.059629 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename proxy @ 05/11/25 14:37:00.06
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:37:00.072
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:37:00.075
  I0511 14:37:00.077957 26 proxy.go:430] Creating pod...
  E0511 14:37:00.329355      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:01.329753      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:37:02.091209 26 proxy.go:454] Creating service...
  I0511 14:37:02.102931 26 proxy.go:491] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7882/pods/agnhost/proxy?method=DELETE
  I0511 14:37:02.105698 26 proxy.go:573] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0511 14:37:02.105734 26 proxy.go:491] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7882/pods/agnhost/proxy?method=OPTIONS
  I0511 14:37:02.107351 26 proxy.go:573] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0511 14:37:02.107380 26 proxy.go:491] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7882/pods/agnhost/proxy?method=PATCH
  I0511 14:37:02.108713 26 proxy.go:573] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0511 14:37:02.108740 26 proxy.go:491] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7882/pods/agnhost/proxy?method=POST
  I0511 14:37:02.110109 26 proxy.go:573] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0511 14:37:02.110142 26 proxy.go:491] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7882/pods/agnhost/proxy?method=PUT
  I0511 14:37:02.111501 26 proxy.go:573] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0511 14:37:02.111516 26 proxy.go:502] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7882/services/e2e-proxy-test-service/proxy?method=DELETE
  I0511 14:37:02.113109 26 proxy.go:573] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0511 14:37:02.113121 26 proxy.go:502] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7882/services/e2e-proxy-test-service/proxy?method=OPTIONS
  I0511 14:37:02.114705 26 proxy.go:573] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0511 14:37:02.114733 26 proxy.go:502] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7882/services/e2e-proxy-test-service/proxy?method=PATCH
  I0511 14:37:02.116329 26 proxy.go:573] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0511 14:37:02.116354 26 proxy.go:502] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7882/services/e2e-proxy-test-service/proxy?method=POST
  I0511 14:37:02.118087 26 proxy.go:573] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0511 14:37:02.118117 26 proxy.go:502] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7882/services/e2e-proxy-test-service/proxy?method=PUT
  I0511 14:37:02.119845 26 proxy.go:573] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0511 14:37:02.119880 26 proxy.go:522] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7882/pods/agnhost/proxy?method=GET
  I0511 14:37:02.121102 26 proxy.go:530] http.Client request:GET StatusCode:301
  I0511 14:37:02.121134 26 proxy.go:522] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7882/services/e2e-proxy-test-service/proxy?method=GET
  I0511 14:37:02.122517 26 proxy.go:530] http.Client request:GET StatusCode:301
  I0511 14:37:02.122543 26 proxy.go:522] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7882/pods/agnhost/proxy?method=HEAD
  I0511 14:37:02.123525 26 proxy.go:530] http.Client request:HEAD StatusCode:301
  I0511 14:37:02.123549 26 proxy.go:522] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7882/services/e2e-proxy-test-service/proxy?method=HEAD
  I0511 14:37:02.124878 26 proxy.go:530] http.Client request:HEAD StatusCode:301
  I0511 14:37:02.124997 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-7882" for this suite. @ 05/11/25 14:37:02.126
• [2.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:394
  STEP: Creating a kubernetes client @ 05/11/25 14:37:02.13
  I0511 14:37:02.130823 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubectl @ 05/11/25 14:37:02.131
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:37:02.136
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:37:02.138
  STEP: creating all guestbook components @ 05/11/25 14:37:02.14
  I0511 14:37:02.140296 26 kubectl.go:400] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  I0511 14:37:02.140360 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-8294 create -f -'
  I0511 14:37:02.219606 26 builder.go:146] stderr: ""
  I0511 14:37:02.219643 26 builder.go:147] stdout: "service/agnhost-replica created\n"
  I0511 14:37:02.219690 26 kubectl.go:400] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  I0511 14:37:02.219761 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-8294 create -f -'
  I0511 14:37:02.297628 26 builder.go:146] stderr: ""
  I0511 14:37:02.297667 26 builder.go:147] stdout: "service/agnhost-primary created\n"
  I0511 14:37:02.297707 26 kubectl.go:400] apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  I0511 14:37:02.297785 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-8294 create -f -'
  E0511 14:37:02.330083      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:37:02.384337 26 builder.go:146] stderr: ""
  I0511 14:37:02.384395 26 builder.go:147] stdout: "service/frontend created\n"
  I0511 14:37:02.384446 26 kubectl.go:400] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.53
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  I0511 14:37:02.384511 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-8294 create -f -'
  I0511 14:37:02.448567 26 builder.go:146] stderr: ""
  I0511 14:37:02.448592 26 builder.go:147] stdout: "deployment.apps/frontend created\n"
  I0511 14:37:02.448636 26 kubectl.go:400] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.53
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0511 14:37:02.448685 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-8294 create -f -'
  I0511 14:37:02.518658 26 builder.go:146] stderr: ""
  I0511 14:37:02.518685 26 builder.go:147] stdout: "deployment.apps/agnhost-primary created\n"
  I0511 14:37:02.518725 26 kubectl.go:400] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.53
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0511 14:37:02.518793 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-8294 create -f -'
  I0511 14:37:02.579723 26 builder.go:146] stderr: ""
  I0511 14:37:02.579759 26 builder.go:147] stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 05/11/25 14:37:02.579
  I0511 14:37:02.579797 26 kubectl.go:2275] Waiting for all frontend pods to be Running.
  E0511 14:37:03.331096      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:04.332226      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:05.332605      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:06.332985      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:07.333777      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:37:07.631119 26 kubectl.go:2279] Waiting for frontend to serve content.
  I0511 14:37:07.635599 26 kubectl.go:2284] Trying to add a new entry to the guestbook.
  I0511 14:37:07.640578 26 kubectl.go:2289] Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 05/11/25 14:37:07.644
  I0511 14:37:07.644257 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-8294 delete --grace-period=0 --force -f -'
  I0511 14:37:07.695353 26 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0511 14:37:07.695388 26 builder.go:147] stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 05/11/25 14:37:07.695
  I0511 14:37:07.695492 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-8294 delete --grace-period=0 --force -f -'
  I0511 14:37:07.753710 26 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0511 14:37:07.753752 26 builder.go:147] stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 05/11/25 14:37:07.753
  I0511 14:37:07.753843 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-8294 delete --grace-period=0 --force -f -'
  I0511 14:37:07.804764 26 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0511 14:37:07.804801 26 builder.go:147] stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 05/11/25 14:37:07.804
  I0511 14:37:07.804911 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-8294 delete --grace-period=0 --force -f -'
  I0511 14:37:07.839173 26 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0511 14:37:07.839207 26 builder.go:147] stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 05/11/25 14:37:07.839
  I0511 14:37:07.839319 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-8294 delete --grace-period=0 --force -f -'
  I0511 14:37:07.888656 26 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0511 14:37:07.888725 26 builder.go:147] stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 05/11/25 14:37:07.888
  I0511 14:37:07.888842 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-8294 delete --grace-period=0 --force -f -'
  I0511 14:37:07.931390 26 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0511 14:37:07.931424 26 builder.go:147] stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  I0511 14:37:07.931555 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8294" for this suite. @ 05/11/25 14:37:07.933
• [5.806 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:109
  STEP: Creating a kubernetes client @ 05/11/25 14:37:07.937
  I0511 14:37:07.937184 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename emptydir @ 05/11/25 14:37:07.937
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:37:07.95
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:37:07.953
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 05/11/25 14:37:07.955
  E0511 14:37:08.334654      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:09.335780      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:10.336738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:11.337329      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:37:11.973
  I0511 14:37:11.976450 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-c340951e-a956-4bc6-b453-0436461e4c04 container test-container: <nil>
  STEP: delete the pod @ 05/11/25 14:37:11.991
  I0511 14:37:12.004425 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7902" for this suite. @ 05/11/25 14:37:12.007
• [4.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:190
  STEP: Creating a kubernetes client @ 05/11/25 14:37:12.012
  I0511 14:37:12.012530 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename var-expansion @ 05/11/25 14:37:12.013
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:37:12.022
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:37:12.026
  E0511 14:37:12.337670      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:13.338202      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:37:14.064063 26 delete.go:62] Deleting pod "var-expansion-f3b127ef-75d6-4007-a93d-3cf74ffc2437" in namespace "var-expansion-6663"
  I0511 14:37:14.072443 26 delete.go:70] Wait up to 5m0s for pod "var-expansion-f3b127ef-75d6-4007-a93d-3cf74ffc2437" to be fully deleted
  E0511 14:37:14.339400      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:15.339551      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:37:16.081620 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6663" for this suite. @ 05/11/25 14:37:16.085
• [4.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 05/11/25 14:37:16.089
  I0511 14:37:16.089931 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 14:37:16.09
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:37:16.098
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:37:16.102
  STEP: Creating projection with secret that has name projected-secret-test-map-abcf9e89-8028-46b7-8222-32c3b1fec600 @ 05/11/25 14:37:16.105
  STEP: Creating a pod to test consume secrets @ 05/11/25 14:37:16.109
  E0511 14:37:16.340145      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:17.340940      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:18.341599      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:19.341659      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:37:20.129
  I0511 14:37:20.132087 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-projected-secrets-f5ff1cd0-e777-4106-b11c-331029f3229b container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/11/25 14:37:20.14
  I0511 14:37:20.157624 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1510" for this suite. @ 05/11/25 14:37:20.161
• [4.076 seconds]
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:109
  STEP: Creating a kubernetes client @ 05/11/25 14:37:20.165
  I0511 14:37:20.165868 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename configmap @ 05/11/25 14:37:20.167
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:37:20.177
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:37:20.18
  STEP: Creating configMap with name configmap-test-volume-map-76f262dd-9f81-4aeb-ab8a-c43099a92171 @ 05/11/25 14:37:20.183
  STEP: Creating a pod to test consume configMaps @ 05/11/25 14:37:20.187
  E0511 14:37:20.342309      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:21.342807      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:22.343682      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:23.343804      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:37:24.209
  I0511 14:37:24.212486 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-5cb89578-bf2d-4812-8f53-cbdd0153314d container agnhost-container: <nil>
  STEP: delete the pod @ 05/11/25 14:37:24.219
  I0511 14:37:24.234371 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6693" for this suite. @ 05/11/25 14:37:24.237
• [4.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 05/11/25 14:37:24.243
  I0511 14:37:24.243838 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename pods @ 05/11/25 14:37:24.244
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:37:24.253
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:37:24.256
  E0511 14:37:24.344811      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:25.344744      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:26.345934      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:27.346864      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:28.347150      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:29.347684      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:37:30.315
  I0511 14:37:30.322623 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod client-envvars-2f536292-8b31-4138-beec-1c5da910de08 container env3cont: <nil>
  STEP: delete the pod @ 05/11/25 14:37:30.33
  I0511 14:37:30.345702 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0511 14:37:30.348674      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Destroying namespace "pods-5228" for this suite. @ 05/11/25 14:37:30.349
• [6.110 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:431
  STEP: Creating a kubernetes client @ 05/11/25 14:37:30.354
  I0511 14:37:30.354309 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename security-context-test @ 05/11/25 14:37:30.355
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:37:30.364
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:37:30.367
  E0511 14:37:31.349820      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:32.350310      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:33.350321      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:34.350864      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:37:34.389103 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-6390" for this suite. @ 05/11/25 14:37:34.392
• [4.044 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:262
  STEP: Creating a kubernetes client @ 05/11/25 14:37:34.398
  I0511 14:37:34.398112 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 14:37:34.398
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:37:34.407
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:37:34.41
  STEP: Creating a pod to test downward API volume plugin @ 05/11/25 14:37:34.413
  E0511 14:37:35.351215      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:36.351839      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:37.351710      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:38.351752      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:37:38.434
  I0511 14:37:38.436452 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-c184df33-b720-4247-903d-75dfc5258381 container client-container: <nil>
  STEP: delete the pod @ 05/11/25 14:37:38.443
  I0511 14:37:38.459315 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6615" for this suite. @ 05/11/25 14:37:38.463
• [4.072 seconds]
------------------------------
SS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:209
  STEP: Creating a kubernetes client @ 05/11/25 14:37:38.47
  I0511 14:37:38.470376 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename dns @ 05/11/25 14:37:38.471
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:37:38.48
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:37:38.483
  STEP: Creating a test headless service @ 05/11/25 14:37:38.486
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5731 A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service.dns-5731;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5731 A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service.dns-5731;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5731.svc A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service.dns-5731.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5731.svc A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service.dns-5731.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5731.svc SRV)" && test -n "$$check" && echo OK > /results/agnhost_udp@_http._tcp.dns-test-service.dns-5731.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5731.svc SRV)" && test -n "$$check" && echo OK > /results/agnhost_tcp@_http._tcp.dns-test-service.dns-5731.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5731.svc SRV)" && test -n "$$check" && echo OK > /results/agnhost_udp@_http._tcp.test-service-2.dns-5731.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5731.svc SRV)" && test -n "$$check" && echo OK > /results/agnhost_tcp@_http._tcp.test-service-2.dns-5731.svc;check="$$(dig +notcp +noall +answer +search 181.59.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.59.181_udp@PTR;check="$$(dig +tcp +noall +answer +search 181.59.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.59.181_tcp@PTR;sleep 1; done
   @ 05/11/25 14:37:38.503
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5731 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5731;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5731 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5731;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5731.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5731.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5731.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5731.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5731.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5731.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5731.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5731.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5731.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5731.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5731.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5731.svc;check="$$(dig +notcp +noall +answer +search 181.59.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.59.181_udp@PTR;check="$$(dig +tcp +noall +answer +search 181.59.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.59.181_tcp@PTR;sleep 1; done
   @ 05/11/25 14:37:38.503
  STEP: creating a pod to probe DNS @ 05/11/25 14:37:38.503
  STEP: submitting the pod to kubernetes @ 05/11/25 14:37:38.503
  E0511 14:37:39.352691      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:40.352847      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/11/25 14:37:40.521
  STEP: looking for the results for each expected name from probers @ 05/11/25 14:37:40.526
  I0511 14:37:40.529234 26 dns_common.go:495] Unable to read agnhost_udp@dns-test-service from pod dns-5731/dns-test-1a209078-2b97-4973-9219-deac30609133: the server could not find the requested resource (get pods dns-test-1a209078-2b97-4973-9219-deac30609133)
  I0511 14:37:40.530935 26 dns_common.go:495] Unable to read agnhost_tcp@dns-test-service from pod dns-5731/dns-test-1a209078-2b97-4973-9219-deac30609133: the server could not find the requested resource (get pods dns-test-1a209078-2b97-4973-9219-deac30609133)
  I0511 14:37:40.533552 26 dns_common.go:495] Unable to read agnhost_udp@dns-test-service.dns-5731 from pod dns-5731/dns-test-1a209078-2b97-4973-9219-deac30609133: the server could not find the requested resource (get pods dns-test-1a209078-2b97-4973-9219-deac30609133)
  I0511 14:37:40.557634 26 dns_common.go:495] Unable to read jessie_udp@dns-test-service from pod dns-5731/dns-test-1a209078-2b97-4973-9219-deac30609133: the server could not find the requested resource (get pods dns-test-1a209078-2b97-4973-9219-deac30609133)
  I0511 14:37:40.559137 26 dns_common.go:495] Unable to read jessie_tcp@dns-test-service from pod dns-5731/dns-test-1a209078-2b97-4973-9219-deac30609133: the server could not find the requested resource (get pods dns-test-1a209078-2b97-4973-9219-deac30609133)
  I0511 14:37:40.560910 26 dns_common.go:495] Unable to read jessie_udp@dns-test-service.dns-5731 from pod dns-5731/dns-test-1a209078-2b97-4973-9219-deac30609133: the server could not find the requested resource (get pods dns-test-1a209078-2b97-4973-9219-deac30609133)
  I0511 14:37:40.562760 26 dns_common.go:495] Unable to read jessie_tcp@dns-test-service.dns-5731 from pod dns-5731/dns-test-1a209078-2b97-4973-9219-deac30609133: the server could not find the requested resource (get pods dns-test-1a209078-2b97-4973-9219-deac30609133)
  I0511 14:37:40.574003 26 dns_common.go:506] Lookups using dns-5731/dns-test-1a209078-2b97-4973-9219-deac30609133 failed for: [agnhost_udp@dns-test-service agnhost_tcp@dns-test-service agnhost_udp@dns-test-service.dns-5731 jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5731 jessie_tcp@dns-test-service.dns-5731]

  I0511 14:37:40.577517 26 dns_common.go:514] Pod client logs for webserver: 
  I0511 14:37:40.581010 26 dns_common.go:514] Pod client logs for agnhost-querier: 
  I0511 14:37:40.584680 26 dns_common.go:514] Pod client logs for jessie-querier: 
  E0511 14:37:41.353826      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:42.354145      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:43.354639      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:44.354799      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:45.355903      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:37:45.595634 26 dns_common.go:546] DNS probes using dns-5731/dns-test-1a209078-2b97-4973-9219-deac30609133 succeeded

  STEP: deleting the pod @ 05/11/25 14:37:45.595
  STEP: deleting the test service @ 05/11/25 14:37:45.61
  STEP: deleting the test headless service @ 05/11/25 14:37:45.631
  I0511 14:37:45.638656 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-5731" for this suite. @ 05/11/25 14:37:45.641
• [7.176 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:171
  STEP: Creating a kubernetes client @ 05/11/25 14:37:45.646
  I0511 14:37:45.646160 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename configmap @ 05/11/25 14:37:45.646
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:37:45.652
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:37:45.654
  STEP: creating a ConfigMap @ 05/11/25 14:37:45.657
  STEP: fetching the ConfigMap @ 05/11/25 14:37:45.661
  STEP: patching the ConfigMap @ 05/11/25 14:37:45.662
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 05/11/25 14:37:45.665
  STEP: deleting the ConfigMap by collection with a label selector @ 05/11/25 14:37:45.666
  STEP: listing all ConfigMaps in test namespace @ 05/11/25 14:37:45.669
  I0511 14:37:45.670973 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6631" for this suite. @ 05/11/25 14:37:45.743
• [0.103 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:166
  STEP: Creating a kubernetes client @ 05/11/25 14:37:45.749
  I0511 14:37:45.749405 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename field-validation @ 05/11/25 14:37:45.75
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:37:45.76
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:37:45.763
  I0511 14:37:45.765468 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  E0511 14:37:46.356772      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:47.357332      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:37:48.292341      26 warnings.go:110] "Warning: unknown field \"alpha\""
  I0511 14:37:48.292382      26 warnings.go:110] "Warning: unknown field \"beta\""
  I0511 14:37:48.292399      26 warnings.go:110] "Warning: unknown field \"delta\""
  I0511 14:37:48.292416      26 warnings.go:110] "Warning: unknown field \"epsilon\""
  I0511 14:37:48.292432      26 warnings.go:110] "Warning: unknown field \"gamma\""
  E0511 14:37:48.358271      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:37:48.830050 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4931" for this suite. @ 05/11/25 14:37:48.832
• [3.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:144
  STEP: Creating a kubernetes client @ 05/11/25 14:37:48.838
  I0511 14:37:48.838948 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename disruption @ 05/11/25 14:37:48.839
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:37:48.848
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:37:48.851
  STEP: Waiting for the pdb to be processed @ 05/11/25 14:37:48.858
  E0511 14:37:49.359025      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:50.359857      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 05/11/25 14:37:50.884
  I0511 14:37:50.892118 26 disruption.go:691] running pods: 0 < 3
  E0511 14:37:51.360309      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:52.360836      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:37:52.894347 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-3146" for this suite. @ 05/11/25 14:37:52.897
• [4.065 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Job should allow to use the pod failure policy on exit code to fail the job early [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:110
  STEP: Creating a kubernetes client @ 05/11/25 14:37:52.904
  I0511 14:37:52.904415 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename job @ 05/11/25 14:37:52.905
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:37:52.915
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:37:52.918
  STEP: Looking for a node to schedule job pod @ 05/11/25 14:37:52.922
  STEP: Creating a job @ 05/11/25 14:37:52.998
  STEP: Ensuring job fails @ 05/11/25 14:37:53.005
  E0511 14:37:53.361159      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:54.361713      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:55.361728      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:56.362222      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:37:57.017111 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2451" for this suite. @ 05/11/25 14:37:57.02
• [4.123 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 05/11/25 14:37:57.028
  I0511 14:37:57.028172 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/11/25 14:37:57.029
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:37:57.042
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:37:57.046
  I0511 14:37:57.049757 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  E0511 14:37:57.363301      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:58.363564      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:37:59.363768      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:38:00.138368 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-1396" for this suite. @ 05/11/25 14:38:00.142
• [3.121 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:140
  STEP: Creating a kubernetes client @ 05/11/25 14:38:00.148
  I0511 14:38:00.148989 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename configmap @ 05/11/25 14:38:00.149
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:38:00.163
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:38:00.165
  STEP: Creating configMap that has name configmap-test-emptyKey-7ca10868-8bd9-4469-85eb-ceb9ae40e46d @ 05/11/25 14:38:00.166
  I0511 14:38:00.167650 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-994" for this suite. @ 05/11/25 14:38:00.244
• [0.102 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:89
  STEP: Creating a kubernetes client @ 05/11/25 14:38:00.251
  I0511 14:38:00.251049 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 14:38:00.252
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:38:00.262
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:38:00.265
  STEP: Creating configMap with name projected-configmap-test-volume-map-35077c79-06c0-4b38-9597-c640978827d0 @ 05/11/25 14:38:00.268
  STEP: Creating a pod to test consume configMaps @ 05/11/25 14:38:00.273
  E0511 14:38:00.364612      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:01.365107      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:38:02.295
  I0511 14:38:02.298921 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-projected-configmaps-d43d6ad8-6dc2-4582-9feb-fbdb037ea495 container agnhost-container: <nil>
  STEP: delete the pod @ 05/11/25 14:38:02.306
  I0511 14:38:02.324022 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4572" for this suite. @ 05/11/25 14:38:02.327
• [2.083 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Downward API should provide hostIPs as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:118
  STEP: Creating a kubernetes client @ 05/11/25 14:38:02.334
  I0511 14:38:02.334332 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename downward-api @ 05/11/25 14:38:02.335
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:38:02.344
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:38:02.347
  STEP: Creating a pod to test downward api env vars @ 05/11/25 14:38:02.35
  E0511 14:38:02.365560      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:03.365939      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:04.366416      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:05.367147      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:06.367733      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:38:06.371
  I0511 14:38:06.373770 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downward-api-e67746e7-d4e8-4184-8b65-c979ee867912 container dapi-container: <nil>
  STEP: delete the pod @ 05/11/25 14:38:06.381
  I0511 14:38:06.395699 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5119" for this suite. @ 05/11/25 14:38:06.399
• [4.071 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:76
  STEP: Creating a kubernetes client @ 05/11/25 14:38:06.405
  I0511 14:38:06.405796 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename containers @ 05/11/25 14:38:06.406
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:38:06.425
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:38:06.428
  STEP: Creating a pod to test override command @ 05/11/25 14:38:06.431
  E0511 14:38:07.368790      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:08.369869      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:38:08.447
  I0511 14:38:08.449626 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod client-containers-2f6f9e68-c2b8-4ca5-b5dc-8a908fab32bd container agnhost-container: <nil>
  STEP: delete the pod @ 05/11/25 14:38:08.457
  I0511 14:38:08.469670 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-4472" for this suite. @ 05/11/25 14:38:08.473
• [2.073 seconds]
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 05/11/25 14:38:08.478
  I0511 14:38:08.478649 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename replicaset @ 05/11/25 14:38:08.479
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:38:08.49
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:38:08.493
  STEP: Create a ReplicaSet @ 05/11/25 14:38:08.496
  STEP: Verify that the required pods have come up @ 05/11/25 14:38:08.501
  I0511 14:38:08.503511 26 resource.go:81] Pod name sample-pod: Found 0 pods out of 3
  E0511 14:38:09.370821      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:10.371407      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:11.372031      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:12.372615      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:13.373347      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:38:13.589657 26 resource.go:81] Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 05/11/25 14:38:13.589
  I0511 14:38:13.591266 26 replica_set.go:588] Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 TerminatingReplicas:<nil> ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 05/11/25 14:38:13.591
  STEP: DeleteCollection of the ReplicaSets @ 05/11/25 14:38:13.627
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 05/11/25 14:38:13.632
  I0511 14:38:13.633390 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3699" for this suite. @ 05/11/25 14:38:13.635
• [5.159 seconds]
------------------------------
SSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:48
  STEP: Creating a kubernetes client @ 05/11/25 14:38:13.638
  I0511 14:38:13.638127 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename secrets @ 05/11/25 14:38:13.638
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:38:13.654
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:38:13.656
  STEP: Creating secret with name secret-test-20b99d96-e2e5-4799-846b-f9d9cc57cc71 @ 05/11/25 14:38:13.659
  STEP: Creating a pod to test consume secrets @ 05/11/25 14:38:13.665
  E0511 14:38:14.373663      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:15.374725      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:16.375710      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:17.376005      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:38:17.723
  I0511 14:38:17.726011 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-secrets-69d56578-f3a1-48bf-a006-d07ef7aa9f7b container secret-env-test: <nil>
  STEP: delete the pod @ 05/11/25 14:38:17.733
  I0511 14:38:17.751498 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3117" for this suite. @ 05/11/25 14:38:17.754
• [4.122 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1533
  STEP: Creating a kubernetes client @ 05/11/25 14:38:17.76
  I0511 14:38:17.760633 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubectl @ 05/11/25 14:38:17.761
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:38:17.768
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:38:17.771
  STEP: creating Agnhost RC @ 05/11/25 14:38:17.773
  I0511 14:38:17.773813 26 kubectl.go:1540] namespace kubectl-9792
  I0511 14:38:17.773871 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-9792 create -f -'
  I0511 14:38:17.847072 26 builder.go:146] stderr: ""
  I0511 14:38:17.847108 26 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 05/11/25 14:38:17.847
  E0511 14:38:18.376904      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:38:18.850424 26 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0511 14:38:18.850480 26 framework.go:733] Found 0 / 1
  E0511 14:38:19.377279      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:38:19.853747 26 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0511 14:38:19.853793 26 framework.go:733] Found 1 / 1
  I0511 14:38:19.853820 26 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0511 14:38:19.856545 26 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0511 14:38:19.856585 26 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0511 14:38:19.856596 26 kubectl.go:1547] wait on agnhost-primary startup in kubectl-9792 
  I0511 14:38:19.856644 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-9792 logs agnhost-primary-f8b8l agnhost-primary'
  I0511 14:38:19.903442 26 builder.go:146] stderr: ""
  I0511 14:38:19.903474 26 builder.go:147] stdout: "Paused\n"
  STEP: exposing RC @ 05/11/25 14:38:19.903
  I0511 14:38:19.903519 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-9792 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  I0511 14:38:19.953014 26 builder.go:146] stderr: ""
  I0511 14:38:19.953063 26 builder.go:147] stdout: "service/rm2 exposed\n"
  I0511 14:38:19.955940 26 utils.go:1115] Service rm2 in namespace kubectl-9792 found.
  E0511 14:38:20.377951      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:21.378806      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: exposing service @ 05/11/25 14:38:21.963
  I0511 14:38:21.963372 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-9792 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  I0511 14:38:22.015798 26 builder.go:146] stderr: ""
  I0511 14:38:22.015868 26 builder.go:147] stdout: "service/rm3 exposed\n"
  I0511 14:38:22.018757 26 utils.go:1115] Service rm3 in namespace kubectl-9792 found.
  E0511 14:38:22.379382      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:23.380083      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:38:24.027371 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9792" for this suite. @ 05/11/25 14:38:24.029
• [6.275 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 05/11/25 14:38:24.036
  I0511 14:38:24.036544 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename container-runtime @ 05/11/25 14:38:24.037
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:38:24.049
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:38:24.052
  STEP: create the container @ 05/11/25 14:38:24.055
  I0511 14:38:24.063176      26 warnings.go:110] "Warning: metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]"
  STEP: wait for the container to reach Failed @ 05/11/25 14:38:24.063
  E0511 14:38:24.380981      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:25.381262      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:26.381666      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/11/25 14:38:27.081
  STEP: the container should be terminated @ 05/11/25 14:38:27.084
  STEP: the termination message should be set @ 05/11/25 14:38:27.084
  I0511 14:38:27.084441 26 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 05/11/25 14:38:27.084
  I0511 14:38:27.101954 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7833" for this suite. @ 05/11/25 14:38:27.105
• [3.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:750
  STEP: Creating a kubernetes client @ 05/11/25 14:38:27.11
  I0511 14:38:27.110345 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename resourcequota @ 05/11/25 14:38:27.111
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:38:27.12
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:38:27.123
  STEP: Creating a ResourceQuota with terminating scope @ 05/11/25 14:38:27.126
  STEP: Ensuring ResourceQuota status is calculated @ 05/11/25 14:38:27.131
  E0511 14:38:27.382319      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:28.382990      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 05/11/25 14:38:29.137
  STEP: Ensuring ResourceQuota status is calculated @ 05/11/25 14:38:29.141
  E0511 14:38:29.383770      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:30.384509      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 05/11/25 14:38:31.146
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 05/11/25 14:38:31.16
  E0511 14:38:31.385118      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:32.385860      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 05/11/25 14:38:33.165
  E0511 14:38:33.386006      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:34.386643      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/11/25 14:38:35.17
  STEP: Ensuring resource quota status released the pod usage @ 05/11/25 14:38:35.179
  E0511 14:38:35.387323      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:36.387807      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 05/11/25 14:38:37.184
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 05/11/25 14:38:37.197
  E0511 14:38:37.388419      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:38.388959      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 05/11/25 14:38:39.2
  E0511 14:38:39.389852      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:40.390237      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/11/25 14:38:41.204
  STEP: Ensuring resource quota status released the pod usage @ 05/11/25 14:38:41.213
  E0511 14:38:41.390611      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:42.391161      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:38:43.218367 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3089" for this suite. @ 05/11/25 14:38:43.221
• [16.121 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:270
  STEP: Creating a kubernetes client @ 05/11/25 14:38:43.231
  I0511 14:38:43.231681 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 14:38:43.232
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:38:43.243
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:38:43.246
  STEP: Setting up server cert @ 05/11/25 14:38:43.263
  E0511 14:38:43.391658      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 14:38:43.636
  STEP: Deploying the webhook pod @ 05/11/25 14:38:43.645
  STEP: Wait for the deployment to be ready @ 05/11/25 14:38:43.658
  I0511 14:38:43.662090 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0511 14:38:44.392292      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:45.392777      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/11/25 14:38:45.673
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 14:38:45.687
  E0511 14:38:46.393129      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:38:46.688642 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 05/11/25 14:38:46.692
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 05/11/25 14:38:46.711
  STEP: Creating a dummy validating-webhook-configuration object @ 05/11/25 14:38:46.725
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 05/11/25 14:38:46.734
  STEP: Creating a dummy mutating-webhook-configuration object @ 05/11/25 14:38:46.739
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 05/11/25 14:38:46.747
  I0511 14:38:46.791329 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8600" for this suite. @ 05/11/25 14:38:46.793
  STEP: Destroying namespace "webhook-markers-6342" for this suite. @ 05/11/25 14:38:46.797
• [3.569 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:55
  STEP: Creating a kubernetes client @ 05/11/25 14:38:46.804
  I0511 14:38:46.804640 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename dns @ 05/11/25 14:38:46.805
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:38:46.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:38:46.813
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 05/11/25 14:38:46.815
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 05/11/25 14:38:46.815
  STEP: creating a pod to probe DNS @ 05/11/25 14:38:46.815
  STEP: submitting the pod to kubernetes @ 05/11/25 14:38:46.815
  E0511 14:38:47.393711      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:48.394698      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/11/25 14:38:48.829
  STEP: looking for the results for each expected name from probers @ 05/11/25 14:38:48.832
  I0511 14:38:48.844718 26 dns_common.go:546] DNS probes using dns-3768/dns-test-04833a25-a4ca-4793-af29-c89b8a2ec213 succeeded

  STEP: deleting the pod @ 05/11/25 14:38:48.844
  I0511 14:38:48.855980 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-3768" for this suite. @ 05/11/25 14:38:48.86
• [2.063 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:142
  STEP: Creating a kubernetes client @ 05/11/25 14:38:48.869
  I0511 14:38:48.869671 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename secrets @ 05/11/25 14:38:48.871
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:38:48.881
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:38:48.883
  STEP: Creating projection with secret that has name secret-emptykey-test-5c257012-0340-494e-8dc0-7f5b1ab838b2 @ 05/11/25 14:38:48.885
  I0511 14:38:48.886380 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4511" for this suite. @ 05/11/25 14:38:48.96
• [0.098 seconds]
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:275
  STEP: Creating a kubernetes client @ 05/11/25 14:38:48.967
  I0511 14:38:48.967694 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename namespaces @ 05/11/25 14:38:48.968
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:38:48.978
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:38:48.981
  STEP: creating a Namespace @ 05/11/25 14:38:48.984
  STEP: patching the Namespace @ 05/11/25 14:38:48.992
  STEP: get the Namespace and ensuring it has the label @ 05/11/25 14:38:48.996
  I0511 14:38:48.999957 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6717" for this suite. @ 05/11/25 14:38:49.061
  STEP: Destroying namespace "nspatchtest-af2998dd-9fab-41f0-b798-bceada20378c-823" for this suite. @ 05/11/25 14:38:49.066
• [0.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:770
  STEP: Creating a kubernetes client @ 05/11/25 14:38:49.074
  I0511 14:38:49.074185 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename svcaccounts @ 05/11/25 14:38:49.075
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:38:49.083
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:38:49.087
  I0511 14:38:49.092809 26 service_accounts.go:782] Got root ca configmap in namespace "svcaccounts-7823"
  I0511 14:38:49.096857 26 service_accounts.go:785] Deleted root ca configmap in namespace "svcaccounts-7823"
  E0511 14:38:49.395810      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: waiting for a new root ca configmap created @ 05/11/25 14:38:49.597
  I0511 14:38:49.601381 26 service_accounts.go:799] Recreated root ca configmap in namespace "svcaccounts-7823"
  I0511 14:38:49.607413 26 service_accounts.go:810] Updated root ca configmap in namespace "svcaccounts-7823"
  STEP: waiting for the root ca configmap reconciled @ 05/11/25 14:38:50.107
  I0511 14:38:50.110916 26 service_accounts.go:828] Reconciled root ca configmap in namespace "svcaccounts-7823"
  I0511 14:38:50.111073 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7823" for this suite. @ 05/11/25 14:38:50.113
• [1.045 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:351
  STEP: Creating a kubernetes client @ 05/11/25 14:38:50.119
  I0511 14:38:50.119690 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename disruption @ 05/11/25 14:38:50.12
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:38:50.13
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:38:50.133
  STEP: Creating a pdb that targets all three pods in a test replica set @ 05/11/25 14:38:50.135
  STEP: Waiting for the pdb to be processed @ 05/11/25 14:38:50.139
  E0511 14:38:50.396899      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:51.397507      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 05/11/25 14:38:52.151
  STEP: Waiting for all pods to be running @ 05/11/25 14:38:52.151
  I0511 14:38:52.154970 26 disruption.go:680] pods: 0 < 3
  E0511 14:38:52.398120      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:53.398544      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 05/11/25 14:38:54.18
  STEP: Updating the pdb to allow a pod to be evicted @ 05/11/25 14:38:54.202
  STEP: Waiting for the pdb to be processed @ 05/11/25 14:38:54.207
  E0511 14:38:54.399400      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:55.399723      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 05/11/25 14:38:56.214
  STEP: Waiting for all pods to be running @ 05/11/25 14:38:56.214
  STEP: Waiting for the pdb to observed all healthy pods @ 05/11/25 14:38:56.217
  STEP: Patching the pdb to disallow a pod to be evicted @ 05/11/25 14:38:56.238
  STEP: Waiting for the pdb to be processed @ 05/11/25 14:38:56.261
  E0511 14:38:56.400377      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:38:57.401704      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 05/11/25 14:38:58.267
  STEP: locating a running pod @ 05/11/25 14:38:58.271
  STEP: Deleting the pdb to allow a pod to be evicted @ 05/11/25 14:38:58.279
  STEP: Waiting for the pdb to be deleted @ 05/11/25 14:38:58.285
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 05/11/25 14:38:58.288
  STEP: Waiting for all pods to be running @ 05/11/25 14:38:58.288
  I0511 14:38:58.385347 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-8919" for this suite. @ 05/11/25 14:38:58.39
• [8.278 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:920
  STEP: Creating a kubernetes client @ 05/11/25 14:38:58.397
  I0511 14:38:58.397924 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename statefulset @ 05/11/25 14:38:58.399
  E0511 14:38:58.401614      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:38:58.413
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:38:58.416
  STEP: Creating service test in namespace statefulset-1548 @ 05/11/25 14:38:58.417
  STEP: Creating statefulset ss in namespace statefulset-1548 @ 05/11/25 14:38:58.42
  I0511 14:38:58.434604 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
  E0511 14:38:59.401805      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:00.402454      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:01.403019      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:02.404046      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:03.404880      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:04.405546      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:05.405770      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:06.406343      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:07.406891      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:08.407956      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:39:08.431007 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 05/11/25 14:39:08.435
  STEP: updating a scale subresource @ 05/11/25 14:39:08.438
  STEP: verifying the statefulset Spec.Replicas was modified @ 05/11/25 14:39:08.444
  STEP: Patch a scale subresource @ 05/11/25 14:39:08.447
  STEP: verifying the statefulset Spec.Replicas was modified @ 05/11/25 14:39:08.453
  I0511 14:39:08.456708 26 statefulset.go:138] Deleting all statefulset in ns statefulset-1548
  I0511 14:39:08.460552 26 rest.go:153] Scaling statefulset ss to 0
  E0511 14:39:09.408261      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:10.408659      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:11.409193      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:12.409887      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:13.410895      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:14.411806      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:15.411842      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:16.412534      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:17.412712      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:18.412829      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:39:18.477089 26 wait.go:159] Waiting for statefulset status.replicas updated to 0
  I0511 14:39:18.479637 26 rest.go:91] Deleting statefulset ss
  I0511 14:39:18.491287 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1548" for this suite. @ 05/11/25 14:39:18.494
• [20.101 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:89
  STEP: Creating a kubernetes client @ 05/11/25 14:39:18.499
  I0511 14:39:18.499305 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename configmap @ 05/11/25 14:39:18.5
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:39:18.51
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:39:18.512
  STEP: Creating configMap with name configmap-test-volume-map-a786cd8c-ac3a-4063-a76f-562967b3db66 @ 05/11/25 14:39:18.515
  STEP: Creating a pod to test consume configMaps @ 05/11/25 14:39:18.519
  E0511 14:39:19.413806      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:20.414153      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:21.414587      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:22.415044      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:39:22.537
  I0511 14:39:22.539150 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-49f2ac7d-7206-44a7-8a72-3a975e92ec03 container agnhost-container: <nil>
  STEP: delete the pod @ 05/11/25 14:39:22.547
  I0511 14:39:22.563944 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8017" for this suite. @ 05/11/25 14:39:22.567
• [4.073 seconds]
------------------------------
SS
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 05/11/25 14:39:22.572
  I0511 14:39:22.572671 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename ingressclass @ 05/11/25 14:39:22.573
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:39:22.581
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:39:22.584
  STEP: getting /apis @ 05/11/25 14:39:22.587
  STEP: getting /apis/networking.k8s.io @ 05/11/25 14:39:22.59
  STEP: getting /apis/networking.k8s.iov1 @ 05/11/25 14:39:22.591
  STEP: creating @ 05/11/25 14:39:22.592
  STEP: getting @ 05/11/25 14:39:22.603
  STEP: listing @ 05/11/25 14:39:22.605
  STEP: watching @ 05/11/25 14:39:22.607
  I0511 14:39:22.607187 26 ingressclass.go:348] starting watch
  STEP: patching @ 05/11/25 14:39:22.608
  STEP: updating @ 05/11/25 14:39:22.613
  I0511 14:39:22.616626 26 ingressclass.go:364] waiting for watch events with expected annotations
  I0511 14:39:22.616671 26 ingressclass.go:377] saw patched and updated annotations
  STEP: deleting @ 05/11/25 14:39:22.616
  STEP: deleting a collection @ 05/11/25 14:39:22.623
  I0511 14:39:22.632269 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-6995" for this suite. @ 05/11/25 14:39:22.669
• [0.101 seconds]
------------------------------
S
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 05/11/25 14:39:22.674
  I0511 14:39:22.674075 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename init-container @ 05/11/25 14:39:22.675
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:39:22.683
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:39:22.686
  STEP: creating the pod @ 05/11/25 14:39:22.688
  I0511 14:39:22.688143 26 init_container.go:213] PodSpec: initContainers in spec.initContainers
  E0511 14:39:23.415574      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:24.415909      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:25.415957      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:26.416342      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:39:27.375429 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-9237" for this suite. @ 05/11/25 14:39:27.377
• [4.707 seconds]
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 05/11/25 14:39:27.38
  I0511 14:39:27.380609 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename hostport @ 05/11/25 14:39:27.381
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:39:27.387
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:39:27.389
  E0511 14:39:27.417117      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 05/11/25 14:39:27.48
  E0511 14:39:28.417622      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:29.418101      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.49.2 on the node which pod1 resides and expect scheduled @ 05/11/25 14:39:29.498
  E0511 14:39:30.419279      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:31.419771      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.49.2 but use UDP protocol on the node which pod2 resides @ 05/11/25 14:39:31.513
  E0511 14:39:32.420712      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:33.420883      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:34.421154      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:35.421692      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:36.422820      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:37.423321      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 05/11/25 14:39:37.552
  I0511 14:39:37.552063 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.49.2 http://127.0.0.1:54323/hostname] Namespace:hostport-9391 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 14:39:37.552093 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 14:39:37.552174 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/hostport-9391/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.49.2+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&stderr=true&stdout=true)
  I0511 14:39:37.609482 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.49.2, port: 54323 @ 05/11/25 14:39:37.609
  I0511 14:39:37.609537 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.49.2:54323/hostname] Namespace:hostport-9391 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 14:39:37.609542 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 14:39:37.609586 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/hostport-9391/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.49.2%3A54323%2Fhostname&container=e2e-host-exec&stderr=true&stdout=true)
  I0511 14:39:37.668660 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.49.2, port: 54323 UDP @ 05/11/25 14:39:37.668
  I0511 14:39:37.668795 26 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.49.2 54323] Namespace:hostport-9391 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0511 14:39:37.668838 26 exec_util.go:68] ExecWithOptions: Clientset creation
  I0511 14:39:37.668918 26 exec_util.go:84] ExecWithOptions: execute(https://10.96.0.1:443/api/v1/namespaces/hostport-9391/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.49.2+54323&container=e2e-host-exec&stderr=true&stdout=true)
  E0511 14:39:38.424529      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:39.424588      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:40.425122      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:41.425172      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:42.425785      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:39:42.752263 26 exec_util.go:201] unexpected error trying to use websockets for pod exec: <nil>
  I0511 14:39:42.752538 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-9391" for this suite. @ 05/11/25 14:39:42.756
• [15.382 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:351
  STEP: Creating a kubernetes client @ 05/11/25 14:39:42.762
  I0511 14:39:42.762894 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubectl @ 05/11/25 14:39:42.763
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:39:42.771
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:39:42.773
  STEP: creating a replication controller @ 05/11/25 14:39:42.775
  I0511 14:39:42.775198 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 create -f -'
  I0511 14:39:42.851069 26 builder.go:146] stderr: ""
  I0511 14:39:42.851118 26 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/11/25 14:39:42.851
  I0511 14:39:42.851197 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:39:42.898134 26 builder.go:146] stderr: ""
  I0511 14:39:42.898170 26 builder.go:147] stdout: "update-demo-nautilus-l7zjl update-demo-nautilus-n9wqx "
  I0511 14:39:42.898215 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-l7zjl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:39:42.936791 26 builder.go:146] stderr: ""
  I0511 14:39:42.936827 26 builder.go:147] stdout: ""
  I0511 14:39:42.936836 26 kubectl.go:2505] update-demo-nautilus-l7zjl is created but not running
  E0511 14:39:43.426643      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:44.427195      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:45.427430      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:46.427860      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:47.428731      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:39:47.937228 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:39:47.987371 26 builder.go:146] stderr: ""
  I0511 14:39:47.987404 26 builder.go:147] stdout: "update-demo-nautilus-l7zjl update-demo-nautilus-n9wqx "
  I0511 14:39:47.987450 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-l7zjl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:39:48.027421 26 builder.go:146] stderr: ""
  I0511 14:39:48.027495 26 builder.go:147] stdout: "true"
  I0511 14:39:48.027535 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-l7zjl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0511 14:39:48.077295 26 builder.go:146] stderr: ""
  I0511 14:39:48.077329 26 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0511 14:39:48.077340 26 kubectl.go:2396] validating pod update-demo-nautilus-l7zjl
  I0511 14:39:48.080762 26 kubectl.go:2416] got data: {
    "image": "nautilus.jpg"
  }

  I0511 14:39:48.080811 26 kubectl.go:2421] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0511 14:39:48.080822 26 kubectl.go:2523] update-demo-nautilus-l7zjl is verified up and running
  I0511 14:39:48.080854 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-n9wqx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:39:48.121512 26 builder.go:146] stderr: ""
  I0511 14:39:48.121541 26 builder.go:147] stdout: "true"
  I0511 14:39:48.121571 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-n9wqx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0511 14:39:48.160316 26 builder.go:146] stderr: ""
  I0511 14:39:48.160350 26 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0511 14:39:48.160362 26 kubectl.go:2396] validating pod update-demo-nautilus-n9wqx
  I0511 14:39:48.162453 26 kubectl.go:2416] got data: {
    "image": "nautilus.jpg"
  }

  I0511 14:39:48.162491 26 kubectl.go:2421] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0511 14:39:48.162502 26 kubectl.go:2523] update-demo-nautilus-n9wqx is verified up and running
  STEP: scaling down the replication controller @ 05/11/25 14:39:48.162
  I0511 14:39:48.163471 26 kubectl.go:320] scanned /root for discovery docs: <nil>
  I0511 14:39:48.163500 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E0511 14:39:48.428773      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:39:49.213404 26 builder.go:146] stderr: ""
  I0511 14:39:49.213481 26 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/11/25 14:39:49.213
  I0511 14:39:49.213625 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:39:49.256724 26 builder.go:146] stderr: ""
  I0511 14:39:49.256758 26 builder.go:147] stdout: "update-demo-nautilus-l7zjl "
  I0511 14:39:49.256798 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-l7zjl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:39:49.298188 26 builder.go:146] stderr: ""
  I0511 14:39:49.298213 26 builder.go:147] stdout: "true"
  I0511 14:39:49.298241 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-l7zjl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0511 14:39:49.334004 26 builder.go:146] stderr: ""
  I0511 14:39:49.334028 26 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0511 14:39:49.334035 26 kubectl.go:2396] validating pod update-demo-nautilus-l7zjl
  I0511 14:39:49.335591 26 kubectl.go:2416] got data: {
    "image": "nautilus.jpg"
  }

  I0511 14:39:49.335633 26 kubectl.go:2421] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0511 14:39:49.335645 26 kubectl.go:2523] update-demo-nautilus-l7zjl is verified up and running
  STEP: scaling up the replication controller @ 05/11/25 14:39:49.335
  I0511 14:39:49.336451 26 kubectl.go:320] scanned /root for discovery docs: <nil>
  I0511 14:39:49.336486 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E0511 14:39:49.429870      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:39:50.385273 26 builder.go:146] stderr: ""
  I0511 14:39:50.385332 26 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/11/25 14:39:50.385
  I0511 14:39:50.385451 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:39:50.429920 26 builder.go:146] stderr: ""
  E0511 14:39:50.429956      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:39:50.429955 26 builder.go:147] stdout: "update-demo-nautilus-94s69 update-demo-nautilus-l7zjl "
  I0511 14:39:50.429997 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-94s69 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:39:50.468091 26 builder.go:146] stderr: ""
  I0511 14:39:50.468128 26 builder.go:147] stdout: ""
  I0511 14:39:50.468137 26 kubectl.go:2505] update-demo-nautilus-94s69 is created but not running
  E0511 14:39:51.430786      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:52.431425      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:53.431823      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:54.432340      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:55.432635      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:39:55.468966 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0511 14:39:55.520033 26 builder.go:146] stderr: ""
  I0511 14:39:55.520067 26 builder.go:147] stdout: "update-demo-nautilus-94s69 update-demo-nautilus-l7zjl "
  I0511 14:39:55.520095 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-94s69 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:39:55.566135 26 builder.go:146] stderr: ""
  I0511 14:39:55.566167 26 builder.go:147] stdout: "true"
  I0511 14:39:55.566193 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-94s69 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0511 14:39:55.607261 26 builder.go:146] stderr: ""
  I0511 14:39:55.607301 26 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0511 14:39:55.607311 26 kubectl.go:2396] validating pod update-demo-nautilus-94s69
  I0511 14:39:55.609401 26 kubectl.go:2416] got data: {
    "image": "nautilus.jpg"
  }

  I0511 14:39:55.609438 26 kubectl.go:2421] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0511 14:39:55.609446 26 kubectl.go:2523] update-demo-nautilus-94s69 is verified up and running
  I0511 14:39:55.609479 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-l7zjl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0511 14:39:55.644288 26 builder.go:146] stderr: ""
  I0511 14:39:55.644322 26 builder.go:147] stdout: "true"
  I0511 14:39:55.644358 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods update-demo-nautilus-l7zjl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0511 14:39:55.678980 26 builder.go:146] stderr: ""
  I0511 14:39:55.679007 26 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0511 14:39:55.679016 26 kubectl.go:2396] validating pod update-demo-nautilus-l7zjl
  I0511 14:39:55.680452 26 kubectl.go:2416] got data: {
    "image": "nautilus.jpg"
  }

  I0511 14:39:55.680504 26 kubectl.go:2421] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0511 14:39:55.680516 26 kubectl.go:2523] update-demo-nautilus-l7zjl is verified up and running
  STEP: using delete to clean up resources @ 05/11/25 14:39:55.68
  I0511 14:39:55.680588 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 delete --grace-period=0 --force -f -'
  I0511 14:39:55.717985 26 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0511 14:39:55.718019 26 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I0511 14:39:55.718060 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get rc,svc -l name=update-demo --no-headers'
  I0511 14:39:55.778838 26 builder.go:146] stderr: "No resources found in kubectl-473 namespace.\n"
  I0511 14:39:55.778879 26 builder.go:147] stdout: ""
  I0511 14:39:55.778922 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-473 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0511 14:39:55.820950 26 builder.go:146] stderr: ""
  I0511 14:39:55.820995 26 builder.go:147] stdout: ""
  I0511 14:39:55.821100 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-473" for this suite. @ 05/11/25 14:39:55.824
• [13.066 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:640
  STEP: Creating a kubernetes client @ 05/11/25 14:39:55.829
  I0511 14:39:55.829114 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 14:39:55.829
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:39:55.841
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:39:55.844
  STEP: Setting up server cert @ 05/11/25 14:39:55.855
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 14:39:55.964
  STEP: Deploying the webhook pod @ 05/11/25 14:39:55.967
  STEP: Wait for the deployment to be ready @ 05/11/25 14:39:55.973
  I0511 14:39:55.977531 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0511 14:39:56.432640      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:39:57.432943      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/11/25 14:39:57.989
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 14:39:58.006
  E0511 14:39:58.433796      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:39:59.007241 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 05/11/25 14:39:59.067
  STEP: Creating a configMap that should be mutated @ 05/11/25 14:39:59.078
  STEP: Deleting the collection of validation webhooks @ 05/11/25 14:39:59.099
  STEP: Creating a configMap that should not be mutated @ 05/11/25 14:39:59.127
  I0511 14:39:59.167111 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1712" for this suite. @ 05/11/25 14:39:59.168
  STEP: Destroying namespace "webhook-markers-128" for this suite. @ 05/11/25 14:39:59.172
• [3.347 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:444
  STEP: Creating a kubernetes client @ 05/11/25 14:39:59.176
  I0511 14:39:59.176230 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/11/25 14:39:59.177
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:39:59.183
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:39:59.185
  STEP: set up a multi version CRD @ 05/11/25 14:39:59.186
  I0511 14:39:59.186990 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  E0511 14:39:59.434073      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:00.434272      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:01.435017      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: mark a version not serverd @ 05/11/25 14:40:02.179
  STEP: check the unserved version gets removed @ 05/11/25 14:40:02.189
  E0511 14:40:02.435296      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 05/11/25 14:40:02.83
  E0511 14:40:03.435449      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:04.436550      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:40:05.173560 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4859" for this suite. @ 05/11/25 14:40:05.18
• [6.009 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1251
  STEP: Creating a kubernetes client @ 05/11/25 14:40:05.185
  I0511 14:40:05.185410 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename services @ 05/11/25 14:40:05.186
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:40:05.195
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:40:05.197
  STEP: creating service nodeport-test with type=NodePort in namespace services-9299 @ 05/11/25 14:40:05.2
  I0511 14:40:05.225568 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0511 14:40:05.436786      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:06.436910      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:40:07.230696 26 resource.go:361] Creating new exec pod
  E0511 14:40:07.437656      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:08.438034      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:40:09.255231 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-9299 exec execpodnwjjq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  I0511 14:40:09.358354 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test (10.106.193.149) 80 port [tcp/http] succeeded!\n"
  I0511 14:40:09.358403 26 builder.go:147] stdout: "nodeport-test-64f748c95b-j9vfp"
  I0511 14:40:09.358509 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-9299 exec execpodnwjjq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.106.193.149 80'
  E0511 14:40:09.439016      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:40:09.449935 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.106.193.149 80\nConnection to 10.106.193.149 80 port [tcp/http] succeeded!\n"
  I0511 14:40:09.450001 26 builder.go:147] stdout: "nodeport-test-64f748c95b-j9vfp"
  I0511 14:40:09.450120 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-9299 exec execpodnwjjq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.49.2 31067'
  I0511 14:40:09.550286 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.49.2 31067\nConnection to 192.168.49.2 31067 port [tcp/*] succeeded!\n"
  I0511 14:40:09.550343 26 builder.go:147] stdout: "nodeport-test-64f748c95b-q82wt"
  I0511 14:40:09.550446 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-9299 exec execpodnwjjq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.49.3 31067'
  I0511 14:40:09.652872 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.49.3 31067\nConnection to 192.168.49.3 31067 port [tcp/*] succeeded!\n"
  I0511 14:40:09.652919 26 builder.go:147] stdout: ""
  E0511 14:40:10.439952      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:40:10.551404 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-9299 exec execpodnwjjq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.49.3 31067'
  I0511 14:40:10.649119 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.49.3 31067\nConnection to 192.168.49.3 31067 port [tcp/*] succeeded!\n"
  I0511 14:40:10.649183 26 builder.go:147] stdout: ""
  E0511 14:40:11.440189      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:40:11.551518 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-9299 exec execpodnwjjq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.49.3 31067'
  I0511 14:40:11.635277 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.49.3 31067\nConnection to 192.168.49.3 31067 port [tcp/*] succeeded!\n"
  I0511 14:40:11.635326 26 builder.go:147] stdout: "nodeport-test-64f748c95b-q82wt"
  I0511 14:40:11.635522 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9299" for this suite. @ 05/11/25 14:40:11.638
• [6.458 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:85
  STEP: Creating a kubernetes client @ 05/11/25 14:40:11.643
  I0511 14:40:11.643915 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename downward-api @ 05/11/25 14:40:11.644
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:40:11.653
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:40:11.654
  STEP: Creating a pod to test downward API volume plugin @ 05/11/25 14:40:11.656
  E0511 14:40:12.440551      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:13.440850      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:14.441124      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:15.441917      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:40:15.67
  I0511 14:40:15.673420 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-00eafd80-3117-476a-92d7-810285a885fe container client-container: <nil>
  STEP: delete the pod @ 05/11/25 14:40:15.678
  I0511 14:40:15.688988 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2900" for this suite. @ 05/11/25 14:40:15.69
• [4.051 seconds]
------------------------------
S
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:87
  STEP: Creating a kubernetes client @ 05/11/25 14:40:15.694
  I0511 14:40:15.694784 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename replication-controller @ 05/11/25 14:40:15.695
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:40:15.702
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:40:15.705
  I0511 14:40:15.706708 26 rc.go:546] Creating quota "condition-test" that allows only two pods to run in the current namespace
  E0511 14:40:16.443019      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 05/11/25 14:40:16.715
  STEP: Checking rc "condition-test" has the desired failure condition set @ 05/11/25 14:40:16.719
  E0511 14:40:17.443884      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 05/11/25 14:40:17.727
  I0511 14:40:17.736393 26 rc.go:733] Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 05/11/25 14:40:17.736
  E0511 14:40:18.444331      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:40:18.741799 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-873" for this suite. @ 05/11/25 14:40:18.746
• [3.056 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:191
  STEP: Creating a kubernetes client @ 05/11/25 14:40:18.751
  I0511 14:40:18.751227 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename svcaccounts @ 05/11/25 14:40:18.752
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:40:18.762
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:40:18.764
  I0511 14:40:18.779998 26 service_accounts.go:281] created pod pod-service-account-defaultsa
  I0511 14:40:18.780030 26 service_accounts.go:295] pod pod-service-account-defaultsa service account token volume mount: true
  I0511 14:40:18.784563 26 service_accounts.go:281] created pod pod-service-account-mountsa
  I0511 14:40:18.784621 26 service_accounts.go:295] pod pod-service-account-mountsa service account token volume mount: true
  I0511 14:40:18.792165 26 service_accounts.go:281] created pod pod-service-account-nomountsa
  I0511 14:40:18.792216 26 service_accounts.go:295] pod pod-service-account-nomountsa service account token volume mount: false
  I0511 14:40:18.799184 26 service_accounts.go:281] created pod pod-service-account-defaultsa-mountspec
  I0511 14:40:18.799226 26 service_accounts.go:295] pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  I0511 14:40:18.808272 26 service_accounts.go:281] created pod pod-service-account-mountsa-mountspec
  I0511 14:40:18.808317 26 service_accounts.go:295] pod pod-service-account-mountsa-mountspec service account token volume mount: true
  I0511 14:40:18.815373 26 service_accounts.go:281] created pod pod-service-account-nomountsa-mountspec
  I0511 14:40:18.815415 26 service_accounts.go:295] pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  I0511 14:40:18.823480 26 service_accounts.go:281] created pod pod-service-account-defaultsa-nomountspec
  I0511 14:40:18.823521 26 service_accounts.go:295] pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  I0511 14:40:18.832195 26 service_accounts.go:281] created pod pod-service-account-mountsa-nomountspec
  I0511 14:40:18.832235 26 service_accounts.go:295] pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  I0511 14:40:18.837676 26 service_accounts.go:281] created pod pod-service-account-nomountsa-nomountspec
  I0511 14:40:18.837715 26 service_accounts.go:295] pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  I0511 14:40:18.837825 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7284" for this suite. @ 05/11/25 14:40:18.847
• [0.107 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:329
  STEP: Creating a kubernetes client @ 05/11/25 14:40:18.857
  I0511 14:40:18.857950 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 14:40:18.858
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:40:18.868
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:40:18.87
  STEP: Setting up server cert @ 05/11/25 14:40:18.883
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 14:40:18.952
  STEP: Deploying the webhook pod @ 05/11/25 14:40:18.957
  STEP: Wait for the deployment to be ready @ 05/11/25 14:40:18.966
  I0511 14:40:18.970912 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0511 14:40:19.444304      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:20.444750      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/11/25 14:40:20.981
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 14:40:20.996
  E0511 14:40:21.444929      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:40:21.997584 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0511 14:40:22.001410 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  E0511 14:40:22.445329      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8777-crds.webhook.example.com via the AdmissionRegistration API @ 05/11/25 14:40:22.511
  STEP: Creating a custom resource that should be mutated by the webhook @ 05/11/25 14:40:22.528
  E0511 14:40:23.445401      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:24.445998      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:40:25.109367 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9108" for this suite. @ 05/11/25 14:40:25.113
  STEP: Destroying namespace "webhook-markers-5173" for this suite. @ 05/11/25 14:40:25.119
• [6.268 seconds]
------------------------------
S
------------------------------
[sig-network] ServiceCIDR and IPAddress API should support ServiceCIDR API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_cidrs.go:163
  STEP: Creating a kubernetes client @ 05/11/25 14:40:25.125
  I0511 14:40:25.125942 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename servicecidr @ 05/11/25 14:40:25.127
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:40:25.136
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:40:25.138
  STEP: getting @ 05/11/25 14:40:25.141
  STEP: patching @ 05/11/25 14:40:25.142
  STEP: updating @ 05/11/25 14:40:25.148
  STEP: listing @ 05/11/25 14:40:25.176
  STEP: watching @ 05/11/25 14:40:25.18
  I0511 14:40:25.182141 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "servicecidr-4548" for this suite. @ 05/11/25 14:40:25.212
• [0.090 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:207
  STEP: Creating a kubernetes client @ 05/11/25 14:40:25.216
  I0511 14:40:25.216050 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 14:40:25.217
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:40:25.222
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:40:25.224
  STEP: Setting up server cert @ 05/11/25 14:40:25.236
  E0511 14:40:25.446290      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 14:40:25.452
  STEP: Deploying the webhook pod @ 05/11/25 14:40:25.455
  STEP: Wait for the deployment to be ready @ 05/11/25 14:40:25.462
  I0511 14:40:25.465688 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0511 14:40:26.446890      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:27.448013      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/11/25 14:40:27.477
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 14:40:27.491
  E0511 14:40:28.448965      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:40:28.492970 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 05/11/25 14:40:28.496
  STEP: create a pod @ 05/11/25 14:40:28.512
  E0511 14:40:29.449888      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:30.450674      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 05/11/25 14:40:30.524
  I0511 14:40:30.524373 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=webhook-6996 attach --namespace=webhook-6996 to-be-attached-pod -i -c=container1'
  I0511 14:40:30.597280 26 builder.go:135] rc: 1
  I0511 14:40:30.625608 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6996" for this suite. @ 05/11/25 14:40:30.628
  STEP: Destroying namespace "webhook-markers-2169" for this suite. @ 05/11/25 14:40:30.635
• [5.422 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:247
  STEP: Creating a kubernetes client @ 05/11/25 14:40:30.638
  I0511 14:40:30.638586 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 14:40:30.639
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:40:30.646
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:40:30.649
  STEP: Setting up server cert @ 05/11/25 14:40:30.664
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 14:40:31.038
  STEP: Deploying the webhook pod @ 05/11/25 14:40:31.041
  STEP: Wait for the deployment to be ready @ 05/11/25 14:40:31.047
  I0511 14:40:31.051375 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0511 14:40:31.451173      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:32.452053      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/11/25 14:40:33.062
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 14:40:33.078
  E0511 14:40:33.452534      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:40:34.079693 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 05/11/25 14:40:34.088
  STEP: create a configmap that should be updated by the webhook @ 05/11/25 14:40:34.109
  I0511 14:40:34.158219 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1802" for this suite. @ 05/11/25 14:40:34.16
  STEP: Destroying namespace "webhook-markers-1780" for this suite. @ 05/11/25 14:40:34.165
• [3.531 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:488
  STEP: Creating a kubernetes client @ 05/11/25 14:40:34.169
  I0511 14:40:34.169496 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename gc @ 05/11/25 14:40:34.17
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:40:34.179
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:40:34.181
  STEP: create the deployment @ 05/11/25 14:40:34.183
  I0511 14:40:34.188122      26 warnings.go:110] "Warning: metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]"
  STEP: Wait for the Deployment to create new ReplicaSet @ 05/11/25 14:40:34.188
  E0511 14:40:34.452927      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 05/11/25 14:40:34.694
  STEP: wait for all rs to be garbage collected @ 05/11/25 14:40:34.698
  STEP: expected 0 pods, got 2 pods @ 05/11/25 14:40:34.71
  STEP: Gathering metrics @ 05/11/25 14:40:35.21
  I0511 14:40:35.302733 26 garbage_collector.go:273] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0511 14:40:35.303001 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-6663" for this suite. @ 05/11/25 14:40:35.31
• [1.144 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 05/11/25 14:40:35.314
  I0511 14:40:35.314078 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename cronjob @ 05/11/25 14:40:35.315
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:40:35.325
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:40:35.328
  STEP: Creating a ForbidConcurrent cronjob @ 05/11/25 14:40:35.331
  STEP: Ensuring a job is scheduled @ 05/11/25 14:40:35.334
  E0511 14:40:35.453856      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:36.454298      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:37.454962      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:38.455404      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:39.456172      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:40.456624      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:41.456840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:42.457498      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:43.458065      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:44.458576      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:45.458611      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:46.459211      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:47.459908      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:48.460364      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:49.460817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:50.461011      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:51.462803      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:52.462999      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:53.463579      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:54.464038      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:55.464777      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:56.465284      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:57.465517      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:58.465976      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:40:59.466195      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:00.466756      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 05/11/25 14:41:01.339
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 05/11/25 14:41:01.342
  STEP: Ensuring no more jobs are scheduled @ 05/11/25 14:41:01.345
  STEP: Removing cronjob @ 05/11/25 14:41:01.347
  I0511 14:41:01.353586 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-2983" for this suite. @ 05/11/25 14:41:01.357
• [26.050 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Job with successPolicy succeededCount rule should succeeded even when some indexes remain pending [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:567
  STEP: Creating a kubernetes client @ 05/11/25 14:41:01.364
  I0511 14:41:01.364120 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename job @ 05/11/25 14:41:01.365
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:41:01.377
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:41:01.38
  STEP: Creating an indexed job with successPolicy succeededCount rule @ 05/11/25 14:41:01.382
  STEP: Awaiting for the job to have the interim SuccessCriteriaMet condition with SuccessPolicy reason @ 05/11/25 14:41:01.386
  E0511 14:41:01.467315      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:02.467773      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:03.468917      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:04.469316      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensure that the job reaches completions @ 05/11/25 14:41:05.398
  STEP: Verifying that the job status to ensure correct final state @ 05/11/25 14:41:05.403
  I0511 14:41:05.405982 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1246" for this suite. @ 05/11/25 14:41:05.408
• [4.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:92
  STEP: Creating a kubernetes client @ 05/11/25 14:41:05.414
  I0511 14:41:05.414654 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename downward-api @ 05/11/25 14:41:05.415
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:41:05.424
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:41:05.427
  STEP: Creating a pod to test downward api env vars @ 05/11/25 14:41:05.429
  E0511 14:41:05.470329      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:06.470792      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:07.471726      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:08.472004      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:41:09.449
  I0511 14:41:09.452452 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downward-api-48c45456-4e2b-4c8f-a6b8-e7fbfbefc893 container dapi-container: <nil>
  STEP: delete the pod @ 05/11/25 14:41:09.46
  E0511 14:41:09.472506      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:41:09.480019 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3936" for this suite. @ 05/11/25 14:41:09.483
• [4.074 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1504
  STEP: Creating a kubernetes client @ 05/11/25 14:41:09.488
  I0511 14:41:09.488548 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename services @ 05/11/25 14:41:09.489
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:41:09.501
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:41:09.504
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-3438 @ 05/11/25 14:41:09.507
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 05/11/25 14:41:09.524
  STEP: creating service externalsvc in namespace services-3438 @ 05/11/25 14:41:09.524
  I0511 14:41:09.566603 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0511 14:41:10.472660      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:11.472857      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: changing the NodePort service to type=ExternalName @ 05/11/25 14:41:11.579
  I0511 14:41:11.601307 26 resource.go:361] Creating new exec pod
  E0511 14:41:12.473752      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:13.474783      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:41:13.614361 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-3438 exec execpodtgzh6 -- /bin/sh -x -c nslookup nodeport-service.services-3438.svc.cluster.local'
  I0511 14:41:13.749755 26 builder.go:146] stderr: "+ nslookup nodeport-service.services-3438.svc.cluster.local\n"
  I0511 14:41:13.749797 26 builder.go:147] stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-3438.svc.cluster.local\tcanonical name = externalsvc.services-3438.svc.cluster.local.\nName:\texternalsvc.services-3438.svc.cluster.local\nAddress: 10.108.62.157\n\n"
  I0511 14:41:13.770694 26 service.go:1515] Cleaning up the NodePort to ExternalName test service
  I0511 14:41:13.786584 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3438" for this suite. @ 05/11/25 14:41:13.79
• [4.308 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 05/11/25 14:41:13.797
  I0511 14:41:13.797029 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename replicaset @ 05/11/25 14:41:13.797
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:41:13.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:41:13.805
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 05/11/25 14:41:13.807
  I0511 14:41:13.819890 26 resource.go:81] Pod name sample-pod: Found 0 pods out of 1
  E0511 14:41:14.475798      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:15.476841      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:16.476738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:17.476939      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:18.477247      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:41:18.823747 26 resource.go:81] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/11/25 14:41:18.823
  STEP: getting scale subresource @ 05/11/25 14:41:18.823
  STEP: updating a scale subresource @ 05/11/25 14:41:18.826
  STEP: verifying the replicaset Spec.Replicas was modified @ 05/11/25 14:41:18.833
  STEP: Patch a scale subresource @ 05/11/25 14:41:18.837
  I0511 14:41:18.852779 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-9641" for this suite. @ 05/11/25 14:41:18.859
• [5.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:96
  STEP: Creating a kubernetes client @ 05/11/25 14:41:18.868
  I0511 14:41:18.868123 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename var-expansion @ 05/11/25 14:41:18.869
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:41:18.879
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:41:18.882
  STEP: Creating a pod to test substitution in container's args @ 05/11/25 14:41:18.883
  E0511 14:41:19.477415      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:20.477888      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:21.478848      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:22.479316      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:41:22.9
  I0511 14:41:22.902764 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod var-expansion-366ed542-2f94-478e-b649-74e9dee778fa container dapi-container: <nil>
  STEP: delete the pod @ 05/11/25 14:41:22.908
  I0511 14:41:22.923718 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-52" for this suite. @ 05/11/25 14:41:22.929
• [4.068 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 05/11/25 14:41:22.936
  I0511 14:41:22.936140 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename chunking @ 05/11/25 14:41:22.937
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:41:22.946
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:41:22.949
  STEP: creating a large number of resources @ 05/11/25 14:41:22.951
  E0511 14:41:23.479826      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:24.480558      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:25.481075      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:26.481694      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:27.481774      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:28.482676      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:29.482874      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:30.483696      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:31.484200      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:32.485346      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:33.485439      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:34.486445      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:35.487075      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:36.487289      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:37.488002      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:38.488270      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:39.488451      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:40.488693      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving those results in paged fashion several times @ 05/11/25 14:41:40.644
  I0511 14:41:40.692562 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  I0511 14:41:40.743414 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  I0511 14:41:40.792909 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  I0511 14:41:40.843662 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  I0511 14:41:40.893415 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  I0511 14:41:40.942792 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  I0511 14:41:40.993196 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  I0511 14:41:41.042311 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  I0511 14:41:41.093518 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  I0511 14:41:41.144148 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  I0511 14:41:41.193270 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  I0511 14:41:41.242385 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  I0511 14:41:41.293640 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  I0511 14:41:41.343499 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  I0511 14:41:41.393823 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  I0511 14:41:41.444289 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  E0511 14:41:41.488842      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:41:41.491831 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  I0511 14:41:41.543645 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  I0511 14:41:41.593688 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  I0511 14:41:41.643049 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  I0511 14:41:41.692917 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  I0511 14:41:41.743908 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  I0511 14:41:41.793349 26 chunking.go:98] Retrieved 17/17 results with rv 23333 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzMsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  I0511 14:41:41.842428 26 chunking.go:98] Retrieved 9/17 results with rv 23333 and continue 
  I0511 14:41:41.892176 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  I0511 14:41:41.943224 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  I0511 14:41:41.993322 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  I0511 14:41:42.043177 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  I0511 14:41:42.092816 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  I0511 14:41:42.143924 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  I0511 14:41:42.193756 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  I0511 14:41:42.243369 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  I0511 14:41:42.292849 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  I0511 14:41:42.340475 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  I0511 14:41:42.393853 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  I0511 14:41:42.443993 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  E0511 14:41:42.488993      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:41:42.493371 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  I0511 14:41:42.541393 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  I0511 14:41:42.593848 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  I0511 14:41:42.643772 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  I0511 14:41:42.691817 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  I0511 14:41:42.743731 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  I0511 14:41:42.793802 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  I0511 14:41:42.843527 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  I0511 14:41:42.894228 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  I0511 14:41:42.942552 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  I0511 14:41:42.992534 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  I0511 14:41:43.042164 26 chunking.go:98] Retrieved 9/17 results with rv 23335 and continue 
  I0511 14:41:43.093809 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  I0511 14:41:43.144085 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  I0511 14:41:43.192609 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  I0511 14:41:43.243041 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  I0511 14:41:43.292597 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  I0511 14:41:43.343545 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  I0511 14:41:43.393663 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  I0511 14:41:43.440798 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  E0511 14:41:43.489340      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:41:43.491132 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  I0511 14:41:43.540697 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  I0511 14:41:43.589900 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  I0511 14:41:43.641159 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  I0511 14:41:43.693148 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  I0511 14:41:43.745142 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  I0511 14:41:43.793133 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  I0511 14:41:43.842983 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  I0511 14:41:43.892935 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  I0511 14:41:43.943997 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  I0511 14:41:43.994194 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  I0511 14:41:44.042883 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  I0511 14:41:44.093342 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  I0511 14:41:44.142994 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  I0511 14:41:44.194089 26 chunking.go:98] Retrieved 17/17 results with rv 23335 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjMzMzUsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  I0511 14:41:44.243815 26 chunking.go:98] Retrieved 9/17 results with rv 23335 and continue 
  STEP: retrieving those results all at once @ 05/11/25 14:41:44.243
  I0511 14:41:44.300146 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-3751" for this suite. @ 05/11/25 14:41:44.342
• [21.455 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3404
  STEP: Creating a kubernetes client @ 05/11/25 14:41:44.391
  I0511 14:41:44.391631 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename services @ 05/11/25 14:41:44.392
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:41:44.4
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:41:44.403
  STEP: creating a Service @ 05/11/25 14:41:44.411
  STEP: watching for the Service to be added @ 05/11/25 14:41:44.429
  I0511 14:41:44.431562 26 service.go:3456] Found Service test-service-ltnmz in namespace services-9171 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 32332}]
  I0511 14:41:44.431619 26 service.go:3463] Service test-service-ltnmz created
  STEP: Getting /status @ 05/11/25 14:41:44.431
  I0511 14:41:44.435239 26 service.go:3474] Service test-service-ltnmz has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 05/11/25 14:41:44.435
  STEP: watching for the Service to be patched @ 05/11/25 14:41:44.44
  I0511 14:41:44.442201 26 service.go:3497] observed Service test-service-ltnmz in namespace services-9171 with annotations: map[] & LoadBalancer: {[]}
  I0511 14:41:44.442309 26 service.go:3500] Found Service test-service-ltnmz in namespace services-9171 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  0xc0039fd030 []}]}
  I0511 14:41:44.442334 26 service.go:3507] Service test-service-ltnmz has service status patched
  STEP: updating the ServiceStatus @ 05/11/25 14:41:44.442
  I0511 14:41:44.448073 26 service.go:3527] updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 05/11/25 14:41:44.448
  I0511 14:41:44.449496 26 service.go:3538] Observed Service test-service-ltnmz in namespace services-9171 with annotations: map[] & Conditions: []
  I0511 14:41:44.449516 26 service.go:3549] Observed Service test-service-ltnmz in namespace services-9171 with annotations: map[patchedstatus:true] & Conditions: []
  I0511 14:41:44.449693 26 service.go:3545] Found Service test-service-ltnmz in namespace services-9171 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0511 14:41:44.449728 26 service.go:3556] Service test-service-ltnmz has service status updated
  STEP: patching the service @ 05/11/25 14:41:44.449
  STEP: watching for the Service to be patched @ 05/11/25 14:41:44.458
  I0511 14:41:44.459963 26 service.go:3579] observed Service test-service-ltnmz in namespace services-9171 with labels: map[test-service-static:true]
  I0511 14:41:44.459987 26 service.go:3579] observed Service test-service-ltnmz in namespace services-9171 with labels: map[test-service-static:true]
  I0511 14:41:44.459999 26 service.go:3579] observed Service test-service-ltnmz in namespace services-9171 with labels: map[test-service-static:true]
  I0511 14:41:44.460022 26 service.go:3582] Found Service test-service-ltnmz in namespace services-9171 with labels: map[test-service:patched test-service-static:true]
  I0511 14:41:44.460033 26 service.go:3589] Service test-service-ltnmz patched
  STEP: deleting the service @ 05/11/25 14:41:44.46
  STEP: watching for the Service to be deleted @ 05/11/25 14:41:44.476
  I0511 14:41:44.477810 26 service.go:3613] Observed event: ADDED
  I0511 14:41:44.477854 26 service.go:3613] Observed event: MODIFIED
  I0511 14:41:44.477968 26 service.go:3613] Observed event: MODIFIED
  I0511 14:41:44.478005 26 service.go:3613] Observed event: MODIFIED
  I0511 14:41:44.478118 26 service.go:3609] Found Service test-service-ltnmz in namespace services-9171 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  I0511 14:41:44.478146 26 service.go:3618] Service test-service-ltnmz deleted
  I0511 14:41:44.478286 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9171" for this suite. @ 05/11/25 14:41:44.481
• [0.093 seconds]
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:47
  STEP: Creating a kubernetes client @ 05/11/25 14:41:44.484
  I0511 14:41:44.484928 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename configmap @ 05/11/25 14:41:44.485
  E0511 14:41:44.489363      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:41:44.493
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:41:44.495
  STEP: Creating configMap configmap-1840/configmap-test-89866560-07ac-45ef-ac5b-e6f5f994dbd3 @ 05/11/25 14:41:44.497
  STEP: Creating a pod to test consume configMaps @ 05/11/25 14:41:44.501
  E0511 14:41:45.490034      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:46.490544      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:47.490823      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:48.491410      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:41:48.521
  I0511 14:41:48.524008 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-cd987e81-0351-4cc1-94e6-6a3da6f4b404 container env-test: <nil>
  STEP: delete the pod @ 05/11/25 14:41:48.531
  I0511 14:41:48.547308 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1840" for this suite. @ 05/11/25 14:41:48.55
• [4.071 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:108
  STEP: Creating a kubernetes client @ 05/11/25 14:41:48.555
  I0511 14:41:48.555812 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename runtimeclass @ 05/11/25 14:41:48.557
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:41:48.566
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:41:48.569
  E0511 14:41:49.491717      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:50.492810      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:41:50.595128 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-6966" for this suite. @ 05/11/25 14:41:50.599
• [2.048 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:90
  STEP: Creating a kubernetes client @ 05/11/25 14:41:50.604
  I0511 14:41:50.604298 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename disruption @ 05/11/25 14:41:50.605
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:41:50.611
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:41:50.613
  STEP: Creating a kubernetes client @ 05/11/25 14:41:50.614
  I0511 14:41:50.614696 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename disruption-2 @ 05/11/25 14:41:50.615
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:41:50.622
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:41:50.624
  STEP: Waiting for the pdb to be processed @ 05/11/25 14:41:50.628
  E0511 14:41:51.493079      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:52.493904      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 05/11/25 14:41:52.639
  E0511 14:41:53.494712      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:54.495282      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 05/11/25 14:41:54.65
  E0511 14:41:55.495817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:56.496397      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: listing a collection of PDBs across all namespaces @ 05/11/25 14:41:56.657
  STEP: listing a collection of PDBs in namespace disruption-2147 @ 05/11/25 14:41:56.66
  STEP: deleting a collection of PDBs @ 05/11/25 14:41:56.663
  STEP: Waiting for the PDB collection to be deleted @ 05/11/25 14:41:56.673
  I0511 14:41:56.676037 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-4766" for this suite. @ 05/11/25 14:41:56.679
  I0511 14:41:56.683699 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2147" for this suite. @ 05/11/25 14:41:56.781
• [6.184 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:817
  STEP: Creating a kubernetes client @ 05/11/25 14:41:56.789
  I0511 14:41:56.789229 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 14:41:56.79
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:41:56.8
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:41:56.802
  STEP: Setting up server cert @ 05/11/25 14:41:56.824
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 14:41:56.98
  STEP: Deploying the webhook pod @ 05/11/25 14:41:56.983
  STEP: Wait for the deployment to be ready @ 05/11/25 14:41:56.99
  I0511 14:41:56.994933 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0511 14:41:57.496409      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:41:58.496887      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/11/25 14:41:59.005
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 14:41:59.022
  E0511 14:41:59.497102      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:00.023096 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 05/11/25 14:42:00.028
  I0511 14:42:00.067205 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7547" for this suite. @ 05/11/25 14:42:00.071
  STEP: Destroying namespace "webhook-markers-8871" for this suite. @ 05/11/25 14:42:00.077
• [3.292 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:236
  STEP: Creating a kubernetes client @ 05/11/25 14:42:00.08
  I0511 14:42:00.080993 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename downward-api @ 05/11/25 14:42:00.082
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:42:00.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:42:00.092
  STEP: Creating a pod to test downward API volume plugin @ 05/11/25 14:42:00.093
  E0511 14:42:00.497608      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:01.498054      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:02.498858      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:03.499185      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:42:04.116
  I0511 14:42:04.119456 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-b74ee318-b204-4690-a53f-9e0853f67e1f container client-container: <nil>
  STEP: delete the pod @ 05/11/25 14:42:04.126
  I0511 14:42:04.141189 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4" for this suite. @ 05/11/25 14:42:04.144
• [4.069 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 05/11/25 14:42:04.15
  I0511 14:42:04.150179 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename container-runtime @ 05/11/25 14:42:04.151
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:42:04.158
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:42:04.161
  STEP: create the container @ 05/11/25 14:42:04.164
  I0511 14:42:04.171455      26 warnings.go:110] "Warning: metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]"
  STEP: wait for the container to reach Succeeded @ 05/11/25 14:42:04.171
  E0511 14:42:04.499277      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:05.499709      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:06.499901      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/11/25 14:42:07.186
  STEP: the container should be terminated @ 05/11/25 14:42:07.189
  STEP: the termination message should be set @ 05/11/25 14:42:07.189
  I0511 14:42:07.189069 26 runtime.go:167] Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 05/11/25 14:42:07.189
  I0511 14:42:07.205314 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7163" for this suite. @ 05/11/25 14:42:07.209
• [3.064 seconds]
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 05/11/25 14:42:07.214
  I0511 14:42:07.214266 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename container-probe @ 05/11/25 14:42:07.215
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:42:07.225
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:42:07.228
  STEP: Creating pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190 @ 05/11/25 14:42:07.231
  E0511 14:42:07.500270      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:08.500802      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/11/25 14:42:09.247
  I0511 14:42:09.251624 26 container_probe.go:1748] Initial restart count of pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 is 0
  I0511 14:42:09.253753 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:09.500942      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:10.501283      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:11.257851 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:11.502245      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:12.502780      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:13.263297 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:13.503873      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:14.504378      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:15.268554 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:15.504987      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:16.505879      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:17.274105 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:17.506556      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:18.507022      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:19.278815 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:19.507153      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:20.507711      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:21.283514 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:21.507920      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:22.508810      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:23.288327 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:23.509662      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:24.510033      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:25.293837 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:25.510242      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:26.510840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:27.298075 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:27.511748      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:28.512337      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:29.301989 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  I0511 14:42:29.302044 26 container_probe.go:1762] Restart count of pod container-probe-7190/liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 is now 1 (20.050368292s elapsed)
  E0511 14:42:29.512644      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:30.512979      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:31.306599 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:31.513964      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:32.514669      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:33.311882 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:33.515321      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:34.515924      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:35.317902 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:35.516365      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:36.516300      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:37.324306 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:37.516788      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:38.516848      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:39.327438 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:39.517935      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:40.518257      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:41.331603 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:41.519161      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:42.519818      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:43.336211 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:43.520813      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:44.521299      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:45.341620 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:45.521805      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:46.522114      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:47.346289 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:47.522721      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:48.523153      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:49.351561 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  I0511 14:42:49.351622 26 container_probe.go:1762] Restart count of pod container-probe-7190/liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 is now 2 (40.099944896s elapsed)
  E0511 14:42:49.523815      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:50.524251      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:51.355902 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:51.525310      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:52.525788      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:53.360961 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:53.526610      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:54.526640      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:55.366801 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:55.527078      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:56.527527      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:57.371696 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:57.527984      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:42:58.528342      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:42:59.376158 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:42:59.528402      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:00.528850      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:01.381734 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:01.528931      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:02.529206      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:03.385302 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:03.529937      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:04.530811      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:05.391293 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:05.531903      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:06.532514      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:07.395910 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:07.533162      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:08.533718      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:09.399367 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  I0511 14:43:09.399415 26 container_probe.go:1762] Restart count of pod container-probe-7190/liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 is now 3 (1m0.147739039s elapsed)
  E0511 14:43:09.534678      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:10.535230      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:11.404374 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:11.535957      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:12.536811      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:13.409614 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:13.537879      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:14.538393      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:15.416049 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:15.539230      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:16.539737      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:17.420742 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:17.540049      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:18.540810      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:19.423593 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:19.541785      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:20.541969      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:21.427030 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:21.542450      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:22.542822      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:23.430395 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:23.543881      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:24.544445      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:25.434890 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:25.545156      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:26.545827      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:27.439657 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:27.546005      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:28.546910      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:29.442761 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  I0511 14:43:29.442791 26 container_probe.go:1762] Restart count of pod container-probe-7190/liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 is now 4 (1m20.191117805s elapsed)
  E0511 14:43:29.547351      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:30.547903      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:31.448924 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:31.549044      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:32.549997      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:33.455307 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:33.550849      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:34.551839      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:35.462228 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:35.552909      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:36.554010      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:37.468819 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:37.555132      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:38.555520      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:39.474340 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:39.556793      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:40.556880      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:41.476598 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:41.557762      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:42.558119      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:43.481054 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:43.558238      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:44.558762      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:45.487564 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:45.559831      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:46.560986      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:47.492572 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:47.561716      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:48.562017      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:49.495824 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:49.563151      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:50.563640      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:51.501726 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:51.563998      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:52.564564      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:53.507544 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:53.564867      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:54.565394      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:55.512922 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:55.566295      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:56.566781      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:57.518353 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:57.567577      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:43:58.567698      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:43:59.523850 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:43:59.568025      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:00.568722      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:01.529137 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:01.569266      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:02.570698      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:03.534674 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:03.570824      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:04.571717      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:05.540944 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:05.572319      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:06.572623      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:07.546710 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:07.572872      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:08.573689      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:09.550863 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:09.574230      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:10.574678      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:11.555904 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:11.575240      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:12.575745      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:13.560183 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:13.576321      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:14.576662      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:15.566311 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:15.577521      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:16.577914      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:17.571495 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:17.578689      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:18.579789      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:19.575972 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:19.580226      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:20.580775      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:21.580625      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:21.580784 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:22.580777      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:23.581421      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:23.586188 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:24.582164      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:25.582757      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:25.591500 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:26.583887      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:27.584849      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:27.595626 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:28.585758      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:29.586355      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:29.600245 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:30.586771      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:31.587391      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:31.604357 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:32.588573      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:33.589141      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:33.609189 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:34.589820      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:35.590012      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:35.615596 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:36.590834      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:37.591157      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:37.621057 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:38.591549      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:39.591767      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:39.626789 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  E0511 14:44:40.592860      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:41.593326      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:41.632525 26 container_probe.go:1758] Get pod liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 in namespace container-probe-7190
  I0511 14:44:41.632593 26 container_probe.go:1762] Restart count of pod container-probe-7190/liveness-28fb7e33-dec7-4012-9b52-584eb1cc5e87 is now 5 (2m32.38091519s elapsed)
  STEP: deleting the pod @ 05/11/25 14:44:41.632
  I0511 14:44:41.645061 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7190" for this suite. @ 05/11/25 14:44:41.648
• [154.438 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_selectable_fields.go:124
  STEP: Creating a kubernetes client @ 05/11/25 14:44:41.652
  I0511 14:44:41.652427 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename crd-selectable-fields @ 05/11/25 14:44:41.653
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:44:41.661
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:44:41.663
  STEP: Setting up server cert @ 05/11/25 14:44:41.664
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 05/11/25 14:44:41.836
  STEP: Deploying the custom resource conversion webhook pod @ 05/11/25 14:44:41.839
  STEP: Wait for the deployment to be ready @ 05/11/25 14:44:41.847
  I0511 14:44:41.849343 26 deployment.go:223] new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
  E0511 14:44:42.593404      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:43.593788      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/11/25 14:44:43.861
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 14:44:43.879
  E0511 14:44:44.594921      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:44.880638 26 util.go:418] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  STEP: Creating a custom resource definition with selectable fields @ 05/11/25 14:44:44.884
  I0511 14:44:44.884352 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Creating a custom resource conversion webhook @ 05/11/25 14:44:45.399
  E0511 14:44:45.595659      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:46.595977      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Watching with field selectors @ 05/11/25 14:44:47.45
  STEP: Registering informers with field selectors @ 05/11/25 14:44:47.453
  STEP: Creating custom resources @ 05/11/25 14:44:47.453
  STEP: Listing v2 custom resources with field selector host=host1 @ 05/11/25 14:44:47.478
  STEP: Listing v2 custom resources with field selector host=host1,port=80 @ 05/11/25 14:44:47.481
  STEP: Listing v1 custom resources with field selector hostPort=host1:80 @ 05/11/25 14:44:47.485
  STEP: Listing v1 custom resources with field selector hostPort=host1:8080 @ 05/11/25 14:44:47.488
  STEP: Waiting for watch events to contain v2 custom resources for field selector host=host1 @ 05/11/25 14:44:47.49
  STEP: Waiting for watch events to contain v2 custom resources for field selector host=host1,port=80 @ 05/11/25 14:44:47.496
  STEP: Waiting for watch events to contain v1 custom resources for field selector hostPort=host1:80 @ 05/11/25 14:44:47.496
  STEP: Waiting for informer events to contain v2 custom resources for field selector host=host1 @ 05/11/25 14:44:47.496
  STEP: Waiting for informer events to contain v2 custom resources for field selector host=host1,port=80 @ 05/11/25 14:44:47.496
  STEP: Deleting one custom resources to ensure that deletions are observed @ 05/11/25 14:44:47.496
  STEP: Updating one custom resources to ensure that deletions are observed @ 05/11/25 14:44:47.51
  STEP: Listing v2 custom resources after updates and deletes for field selector host=host1 @ 05/11/25 14:44:47.521
  STEP: Listing v2 custom resources after updates and deletes for field selector host=host1,port=80 @ 05/11/25 14:44:47.523
  STEP: Waiting for v2 watch events after updates and deletes for field selector host=host1 @ 05/11/25 14:44:47.526
  STEP: Waiting for v2 watch events after updates and deletes for field selector host=host1,port=80 @ 05/11/25 14:44:47.531
  STEP: Waiting for v1 watch events after updates and deletes for field selector hostPort=host1:80 @ 05/11/25 14:44:47.531
  STEP: Waiting for v2 informer events after updates and deletes for field selector host=host1 @ 05/11/25 14:44:47.531
  STEP: Waiting for v2 informer events after updates and deletes for field selector host=host1,port=80 @ 05/11/25 14:44:47.531
  E0511 14:44:47.597086      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:48.086944 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-selectable-fields-6687" for this suite. @ 05/11/25 14:44:48.09
• [6.446 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 05/11/25 14:44:48.099
  I0511 14:44:48.099561 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename watch @ 05/11/25 14:44:48.101
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:44:48.11
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:44:48.115
  STEP: creating a new configmap @ 05/11/25 14:44:48.116
  STEP: modifying the configmap once @ 05/11/25 14:44:48.12
  STEP: modifying the configmap a second time @ 05/11/25 14:44:48.124
  STEP: deleting the configmap @ 05/11/25 14:44:48.13
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 05/11/25 14:44:48.133
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 05/11/25 14:44:48.134
  I0511 14:44:48.134570 26 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7124  a96a7fd3-978b-4bf1-9de7-2cf25b1a7555 24256 0 2025-05-11 14:44:48 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2025-05-11 14:44:48 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0511 14:44:48.134670 26 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7124  a96a7fd3-978b-4bf1-9de7-2cf25b1a7555 24257 0 2025-05-11 14:44:48 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2025-05-11 14:44:48 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0511 14:44:48.134747 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-7124" for this suite. @ 05/11/25 14:44:48.191
• [0.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:298
  STEP: Creating a kubernetes client @ 05/11/25 14:44:48.197
  I0511 14:44:48.197257 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 14:44:48.198
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:44:48.207
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:44:48.21
  STEP: Setting up server cert @ 05/11/25 14:44:48.223
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 14:44:48.593
  STEP: Deploying the webhook pod @ 05/11/25 14:44:48.596
  E0511 14:44:48.597468      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Wait for the deployment to be ready @ 05/11/25 14:44:48.604
  I0511 14:44:48.607708 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0511 14:44:49.597821      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:50.598752      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/11/25 14:44:50.619
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 14:44:50.634
  E0511 14:44:51.599627      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:51.634640 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 05/11/25 14:44:51.639
  STEP: Creating a custom resource definition that should be denied by the webhook @ 05/11/25 14:44:51.657
  I0511 14:44:51.657518 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  I0511 14:44:51.701672 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7268" for this suite. @ 05/11/25 14:44:51.705
  STEP: Destroying namespace "webhook-markers-2322" for this suite. @ 05/11/25 14:44:51.714
• [3.521 seconds]
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 05/11/25 14:44:51.718
  I0511 14:44:51.718287 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename deployment @ 05/11/25 14:44:51.718
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:44:51.728
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:44:51.73
  STEP: creating a Deployment @ 05/11/25 14:44:51.733
  STEP: waiting for Deployment to be created @ 05/11/25 14:44:51.737
  STEP: waiting for all Replicas to be Ready @ 05/11/25 14:44:51.738
  I0511 14:44:51.739631 26 deployment.go:246] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0511 14:44:51.739655 26 deployment.go:248] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0511 14:44:51.744970 26 deployment.go:246] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0511 14:44:51.745001 26 deployment.go:248] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0511 14:44:51.753179 26 deployment.go:246] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0511 14:44:51.753216 26 deployment.go:248] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0511 14:44:51.776853 26 deployment.go:246] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0511 14:44:51.776881 26 deployment.go:248] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0511 14:44:52.599728      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:52.885765 26 deployment.go:246] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0511 14:44:52.885844 26 deployment.go:248] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0511 14:44:52.999572 26 deployment.go:248] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 05/11/25 14:44:52.999
  I0511 14:44:53.006360 26 deployment.go:290] observed event type ADDED
  STEP: waiting for Replicas to scale @ 05/11/25 14:44:53.006
  I0511 14:44:53.007226 26 deployment.go:309] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 0
  I0511 14:44:53.007246 26 deployment.go:311] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 0
  I0511 14:44:53.007255 26 deployment.go:309] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 0
  I0511 14:44:53.007263 26 deployment.go:311] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 0
  I0511 14:44:53.007316 26 deployment.go:309] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 0
  I0511 14:44:53.007331 26 deployment.go:311] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 0
  I0511 14:44:53.007337 26 deployment.go:309] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 0
  I0511 14:44:53.007342 26 deployment.go:311] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 0
  I0511 14:44:53.007349 26 deployment.go:309] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1
  I0511 14:44:53.007356 26 deployment.go:311] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1
  I0511 14:44:53.007428 26 deployment.go:309] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 2
  I0511 14:44:53.007440 26 deployment.go:311] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 2
  I0511 14:44:53.007452 26 deployment.go:309] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 2
  I0511 14:44:53.007482 26 deployment.go:311] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 2
  I0511 14:44:53.014674 26 deployment.go:309] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 2
  I0511 14:44:53.014700 26 deployment.go:311] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 2
  I0511 14:44:53.023230 26 deployment.go:309] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 2
  I0511 14:44:53.023256 26 deployment.go:311] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 2
  I0511 14:44:53.030732 26 deployment.go:309] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1
  I0511 14:44:53.030766 26 deployment.go:311] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1
  I0511 14:44:53.038530 26 deployment.go:309] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1
  I0511 14:44:53.038559 26 deployment.go:311] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1
  E0511 14:44:53.600869      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:53.902949 26 deployment.go:309] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 2
  I0511 14:44:53.902977 26 deployment.go:311] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 2
  I0511 14:44:53.920129 26 deployment.go:311] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1
  STEP: listing Deployments @ 05/11/25 14:44:53.92
  I0511 14:44:53.922358 26 deployment.go:327] Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 05/11/25 14:44:53.922
  I0511 14:44:53.931080 26 deployment.go:360] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 05/11/25 14:44:53.931
  I0511 14:44:53.934237 26 deployment.go:389] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0511 14:44:53.940097 26 deployment.go:389] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0511 14:44:53.955118 26 deployment.go:389] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0511 14:44:53.972788 26 deployment.go:389] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0511 14:44:53.977664 26 deployment.go:389] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0511 14:44:54.601633      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:54.924368 26 deployment.go:389] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0511 14:44:54.934789 26 deployment.go:389] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0511 14:44:54.941897 26 deployment.go:389] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0511 14:44:54.955804 26 deployment.go:389] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0511 14:44:55.602583      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:44:56.069499 26 deployment.go:389] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 05/11/25 14:44:56.084
  STEP: fetching the DeploymentStatus @ 05/11/25 14:44:56.091
  I0511 14:44:56.094199 26 deployment.go:448] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1
  I0511 14:44:56.094296 26 deployment.go:448] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1
  I0511 14:44:56.094338 26 deployment.go:448] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1
  I0511 14:44:56.094356 26 deployment.go:448] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1
  I0511 14:44:56.094476 26 deployment.go:448] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 1
  I0511 14:44:56.094531 26 deployment.go:448] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 2
  I0511 14:44:56.094580 26 deployment.go:448] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 2
  I0511 14:44:56.094610 26 deployment.go:448] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 2
  I0511 14:44:56.094646 26 deployment.go:448] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 2
  I0511 14:44:56.094708 26 deployment.go:448] observed Deployment test-deployment in namespace deployment-9544 with ReadyReplicas 3
  STEP: deleting the Deployment @ 05/11/25 14:44:56.094
  I0511 14:44:56.101937 26 deployment.go:474] observed event type MODIFIED
  I0511 14:44:56.102131 26 deployment.go:474] observed event type MODIFIED
  I0511 14:44:56.102159 26 deployment.go:474] observed event type MODIFIED
  I0511 14:44:56.102179 26 deployment.go:474] observed event type MODIFIED
  I0511 14:44:56.102340 26 deployment.go:474] observed event type MODIFIED
  I0511 14:44:56.102521 26 deployment.go:474] observed event type MODIFIED
  I0511 14:44:56.102698 26 deployment.go:474] observed event type MODIFIED
  I0511 14:44:56.102773 26 deployment.go:474] observed event type MODIFIED
  I0511 14:44:56.103100 26 deployment.go:474] observed event type MODIFIED
  I0511 14:44:56.103238 26 deployment.go:474] observed event type MODIFIED
  I0511 14:44:56.103295 26 deployment.go:474] observed event type MODIFIED
  I0511 14:44:56.103439 26 deployment.go:474] observed event type MODIFIED
  I0511 14:44:56.103726 26 deployment.go:474] observed event type MODIFIED
  I0511 14:44:56.106755 26 deployment.go:649] Log out all the ReplicaSets if there is no deployment created
  I0511 14:44:56.111750 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9544" for this suite. @ 05/11/25 14:44:56.114
• [4.402 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:124
  STEP: Creating a kubernetes client @ 05/11/25 14:44:56.12
  I0511 14:44:56.120105 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 14:44:56.12
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:44:56.13
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:44:56.132
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-bd27f7a6-10f7-4b0f-890f-d4cfafa6e03f @ 05/11/25 14:44:56.215
  STEP: Creating the pod @ 05/11/25 14:44:56.219
  E0511 14:44:56.603073      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:57.603786      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-bd27f7a6-10f7-4b0f-890f-d4cfafa6e03f @ 05/11/25 14:44:58.254
  STEP: waiting to observe update in volume @ 05/11/25 14:44:58.262
  E0511 14:44:58.604861      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:44:59.605353      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:00.606572      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:01.607306      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:02.608016      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:03.608530      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:04.608758      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:05.609207      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:06.610216      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:07.610797      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:08.611523      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:09.611795      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:10.612789      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:11.613161      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:12.613495      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:13.613812      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:14.614582      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:15.615085      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:16.615239      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:17.615712      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:18.616000      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:19.616583      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:20.616652      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:21.616955      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:22.617928      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:23.618648      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:24.619034      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:25.619052      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:26.619414      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:27.619819      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:28.620559      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:29.621072      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:30.621681      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:31.621688      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:32.622038      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:33.622443      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:34.623264      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:35.623967      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:36.624804      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:37.625802      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:38.626309      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:39.626850      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:40.627791      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:41.628229      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:42.629331      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:43.629805      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:44.630573      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:45.631021      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:46.632087      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:47.632625      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:48.633271      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:49.633938      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:50.634796      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:51.635316      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:52.636435      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:53.636909      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:54.637052      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:55.637594      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:56.638483      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:57.638907      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:58.639668      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:45:59.640237      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:00.640854      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:01.641851      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:02.642205      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:03.642799      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:04.643001      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:05.643921      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:06.644228      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:07.644615      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:08.645035      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:09.645451      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:10.645697      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:11.646376      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:12.646939      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:13.647320      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:14.647802      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:15.648019      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:16.649123      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:17.650079      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:18.650395      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:19.650989      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:20.651392      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:21.651801      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:22.651973      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:23.653041      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:24.653815      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:25.654604      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:26.654766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:46:26.763059 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8897" for this suite. @ 05/11/25 14:46:26.767
• [90.655 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:79
  STEP: Creating a kubernetes client @ 05/11/25 14:46:26.775
  I0511 14:46:26.775618 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename svcaccounts @ 05/11/25 14:46:26.776
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:46:26.788
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:46:26.792
  E0511 14:46:27.655389      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:28.655847      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 05/11/25 14:46:28.821
  I0511 14:46:28.822081 26 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3353 pod-service-account-81f1d947-97ae-4454-b1b3-75f43b3d7fa5 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 05/11/25 14:46:28.915
  I0511 14:46:28.915350 26 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3353 pod-service-account-81f1d947-97ae-4454-b1b3-75f43b3d7fa5 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 05/11/25 14:46:28.996
  I0511 14:46:28.997073 26 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3353 pod-service-account-81f1d947-97ae-4454-b1b3-75f43b3d7fa5 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  I0511 14:46:29.083299 26 service_accounts.go:119] Got root ca configmap in namespace "svcaccounts-3353"
  I0511 14:46:29.085667 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-3353" for this suite. @ 05/11/25 14:46:29.088
• [2.319 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:156
  STEP: Creating a kubernetes client @ 05/11/25 14:46:29.095
  I0511 14:46:29.095230 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename secrets @ 05/11/25 14:46:29.096
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:46:29.108
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:46:29.112
  STEP: creating a secret @ 05/11/25 14:46:29.115
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 05/11/25 14:46:29.118
  STEP: patching the secret @ 05/11/25 14:46:29.121
  STEP: deleting the secret using a LabelSelector @ 05/11/25 14:46:29.13
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 05/11/25 14:46:29.135
  I0511 14:46:29.137770 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7711" for this suite. @ 05/11/25 14:46:29.19
• [0.102 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:46
  STEP: Creating a kubernetes client @ 05/11/25 14:46:29.196
  I0511 14:46:29.196991 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename downward-api @ 05/11/25 14:46:29.197
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:46:29.207
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:46:29.211
  STEP: Creating a pod to test downward api env vars @ 05/11/25 14:46:29.214
  E0511 14:46:29.656511      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:30.656889      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:31.657157      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:32.657686      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:46:33.235
  I0511 14:46:33.237963 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downward-api-5e5e184e-72a7-46ea-a154-e3b16c632721 container dapi-container: <nil>
  STEP: delete the pod @ 05/11/25 14:46:33.245
  I0511 14:46:33.267685 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6805" for this suite. @ 05/11/25 14:46:33.271
• [4.080 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 05/11/25 14:46:33.277
  I0511 14:46:33.277110 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename server-version @ 05/11/25 14:46:33.278
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:46:33.288
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:46:33.291
  STEP: Request ServerVersion @ 05/11/25 14:46:33.295
  STEP: Confirm major version @ 05/11/25 14:46:33.296
  I0511 14:46:33.296328 26 server_version.go:52] Major version: 1
  STEP: Confirm minor version @ 05/11/25 14:46:33.296
  I0511 14:46:33.296392 26 server_version.go:58] cleanMinorVersion: 33
  I0511 14:46:33.296416 26 server_version.go:62] Minor version: 33
  I0511 14:46:33.296567 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-8366" for this suite. @ 05/11/25 14:46:33.373
• [0.102 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Serial] [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:722
  STEP: Creating a kubernetes client @ 05/11/25 14:46:33.379
  I0511 14:46:33.379802 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename gc @ 05/11/25 14:46:33.38
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:46:33.389
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:46:33.392
  STEP: create the rc1 @ 05/11/25 14:46:33.476
  STEP: create the rc2 @ 05/11/25 14:46:33.482
  E0511 14:46:33.658275      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:34.658686      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:35.660938      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:36.659154      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:37.659648      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:38.659766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 05/11/25 14:46:39.492
  E0511 14:46:39.660490      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the rc simpletest-rc-to-be-deleted @ 05/11/25 14:46:39.829
  STEP: wait for the rc to be deleted @ 05/11/25 14:46:39.835
  E0511 14:46:40.660598      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:41.660813      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:42.661165      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:43.661653      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:44.662679      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:46:44.843136 26 garbage_collector.go:770] 68 pods remaining
  I0511 14:46:44.843169 26 garbage_collector.go:777] 68 pods has nil DeletionTimestamp
  I0511 14:46:44.843178 26 garbage_collector.go:778] 
  E0511 14:46:45.663667      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:46.664642      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:47.665739      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:48.666086      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:49.666832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/11/25 14:46:49.847
  I0511 14:46:49.940907 26 garbage_collector.go:273] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0511 14:46:49.940942 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2bcrp" in namespace "gc-1102"
  I0511 14:46:49.950120 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2jtrk" in namespace "gc-1102"
  I0511 14:46:49.960212 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2w82p" in namespace "gc-1102"
  I0511 14:46:49.968331 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-479wn" in namespace "gc-1102"
  I0511 14:46:49.979351 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-47kn7" in namespace "gc-1102"
  I0511 14:46:49.990943 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4r727" in namespace "gc-1102"
  I0511 14:46:50.000838 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4tlxr" in namespace "gc-1102"
  I0511 14:46:50.010847 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-56jvb" in namespace "gc-1102"
  I0511 14:46:50.020760 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5hvdn" in namespace "gc-1102"
  I0511 14:46:50.034619 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5x5gk" in namespace "gc-1102"
  I0511 14:46:50.046857 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-66htd" in namespace "gc-1102"
  I0511 14:46:50.060497 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-67xt4" in namespace "gc-1102"
  I0511 14:46:50.073294 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6jjxs" in namespace "gc-1102"
  I0511 14:46:50.089960 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6w2kn" in namespace "gc-1102"
  I0511 14:46:50.103902 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-76w8l" in namespace "gc-1102"
  I0511 14:46:50.115731 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-79k7v" in namespace "gc-1102"
  I0511 14:46:50.130391 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7dwt9" in namespace "gc-1102"
  I0511 14:46:50.139810 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7lv44" in namespace "gc-1102"
  I0511 14:46:50.152916 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7qqtq" in namespace "gc-1102"
  I0511 14:46:50.163229 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7sbqz" in namespace "gc-1102"
  I0511 14:46:50.181728 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8bnr5" in namespace "gc-1102"
  I0511 14:46:50.199608 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8x5x6" in namespace "gc-1102"
  I0511 14:46:50.212495 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8xbqq" in namespace "gc-1102"
  I0511 14:46:50.233746 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9ndmv" in namespace "gc-1102"
  I0511 14:46:50.249524 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9qpz9" in namespace "gc-1102"
  I0511 14:46:50.268720 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bj2j6" in namespace "gc-1102"
  I0511 14:46:50.283340 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bm5nq" in namespace "gc-1102"
  I0511 14:46:50.303216 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bz4mg" in namespace "gc-1102"
  I0511 14:46:50.322137 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-c89wq" in namespace "gc-1102"
  I0511 14:46:50.340661 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cfhq7" in namespace "gc-1102"
  I0511 14:46:50.350805 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cgkcw" in namespace "gc-1102"
  I0511 14:46:50.366257 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cnk5c" in namespace "gc-1102"
  I0511 14:46:50.385357 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dkfl6" in namespace "gc-1102"
  I0511 14:46:50.403543 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-f5zk4" in namespace "gc-1102"
  I0511 14:46:50.426879 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-f72nq" in namespace "gc-1102"
  I0511 14:46:50.442482 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-fhmwp" in namespace "gc-1102"
  I0511 14:46:50.457072 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-fncx8" in namespace "gc-1102"
  I0511 14:46:50.470422 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gpfll" in namespace "gc-1102"
  I0511 14:46:50.488867 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-h4m55" in namespace "gc-1102"
  I0511 14:46:50.505503 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-hjvfq" in namespace "gc-1102"
  I0511 14:46:50.519398 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-hrvsf" in namespace "gc-1102"
  I0511 14:46:50.540060 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-j5jkr" in namespace "gc-1102"
  I0511 14:46:50.553622 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-j7xtn" in namespace "gc-1102"
  I0511 14:46:50.567736 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-jcnbj" in namespace "gc-1102"
  I0511 14:46:50.583756 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-jrph4" in namespace "gc-1102"
  I0511 14:46:50.604278 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-jt568" in namespace "gc-1102"
  I0511 14:46:50.621611 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-jt7gk" in namespace "gc-1102"
  I0511 14:46:50.638602 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-k6cxq" in namespace "gc-1102"
  I0511 14:46:50.649607 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-kcncx" in namespace "gc-1102"
  I0511 14:46:50.662756 26 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-kk88g" in namespace "gc-1102"
  E0511 14:46:50.667243      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:46:50.681424 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1102" for this suite. @ 05/11/25 14:46:50.688
• [17.317 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:426
  STEP: Creating a kubernetes client @ 05/11/25 14:46:50.696
  I0511 14:46:50.696739 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename replication-controller @ 05/11/25 14:46:50.697
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:46:50.711
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:46:50.714
  STEP: Creating ReplicationController "e2e-rc-n45fp" @ 05/11/25 14:46:50.72
  I0511 14:46:50.732758 26 rc.go:795] Get Replication Controller "e2e-rc-n45fp" to confirm replicas
  E0511 14:46:51.668325      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:46:51.733640 26 rc.go:795] Get Replication Controller "e2e-rc-n45fp" to confirm replicas
  I0511 14:46:51.738602 26 rc.go:804] Found 1 replicas for "e2e-rc-n45fp" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-n45fp" @ 05/11/25 14:46:51.738
  STEP: Updating a scale subresource @ 05/11/25 14:46:51.741
  STEP: Verifying replicas where modified for replication controller "e2e-rc-n45fp" @ 05/11/25 14:46:51.746
  I0511 14:46:51.746174 26 rc.go:795] Get Replication Controller "e2e-rc-n45fp" to confirm replicas
  E0511 14:46:52.668999      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:46:52.747294 26 rc.go:795] Get Replication Controller "e2e-rc-n45fp" to confirm replicas
  I0511 14:46:52.751708 26 rc.go:804] Found 2 replicas for "e2e-rc-n45fp" replication controller
  I0511 14:46:52.751916 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-9061" for this suite. @ 05/11/25 14:46:52.755
• [2.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:240
  STEP: Creating a kubernetes client @ 05/11/25 14:46:52.761
  I0511 14:46:52.761973 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename configmap @ 05/11/25 14:46:52.763
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:46:52.774
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:46:52.777
  STEP: Creating configMap with name cm-test-opt-del-21047c0d-3caf-42d3-b32a-88704023c46c @ 05/11/25 14:46:52.857
  STEP: Creating configMap with name cm-test-opt-upd-49d052bb-04fe-467f-957f-4e6f0ecc4cf3 @ 05/11/25 14:46:52.862
  STEP: Creating the pod @ 05/11/25 14:46:52.866
  E0511 14:46:53.669531      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:54.669948      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-21047c0d-3caf-42d3-b32a-88704023c46c @ 05/11/25 14:46:54.908
  STEP: Updating configmap cm-test-opt-upd-49d052bb-04fe-467f-957f-4e6f0ecc4cf3 @ 05/11/25 14:46:54.915
  STEP: Creating configMap with name cm-test-opt-create-3d34bd09-ab18-46ea-b3db-f7f478a6681f @ 05/11/25 14:46:54.922
  STEP: waiting to observe update in volume @ 05/11/25 14:46:54.927
  E0511 14:46:55.670549      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:56.670730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:57.671039      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:58.671056      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:46:59.671956      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:00.672300      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:01.673005      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:02.673533      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:03.673708      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:04.674245      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:05.675284      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:06.675713      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:07.676815      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:08.677842      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:09.678021      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:10.678909      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:11.679881      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:12.680769      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:13.680751      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:14.681778      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:15.682372      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:16.682730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:17.683210      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:18.683766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:19.683861      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:20.684615      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:21.684893      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:22.685760      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:23.686849      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:24.687029      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:25.687941      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:26.688198      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:27.688588      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:28.689002      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:29.689838      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:30.689967      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:31.690812      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:32.691758      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:33.692877      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:34.693816      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:35.694733      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:36.694900      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:37.694910      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:38.695892      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:39.696912      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:40.697912      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:41.698487      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:42.698872      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:43.699859      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:44.699858      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:45.700369      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:46.700688      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:47.701242      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:48.701908      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:49.702066      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:50.702352      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:51.702536      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:52.703045      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:53.703954      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:54.703995      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:55.704525      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:56.704954      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:57.705803      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:58.705916      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:47:59.706449      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:00.707196      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:01.708054      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:02.709033      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:03.710124      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:04.710165      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:05.710249      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:06.710755      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:07.711409      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:08.711956      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:09.712690      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:10.713187      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:11.713390      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:12.713869      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:13.714153      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:14.714261      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:15.714776      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:16.715156      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:17.715839      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:18.716430      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:19.716827      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:20.717737      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:21.718019      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:22.718581      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:23.718843      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:24.718910      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:48:25.453570 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8159" for this suite. @ 05/11/25 14:48:25.456
• [92.700 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:1049
  STEP: Creating a kubernetes client @ 05/11/25 14:48:25.463
  I0511 14:48:25.463080 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename statefulset @ 05/11/25 14:48:25.464
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:48:25.475
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:48:25.478
  STEP: Creating service test in namespace statefulset-9977 @ 05/11/25 14:48:25.481
  STEP: Creating statefulset ss in namespace statefulset-9977 @ 05/11/25 14:48:25.488
  I0511 14:48:25.495276 26 wait.go:44] Found 0 stateful pods, waiting for 1
  E0511 14:48:25.719900      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:26.720781      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:27.721370      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:28.721899      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:29.722408      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:30.722782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:31.723227      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:32.723785      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:33.724771      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:34.725829      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:48:35.498012 26 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 05/11/25 14:48:35.502
  STEP: Getting /status @ 05/11/25 14:48:35.516
  I0511 14:48:35.517966 26 statefulset.go:1085] StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 05/11/25 14:48:35.517
  I0511 14:48:35.523265 26 statefulset.go:1105] updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 05/11/25 14:48:35.523
  I0511 14:48:35.524325 26 statefulset.go:1133] Observed &StatefulSet event: ADDED
  I0511 14:48:35.524350 26 statefulset.go:1126] Found Statefulset ss in namespace statefulset-9977 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0511 14:48:35.524362 26 statefulset.go:1137] Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 05/11/25 14:48:35.524
  I0511 14:48:35.524390 26 statefulset.go:1141] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0511 14:48:35.528070 26 statefulset.go:1145] Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 05/11/25 14:48:35.528
  I0511 14:48:35.529135 26 statefulset.go:1170] Observed &StatefulSet event: ADDED
  I0511 14:48:35.529195 26 statefulset.go:138] Deleting all statefulset in ns statefulset-9977
  I0511 14:48:35.532431 26 rest.go:153] Scaling statefulset ss to 0
  E0511 14:48:35.726034      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:36.726545      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:37.726644      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:38.726973      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:39.727843      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:40.727888      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:41.728902      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:42.729927      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:43.730406      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:44.731008      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:48:45.543181 26 wait.go:159] Waiting for statefulset status.replicas updated to 0
  I0511 14:48:45.546045 26 rest.go:91] Deleting statefulset ss
  I0511 14:48:45.558680 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-9977" for this suite. @ 05/11/25 14:48:45.561
• [20.104 seconds]
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:677
  STEP: Creating a kubernetes client @ 05/11/25 14:48:45.566
  I0511 14:48:45.566906 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename svcaccounts @ 05/11/25 14:48:45.567
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:48:45.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:48:45.579
  STEP: creating a ServiceAccount @ 05/11/25 14:48:45.58
  STEP: watching for the ServiceAccount to be added @ 05/11/25 14:48:45.586
  STEP: patching the ServiceAccount @ 05/11/25 14:48:45.587
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 05/11/25 14:48:45.592
  STEP: deleting the ServiceAccount @ 05/11/25 14:48:45.594
  I0511 14:48:45.599672 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5357" for this suite. @ 05/11/25 14:48:45.664
• [0.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 05/11/25 14:48:45.671
  I0511 14:48:45.671358 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename init-container @ 05/11/25 14:48:45.672
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:48:45.683
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:48:45.685
  STEP: creating the pod @ 05/11/25 14:48:45.689
  I0511 14:48:45.690075 26 init_container.go:499] PodSpec: initContainers in spec.initContainers
  E0511 14:48:45.731417      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:46.731944      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:47.732029      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:48.732091      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:48:49.344125 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-7935" for this suite. @ 05/11/25 14:48:49.347
• [3.680 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 05/11/25 14:48:49.351
  I0511 14:48:49.351676 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename pods @ 05/11/25 14:48:49.352
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:48:49.359
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:48:49.362
  STEP: creating the pod @ 05/11/25 14:48:49.365
  STEP: submitting the pod to kubernetes @ 05/11/25 14:48:49.365
  E0511 14:48:49.732774      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:50.733670      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 05/11/25 14:48:51.381
  STEP: updating the pod @ 05/11/25 14:48:51.383
  E0511 14:48:51.734087      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:48:51.898189 26 pod_client.go:173] Successfully updated pod "pod-update-816b9a63-816f-4f9d-b848-8e20e9c98cf2"
  STEP: verifying the updated pod is in kubernetes @ 05/11/25 14:48:51.901
  I0511 14:48:51.904255 26 pods.go:391] Pod update OK
  I0511 14:48:51.904537 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2246" for this suite. @ 05/11/25 14:48:51.907
• [2.563 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:160
  STEP: Creating a kubernetes client @ 05/11/25 14:48:51.915
  I0511 14:48:51.915511 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename runtimeclass @ 05/11/25 14:48:51.916
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:48:51.925
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:48:51.928
  STEP: Deleting RuntimeClass runtimeclass-5553-delete-me @ 05/11/25 14:48:51.937
  STEP: Waiting for the RuntimeClass to disappear @ 05/11/25 14:48:51.942
  I0511 14:48:51.951348 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-5553" for this suite. @ 05/11/25 14:48:52.01
• [0.100 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 05/11/25 14:48:52.015
  I0511 14:48:52.015893 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename container-probe @ 05/11/25 14:48:52.016
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:48:52.027
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:48:52.03
  STEP: Creating pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233 @ 05/11/25 14:48:52.033
  E0511 14:48:52.734863      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:53.735582      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/11/25 14:48:54.062
  I0511 14:48:54.065265 26 container_probe.go:1748] Initial restart count of pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b is 0
  I0511 14:48:54.067497 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:48:54.736290      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:55.736533      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:48:56.072839 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:48:56.736840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:57.737429      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:48:58.078705 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:48:58.738172      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:48:59.738303      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:00.083967 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:00.738821      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:01.739556      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:02.086622 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:02.740670      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:03.741167      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:04.092593 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:04.741819      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:05.742310      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:06.096879 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:06.742847      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:07.743496      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:08.102431 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:08.744330      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:09.745375      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:10.106306 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:10.745958      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:11.746027      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:12.111507 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:12.746337      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:13.746915      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:14.116128 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:14.747545      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:15.748228      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:16.121481 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:16.748315      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:17.748878      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:18.127209 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:18.750056      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:19.751113      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:20.131401 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:20.751812      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:21.752392      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:22.136767 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:22.752677      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:23.753175      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:24.142198 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:24.754241      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:25.754774      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:26.148445 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:26.755277      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:27.755839      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:28.152159 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:28.756964      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:29.756979      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:30.156146 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:30.758076      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:31.758757      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:32.161481 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:32.759310      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:33.759776      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:34.164021 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:34.760916      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:35.761382      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:36.169690 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:36.761430      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:37.762123      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:38.175623 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:38.762410      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:39.762846      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:40.179315 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:40.763137      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:41.763695      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:42.184206 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:42.763909      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:43.764871      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:44.189408 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:44.765291      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:45.765824      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:46.192625 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:46.766531      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:47.767158      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:48.198340 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:48.767272      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:49.768119      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:50.203832 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:50.768620      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:51.768935      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:52.210201 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:52.769990      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:53.770556      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:54.213251 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:54.771050      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:55.771307      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:56.218709 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:56.771775      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:57.772735      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:49:58.221718 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:49:58.773176      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:49:59.774071      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:00.227084 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:00.774799      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:01.775000      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:02.232059 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:02.775871      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:03.776277      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:04.238112 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:04.776791      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:05.776726      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:06.242372 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:06.777051      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:07.777242      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:08.245972 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:08.777641      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:09.777867      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:10.252312 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:10.778893      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:11.779884      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:12.258514 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:12.780087      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:13.780591      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:14.264498 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:14.781003      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:15.781253      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:16.269329 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:16.781843      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:17.781735      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:18.274737 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:18.782315      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:19.783268      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:20.279895 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:20.783740      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:21.784266      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:22.286121 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:22.784838      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:23.785161      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:24.289062 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:24.785766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:25.786916      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:26.291991 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:26.787803      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:27.788296      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:28.298098 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:28.788750      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:29.789184      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:30.302454 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:30.790303      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:31.790733      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:32.308455 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:32.791159      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:33.791832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:34.314864 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:34.792338      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:35.793605      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:36.321097 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:36.793902      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:37.794689      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:38.325000 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:38.794757      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:39.795196      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:40.328036 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:40.795715      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:41.795985      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:42.331276 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:42.796794      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:43.797514      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:44.336490 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:44.797620      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:45.798081      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:46.341780 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:46.798330      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:47.798915      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:48.345269 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:48.799888      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:49.800961      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:50.349382 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:50.802110      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:51.802341      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:52.354680 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:52.803493      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:53.803723      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:54.359650 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:54.804224      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:55.804843      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:56.365926 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:56.805762      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:57.806310      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:50:58.370766 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:50:58.806362      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:50:59.806766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:00.374416 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:00.806998      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:01.807446      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:02.379693 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:02.808651      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:03.809100      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:04.385156 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:04.809871      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:05.810373      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:06.389302 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:06.811181      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:07.811789      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:08.391456 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:08.812276      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:09.812934      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:10.396194 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:10.813992      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:11.814595      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:12.400968 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:12.815792      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:13.816330      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:14.407334 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:14.817316      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:15.818092      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:16.412097 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:16.818727      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:17.819301      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:18.418171 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:18.819616      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:19.820335      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:20.423700 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:20.821401      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:21.822303      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:22.429424 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:22.823067      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:23.823640      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:24.433854 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:24.824950      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:25.825434      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:26.439746 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:26.826329      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:27.826852      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:28.445336 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:28.827809      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:29.828115      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:30.450378 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:30.828919      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:31.829967      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:32.455446 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:32.830276      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:33.830925      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:34.461597 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:34.831687      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:35.831974      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:36.467542 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:36.832041      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:37.832581      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:38.472206 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:38.832597      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:39.833204      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:40.477239 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:40.834014      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:41.834098      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:42.481404 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:42.835226      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:43.835479      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:44.484238 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:44.835972      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:45.836831      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:46.488798 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:46.837352      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:47.837881      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:48.492682 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:48.838212      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:49.839271      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:50.497736 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:50.839382      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:51.839903      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:52.500654 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:52.840404      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:53.841024      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:54.505034 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:54.841745      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:55.842146      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:56.509362 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:56.843007      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:57.843309      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:51:58.514229 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:51:58.843684      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:51:59.844301      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:00.519105 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:00.845291      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:01.846418      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:02.524691 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:02.846849      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:03.847900      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:04.528836 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:04.848634      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:05.849188      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:06.533025 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:06.849606      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:07.850105      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:08.537272 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:08.850858      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:09.851327      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:10.542160 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:10.851738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:11.851949      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:12.547271 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:12.852819      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:13.853368      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:14.552836 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:14.853869      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:15.854367      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:16.558025 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:16.855482      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:17.856029      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:18.564254 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:18.856702      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:19.857113      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:20.570315 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:20.857851      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:21.858791      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:22.573890 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:22.859401      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:23.859802      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:24.577559 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:24.860299      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:25.860794      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:26.583605 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:26.860972      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:27.861723      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:28.589714 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:28.862192      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:29.862271      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:30.594936 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:30.863378      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:31.863920      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:32.599711 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:32.864141      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:33.864847      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:34.603810 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:34.865621      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:35.866844      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:36.609240 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:36.866885      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:37.867400      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:38.614033 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:38.867593      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:39.868386      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:40.618262 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:40.868637      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:41.869321      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:42.623360 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:42.870007      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:43.870824      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:44.628450 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:44.871030      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:45.871433      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:46.633192 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:46.871493      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:47.871723      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:48.638333 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:48.872585      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:49.873275      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:50.643536 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:50.874154      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:51.874360      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:52:52.648471 26 container_probe.go:1758] Get pod busybox-7de23ea4-f3ed-4cc1-b9e4-66220217fb2b in namespace container-probe-3233
  E0511 14:52:52.874906      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:53.875303      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 05/11/25 14:52:54.649
  I0511 14:52:54.661928 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-3233" for this suite. @ 05/11/25 14:52:54.667
• [242.658 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:194
  STEP: Creating a kubernetes client @ 05/11/25 14:52:54.674
  I0511 14:52:54.674198 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename runtimeclass @ 05/11/25 14:52:54.675
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:52:54.686
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:52:54.688
  STEP: getting /apis @ 05/11/25 14:52:54.691
  STEP: getting /apis/node.k8s.io @ 05/11/25 14:52:54.694
  STEP: getting /apis/node.k8s.io/v1 @ 05/11/25 14:52:54.695
  STEP: creating @ 05/11/25 14:52:54.695
  STEP: watching @ 05/11/25 14:52:54.704
  I0511 14:52:54.704551 26 runtimeclass.go:278] starting watch
  STEP: getting @ 05/11/25 14:52:54.707
  STEP: listing @ 05/11/25 14:52:54.709
  STEP: patching @ 05/11/25 14:52:54.71
  STEP: updating @ 05/11/25 14:52:54.715
  I0511 14:52:54.718339 26 runtimeclass.go:308] waiting for watch events with expected annotations
  STEP: deleting @ 05/11/25 14:52:54.718
  STEP: deleting a collection @ 05/11/25 14:52:54.723
  I0511 14:52:54.730488 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8694" for this suite. @ 05/11/25 14:52:54.768
• [0.099 seconds]
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:308
  STEP: Creating a kubernetes client @ 05/11/25 14:52:54.773
  I0511 14:52:54.773633 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename dns @ 05/11/25 14:52:54.774
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:52:54.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:52:54.786
  STEP: Creating a test headless service @ 05/11/25 14:52:54.788
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-81.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-querier-2.dns-test-service-2.dns-81.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-81.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-querier-2.dns-test-service-2.dns-81.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-81.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service-2.dns-81.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-81.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service-2.dns-81.svc.cluster.local;sleep 1; done
   @ 05/11/25 14:52:54.792
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-81.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-81.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-81.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-81.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-81.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-81.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-81.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-81.svc.cluster.local;sleep 1; done
   @ 05/11/25 14:52:54.792
  STEP: creating a pod to probe DNS @ 05/11/25 14:52:54.792
  STEP: submitting the pod to kubernetes @ 05/11/25 14:52:54.792
  E0511 14:52:54.875428      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:55.876123      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/11/25 14:52:56.806
  STEP: looking for the results for each expected name from probers @ 05/11/25 14:52:56.808
  I0511 14:52:56.815105 26 dns_common.go:495] Unable to read agnhost_tcp@dns-test-service-2.dns-81.svc.cluster.local from pod dns-81/dns-test-22da1f36-2a44-4245-9b87-5ed353626576: the server could not find the requested resource (get pods dns-test-22da1f36-2a44-4245-9b87-5ed353626576)
  I0511 14:52:56.821280 26 dns_common.go:506] Lookups using dns-81/dns-test-22da1f36-2a44-4245-9b87-5ed353626576 failed for: [agnhost_tcp@dns-test-service-2.dns-81.svc.cluster.local]

  I0511 14:52:56.833003 26 dns_common.go:514] Pod client logs for webserver: 
  I0511 14:52:56.838936 26 dns_common.go:514] Pod client logs for agnhost-querier: 
  I0511 14:52:56.845216 26 dns_common.go:514] Pod client logs for jessie-querier: 
  E0511 14:52:56.876892      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:57.877420      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:58.878034      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:52:59.878039      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:00.878819      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:53:01.835236 26 dns_common.go:546] DNS probes using dns-81/dns-test-22da1f36-2a44-4245-9b87-5ed353626576 succeeded

  STEP: deleting the pod @ 05/11/25 14:53:01.835
  STEP: deleting the test headless service @ 05/11/25 14:53:01.849
  I0511 14:53:01.866977 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-81" for this suite. @ 05/11/25 14:53:01.875
  E0511 14:53:01.879446      26 retrywatcher.go:169] "Watch failed" err="context canceled"
• [7.107 seconds]
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:884
  STEP: Creating a kubernetes client @ 05/11/25 14:53:01.881
  I0511 14:53:01.881038 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubectl @ 05/11/25 14:53:01.881
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:53:01.889
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:53:01.892
  STEP: validating api versions @ 05/11/25 14:53:01.893
  I0511 14:53:01.893477 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-7790 api-versions'
  I0511 14:53:01.934317 26 builder.go:146] stderr: ""
  I0511 14:53:01.934355 26 builder.go:147] stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  I0511 14:53:01.934486 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7790" for this suite. @ 05/11/25 14:53:01.973
• [0.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:194
  STEP: Creating a kubernetes client @ 05/11/25 14:53:01.981
  I0511 14:53:01.981138 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename aggregateddiscovery @ 05/11/25 14:53:01.982
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:53:01.992
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:53:01.995
  I0511 14:53:01.997312 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  E0511 14:53:02.880425      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:03.880927      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:04.881228      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:53:05.045267 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-2920" for this suite. @ 05/11/25 14:53:05.049
• [3.074 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 05/11/25 14:53:05.055
  I0511 14:53:05.055779 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/11/25 14:53:05.056
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:53:05.069
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:53:05.072
  STEP: fetching the /apis discovery document @ 05/11/25 14:53:05.076
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 05/11/25 14:53:05.077
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 05/11/25 14:53:05.077
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 05/11/25 14:53:05.077
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 05/11/25 14:53:05.078
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 05/11/25 14:53:05.078
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 05/11/25 14:53:05.079
  I0511 14:53:05.080003 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-8366" for this suite. @ 05/11/25 14:53:05.151
• [0.101 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:1086
  STEP: Creating a kubernetes client @ 05/11/25 14:53:05.157
  I0511 14:53:05.157588 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename pods @ 05/11/25 14:53:05.158
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:53:05.168
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:53:05.171
  STEP: Create a pod @ 05/11/25 14:53:05.175
  E0511 14:53:05.881741      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:06.881723      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: patching /status @ 05/11/25 14:53:07.19
  I0511 14:53:07.198227 26 pods.go:1123] Status Message: "Patched by e2e test" and Reason: "E2E"
  I0511 14:53:07.198452 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3244" for this suite. @ 05/11/25 14:53:07.202
• [2.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 05/11/25 14:53:07.211
  I0511 14:53:07.211183 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename svc-latency @ 05/11/25 14:53:07.212
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:53:07.221
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:53:07.224
  I0511 14:53:07.227849 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  I0511 14:53:07.237994 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0511 14:53:07.882876      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:08.883313      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:53:09.243958      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 14:53:09.245212      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 14:53:09.361009 26 service_latency.go:351] Created: latency-svc-fpdm4
  I0511 14:53:09.368799 26 service_latency.go:358] Got endpoints: latency-svc-fpdm4 [26.425726ms]
  I0511 14:53:09.387043 26 service_latency.go:351] Created: latency-svc-pgf8t
  I0511 14:53:09.394224 26 service_latency.go:358] Got endpoints: latency-svc-pgf8t [25.143237ms]
  I0511 14:53:09.394839 26 service_latency.go:351] Created: latency-svc-fwxl5
  I0511 14:53:09.401768 26 service_latency.go:358] Got endpoints: latency-svc-fwxl5 [32.487404ms]
  I0511 14:53:09.402003 26 service_latency.go:351] Created: latency-svc-b2kvn
  I0511 14:53:09.407608 26 service_latency.go:358] Got endpoints: latency-svc-b2kvn [38.673765ms]
  I0511 14:53:09.411429 26 service_latency.go:351] Created: latency-svc-ld766
  I0511 14:53:09.416642 26 service_latency.go:358] Got endpoints: latency-svc-ld766 [47.555267ms]
  I0511 14:53:09.425358 26 service_latency.go:351] Created: latency-svc-h7486
  I0511 14:53:09.443358 26 service_latency.go:358] Got endpoints: latency-svc-h7486 [74.119497ms]
  I0511 14:53:09.443422 26 service_latency.go:351] Created: latency-svc-5tdkd
  I0511 14:53:09.449754 26 service_latency.go:358] Got endpoints: latency-svc-5tdkd [80.521135ms]
  I0511 14:53:09.453088 26 service_latency.go:351] Created: latency-svc-hcc75
  I0511 14:53:09.458536 26 service_latency.go:358] Got endpoints: latency-svc-hcc75 [89.427948ms]
  I0511 14:53:09.464172 26 service_latency.go:351] Created: latency-svc-s9mnr
  I0511 14:53:09.484960 26 service_latency.go:358] Got endpoints: latency-svc-s9mnr [115.616233ms]
  I0511 14:53:09.492806 26 service_latency.go:351] Created: latency-svc-mr6xs
  I0511 14:53:09.496729 26 service_latency.go:358] Got endpoints: latency-svc-mr6xs [127.406405ms]
  I0511 14:53:09.508407 26 service_latency.go:351] Created: latency-svc-2g64l
  I0511 14:53:09.512995 26 service_latency.go:358] Got endpoints: latency-svc-2g64l [143.601623ms]
  I0511 14:53:09.516734 26 service_latency.go:351] Created: latency-svc-stxwb
  I0511 14:53:09.520840 26 service_latency.go:358] Got endpoints: latency-svc-stxwb [151.45623ms]
  I0511 14:53:09.526140 26 service_latency.go:351] Created: latency-svc-hbthb
  I0511 14:53:09.530558 26 service_latency.go:358] Got endpoints: latency-svc-hbthb [161.186789ms]
  I0511 14:53:09.535133 26 service_latency.go:351] Created: latency-svc-jt9xm
  I0511 14:53:09.539793 26 service_latency.go:358] Got endpoints: latency-svc-jt9xm [170.363549ms]
  I0511 14:53:09.548901 26 service_latency.go:351] Created: latency-svc-d8s85
  I0511 14:53:09.553331 26 service_latency.go:358] Got endpoints: latency-svc-d8s85 [183.894634ms]
  I0511 14:53:09.554844 26 service_latency.go:351] Created: latency-svc-sd6q2
  I0511 14:53:09.561215 26 service_latency.go:358] Got endpoints: latency-svc-sd6q2 [191.78701ms]
  I0511 14:53:09.564522 26 service_latency.go:351] Created: latency-svc-ngbg4
  I0511 14:53:09.569886 26 service_latency.go:358] Got endpoints: latency-svc-ngbg4 [175.596583ms]
  I0511 14:53:09.574061 26 service_latency.go:351] Created: latency-svc-569g9
  I0511 14:53:09.578279 26 service_latency.go:358] Got endpoints: latency-svc-569g9 [176.445938ms]
  I0511 14:53:09.616099 26 service_latency.go:351] Created: latency-svc-z8lc6
  I0511 14:53:09.633879 26 service_latency.go:358] Got endpoints: latency-svc-z8lc6 [226.212469ms]
  I0511 14:53:09.652898 26 service_latency.go:351] Created: latency-svc-ff7n4
  I0511 14:53:09.665025 26 service_latency.go:358] Got endpoints: latency-svc-ff7n4 [248.319211ms]
  I0511 14:53:09.666067 26 service_latency.go:351] Created: latency-svc-qwkdd
  I0511 14:53:09.668765 26 service_latency.go:358] Got endpoints: latency-svc-qwkdd [225.304718ms]
  I0511 14:53:09.682780 26 service_latency.go:351] Created: latency-svc-hf85n
  I0511 14:53:09.685312 26 service_latency.go:351] Created: latency-svc-2zppj
  I0511 14:53:09.686489 26 service_latency.go:358] Got endpoints: latency-svc-hf85n [236.615898ms]
  I0511 14:53:09.691065 26 service_latency.go:358] Got endpoints: latency-svc-2zppj [232.392924ms]
  I0511 14:53:09.694296 26 service_latency.go:351] Created: latency-svc-dkxbb
  I0511 14:53:09.699188 26 service_latency.go:358] Got endpoints: latency-svc-dkxbb [214.115703ms]
  I0511 14:53:09.706839 26 service_latency.go:351] Created: latency-svc-5bgqb
  I0511 14:53:09.710175 26 service_latency.go:358] Got endpoints: latency-svc-5bgqb [213.343747ms]
  I0511 14:53:09.744150 26 service_latency.go:351] Created: latency-svc-fbbxj
  I0511 14:53:09.748494 26 service_latency.go:351] Created: latency-svc-zt62l
  I0511 14:53:09.750259 26 service_latency.go:358] Got endpoints: latency-svc-fbbxj [237.145775ms]
  I0511 14:53:09.756659 26 service_latency.go:358] Got endpoints: latency-svc-zt62l [235.510522ms]
  I0511 14:53:09.765487 26 service_latency.go:351] Created: latency-svc-nd845
  I0511 14:53:09.774548 26 service_latency.go:358] Got endpoints: latency-svc-nd845 [243.947358ms]
  I0511 14:53:09.776860 26 service_latency.go:351] Created: latency-svc-56bvf
  I0511 14:53:09.780915 26 service_latency.go:351] Created: latency-svc-gkfjw
  I0511 14:53:09.781439 26 service_latency.go:358] Got endpoints: latency-svc-56bvf [241.527372ms]
  I0511 14:53:09.784964 26 service_latency.go:358] Got endpoints: latency-svc-gkfjw [231.523941ms]
  I0511 14:53:09.794099 26 service_latency.go:351] Created: latency-svc-lxrkw
  I0511 14:53:09.800595 26 service_latency.go:358] Got endpoints: latency-svc-lxrkw [239.340188ms]
  I0511 14:53:09.801562 26 service_latency.go:351] Created: latency-svc-kbhqd
  I0511 14:53:09.805214 26 service_latency.go:351] Created: latency-svc-bhpfb
  I0511 14:53:09.806021 26 service_latency.go:358] Got endpoints: latency-svc-kbhqd [236.063276ms]
  I0511 14:53:09.810863 26 service_latency.go:358] Got endpoints: latency-svc-bhpfb [232.529105ms]
  I0511 14:53:09.821899 26 service_latency.go:351] Created: latency-svc-spxnm
  I0511 14:53:09.825582 26 service_latency.go:358] Got endpoints: latency-svc-spxnm [191.547874ms]
  I0511 14:53:09.829593 26 service_latency.go:351] Created: latency-svc-fxl8v
  I0511 14:53:09.833613 26 service_latency.go:358] Got endpoints: latency-svc-fxl8v [168.523342ms]
  I0511 14:53:09.837144 26 service_latency.go:351] Created: latency-svc-pbdtz
  I0511 14:53:09.872721 26 service_latency.go:358] Got endpoints: latency-svc-pbdtz [203.900258ms]
  I0511 14:53:09.873884 26 service_latency.go:351] Created: latency-svc-4ctb8
  I0511 14:53:09.880380 26 service_latency.go:358] Got endpoints: latency-svc-4ctb8 [193.835617ms]
  E0511 14:53:09.883733      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:53:09.884943 26 service_latency.go:351] Created: latency-svc-kxhbz
  I0511 14:53:09.888950 26 service_latency.go:358] Got endpoints: latency-svc-kxhbz [197.844901ms]
  I0511 14:53:09.895266 26 service_latency.go:351] Created: latency-svc-httzp
  I0511 14:53:09.898870 26 service_latency.go:358] Got endpoints: latency-svc-httzp [199.641123ms]
  I0511 14:53:09.903436 26 service_latency.go:351] Created: latency-svc-w2gqx
  I0511 14:53:09.908967 26 service_latency.go:358] Got endpoints: latency-svc-w2gqx [198.710723ms]
  I0511 14:53:09.914260 26 service_latency.go:351] Created: latency-svc-v2csk
  I0511 14:53:09.918394 26 service_latency.go:358] Got endpoints: latency-svc-v2csk [168.052022ms]
  I0511 14:53:09.925829 26 service_latency.go:351] Created: latency-svc-v52mn
  I0511 14:53:09.928631 26 service_latency.go:351] Created: latency-svc-zqtns
  I0511 14:53:09.938420 26 service_latency.go:351] Created: latency-svc-dt89t
  I0511 14:53:09.945770 26 service_latency.go:351] Created: latency-svc-9hqp4
  I0511 14:53:09.953830 26 service_latency.go:351] Created: latency-svc-2zkk5
  I0511 14:53:09.962838 26 service_latency.go:351] Created: latency-svc-7ghwc
  I0511 14:53:09.966447 26 service_latency.go:351] Created: latency-svc-nq9kv
  I0511 14:53:09.966993 26 service_latency.go:358] Got endpoints: latency-svc-v52mn [210.217899ms]
  I0511 14:53:10.003636 26 service_latency.go:351] Created: latency-svc-9hrpv
  I0511 14:53:10.012087 26 service_latency.go:351] Created: latency-svc-57cwg
  I0511 14:53:10.020296 26 service_latency.go:358] Got endpoints: latency-svc-zqtns [245.681573ms]
  I0511 14:53:10.020794 26 service_latency.go:351] Created: latency-svc-nmwzh
  I0511 14:53:10.030018 26 service_latency.go:351] Created: latency-svc-nfj4z
  I0511 14:53:10.033684 26 service_latency.go:351] Created: latency-svc-t987r
  I0511 14:53:10.042170 26 service_latency.go:351] Created: latency-svc-7hthp
  I0511 14:53:10.047504 26 service_latency.go:351] Created: latency-svc-sdhv8
  I0511 14:53:10.056976 26 service_latency.go:351] Created: latency-svc-vc8jr
  I0511 14:53:10.064479 26 service_latency.go:351] Created: latency-svc-kf759
  I0511 14:53:10.066033 26 service_latency.go:358] Got endpoints: latency-svc-dt89t [284.487048ms]
  I0511 14:53:10.068787 26 service_latency.go:351] Created: latency-svc-ncp9x
  I0511 14:53:10.079342 26 service_latency.go:351] Created: latency-svc-xzjgc
  I0511 14:53:10.123190 26 service_latency.go:358] Got endpoints: latency-svc-9hqp4 [338.126613ms]
  I0511 14:53:10.144981 26 service_latency.go:351] Created: latency-svc-msgd7
  I0511 14:53:10.166438 26 service_latency.go:358] Got endpoints: latency-svc-2zkk5 [365.788478ms]
  I0511 14:53:10.183556 26 service_latency.go:351] Created: latency-svc-ks774
  I0511 14:53:10.217644 26 service_latency.go:358] Got endpoints: latency-svc-7ghwc [411.566441ms]
  I0511 14:53:10.236769 26 service_latency.go:351] Created: latency-svc-6cqr4
  I0511 14:53:10.268222 26 service_latency.go:358] Got endpoints: latency-svc-nq9kv [457.254615ms]
  I0511 14:53:10.286023 26 service_latency.go:351] Created: latency-svc-rhjr9
  I0511 14:53:10.315988 26 service_latency.go:358] Got endpoints: latency-svc-9hrpv [490.320742ms]
  I0511 14:53:10.345079 26 service_latency.go:351] Created: latency-svc-7mwcz
  I0511 14:53:10.364135 26 service_latency.go:358] Got endpoints: latency-svc-57cwg [530.453963ms]
  I0511 14:53:10.376213 26 service_latency.go:351] Created: latency-svc-lfk67
  I0511 14:53:10.413851 26 service_latency.go:358] Got endpoints: latency-svc-nmwzh [541.003289ms]
  I0511 14:53:10.424428 26 service_latency.go:351] Created: latency-svc-9h94b
  I0511 14:53:10.466522 26 service_latency.go:358] Got endpoints: latency-svc-nfj4z [586.000461ms]
  I0511 14:53:10.483582 26 service_latency.go:351] Created: latency-svc-fqscv
  I0511 14:53:10.515423 26 service_latency.go:358] Got endpoints: latency-svc-t987r [626.423429ms]
  I0511 14:53:10.532646 26 service_latency.go:351] Created: latency-svc-p287t
  I0511 14:53:10.566303 26 service_latency.go:358] Got endpoints: latency-svc-7hthp [667.384366ms]
  I0511 14:53:10.584674 26 service_latency.go:351] Created: latency-svc-tx2ds
  I0511 14:53:10.616772 26 service_latency.go:358] Got endpoints: latency-svc-sdhv8 [707.758935ms]
  I0511 14:53:10.631869 26 service_latency.go:351] Created: latency-svc-wqllv
  I0511 14:53:10.669308 26 service_latency.go:358] Got endpoints: latency-svc-vc8jr [750.781677ms]
  I0511 14:53:10.712609 26 service_latency.go:351] Created: latency-svc-nccdk
  I0511 14:53:10.719354 26 service_latency.go:358] Got endpoints: latency-svc-kf759 [752.325632ms]
  I0511 14:53:10.729530 26 service_latency.go:351] Created: latency-svc-ph6cs
  I0511 14:53:10.766564 26 service_latency.go:358] Got endpoints: latency-svc-ncp9x [746.155356ms]
  I0511 14:53:10.791182 26 service_latency.go:351] Created: latency-svc-wdnj7
  I0511 14:53:10.815592 26 service_latency.go:358] Got endpoints: latency-svc-xzjgc [749.468815ms]
  I0511 14:53:10.826764 26 service_latency.go:351] Created: latency-svc-htjbq
  I0511 14:53:10.866410 26 service_latency.go:358] Got endpoints: latency-svc-msgd7 [743.120918ms]
  E0511 14:53:10.883782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:53:10.886678 26 service_latency.go:351] Created: latency-svc-cn6nd
  I0511 14:53:10.916448 26 service_latency.go:358] Got endpoints: latency-svc-ks774 [749.899144ms]
  I0511 14:53:10.931945 26 service_latency.go:351] Created: latency-svc-zxrz7
  I0511 14:53:10.965643 26 service_latency.go:358] Got endpoints: latency-svc-6cqr4 [747.898443ms]
  I0511 14:53:10.980828 26 service_latency.go:351] Created: latency-svc-jxzgh
  I0511 14:53:11.016239 26 service_latency.go:358] Got endpoints: latency-svc-rhjr9 [747.936365ms]
  I0511 14:53:11.032925 26 service_latency.go:351] Created: latency-svc-d5nlv
  I0511 14:53:11.068478 26 service_latency.go:358] Got endpoints: latency-svc-7mwcz [752.413902ms]
  I0511 14:53:11.081800 26 service_latency.go:351] Created: latency-svc-n748w
  I0511 14:53:11.116704 26 service_latency.go:358] Got endpoints: latency-svc-lfk67 [752.51307ms]
  I0511 14:53:11.133574 26 service_latency.go:351] Created: latency-svc-hb52g
  I0511 14:53:11.167739 26 service_latency.go:358] Got endpoints: latency-svc-9h94b [753.837072ms]
  I0511 14:53:11.184490 26 service_latency.go:351] Created: latency-svc-wl6qq
  I0511 14:53:11.215475 26 service_latency.go:358] Got endpoints: latency-svc-fqscv [748.847742ms]
  I0511 14:53:11.231669 26 service_latency.go:351] Created: latency-svc-9bw2l
  I0511 14:53:11.266594 26 service_latency.go:358] Got endpoints: latency-svc-p287t [751.062147ms]
  I0511 14:53:11.288902 26 service_latency.go:351] Created: latency-svc-h8xpx
  I0511 14:53:11.316324 26 service_latency.go:358] Got endpoints: latency-svc-tx2ds [749.922779ms]
  I0511 14:53:11.332301 26 service_latency.go:351] Created: latency-svc-g2k68
  I0511 14:53:11.365590 26 service_latency.go:358] Got endpoints: latency-svc-wqllv [748.739766ms]
  I0511 14:53:11.381139 26 service_latency.go:351] Created: latency-svc-5sw2c
  I0511 14:53:11.414288 26 service_latency.go:358] Got endpoints: latency-svc-nccdk [744.758113ms]
  I0511 14:53:11.432309 26 service_latency.go:351] Created: latency-svc-k9fhb
  I0511 14:53:11.466285 26 service_latency.go:358] Got endpoints: latency-svc-ph6cs [746.881819ms]
  I0511 14:53:11.482931 26 service_latency.go:351] Created: latency-svc-9vhwg
  I0511 14:53:11.514192 26 service_latency.go:358] Got endpoints: latency-svc-wdnj7 [747.553514ms]
  I0511 14:53:11.529085 26 service_latency.go:351] Created: latency-svc-44pgm
  I0511 14:53:11.565824 26 service_latency.go:358] Got endpoints: latency-svc-htjbq [750.120267ms]
  I0511 14:53:11.580533 26 service_latency.go:351] Created: latency-svc-q5f9k
  I0511 14:53:11.617640 26 service_latency.go:358] Got endpoints: latency-svc-cn6nd [751.120163ms]
  I0511 14:53:11.638356 26 service_latency.go:351] Created: latency-svc-gvh4w
  I0511 14:53:11.668004 26 service_latency.go:358] Got endpoints: latency-svc-zxrz7 [751.466306ms]
  I0511 14:53:11.683398 26 service_latency.go:351] Created: latency-svc-66sqw
  I0511 14:53:11.717865 26 service_latency.go:358] Got endpoints: latency-svc-jxzgh [752.138294ms]
  I0511 14:53:11.733390 26 service_latency.go:351] Created: latency-svc-dswl5
  I0511 14:53:11.767423 26 service_latency.go:358] Got endpoints: latency-svc-d5nlv [751.112514ms]
  I0511 14:53:11.782733 26 service_latency.go:351] Created: latency-svc-rtldm
  I0511 14:53:11.814896 26 service_latency.go:358] Got endpoints: latency-svc-n748w [746.359062ms]
  I0511 14:53:11.830350 26 service_latency.go:351] Created: latency-svc-fn7f7
  I0511 14:53:11.866821 26 service_latency.go:358] Got endpoints: latency-svc-hb52g [750.027158ms]
  I0511 14:53:11.882703 26 service_latency.go:351] Created: latency-svc-kxlzm
  E0511 14:53:11.883782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:53:11.915353 26 service_latency.go:358] Got endpoints: latency-svc-wl6qq [747.50807ms]
  I0511 14:53:11.932420 26 service_latency.go:351] Created: latency-svc-df944
  I0511 14:53:11.966288 26 service_latency.go:358] Got endpoints: latency-svc-9bw2l [750.733258ms]
  I0511 14:53:11.984522 26 service_latency.go:351] Created: latency-svc-dklgc
  I0511 14:53:12.016610 26 service_latency.go:358] Got endpoints: latency-svc-h8xpx [749.946126ms]
  I0511 14:53:12.034637 26 service_latency.go:351] Created: latency-svc-75pbn
  I0511 14:53:12.067365 26 service_latency.go:358] Got endpoints: latency-svc-g2k68 [750.949727ms]
  I0511 14:53:12.084456 26 service_latency.go:351] Created: latency-svc-cdzn5
  I0511 14:53:12.115884 26 service_latency.go:358] Got endpoints: latency-svc-5sw2c [750.173773ms]
  I0511 14:53:12.135000 26 service_latency.go:351] Created: latency-svc-4tkhc
  I0511 14:53:12.168396 26 service_latency.go:358] Got endpoints: latency-svc-k9fhb [754.050099ms]
  I0511 14:53:12.184819 26 service_latency.go:351] Created: latency-svc-x8htb
  I0511 14:53:12.216004 26 service_latency.go:358] Got endpoints: latency-svc-9vhwg [749.613002ms]
  I0511 14:53:12.233825 26 service_latency.go:351] Created: latency-svc-kxsks
  I0511 14:53:12.265568 26 service_latency.go:358] Got endpoints: latency-svc-44pgm [751.300285ms]
  I0511 14:53:12.292219 26 service_latency.go:351] Created: latency-svc-fxjwb
  I0511 14:53:12.316383 26 service_latency.go:358] Got endpoints: latency-svc-q5f9k [750.480465ms]
  I0511 14:53:12.334106 26 service_latency.go:351] Created: latency-svc-tb4hv
  I0511 14:53:12.365903 26 service_latency.go:358] Got endpoints: latency-svc-gvh4w [748.199179ms]
  I0511 14:53:12.383810 26 service_latency.go:351] Created: latency-svc-lkx4g
  I0511 14:53:12.416581 26 service_latency.go:358] Got endpoints: latency-svc-66sqw [748.510476ms]
  I0511 14:53:12.429596 26 service_latency.go:351] Created: latency-svc-swk5p
  I0511 14:53:12.464700 26 service_latency.go:358] Got endpoints: latency-svc-dswl5 [746.741484ms]
  I0511 14:53:12.473639 26 service_latency.go:351] Created: latency-svc-ql7dt
  I0511 14:53:12.516922 26 service_latency.go:358] Got endpoints: latency-svc-rtldm [749.357737ms]
  I0511 14:53:12.533187 26 service_latency.go:351] Created: latency-svc-7zsqj
  I0511 14:53:12.567246 26 service_latency.go:358] Got endpoints: latency-svc-fn7f7 [752.264987ms]
  I0511 14:53:12.582897 26 service_latency.go:351] Created: latency-svc-ftvss
  I0511 14:53:12.616682 26 service_latency.go:358] Got endpoints: latency-svc-kxlzm [749.795504ms]
  I0511 14:53:12.631002 26 service_latency.go:351] Created: latency-svc-wdrcr
  I0511 14:53:12.666303 26 service_latency.go:358] Got endpoints: latency-svc-df944 [750.883847ms]
  I0511 14:53:12.682241 26 service_latency.go:351] Created: latency-svc-z95wh
  I0511 14:53:12.716243 26 service_latency.go:358] Got endpoints: latency-svc-dklgc [749.85366ms]
  I0511 14:53:12.731365 26 service_latency.go:351] Created: latency-svc-drxgs
  I0511 14:53:12.766066 26 service_latency.go:358] Got endpoints: latency-svc-75pbn [749.343843ms]
  I0511 14:53:12.781222 26 service_latency.go:351] Created: latency-svc-55h9d
  I0511 14:53:12.817712 26 service_latency.go:358] Got endpoints: latency-svc-cdzn5 [750.261105ms]
  I0511 14:53:12.860163 26 service_latency.go:351] Created: latency-svc-qfp5x
  I0511 14:53:12.863861 26 service_latency.go:358] Got endpoints: latency-svc-4tkhc [747.911985ms]
  I0511 14:53:12.872879 26 service_latency.go:351] Created: latency-svc-78fvl
  E0511 14:53:12.884146      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:53:12.916586 26 service_latency.go:358] Got endpoints: latency-svc-x8htb [748.044656ms]
  I0511 14:53:12.933091 26 service_latency.go:351] Created: latency-svc-6c9zd
  I0511 14:53:12.965406 26 service_latency.go:358] Got endpoints: latency-svc-kxsks [749.324346ms]
  I0511 14:53:12.981293 26 service_latency.go:351] Created: latency-svc-q5fp4
  I0511 14:53:13.016134 26 service_latency.go:358] Got endpoints: latency-svc-fxjwb [750.498943ms]
  I0511 14:53:13.035054 26 service_latency.go:351] Created: latency-svc-zq7gr
  I0511 14:53:13.065859 26 service_latency.go:358] Got endpoints: latency-svc-tb4hv [749.408711ms]
  I0511 14:53:13.078594 26 service_latency.go:351] Created: latency-svc-c7pv8
  I0511 14:53:13.120069 26 service_latency.go:358] Got endpoints: latency-svc-lkx4g [754.11133ms]
  I0511 14:53:13.139627 26 service_latency.go:351] Created: latency-svc-74cpp
  I0511 14:53:13.165002 26 service_latency.go:358] Got endpoints: latency-svc-swk5p [748.37285ms]
  I0511 14:53:13.176305 26 service_latency.go:351] Created: latency-svc-gw4xm
  I0511 14:53:13.217153 26 service_latency.go:358] Got endpoints: latency-svc-ql7dt [752.403907ms]
  I0511 14:53:13.240765 26 service_latency.go:351] Created: latency-svc-xkvwt
  I0511 14:53:13.267586 26 service_latency.go:358] Got endpoints: latency-svc-7zsqj [750.582268ms]
  I0511 14:53:13.284184 26 service_latency.go:351] Created: latency-svc-qw9jj
  I0511 14:53:13.316635 26 service_latency.go:358] Got endpoints: latency-svc-ftvss [749.306392ms]
  I0511 14:53:13.331752 26 service_latency.go:351] Created: latency-svc-tz5fx
  I0511 14:53:13.368229 26 service_latency.go:358] Got endpoints: latency-svc-wdrcr [751.478806ms]
  I0511 14:53:13.381553 26 service_latency.go:351] Created: latency-svc-59fzc
  I0511 14:53:13.414957 26 service_latency.go:358] Got endpoints: latency-svc-z95wh [748.585876ms]
  I0511 14:53:13.432929 26 service_latency.go:351] Created: latency-svc-hfdld
  I0511 14:53:13.463970 26 service_latency.go:358] Got endpoints: latency-svc-drxgs [747.66299ms]
  I0511 14:53:13.473314 26 service_latency.go:351] Created: latency-svc-hkbz6
  I0511 14:53:13.516855 26 service_latency.go:358] Got endpoints: latency-svc-55h9d [750.629894ms]
  I0511 14:53:13.533529 26 service_latency.go:351] Created: latency-svc-n57t9
  I0511 14:53:13.567737 26 service_latency.go:358] Got endpoints: latency-svc-qfp5x [749.953762ms]
  I0511 14:53:13.587061 26 service_latency.go:351] Created: latency-svc-gms6b
  I0511 14:53:13.615368 26 service_latency.go:358] Got endpoints: latency-svc-78fvl [751.47557ms]
  I0511 14:53:13.624340 26 service_latency.go:351] Created: latency-svc-85cq2
  I0511 14:53:13.665243 26 service_latency.go:358] Got endpoints: latency-svc-6c9zd [748.591833ms]
  I0511 14:53:13.677544 26 service_latency.go:351] Created: latency-svc-6ll66
  I0511 14:53:13.716007 26 service_latency.go:358] Got endpoints: latency-svc-q5fp4 [750.508695ms]
  I0511 14:53:13.732109 26 service_latency.go:351] Created: latency-svc-fc2zt
  I0511 14:53:13.765713 26 service_latency.go:358] Got endpoints: latency-svc-zq7gr [749.462531ms]
  I0511 14:53:13.781144 26 service_latency.go:351] Created: latency-svc-895pg
  I0511 14:53:13.816073 26 service_latency.go:358] Got endpoints: latency-svc-c7pv8 [750.163187ms]
  I0511 14:53:13.833034 26 service_latency.go:351] Created: latency-svc-9w8rq
  I0511 14:53:13.865810 26 service_latency.go:358] Got endpoints: latency-svc-74cpp [745.63383ms]
  I0511 14:53:13.882602 26 service_latency.go:351] Created: latency-svc-vhgdh
  E0511 14:53:13.884697      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:53:13.915672 26 service_latency.go:358] Got endpoints: latency-svc-gw4xm [750.571349ms]
  I0511 14:53:13.926277 26 service_latency.go:351] Created: latency-svc-wmhnx
  I0511 14:53:13.967377 26 service_latency.go:358] Got endpoints: latency-svc-xkvwt [750.145632ms]
  I0511 14:53:13.983791 26 service_latency.go:351] Created: latency-svc-9v6f2
  I0511 14:53:14.013787 26 service_latency.go:358] Got endpoints: latency-svc-qw9jj [746.089183ms]
  I0511 14:53:14.023934 26 service_latency.go:351] Created: latency-svc-mvvh8
  I0511 14:53:14.065946 26 service_latency.go:358] Got endpoints: latency-svc-tz5fx [749.228337ms]
  I0511 14:53:14.081495 26 service_latency.go:351] Created: latency-svc-xzcqt
  I0511 14:53:14.117782 26 service_latency.go:358] Got endpoints: latency-svc-59fzc [749.484986ms]
  I0511 14:53:14.135489 26 service_latency.go:351] Created: latency-svc-lws62
  I0511 14:53:14.166997 26 service_latency.go:358] Got endpoints: latency-svc-hfdld [751.976841ms]
  I0511 14:53:14.182740 26 service_latency.go:351] Created: latency-svc-gm9ns
  I0511 14:53:14.216326 26 service_latency.go:358] Got endpoints: latency-svc-hkbz6 [752.307234ms]
  I0511 14:53:14.233765 26 service_latency.go:351] Created: latency-svc-gb6sz
  I0511 14:53:14.266350 26 service_latency.go:358] Got endpoints: latency-svc-n57t9 [749.431858ms]
  I0511 14:53:14.285999 26 service_latency.go:351] Created: latency-svc-srj2l
  I0511 14:53:14.315486 26 service_latency.go:358] Got endpoints: latency-svc-gms6b [747.652496ms]
  I0511 14:53:14.334254 26 service_latency.go:351] Created: latency-svc-6m478
  I0511 14:53:14.367080 26 service_latency.go:358] Got endpoints: latency-svc-85cq2 [751.660918ms]
  I0511 14:53:14.381325 26 service_latency.go:351] Created: latency-svc-wsptk
  I0511 14:53:14.415607 26 service_latency.go:358] Got endpoints: latency-svc-6ll66 [750.319268ms]
  I0511 14:53:14.425232 26 service_latency.go:351] Created: latency-svc-txsrs
  I0511 14:53:14.469261 26 service_latency.go:358] Got endpoints: latency-svc-fc2zt [753.164137ms]
  I0511 14:53:14.490571 26 service_latency.go:351] Created: latency-svc-vnwrb
  I0511 14:53:14.518294 26 service_latency.go:358] Got endpoints: latency-svc-895pg [752.45923ms]
  I0511 14:53:14.536958 26 service_latency.go:351] Created: latency-svc-dbs57
  I0511 14:53:14.567600 26 service_latency.go:358] Got endpoints: latency-svc-9w8rq [751.45636ms]
  I0511 14:53:14.594494 26 service_latency.go:351] Created: latency-svc-gn2lf
  I0511 14:53:14.615349 26 service_latency.go:358] Got endpoints: latency-svc-vhgdh [749.468233ms]
  I0511 14:53:14.632192 26 service_latency.go:351] Created: latency-svc-85flk
  I0511 14:53:14.665674 26 service_latency.go:358] Got endpoints: latency-svc-wmhnx [749.913387ms]
  I0511 14:53:14.682569 26 service_latency.go:351] Created: latency-svc-r7dql
  I0511 14:53:14.716255 26 service_latency.go:358] Got endpoints: latency-svc-9v6f2 [748.801179ms]
  I0511 14:53:14.732431 26 service_latency.go:351] Created: latency-svc-5glsd
  I0511 14:53:14.766716 26 service_latency.go:358] Got endpoints: latency-svc-mvvh8 [752.886273ms]
  I0511 14:53:14.781997 26 service_latency.go:351] Created: latency-svc-5prpj
  I0511 14:53:14.819876 26 service_latency.go:358] Got endpoints: latency-svc-xzcqt [753.863885ms]
  I0511 14:53:14.830058 26 service_latency.go:351] Created: latency-svc-p6k8g
  I0511 14:53:14.867091 26 service_latency.go:358] Got endpoints: latency-svc-lws62 [749.230047ms]
  I0511 14:53:14.882402 26 service_latency.go:351] Created: latency-svc-nvqq2
  E0511 14:53:14.885633      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:53:14.915747 26 service_latency.go:358] Got endpoints: latency-svc-gm9ns [748.676407ms]
  I0511 14:53:14.931813 26 service_latency.go:351] Created: latency-svc-5bt6h
  I0511 14:53:14.965810 26 service_latency.go:358] Got endpoints: latency-svc-gb6sz [749.415853ms]
  I0511 14:53:14.980618 26 service_latency.go:351] Created: latency-svc-brwjw
  I0511 14:53:15.018182 26 service_latency.go:358] Got endpoints: latency-svc-srj2l [751.748032ms]
  I0511 14:53:15.034799 26 service_latency.go:351] Created: latency-svc-zh9rh
  I0511 14:53:15.065822 26 service_latency.go:358] Got endpoints: latency-svc-6m478 [750.264142ms]
  I0511 14:53:15.098235 26 service_latency.go:351] Created: latency-svc-q2xhg
  I0511 14:53:15.114852 26 service_latency.go:358] Got endpoints: latency-svc-wsptk [747.698482ms]
  I0511 14:53:15.124453 26 service_latency.go:351] Created: latency-svc-57fhb
  I0511 14:53:15.165939 26 service_latency.go:358] Got endpoints: latency-svc-txsrs [750.259713ms]
  I0511 14:53:15.182621 26 service_latency.go:351] Created: latency-svc-jnmrh
  I0511 14:53:15.218801 26 service_latency.go:358] Got endpoints: latency-svc-vnwrb [749.452414ms]
  I0511 14:53:15.235192 26 service_latency.go:351] Created: latency-svc-dlzhs
  I0511 14:53:15.266051 26 service_latency.go:358] Got endpoints: latency-svc-dbs57 [747.6688ms]
  I0511 14:53:15.281406 26 service_latency.go:351] Created: latency-svc-8bqhg
  I0511 14:53:15.322403 26 service_latency.go:358] Got endpoints: latency-svc-gn2lf [754.728049ms]
  I0511 14:53:15.333401 26 service_latency.go:351] Created: latency-svc-28qbb
  I0511 14:53:15.367144 26 service_latency.go:358] Got endpoints: latency-svc-85flk [751.715124ms]
  I0511 14:53:15.382042 26 service_latency.go:351] Created: latency-svc-8q6xk
  I0511 14:53:15.416004 26 service_latency.go:358] Got endpoints: latency-svc-r7dql [750.223558ms]
  I0511 14:53:15.434432 26 service_latency.go:351] Created: latency-svc-ch5sd
  I0511 14:53:15.465940 26 service_latency.go:358] Got endpoints: latency-svc-5glsd [749.611257ms]
  I0511 14:53:15.482833 26 service_latency.go:351] Created: latency-svc-52r64
  I0511 14:53:15.516105 26 service_latency.go:358] Got endpoints: latency-svc-5prpj [749.314099ms]
  I0511 14:53:15.536950 26 service_latency.go:351] Created: latency-svc-lrd55
  I0511 14:53:15.566554 26 service_latency.go:358] Got endpoints: latency-svc-p6k8g [746.619708ms]
  I0511 14:53:15.583887 26 service_latency.go:351] Created: latency-svc-mf66x
  I0511 14:53:15.616524 26 service_latency.go:358] Got endpoints: latency-svc-nvqq2 [749.361015ms]
  I0511 14:53:15.633286 26 service_latency.go:351] Created: latency-svc-ncpwf
  I0511 14:53:15.667703 26 service_latency.go:358] Got endpoints: latency-svc-5bt6h [751.888152ms]
  I0511 14:53:15.684224 26 service_latency.go:351] Created: latency-svc-vs46t
  I0511 14:53:15.717491 26 service_latency.go:358] Got endpoints: latency-svc-brwjw [751.584075ms]
  I0511 14:53:15.734186 26 service_latency.go:351] Created: latency-svc-tcl6q
  I0511 14:53:15.766886 26 service_latency.go:358] Got endpoints: latency-svc-zh9rh [748.636024ms]
  I0511 14:53:15.779739 26 service_latency.go:351] Created: latency-svc-sh6kv
  I0511 14:53:15.815184 26 service_latency.go:358] Got endpoints: latency-svc-q2xhg [749.280638ms]
  I0511 14:53:15.830585 26 service_latency.go:351] Created: latency-svc-j2mkc
  I0511 14:53:15.867046 26 service_latency.go:358] Got endpoints: latency-svc-57fhb [752.145391ms]
  I0511 14:53:15.882485 26 service_latency.go:351] Created: latency-svc-ts7x8
  E0511 14:53:15.886630      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:53:15.915939 26 service_latency.go:358] Got endpoints: latency-svc-jnmrh [749.927317ms]
  I0511 14:53:15.930855 26 service_latency.go:351] Created: latency-svc-7drq5
  I0511 14:53:15.966182 26 service_latency.go:358] Got endpoints: latency-svc-dlzhs [747.289449ms]
  I0511 14:53:15.979584 26 service_latency.go:351] Created: latency-svc-zzl9f
  I0511 14:53:16.015504 26 service_latency.go:358] Got endpoints: latency-svc-8bqhg [749.384864ms]
  I0511 14:53:16.031523 26 service_latency.go:351] Created: latency-svc-phhkl
  I0511 14:53:16.066662 26 service_latency.go:358] Got endpoints: latency-svc-28qbb [744.168807ms]
  I0511 14:53:16.087541 26 service_latency.go:351] Created: latency-svc-978zn
  I0511 14:53:16.116975 26 service_latency.go:358] Got endpoints: latency-svc-8q6xk [749.710595ms]
  I0511 14:53:16.132905 26 service_latency.go:351] Created: latency-svc-k4vng
  I0511 14:53:16.166721 26 service_latency.go:358] Got endpoints: latency-svc-ch5sd [750.642815ms]
  I0511 14:53:16.183718 26 service_latency.go:351] Created: latency-svc-7kkkn
  I0511 14:53:16.217800 26 service_latency.go:358] Got endpoints: latency-svc-52r64 [751.788758ms]
  I0511 14:53:16.232433 26 service_latency.go:351] Created: latency-svc-hcwcg
  I0511 14:53:16.266128 26 service_latency.go:358] Got endpoints: latency-svc-lrd55 [749.865755ms]
  I0511 14:53:16.282875 26 service_latency.go:351] Created: latency-svc-bx9qf
  I0511 14:53:16.313463 26 service_latency.go:358] Got endpoints: latency-svc-mf66x [746.840935ms]
  I0511 14:53:16.322651 26 service_latency.go:351] Created: latency-svc-fvcnn
  I0511 14:53:16.369480 26 service_latency.go:358] Got endpoints: latency-svc-ncpwf [752.858349ms]
  I0511 14:53:16.383866 26 service_latency.go:351] Created: latency-svc-p8fnt
  I0511 14:53:16.416748 26 service_latency.go:358] Got endpoints: latency-svc-vs46t [748.95716ms]
  I0511 14:53:16.431034 26 service_latency.go:351] Created: latency-svc-jkwr7
  I0511 14:53:16.466511 26 service_latency.go:358] Got endpoints: latency-svc-tcl6q [748.934018ms]
  I0511 14:53:16.486883 26 service_latency.go:351] Created: latency-svc-kmlk7
  I0511 14:53:16.515565 26 service_latency.go:358] Got endpoints: latency-svc-sh6kv [748.59091ms]
  I0511 14:53:16.531771 26 service_latency.go:351] Created: latency-svc-wzn2r
  I0511 14:53:16.566944 26 service_latency.go:358] Got endpoints: latency-svc-j2mkc [751.685447ms]
  I0511 14:53:16.583755 26 service_latency.go:351] Created: latency-svc-hrtkf
  I0511 14:53:16.615918 26 service_latency.go:358] Got endpoints: latency-svc-ts7x8 [748.756469ms]
  I0511 14:53:16.631867 26 service_latency.go:351] Created: latency-svc-kjz67
  I0511 14:53:16.666786 26 service_latency.go:358] Got endpoints: latency-svc-7drq5 [750.765503ms]
  I0511 14:53:16.685720 26 service_latency.go:351] Created: latency-svc-4h7gb
  I0511 14:53:16.715903 26 service_latency.go:358] Got endpoints: latency-svc-zzl9f [749.621219ms]
  I0511 14:53:16.731860 26 service_latency.go:351] Created: latency-svc-7ztt6
  I0511 14:53:16.767290 26 service_latency.go:358] Got endpoints: latency-svc-phhkl [751.721294ms]
  I0511 14:53:16.779069 26 service_latency.go:351] Created: latency-svc-tfb4p
  I0511 14:53:16.817770 26 service_latency.go:358] Got endpoints: latency-svc-978zn [751.023653ms]
  I0511 14:53:16.832253 26 service_latency.go:351] Created: latency-svc-8dsrn
  I0511 14:53:16.866585 26 service_latency.go:358] Got endpoints: latency-svc-k4vng [749.52966ms]
  I0511 14:53:16.881010 26 service_latency.go:351] Created: latency-svc-5flxg
  E0511 14:53:16.887144      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:53:16.917898 26 service_latency.go:358] Got endpoints: latency-svc-7kkkn [751.104923ms]
  I0511 14:53:16.933350 26 service_latency.go:351] Created: latency-svc-c8pbt
  I0511 14:53:16.967286 26 service_latency.go:358] Got endpoints: latency-svc-hcwcg [749.410909ms]
  I0511 14:53:16.983449 26 service_latency.go:351] Created: latency-svc-wb7hg
  I0511 14:53:17.015484 26 service_latency.go:358] Got endpoints: latency-svc-bx9qf [749.287955ms]
  I0511 14:53:17.032713 26 service_latency.go:351] Created: latency-svc-krmp8
  I0511 14:53:17.067623 26 service_latency.go:358] Got endpoints: latency-svc-fvcnn [754.088459ms]
  I0511 14:53:17.079924 26 service_latency.go:351] Created: latency-svc-5npsm
  I0511 14:53:17.115549 26 service_latency.go:358] Got endpoints: latency-svc-p8fnt [745.969367ms]
  I0511 14:53:17.130761 26 service_latency.go:351] Created: latency-svc-7rlcl
  I0511 14:53:17.167357 26 service_latency.go:358] Got endpoints: latency-svc-jkwr7 [750.520875ms]
  I0511 14:53:17.184812 26 service_latency.go:351] Created: latency-svc-xxbdt
  I0511 14:53:17.218299 26 service_latency.go:358] Got endpoints: latency-svc-kmlk7 [751.711577ms]
  I0511 14:53:17.265675 26 service_latency.go:358] Got endpoints: latency-svc-wzn2r [750.039482ms]
  I0511 14:53:17.318067 26 service_latency.go:358] Got endpoints: latency-svc-hrtkf [751.04217ms]
  I0511 14:53:17.367121 26 service_latency.go:358] Got endpoints: latency-svc-kjz67 [751.029038ms]
  I0511 14:53:17.418555 26 service_latency.go:358] Got endpoints: latency-svc-4h7gb [751.687217ms]
  I0511 14:53:17.467599 26 service_latency.go:358] Got endpoints: latency-svc-7ztt6 [751.613877ms]
  I0511 14:53:17.517895 26 service_latency.go:358] Got endpoints: latency-svc-tfb4p [750.540314ms]
  I0511 14:53:17.567107 26 service_latency.go:358] Got endpoints: latency-svc-8dsrn [749.264717ms]
  I0511 14:53:17.618677 26 service_latency.go:358] Got endpoints: latency-svc-5flxg [752.018209ms]
  I0511 14:53:17.668241 26 service_latency.go:358] Got endpoints: latency-svc-c8pbt [750.274721ms]
  I0511 14:53:17.717676 26 service_latency.go:358] Got endpoints: latency-svc-wb7hg [750.321048ms]
  I0511 14:53:17.767400 26 service_latency.go:358] Got endpoints: latency-svc-krmp8 [751.773954ms]
  I0511 14:53:17.818376 26 service_latency.go:358] Got endpoints: latency-svc-5npsm [750.649961ms]
  I0511 14:53:17.868395 26 service_latency.go:358] Got endpoints: latency-svc-7rlcl [752.778029ms]
  E0511 14:53:17.887834      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:53:17.918148 26 service_latency.go:358] Got endpoints: latency-svc-xxbdt [750.706854ms]
  I0511 14:53:17.918317 26 service_latency.go:114] Latencies: [25.143237ms 32.487404ms 38.673765ms 47.555267ms 74.119497ms 80.521135ms 89.427948ms 115.616233ms 127.406405ms 143.601623ms 151.45623ms 161.186789ms 168.052022ms 168.523342ms 170.363549ms 175.596583ms 176.445938ms 183.894634ms 191.547874ms 191.78701ms 193.835617ms 197.844901ms 198.710723ms 199.641123ms 203.900258ms 210.217899ms 213.343747ms 214.115703ms 225.304718ms 226.212469ms 231.523941ms 232.392924ms 232.529105ms 235.510522ms 236.063276ms 236.615898ms 237.145775ms 239.340188ms 241.527372ms 243.947358ms 245.681573ms 248.319211ms 284.487048ms 338.126613ms 365.788478ms 411.566441ms 457.254615ms 490.320742ms 530.453963ms 541.003289ms 586.000461ms 626.423429ms 667.384366ms 707.758935ms 743.120918ms 744.168807ms 744.758113ms 745.63383ms 745.969367ms 746.089183ms 746.155356ms 746.359062ms 746.619708ms 746.741484ms 746.840935ms 746.881819ms 747.289449ms 747.50807ms 747.553514ms 747.652496ms 747.66299ms 747.6688ms 747.698482ms 747.898443ms 747.911985ms 747.936365ms 748.044656ms 748.199179ms 748.37285ms 748.510476ms 748.585876ms 748.59091ms 748.591833ms 748.636024ms 748.676407ms 748.739766ms 748.756469ms 748.801179ms 748.847742ms 748.934018ms 748.95716ms 749.228337ms 749.230047ms 749.264717ms 749.280638ms 749.287955ms 749.306392ms 749.314099ms 749.324346ms 749.343843ms 749.357737ms 749.361015ms 749.384864ms 749.408711ms 749.410909ms 749.415853ms 749.431858ms 749.452414ms 749.462531ms 749.468233ms 749.468815ms 749.484986ms 749.52966ms 749.611257ms 749.613002ms 749.621219ms 749.710595ms 749.795504ms 749.85366ms 749.865755ms 749.899144ms 749.913387ms 749.922779ms 749.927317ms 749.946126ms 749.953762ms 750.027158ms 750.039482ms 750.120267ms 750.145632ms 750.163187ms 750.173773ms 750.223558ms 750.259713ms 750.261105ms 750.264142ms 750.274721ms 750.319268ms 750.321048ms 750.480465ms 750.498943ms 750.508695ms 750.520875ms 750.540314ms 750.571349ms 750.582268ms 750.629894ms 750.642815ms 750.649961ms 750.706854ms 750.733258ms 750.765503ms 750.781677ms 750.883847ms 750.949727ms 751.023653ms 751.029038ms 751.04217ms 751.062147ms 751.104923ms 751.112514ms 751.120163ms 751.300285ms 751.45636ms 751.466306ms 751.47557ms 751.478806ms 751.584075ms 751.613877ms 751.660918ms 751.685447ms 751.687217ms 751.711577ms 751.715124ms 751.721294ms 751.748032ms 751.773954ms 751.788758ms 751.888152ms 751.976841ms 752.018209ms 752.138294ms 752.145391ms 752.264987ms 752.307234ms 752.325632ms 752.403907ms 752.413902ms 752.45923ms 752.51307ms 752.778029ms 752.858349ms 752.886273ms 753.164137ms 753.837072ms 753.863885ms 754.050099ms 754.088459ms 754.11133ms 754.728049ms]
  I0511 14:53:17.918338 26 service_latency.go:118] 50 %ile: 749.357737ms
  I0511 14:53:17.918349 26 service_latency.go:119] 90 %ile: 752.018209ms
  I0511 14:53:17.918360 26 service_latency.go:120] 99 %ile: 754.11133ms
  I0511 14:53:17.918371 26 service_latency.go:121] Total sample count: 200
  I0511 14:53:17.918652 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-2044" for this suite. @ 05/11/25 14:53:17.924
• [10.719 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job with successPolicy succeededIndexes rule should succeeded even when some indexes remain pending [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:526
  STEP: Creating a kubernetes client @ 05/11/25 14:53:17.93
  I0511 14:53:17.930612 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename job @ 05/11/25 14:53:17.931
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:53:17.942
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:53:17.946
  STEP: Creating an indexed job with successPolicy succeededIndexes rule @ 05/11/25 14:53:17.948
  STEP: Awaiting for the job to have the interim SuccessCriteriaMet with SuccessPolicy reason condition @ 05/11/25 14:53:17.952
  E0511 14:53:18.888689      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:19.888840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:20.889436      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:21.889897      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensure that the job reaches completions @ 05/11/25 14:53:21.964
  STEP: Verifying that the only appropriately index succeeded @ 05/11/25 14:53:21.972
  I0511 14:53:21.974644 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2242" for this suite. @ 05/11/25 14:53:21.977
• [4.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:148
  STEP: Creating a kubernetes client @ 05/11/25 14:53:21.984
  I0511 14:53:21.984043 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubelet-test @ 05/11/25 14:53:21.985
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:53:21.994
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:53:21.997
  STEP: Waiting for pod completion @ 05/11/25 14:53:22.007
  E0511 14:53:22.890754      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:23.891664      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:24.892161      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:25.892732      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:53:26.056450 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-9109" for this suite. @ 05/11/25 14:53:26.06
• [4.086 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/volume_attachment.go:59
  STEP: Creating a kubernetes client @ 05/11/25 14:53:26.07
  I0511 14:53:26.070309 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename volumeattachment @ 05/11/25 14:53:26.072
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:53:26.084
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:53:26.086
  STEP: Create VolumeAttachment "va-e2e-t7tb8" on node "k8sconformance-m02" @ 05/11/25 14:53:26.17
  STEP: Get VolumeAttachment "va-e2e-t7tb8" on node "k8sconformance-m02" @ 05/11/25 14:53:26.176
  STEP: Patch VolumeAttachment "va-e2e-t7tb8" on node "k8sconformance-m02" @ 05/11/25 14:53:26.18
  STEP: List VolumeAttachments with "va-e2e-t7tb8=patched" label @ 05/11/25 14:53:26.185
  STEP: Delete VolumeAttachment "va-e2e-t7tb8" on node "k8sconformance-m02" @ 05/11/25 14:53:26.188
  STEP: Confirm deletion of VolumeAttachment "va-e2e-t7tb8" on node "k8sconformance-m02" @ 05/11/25 14:53:26.192
  STEP: Create VolumeAttachment "va-e2e-nbkwr" on node "k8sconformance-m02" @ 05/11/25 14:53:26.261
  STEP: Update the VolumeAttachment "va-e2e-nbkwr" on node "k8sconformance-m02" with label "va-e2e=updated" @ 05/11/25 14:53:26.266
  STEP: Create VolumeAttachment "va-e2e-g2t7s" on node "k8sconformance" @ 05/11/25 14:53:26.36
  STEP: Update the VolumeAttachment "va-e2e-g2t7s" on node "k8sconformance" with label "va-e2e=updated" @ 05/11/25 14:53:26.363
  STEP: DeleteCollection of VolumeAttachments with "va-e2e=updated" label @ 05/11/25 14:53:26.367
  STEP: Confirm deleteCollection of VolumeAttachments with "va-e2e=updated" label @ 05/11/25 14:53:26.373
  I0511 14:53:26.374536 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "volumeattachment-5296" for this suite. @ 05/11/25 14:53:26.462
• [0.397 seconds]
------------------------------
SS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:47
  STEP: Creating a kubernetes client @ 05/11/25 14:53:26.467
  I0511 14:53:26.467612 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename configmap @ 05/11/25 14:53:26.469
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:53:26.479
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:53:26.48
  STEP: Creating configMap with name configmap-test-volume-4060e3d1-bdc3-46e9-9311-af2c6b2864d9 @ 05/11/25 14:53:26.482
  STEP: Creating a pod to test consume configMaps @ 05/11/25 14:53:26.485
  E0511 14:53:26.893715      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:27.894806      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:53:28.5
  I0511 14:53:28.502578 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-8aacf12a-d93e-45aa-bb15-fae9d9cb05eb container agnhost-container: <nil>
  STEP: delete the pod @ 05/11/25 14:53:28.509
  I0511 14:53:28.524485 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4792" for this suite. @ 05/11/25 14:53:28.528
• [2.067 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Job should execute all indexes despite some failing when using backoffLimitPerIndex [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:609
  STEP: Creating a kubernetes client @ 05/11/25 14:53:28.535
  I0511 14:53:28.535173 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename job @ 05/11/25 14:53:28.536
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:53:28.548
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:53:28.551
  STEP: Creating an indexed job with backoffLimit per index and failing pods @ 05/11/25 14:53:28.554
  STEP: Awaiting for the job to fail as there are failed indexes @ 05/11/25 14:53:28.559
  E0511 14:53:28.895086      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:29.895692      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:30.896008      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:31.896767      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:32.897793      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:33.898906      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:34.898980      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:35.899871      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:36.900911      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:37.901829      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:38.902133      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:39.902795      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:40.902962      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:41.903485      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:42.904217      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:43.904696      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:44.905385      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:45.905951      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:46.906725      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:47.907165      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:48.907571      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:49.908025      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Verifying the Job status fields to ensure all indexes were executed @ 05/11/25 14:53:50.61
  I0511 14:53:50.612977 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2678" for this suite. @ 05/11/25 14:53:50.616
• [22.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] VolumeAttachment Conformance should apply changes to a volumeattachment status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/volume_attachment.go:180
  STEP: Creating a kubernetes client @ 05/11/25 14:53:50.623
  I0511 14:53:50.623181 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename volumeattachment @ 05/11/25 14:53:50.624
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:53:50.635
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:53:50.639
  STEP: Create VolumeAttachment "va-e2e-vxtcn" on node "k8sconformance" @ 05/11/25 14:53:50.718
  STEP: Patch VolumeAttachment "va-e2e-vxtcn" on node "k8sconformance" @ 05/11/25 14:53:50.722
  STEP: Reading "va-e2e-vxtcn" Status @ 05/11/25 14:53:50.727
  STEP: Patching "va-e2e-vxtcn" Status @ 05/11/25 14:53:50.731
  I0511 14:53:50.735742 26 volume_attachment.go:224] "va-e2e-vxtcn" Status.Attached: true
  STEP: Updating "va-e2e-vxtcn" Status @ 05/11/25 14:53:50.735
  I0511 14:53:50.743525 26 volume_attachment.go:240] "va-e2e-vxtcn" Status.Attached: false
  STEP: Delete VolumeAttachment "va-e2e-vxtcn" on node "k8sconformance" @ 05/11/25 14:53:50.743
  STEP: Confirm deletion of VolumeAttachment "va-e2e-vxtcn" on node "k8sconformance" @ 05/11/25 14:53:50.748
  I0511 14:53:50.751290 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "volumeattachment-8790" for this suite. @ 05/11/25 14:53:50.819
• [0.202 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 05/11/25 14:53:50.826
  I0511 14:53:50.826306 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename container-probe @ 05/11/25 14:53:50.827
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:53:50.838
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:53:50.84
  E0511 14:53:50.908824      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:51.909420      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:52.910037      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:53.910552      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:54.911091      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:55.911735      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:56.912149      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:57.912805      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:58.912815      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:53:59.913186      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:00.914233      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:01.914816      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:02.915562      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:03.916112      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:04.916654      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:05.917219      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:06.917794      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:07.918446      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:08.919114      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:09.919255      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:10.920021      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:11.920661      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:54:12.914850 26 container_probe.go:91] Container started at 2025-05-11 14:53:51 +0000 UTC, pod became ready at 2025-05-11 14:54:12 +0000 UTC
  I0511 14:54:12.915068 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6218" for this suite. @ 05/11/25 14:54:12.917
  E0511 14:54:12.920602      26 retrywatcher.go:169] "Watch failed" err="context canceled"
• [22.102 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:52
  STEP: Creating a kubernetes client @ 05/11/25 14:54:12.928
  I0511 14:54:12.928710 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubelet-test @ 05/11/25 14:54:12.93
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:54:12.939
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:54:12.94
  E0511 14:54:13.920771      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:14.921286      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:54:14.967168 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-3621" for this suite. @ 05/11/25 14:54:14.971
• [2.050 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:278
  STEP: Creating a kubernetes client @ 05/11/25 14:54:14.979
  I0511 14:54:14.979058 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/11/25 14:54:14.98
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:54:14.992
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:54:14.996
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 05/11/25 14:54:14.999
  I0511 14:54:15.000615 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  E0511 14:54:15.922203      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:54:16.170606 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  E0511 14:54:16.922934      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:17.923169      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:18.924157      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:19.924997      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:54:20.819019 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5914" for this suite. @ 05/11/25 14:54:20.825
• [5.852 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:492
  STEP: Creating a kubernetes client @ 05/11/25 14:54:20.831
  I0511 14:54:20.831453 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 14:54:20.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:54:20.84
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:54:20.843
  STEP: Setting up server cert @ 05/11/25 14:54:20.854
  E0511 14:54:20.925236      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 14:54:21.179
  STEP: Deploying the webhook pod @ 05/11/25 14:54:21.182
  STEP: Wait for the deployment to be ready @ 05/11/25 14:54:21.189
  I0511 14:54:21.193954 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0511 14:54:21.925999      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:22.926300      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/11/25 14:54:23.205
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 14:54:23.222
  E0511 14:54:23.926713      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:54:24.224094 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 05/11/25 14:54:24.228
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 05/11/25 14:54:24.249
  STEP: Creating a configMap that should not be mutated @ 05/11/25 14:54:24.254
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 05/11/25 14:54:24.263
  STEP: Creating a configMap that should be mutated @ 05/11/25 14:54:24.27
  I0511 14:54:24.320093 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2202" for this suite. @ 05/11/25 14:54:24.325
  STEP: Destroying namespace "webhook-markers-440" for this suite. @ 05/11/25 14:54:24.329
• [3.503 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Job should mark indexes as failed when the FailIndex action is matched in podFailurePolicy [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:730
  STEP: Creating a kubernetes client @ 05/11/25 14:54:24.334
  I0511 14:54:24.334238 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename job @ 05/11/25 14:54:24.334
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:54:24.342
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:54:24.343
  STEP: Creating an indexed job with failing pods matching the FailIndex action @ 05/11/25 14:54:24.345
  STEP: Awaiting for the job to fail as all indexes are failed @ 05/11/25 14:54:24.349
  E0511 14:54:24.927632      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:25.927767      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:26.928910      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:27.929514      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Verifying the Job status fields to ensure the upper indexes didn't execute @ 05/11/25 14:54:28.357
  I0511 14:54:28.359609 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2991" for this suite. @ 05/11/25 14:54:28.361
• [4.030 seconds]
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:559
  STEP: Creating a kubernetes client @ 05/11/25 14:54:28.364
  I0511 14:54:28.364572 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename svcaccounts @ 05/11/25 14:54:28.365
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:54:28.373
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:54:28.375
  I0511 14:54:28.389260 26 service_accounts.go:646] created pod
  E0511 14:54:28.929678      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:29.930039      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:54:30.396
  E0511 14:54:30.930261      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:31.930872      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:32.931370      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:33.931901      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:34.932763      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:35.933134      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:36.933328      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:37.933816      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:38.934232      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:39.934292      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:40.934676      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:41.935840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:42.936380      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:43.936932      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:44.937306      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:45.937821      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:46.938781      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:47.939569      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:48.940270      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:49.940653      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:50.940863      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:51.941391      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:52.941779      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:53.942351      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:54.942728      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:55.943037      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:56.943883      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:57.944418      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:58.944920      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:54:59.945061      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:55:00.396998 26 service_accounts.go:652] polling logs
  I0511 14:55:00.407637 26 service_accounts.go:662] Pod logs: 
  I0511 14:54:29.022642       1 log.go:245] OK: Got token
  I0511 14:54:29.022682       1 log.go:245] validating with in-cluster discovery
  I0511 14:54:29.022801       1 log.go:245] OK: got issuer https://kubernetes.default.svc.cluster.local
  I0511 14:54:29.022816       1 log.go:245] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-9900:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000338c80), NotBefore:(*jwt.NumericDate)(0xc000338d70), IssuedAt:(*jwt.NumericDate)(0xc000338c90), ID:"360972c7-ef12-4e37-92b7-a689154cebe3"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-9900", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"be4fa447-e9eb-42b4-a062-34dd5398c634"}}}
  I0511 14:54:29.029106       1 log.go:245] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
  I0511 14:54:29.032330       1 log.go:245] OK: Validated signature on JWT
  I0511 14:54:29.032425       1 log.go:245] OK: Got valid claims from token!
  I0511 14:54:29.032451       1 log.go:245] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-9900:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000013010), NotBefore:(*jwt.NumericDate)(0xc000013038), IssuedAt:(*jwt.NumericDate)(0xc000013018), ID:"360972c7-ef12-4e37-92b7-a689154cebe3"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-9900", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"be4fa447-e9eb-42b4-a062-34dd5398c634"}}}

  I0511 14:55:00.407715 26 service_accounts.go:666] completed pod
  I0511 14:55:00.415657 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-9900" for this suite. @ 05/11/25 14:55:00.419
• [32.060 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:209
  STEP: Creating a kubernetes client @ 05/11/25 14:55:00.424
  I0511 14:55:00.424489 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename emptydir @ 05/11/25 14:55:00.425
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:55:00.437
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:55:00.44
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 05/11/25 14:55:00.443
  E0511 14:55:00.945171      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:01.945416      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:02.946262      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:03.946773      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:55:04.465
  I0511 14:55:04.468045 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-d18577e3-6635-4d9a-8142-1d7f4eb420c7 container test-container: <nil>
  STEP: delete the pod @ 05/11/25 14:55:04.475
  I0511 14:55:04.493301 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5921" for this suite. @ 05/11/25 14:55:04.496
• [4.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 05/11/25 14:55:04.503
  I0511 14:55:04.503428 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename subpath @ 05/11/25 14:55:04.504
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:55:04.513
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:55:04.516
  STEP: Setting up data @ 05/11/25 14:55:04.519
  STEP: Creating pod pod-subpath-test-configmap-zk4h @ 05/11/25 14:55:04.526
  STEP: Creating a pod to test atomic-volume-subpath @ 05/11/25 14:55:04.526
  E0511 14:55:04.946818      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:05.947288      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:06.947404      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:07.947995      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:08.948427      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:09.949527      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:10.950528      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:11.951103      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:12.951955      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:13.952550      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:14.953381      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:15.953964      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:16.954204      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:17.954774      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:18.955048      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:19.955366      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:20.955604      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:21.955758      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:22.955916      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:23.956488      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:24.956851      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:25.957416      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:26.957545      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:27.958098      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:55:28.597
  I0511 14:55:28.599494 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-subpath-test-configmap-zk4h container test-container-subpath-configmap-zk4h: <nil>
  STEP: delete the pod @ 05/11/25 14:55:28.607
  STEP: Deleting pod pod-subpath-test-configmap-zk4h @ 05/11/25 14:55:28.622
  I0511 14:55:28.622942 26 delete.go:62] Deleting pod "pod-subpath-test-configmap-zk4h" in namespace "subpath-6942"
  I0511 14:55:28.625630 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-6942" for this suite. @ 05/11/25 14:55:28.628
• [24.131 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:443
  STEP: Creating a kubernetes client @ 05/11/25 14:55:28.64
  I0511 14:55:28.640605 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename sched-pred @ 05/11/25 14:55:28.641
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:55:28.647
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:55:28.649
  I0511 14:55:28.651610 26 helper.go:125] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0511 14:55:28.733308 26 util.go:390] Waiting for terminating namespaces to be deleted...
  I0511 14:55:28.736027 26 predicates.go:118] 
  Logging pods the apiserver thinks is on node k8sconformance before test
  I0511 14:55:28.739603 26 predicates.go:956] coredns-674b8bbfcf-68gnm from kube-system started at 2025-05-11 13:00:07 +0000 UTC (1 container statuses recorded)
  I0511 14:55:28.739636 26 predicates.go:958] 	Container coredns ready: true, restart count 4
  I0511 14:55:28.739650 26 predicates.go:956] etcd-k8sconformance from kube-system started at 2025-05-11 13:00:02 +0000 UTC (1 container statuses recorded)
  I0511 14:55:28.739660 26 predicates.go:958] 	Container etcd ready: true, restart count 0
  I0511 14:55:28.739672 26 predicates.go:956] kindnet-cs969 from kube-system started at 2025-05-11 13:00:07 +0000 UTC (1 container statuses recorded)
  I0511 14:55:28.739683 26 predicates.go:958] 	Container kindnet-cni ready: true, restart count 0
  I0511 14:55:28.739693 26 predicates.go:956] kube-apiserver-k8sconformance from kube-system started at 2025-05-11 13:00:02 +0000 UTC (1 container statuses recorded)
  I0511 14:55:28.739701 26 predicates.go:958] 	Container kube-apiserver ready: true, restart count 0
  I0511 14:55:28.739711 26 predicates.go:956] kube-controller-manager-k8sconformance from kube-system started at 2025-05-11 13:00:02 +0000 UTC (1 container statuses recorded)
  I0511 14:55:28.739721 26 predicates.go:958] 	Container kube-controller-manager ready: true, restart count 0
  I0511 14:55:28.739731 26 predicates.go:956] kube-proxy-ssjxm from kube-system started at 2025-05-11 13:00:07 +0000 UTC (1 container statuses recorded)
  I0511 14:55:28.739739 26 predicates.go:958] 	Container kube-proxy ready: true, restart count 0
  I0511 14:55:28.739749 26 predicates.go:956] kube-scheduler-k8sconformance from kube-system started at 2025-05-11 13:00:02 +0000 UTC (1 container statuses recorded)
  I0511 14:55:28.739758 26 predicates.go:958] 	Container kube-scheduler ready: true, restart count 0
  I0511 14:55:28.739768 26 predicates.go:956] storage-provisioner from kube-system started at 2025-05-11 13:00:08 +0000 UTC (1 container statuses recorded)
  I0511 14:55:28.739777 26 predicates.go:958] 	Container storage-provisioner ready: true, restart count 0
  I0511 14:55:28.739787 26 predicates.go:956] sonobuoy-systemd-logs-daemon-set-3b1a685ddb394b60-rggfh from sonobuoy started at 2025-05-11 13:02:10 +0000 UTC (2 container statuses recorded)
  I0511 14:55:28.739795 26 predicates.go:958] 	Container sonobuoy-worker ready: true, restart count 0
  I0511 14:55:28.739804 26 predicates.go:958] 	Container systemd-logs ready: true, restart count 0
  I0511 14:55:28.739814 26 predicates.go:118] 
  Logging pods the apiserver thinks is on node k8sconformance-m02 before test
  I0511 14:55:28.742733 26 predicates.go:956] kindnet-5r7wn from kube-system started at 2025-05-11 13:31:32 +0000 UTC (1 container statuses recorded)
  I0511 14:55:28.742765 26 predicates.go:958] 	Container kindnet-cni ready: true, restart count 0
  I0511 14:55:28.742780 26 predicates.go:956] kube-proxy-wwbpc from kube-system started at 2025-05-11 13:00:19 +0000 UTC (1 container statuses recorded)
  I0511 14:55:28.742791 26 predicates.go:958] 	Container kube-proxy ready: true, restart count 0
  I0511 14:55:28.742806 26 predicates.go:956] sonobuoy from sonobuoy started at 2025-05-11 13:01:52 +0000 UTC (1 container statuses recorded)
  I0511 14:55:28.742815 26 predicates.go:958] 	Container kube-sonobuoy ready: true, restart count 0
  I0511 14:55:28.742826 26 predicates.go:956] sonobuoy-e2e-job-32c36e3a15c942ea from sonobuoy started at 2025-05-11 13:02:10 +0000 UTC (2 container statuses recorded)
  I0511 14:55:28.742835 26 predicates.go:958] 	Container e2e ready: true, restart count 0
  I0511 14:55:28.742845 26 predicates.go:958] 	Container sonobuoy-worker ready: true, restart count 0
  I0511 14:55:28.742855 26 predicates.go:956] sonobuoy-systemd-logs-daemon-set-3b1a685ddb394b60-t2p28 from sonobuoy started at 2025-05-11 13:02:10 +0000 UTC (2 container statuses recorded)
  I0511 14:55:28.742865 26 predicates.go:958] 	Container sonobuoy-worker ready: true, restart count 0
  I0511 14:55:28.742874 26 predicates.go:958] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 05/11/25 14:55:28.742
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.183e80ce3de77b15], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match Pod's node affinity/selector. preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling.] @ 05/11/25 14:55:28.764
  E0511 14:55:28.958854      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:55:29.762939 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-9312" for this suite. @ 05/11/25 14:55:29.766
• [1.132 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:168
  STEP: Creating a kubernetes client @ 05/11/25 14:55:29.772
  I0511 14:55:29.772412 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename resourcequota @ 05/11/25 14:55:29.773
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:55:29.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:55:29.786
  STEP: Discovering how many secrets are in namespace by default @ 05/11/25 14:55:29.789
  E0511 14:55:29.959739      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:30.960300      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:31.960399      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:32.960684      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:33.960887      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 05/11/25 14:55:34.794
  E0511 14:55:34.961890      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:35.962984      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:36.963402      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:37.963481      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:38.963642      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/11/25 14:55:39.798
  STEP: Ensuring resource quota status is calculated @ 05/11/25 14:55:39.804
  E0511 14:55:39.964362      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:40.964983      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 05/11/25 14:55:41.81
  STEP: Ensuring resource quota status captures secret creation @ 05/11/25 14:55:41.822
  E0511 14:55:41.966008      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:42.966836      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 05/11/25 14:55:43.826
  STEP: Ensuring resource quota status released usage @ 05/11/25 14:55:43.832
  E0511 14:55:43.967628      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:44.967987      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:55:45.839060 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2835" for this suite. @ 05/11/25 14:55:45.842
• [16.077 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:348
  STEP: Creating a kubernetes client @ 05/11/25 14:55:45.849
  I0511 14:55:45.849424 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename field-validation @ 05/11/25 14:55:45.85
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:55:45.86
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:55:45.863
  I0511 14:55:45.866871 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  W0511 14:55:45.867764      26 field_validation.go:421] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc004c598a0 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E0511 14:55:45.968101      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:46.968581      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:47.969025      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:55:48.412084      26 warnings.go:110] "Warning: unknown field \"alpha\""
  I0511 14:55:48.412127      26 warnings.go:110] "Warning: unknown field \"beta\""
  I0511 14:55:48.412144      26 warnings.go:110] "Warning: unknown field \"delta\""
  I0511 14:55:48.412159      26 warnings.go:110] "Warning: unknown field \"epsilon\""
  I0511 14:55:48.412175      26 warnings.go:110] "Warning: unknown field \"gamma\""
  I0511 14:55:48.946418 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2892" for this suite. @ 05/11/25 14:55:48.949
• [3.106 seconds]
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 05/11/25 14:55:48.955
  I0511 14:55:48.955761 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename daemonsets @ 05/11/25 14:55:48.956
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:55:48.967
  E0511 14:55:48.969375      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:55:48.97
  STEP: Creating simple DaemonSet "daemon-set" @ 05/11/25 14:55:49.056
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/11/25 14:55:49.062
  I0511 14:55:49.155851 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 14:55:49.155906 26 fixtures.go:131] Node k8sconformance is running 0 daemon pod, expected 1
  E0511 14:55:49.969918      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:55:50.070456 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0511 14:55:50.070514 26 fixtures.go:131] Node k8sconformance is running 0 daemon pod, expected 1
  E0511 14:55:50.971779      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:55:51.069912 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0511 14:55:51.069962 26 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 05/11/25 14:55:51.072
  I0511 14:55:51.172814 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0511 14:55:51.172858 26 fixtures.go:131] Node k8sconformance is running 0 daemon pod, expected 1
  E0511 14:55:51.971817      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:55:52.087654 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0511 14:55:52.087694 26 fixtures.go:131] Node k8sconformance is running 0 daemon pod, expected 1
  E0511 14:55:52.972730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:55:53.087665 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0511 14:55:53.087710 26 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 05/11/25 14:55:53.089
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2999, will wait for the garbage collector to delete the pods @ 05/11/25 14:55:53.089
  I0511 14:55:53.151335 26 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 8.93971ms
  I0511 14:55:53.251921 26 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.562726ms
  E0511 14:55:53.972782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:55:54.357201 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 14:55:54.357263 26 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0511 14:55:54.360307 26 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"30319"},"items":null}

  I0511 14:55:54.362385 26 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"30319"},"items":null}

  I0511 14:55:54.369566 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-2999" for this suite. @ 05/11/25 14:55:54.371
• [5.420 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:287
  STEP: Creating a kubernetes client @ 05/11/25 14:55:54.375
  I0511 14:55:54.375966 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename field-validation @ 05/11/25 14:55:54.376
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:55:54.384
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:55:54.387
  I0511 14:55:54.389586 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  E0511 14:55:54.973639      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:55.974287      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:56.974537      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:55:57.454480 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4003" for this suite. @ 05/11/25 14:55:57.457
• [3.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 05/11/25 14:55:57.463
  I0511 14:55:57.463114 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename endpointslicemirroring @ 05/11/25 14:55:57.464
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:55:57.474
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:55:57.477
  STEP: mirroring a new custom Endpoint @ 05/11/25 14:55:57.495
  I0511 14:55:57.499815      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 14:55:57.503393 26 endpointslicemirroring.go:96] Waiting for at least 1 EndpointSlice to exist, got 0
  E0511 14:55:57.975337      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:55:58.976017      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 05/11/25 14:55:59.505
  I0511 14:55:59.508086      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: mirroring deletion of a custom Endpoint @ 05/11/25 14:55:59.512
  I0511 14:55:59.516205      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 14:55:59.520438 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-256" for this suite. @ 05/11/25 14:55:59.522
• [2.063 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:194
  STEP: Creating a kubernetes client @ 05/11/25 14:55:59.526
  I0511 14:55:59.526330 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename downward-api @ 05/11/25 14:55:59.526
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:55:59.533
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:55:59.535
  STEP: Creating a pod to test downward API volume plugin @ 05/11/25 14:55:59.537
  E0511 14:55:59.976760      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:00.977573      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:01.977609      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:02.978081      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:56:03.557
  I0511 14:56:03.561299 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-0e2dd03a-04eb-45b8-aff7-427e4177e695 container client-container: <nil>
  STEP: delete the pod @ 05/11/25 14:56:03.569
  I0511 14:56:03.586935 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8019" for this suite. @ 05/11/25 14:56:03.59
• [4.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 05/11/25 14:56:03.597
  I0511 14:56:03.597901 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename endpointslice @ 05/11/25 14:56:03.599
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:56:03.608
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:56:03.611
  I0511 14:56:03.631370      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  E0511 14:56:03.979131      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:04.979120      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:56:05.635692      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 14:56:05.660936      26 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0511 14:56:05.740275 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-635" for this suite. @ 05/11/25 14:56:05.744
• [2.151 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:71
  STEP: Creating a kubernetes client @ 05/11/25 14:56:05.749
  I0511 14:56:05.749267 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/11/25 14:56:05.75
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:56:05.76
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:56:05.764
  I0511 14:56:05.768091 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  E0511 14:56:05.979122      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 05/11/25 14:56:06.925
  I0511 14:56:06.925273 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-5105 --namespace=crd-publish-openapi-5105 create -f -'
  E0511 14:56:06.979645      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:07.980087      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:08.980599      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:56:08.991280 26 builder.go:146] stderr: ""
  I0511 14:56:08.991336 26 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8217-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0511 14:56:08.991398 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-5105 --namespace=crd-publish-openapi-5105 delete e2e-test-crd-publish-openapi-8217-crds test-foo'
  I0511 14:56:09.037378 26 builder.go:146] stderr: ""
  I0511 14:56:09.037412 26 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8217-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  I0511 14:56:09.037455 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-5105 --namespace=crd-publish-openapi-5105 apply -f -'
  I0511 14:56:09.080059 26 builder.go:146] stderr: ""
  I0511 14:56:09.080099 26 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8217-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0511 14:56:09.080143 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-5105 --namespace=crd-publish-openapi-5105 delete e2e-test-crd-publish-openapi-8217-crds test-foo'
  I0511 14:56:09.122553 26 builder.go:146] stderr: ""
  I0511 14:56:09.122592 26 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8217-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 05/11/25 14:56:09.122
  I0511 14:56:09.122663 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-5105 --namespace=crd-publish-openapi-5105 create -f -'
  I0511 14:56:09.160192 26 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 05/11/25 14:56:09.16
  I0511 14:56:09.160300 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-5105 --namespace=crd-publish-openapi-5105 create -f -'
  I0511 14:56:09.197453 26 builder.go:135] rc: 1
  I0511 14:56:09.197545 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-5105 --namespace=crd-publish-openapi-5105 apply -f -'
  I0511 14:56:09.235576 26 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 05/11/25 14:56:09.235
  I0511 14:56:09.235647 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-5105 --namespace=crd-publish-openapi-5105 create -f -'
  I0511 14:56:09.274834 26 builder.go:135] rc: 1
  I0511 14:56:09.274913 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-5105 --namespace=crd-publish-openapi-5105 apply -f -'
  I0511 14:56:09.321816 26 builder.go:135] rc: 1
  STEP: kubectl explain works to explain CR properties @ 05/11/25 14:56:09.321
  I0511 14:56:09.321921 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-5105 explain e2e-test-crd-publish-openapi-8217-crds'
  I0511 14:56:09.358092 26 builder.go:146] stderr: ""
  I0511 14:56:09.358143 26 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-8217-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 05/11/25 14:56:09.358
  I0511 14:56:09.358363 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-5105 explain e2e-test-crd-publish-openapi-8217-crds.metadata'
  I0511 14:56:09.395158 26 builder.go:146] stderr: ""
  I0511 14:56:09.395259 26 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-8217-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  I0511 14:56:09.395418 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-5105 explain e2e-test-crd-publish-openapi-8217-crds.spec'
  I0511 14:56:09.432247 26 builder.go:146] stderr: ""
  I0511 14:56:09.432280 26 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-8217-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  I0511 14:56:09.432338 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-5105 explain e2e-test-crd-publish-openapi-8217-crds.spec.bars'
  I0511 14:56:09.466825 26 builder.go:146] stderr: ""
  I0511 14:56:09.466871 26 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-8217-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n  enum: Great, Down\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 05/11/25 14:56:09.467
  I0511 14:56:09.467046 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=crd-publish-openapi-5105 explain e2e-test-crd-publish-openapi-8217-crds.spec.bars2'
  I0511 14:56:09.501432 26 builder.go:135] rc: 1
  E0511 14:56:09.980559      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:56:10.646669 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5105" for this suite. @ 05/11/25 14:56:10.653
• [4.909 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:85
  STEP: Creating a kubernetes client @ 05/11/25 14:56:10.658
  I0511 14:56:10.658579 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 14:56:10.659
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:56:10.668
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:56:10.67
  STEP: Creating a pod to test downward API volume plugin @ 05/11/25 14:56:10.672
  E0511 14:56:10.980881      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:11.980780      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:12.981832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:13.982808      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:56:14.687
  I0511 14:56:14.690177 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-c61e7176-cda3-4a16-b72b-9f4df837795f container client-container: <nil>
  STEP: delete the pod @ 05/11/25 14:56:14.697
  I0511 14:56:14.714152 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5659" for this suite. @ 05/11/25 14:56:14.719
• [4.066 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 05/11/25 14:56:14.725
  I0511 14:56:14.725042 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename crd-watch @ 05/11/25 14:56:14.726
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:56:14.738
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:56:14.742
  I0511 14:56:14.744632 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  E0511 14:56:14.982971      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:15.983551      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:16.984079      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 05/11/25 14:56:17.29
  I0511 14:56:17.295600 26 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2025-05-11T14:56:17Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2025-05-11T14:56:17Z]] name:name1 resourceVersion:30494 uid:2489dec1-885d-4c34-ad68-117efb27a10b] num:map[num1:9223372036854775807 num2:1000000]]}
  E0511 14:56:17.984800      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:18.985247      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:19.985706      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:20.985762      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:21.986791      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:22.987187      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:23.987720      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:24.987970      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:25.988358      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:26.988751      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 05/11/25 14:56:27.296
  I0511 14:56:27.304971 26 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2025-05-11T14:56:27Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2025-05-11T14:56:27Z]] name:name2 resourceVersion:30512 uid:7180c2d1-7513-4382-815e-d39f72dfd677] num:map[num1:9223372036854775807 num2:1000000]]}
  E0511 14:56:27.988878      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:28.989732      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:29.990064      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:30.990506      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:31.991088      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:32.991755      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:33.992829      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:34.993870      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:35.994833      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:36.995666      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 05/11/25 14:56:37.306
  I0511 14:56:37.316414 26 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2025-05-11T14:56:17Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2025-05-11T14:56:37Z]] name:name1 resourceVersion:30522 uid:2489dec1-885d-4c34-ad68-117efb27a10b] num:map[num1:9223372036854775807 num2:1000000]]}
  E0511 14:56:37.995735      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:38.996080      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:39.996716      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:40.997504      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:41.997812      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:42.998898      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:43.999838      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:45.000147      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:46.000671      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:47.000774      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 05/11/25 14:56:47.317
  I0511 14:56:47.328365 26 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2025-05-11T14:56:27Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2025-05-11T14:56:47Z]] name:name2 resourceVersion:30532 uid:7180c2d1-7513-4382-815e-d39f72dfd677] num:map[num1:9223372036854775807 num2:1000000]]}
  E0511 14:56:48.000892      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:49.001987      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:50.002194      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:51.002589      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:52.002856      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:53.003828      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:54.004746      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:55.005749      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:56.006153      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:57.006586      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 05/11/25 14:56:57.328
  I0511 14:56:57.337209 26 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2025-05-11T14:56:17Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2025-05-11T14:56:37Z]] name:name1 resourceVersion:30542 uid:2489dec1-885d-4c34-ad68-117efb27a10b] num:map[num1:9223372036854775807 num2:1000000]]}
  E0511 14:56:58.006940      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:56:59.007351      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:00.007631      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:01.008037      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:02.008540      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:03.008732      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:04.008831      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:05.009793      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:06.010193      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:07.010831      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 05/11/25 14:57:07.338
  I0511 14:57:07.345242 26 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2025-05-11T14:56:27Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2025-05-11T14:56:47Z]] name:name2 resourceVersion:30552 uid:7180c2d1-7513-4382-815e-d39f72dfd677] num:map[num1:9223372036854775807 num2:1000000]]}
  E0511 14:57:08.011889      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:09.012893      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:10.013242      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:11.013564      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:12.014183      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:13.014681      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:14.014749      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:15.015272      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:16.015743      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:17.015774      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:57:17.859130 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-9505" for this suite. @ 05/11/25 14:57:17.863
• [63.146 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1368
  STEP: Creating a kubernetes client @ 05/11/25 14:57:17.87
  I0511 14:57:17.870856 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubectl @ 05/11/25 14:57:17.872
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:57:17.885
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:57:17.888
  STEP: validating cluster-info @ 05/11/25 14:57:17.891
  I0511 14:57:17.891250 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-2837 cluster-info'
  I0511 14:57:17.935816 26 builder.go:146] stderr: ""
  I0511 14:57:17.935852 26 builder.go:147] stdout: "Kubernetes control plane is running at https://10.96.0.1:443\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  I0511 14:57:17.935968 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2837" for this suite. @ 05/11/25 14:57:17.964
• [0.100 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:95
  STEP: Creating a kubernetes client @ 05/11/25 14:57:17.97
  I0511 14:57:17.970854 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename configmap @ 05/11/25 14:57:17.971
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:57:17.982
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:57:17.986
  STEP: Creating configMap configmap-7740/configmap-test-75f8d1e5-45ad-4718-a0ed-4f3fe6afcebd @ 05/11/25 14:57:17.989
  STEP: Creating a pod to test consume configMaps @ 05/11/25 14:57:17.993
  E0511 14:57:18.016529      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:19.016696      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:20.017400      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:21.017766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:57:22.008
  I0511 14:57:22.011414 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-94711df1-68d3-4c41-833f-af15aa08e19a container env-test: <nil>
  E0511 14:57:22.018740      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the pod @ 05/11/25 14:57:22.019
  I0511 14:57:22.035847 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7740" for this suite. @ 05/11/25 14:57:22.039
• [4.073 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:109
  STEP: Creating a kubernetes client @ 05/11/25 14:57:22.044
  I0511 14:57:22.044178 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 14:57:22.045
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:57:22.055
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:57:22.057
  STEP: Creating configMap with name projected-configmap-test-volume-map-5193588a-3f8f-4756-b42b-12cd04a05f3e @ 05/11/25 14:57:22.06
  STEP: Creating a pod to test consume configMaps @ 05/11/25 14:57:22.064
  E0511 14:57:23.019655      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:24.019953      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:25.020699      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:26.021864      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:57:26.086
  I0511 14:57:26.089552 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-projected-configmaps-e0af69ac-3251-4b0b-a04b-e3ee6e679ccd container agnhost-container: <nil>
  STEP: delete the pod @ 05/11/25 14:57:26.094
  I0511 14:57:26.106757 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1887" for this suite. @ 05/11/25 14:57:26.108
• [4.068 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:137
  STEP: Creating a kubernetes client @ 05/11/25 14:57:26.112
  I0511 14:57:26.112419 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/11/25 14:57:26.113
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:57:26.122
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:57:26.124
  STEP: create the container to handle the HTTPGet hook request. @ 05/11/25 14:57:26.211
  E0511 14:57:27.022612      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:28.022669      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/11/25 14:57:28.235
  E0511 14:57:29.022905      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:30.023093      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 05/11/25 14:57:30.253
  STEP: delete the pod with lifecycle hook @ 05/11/25 14:57:30.27
  E0511 14:57:31.024358      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:32.024802      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:33.024941      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:34.025340      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:57:34.291736 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-508" for this suite. @ 05/11/25 14:57:34.295
• [8.189 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 05/11/25 14:57:34.302
  I0511 14:57:34.302234 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename pods @ 05/11/25 14:57:34.303
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:57:34.315
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:57:34.318
  STEP: creating pod @ 05/11/25 14:57:34.321
  E0511 14:57:35.025526      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:36.025642      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:57:36.339329 26 pods.go:83] Pod pod-hostip-f5f0da48-380a-45b1-8769-32c7438fb99a has hostIP: 192.168.49.3
  I0511 14:57:36.339517 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-178" for this suite. @ 05/11/25 14:57:36.342
• [2.051 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:368
  STEP: Creating a kubernetes client @ 05/11/25 14:57:36.353
  I0511 14:57:36.353934 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename webhook @ 05/11/25 14:57:36.355
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:57:36.363
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:57:36.365
  STEP: Setting up server cert @ 05/11/25 14:57:36.38
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/11/25 14:57:36.572
  STEP: Deploying the webhook pod @ 05/11/25 14:57:36.575
  STEP: Wait for the deployment to be ready @ 05/11/25 14:57:36.581
  I0511 14:57:36.585783 26 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0511 14:57:37.026309      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:38.026808      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/11/25 14:57:38.597
  STEP: Verifying the service has paired with the endpoint @ 05/11/25 14:57:38.614
  E0511 14:57:39.027645      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:57:39.615645 26 util.go:418] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 05/11/25 14:57:39.62
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/11/25 14:57:39.62
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 05/11/25 14:57:39.638
  E0511 14:57:40.027574      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 05/11/25 14:57:40.65
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/11/25 14:57:40.65
  E0511 14:57:41.028453      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 05/11/25 14:57:41.682
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/11/25 14:57:41.682
  E0511 14:57:42.029024      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:43.029605      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:44.030090      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:45.030273      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:46.031134      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 05/11/25 14:57:46.718
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/11/25 14:57:46.718
  E0511 14:57:47.031778      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:48.031804      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:49.031847      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:50.032751      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:51.033848      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:57:51.798848 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4942" for this suite. @ 05/11/25 14:57:51.8
  STEP: Destroying namespace "webhook-markers-3318" for this suite. @ 05/11/25 14:57:51.807
• [15.458 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:149
  STEP: Creating a kubernetes client @ 05/11/25 14:57:51.811
  I0511 14:57:51.811369 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename emptydir @ 05/11/25 14:57:51.812
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:57:51.819
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:57:51.822
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 05/11/25 14:57:51.824
  E0511 14:57:52.034302      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:53.034792      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:54.035887      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:55.035966      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:57:55.843
  I0511 14:57:55.846575 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-dfeb9f9a-fc36-449a-9cab-7d11ded61226 container test-container: <nil>
  STEP: delete the pod @ 05/11/25 14:57:55.854
  I0511 14:57:55.871715 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5079" for this suite. @ 05/11/25 14:57:55.874
• [4.068 seconds]
------------------------------
S
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1464
  STEP: Creating a kubernetes client @ 05/11/25 14:57:55.879
  I0511 14:57:55.879732 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename services @ 05/11/25 14:57:55.88
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:57:55.889
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:57:55.893
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-5459 @ 05/11/25 14:57:55.896
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 05/11/25 14:57:55.91
  STEP: creating service externalsvc in namespace services-5459 @ 05/11/25 14:57:55.91
  I0511 14:57:55.935644 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0511 14:57:56.036901      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:57.037840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: changing the ClusterIP service to type=ExternalName @ 05/11/25 14:57:57.947
  I0511 14:57:57.965447 26 resource.go:361] Creating new exec pod
  E0511 14:57:58.038385      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:57:59.038669      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:57:59.984872 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-5459 exec execpodr2qpx -- /bin/sh -x -c nslookup clusterip-service.services-5459.svc.cluster.local'
  E0511 14:58:00.039258      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:58:00.115265 26 builder.go:146] stderr: "+ nslookup clusterip-service.services-5459.svc.cluster.local\n"
  I0511 14:58:00.115336 26 builder.go:147] stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-5459.svc.cluster.local\tcanonical name = externalsvc.services-5459.svc.cluster.local.\nName:\texternalsvc.services-5459.svc.cluster.local\nAddress: 10.97.84.168\n\n"
  I0511 14:58:00.140097 26 service.go:1473] Cleaning up the ClusterIP to ExternalName test service
  I0511 14:58:00.157543 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5459" for this suite. @ 05/11/25 14:58:00.162
• [4.287 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1693
  STEP: Creating a kubernetes client @ 05/11/25 14:58:00.166
  I0511 14:58:00.166780 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubectl @ 05/11/25 14:58:00.167
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:58:00.173
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:58:00.174
  STEP: creating Agnhost RC @ 05/11/25 14:58:00.175
  I0511 14:58:00.175772 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-279 create -f -'
  I0511 14:58:00.247823 26 builder.go:146] stderr: ""
  I0511 14:58:00.247860 26 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 05/11/25 14:58:00.247
  E0511 14:58:01.039795      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 14:58:01.252760 26 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0511 14:58:01.252807 26 framework.go:733] Found 1 / 1
  I0511 14:58:01.252830 26 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 05/11/25 14:58:01.252
  I0511 14:58:01.255335 26 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0511 14:58:01.255364 26 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0511 14:58:01.255408 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-279 patch pod agnhost-primary-5dft9 -p {"metadata":{"annotations":{"x":"y"}}}'
  I0511 14:58:01.311136 26 builder.go:146] stderr: ""
  I0511 14:58:01.311180 26 builder.go:147] stdout: "pod/agnhost-primary-5dft9 patched\n"
  STEP: checking annotations @ 05/11/25 14:58:01.311
  I0511 14:58:01.313293 26 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0511 14:58:01.313318 26 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0511 14:58:01.313423 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-279" for this suite. @ 05/11/25 14:58:01.315
• [1.153 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:74
  STEP: Creating a kubernetes client @ 05/11/25 14:58:01.32
  I0511 14:58:01.320248 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 14:58:01.321
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:58:01.329
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:58:01.331
  STEP: Creating configMap with name projected-configmap-test-volume-06d5c6eb-814c-41cc-ab65-3ff44275b88c @ 05/11/25 14:58:01.333
  STEP: Creating a pod to test consume configMaps @ 05/11/25 14:58:01.335
  E0511 14:58:02.040116      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:03.041043      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 14:58:03.347
  I0511 14:58:03.350795 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-projected-configmaps-230657d8-9e6f-449d-8eb0-40e21bd267cf container agnhost-container: <nil>
  STEP: delete the pod @ 05/11/25 14:58:03.361
  I0511 14:58:03.376279 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-919" for this suite. @ 05/11/25 14:58:03.379
• [2.063 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:704
  STEP: Creating a kubernetes client @ 05/11/25 14:58:03.384
  I0511 14:58:03.384262 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename sched-pred @ 05/11/25 14:58:03.385
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 14:58:03.394
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 14:58:03.397
  I0511 14:58:03.400579 26 helper.go:125] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0511 14:58:03.484792 26 util.go:390] Waiting for terminating namespaces to be deleted...
  I0511 14:58:03.490298 26 predicates.go:118] 
  Logging pods the apiserver thinks is on node k8sconformance before test
  I0511 14:58:03.494242 26 predicates.go:956] coredns-674b8bbfcf-68gnm from kube-system started at 2025-05-11 13:00:07 +0000 UTC (1 container statuses recorded)
  I0511 14:58:03.494262 26 predicates.go:958] 	Container coredns ready: true, restart count 4
  I0511 14:58:03.494268 26 predicates.go:956] etcd-k8sconformance from kube-system started at 2025-05-11 13:00:02 +0000 UTC (1 container statuses recorded)
  I0511 14:58:03.494271 26 predicates.go:958] 	Container etcd ready: true, restart count 0
  I0511 14:58:03.494275 26 predicates.go:956] kindnet-cs969 from kube-system started at 2025-05-11 13:00:07 +0000 UTC (1 container statuses recorded)
  I0511 14:58:03.494280 26 predicates.go:958] 	Container kindnet-cni ready: true, restart count 0
  I0511 14:58:03.494284 26 predicates.go:956] kube-apiserver-k8sconformance from kube-system started at 2025-05-11 13:00:02 +0000 UTC (1 container statuses recorded)
  I0511 14:58:03.494288 26 predicates.go:958] 	Container kube-apiserver ready: true, restart count 0
  I0511 14:58:03.494291 26 predicates.go:956] kube-controller-manager-k8sconformance from kube-system started at 2025-05-11 13:00:02 +0000 UTC (1 container statuses recorded)
  I0511 14:58:03.494295 26 predicates.go:958] 	Container kube-controller-manager ready: true, restart count 0
  I0511 14:58:03.494299 26 predicates.go:956] kube-proxy-ssjxm from kube-system started at 2025-05-11 13:00:07 +0000 UTC (1 container statuses recorded)
  I0511 14:58:03.494303 26 predicates.go:958] 	Container kube-proxy ready: true, restart count 0
  I0511 14:58:03.494308 26 predicates.go:956] kube-scheduler-k8sconformance from kube-system started at 2025-05-11 13:00:02 +0000 UTC (1 container statuses recorded)
  I0511 14:58:03.494314 26 predicates.go:958] 	Container kube-scheduler ready: true, restart count 0
  I0511 14:58:03.494318 26 predicates.go:956] storage-provisioner from kube-system started at 2025-05-11 13:00:08 +0000 UTC (1 container statuses recorded)
  I0511 14:58:03.494322 26 predicates.go:958] 	Container storage-provisioner ready: true, restart count 0
  I0511 14:58:03.494325 26 predicates.go:956] sonobuoy-systemd-logs-daemon-set-3b1a685ddb394b60-rggfh from sonobuoy started at 2025-05-11 13:02:10 +0000 UTC (2 container statuses recorded)
  I0511 14:58:03.494328 26 predicates.go:958] 	Container sonobuoy-worker ready: true, restart count 0
  I0511 14:58:03.494331 26 predicates.go:958] 	Container systemd-logs ready: true, restart count 0
  I0511 14:58:03.494336 26 predicates.go:118] 
  Logging pods the apiserver thinks is on node k8sconformance-m02 before test
  I0511 14:58:03.496233 26 predicates.go:956] kindnet-5r7wn from kube-system started at 2025-05-11 13:31:32 +0000 UTC (1 container statuses recorded)
  I0511 14:58:03.496254 26 predicates.go:958] 	Container kindnet-cni ready: true, restart count 0
  I0511 14:58:03.496263 26 predicates.go:956] kube-proxy-wwbpc from kube-system started at 2025-05-11 13:00:19 +0000 UTC (1 container statuses recorded)
  I0511 14:58:03.496269 26 predicates.go:958] 	Container kube-proxy ready: true, restart count 0
  I0511 14:58:03.496276 26 predicates.go:956] agnhost-primary-5dft9 from kubectl-279 started at 2025-05-11 14:58:00 +0000 UTC (1 container statuses recorded)
  I0511 14:58:03.496283 26 predicates.go:958] 	Container agnhost-primary ready: true, restart count 0
  I0511 14:58:03.496289 26 predicates.go:956] execpodr2qpx from services-5459 started at 2025-05-11 14:57:57 +0000 UTC (1 container statuses recorded)
  I0511 14:58:03.496294 26 predicates.go:958] 	Container agnhost-container ready: true, restart count 0
  I0511 14:58:03.496300 26 predicates.go:956] sonobuoy from sonobuoy started at 2025-05-11 13:01:52 +0000 UTC (1 container statuses recorded)
  I0511 14:58:03.496306 26 predicates.go:958] 	Container kube-sonobuoy ready: true, restart count 0
  I0511 14:58:03.496312 26 predicates.go:956] sonobuoy-e2e-job-32c36e3a15c942ea from sonobuoy started at 2025-05-11 13:02:10 +0000 UTC (2 container statuses recorded)
  I0511 14:58:03.496321 26 predicates.go:958] 	Container e2e ready: true, restart count 0
  I0511 14:58:03.496326 26 predicates.go:958] 	Container sonobuoy-worker ready: true, restart count 0
  I0511 14:58:03.496335 26 predicates.go:956] sonobuoy-systemd-logs-daemon-set-3b1a685ddb394b60-t2p28 from sonobuoy started at 2025-05-11 13:02:10 +0000 UTC (2 container statuses recorded)
  I0511 14:58:03.496341 26 predicates.go:958] 	Container sonobuoy-worker ready: true, restart count 0
  I0511 14:58:03.496346 26 predicates.go:958] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 05/11/25 14:58:03.496
  E0511 14:58:04.041684      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:05.042774      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 05/11/25 14:58:05.511
  STEP: Trying to apply a random label on the found node. @ 05/11/25 14:58:05.526
  STEP: verifying the node has the label kubernetes.io/e2e-023f1aae-acb6-4359-9197-498690274997 95 @ 05/11/25 14:58:05.533
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 05/11/25 14:58:05.538
  E0511 14:58:06.043343      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:07.043631      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.49.3 on the node which pod4 resides and expect not scheduled @ 05/11/25 14:58:07.557
  E0511 14:58:08.044759      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:09.045359      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:10.045571      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:11.046003      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:12.046144      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:13.046802      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:14.047766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:15.047668      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:16.048050      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:17.048451      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:18.049288      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:19.049663      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:20.050658      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:21.051036      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:22.051129      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:23.051530      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:24.051867      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:25.052394      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:26.052888      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:27.053223      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:28.053977      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:29.054863      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:30.055717      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:31.056861      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:32.057673      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:33.058106      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:34.058538      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:35.058532      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:36.058756      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:37.058906      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:38.059550      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:39.059810      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:40.060474      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:41.060766      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:42.061814      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:43.062017      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:44.062589      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:45.062786      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:46.063975      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:47.064989      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:48.065939      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:49.066014      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:50.066536      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:51.066947      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:52.067923      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:53.068455      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:54.069190      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:55.069140      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:56.069574      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:57.070235      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:58.071089      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:58:59.071880      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:00.072655      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:01.073073      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:02.073994      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:03.074322      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:04.074903      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:05.075699      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:06.076019      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:07.076979      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:08.077216      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:09.077941      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:10.078109      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:11.078398      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:12.079072      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:13.079564      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:14.079896      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:15.080724      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:16.081747      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:17.082202      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:18.083221      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:19.083841      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:20.084636      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:21.085044      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:22.085960      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:23.086401      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:24.087474      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:25.088258      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:26.089507      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:27.090105      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:28.090145      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:29.090738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:30.091383      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:31.091832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:32.092150      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:33.092647      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:34.093021      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:35.093207      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:36.093606      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:37.094398      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:38.094533      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:39.094697      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:40.095470      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:41.095842      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:42.096181      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:43.096716      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:44.097708      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:45.097574      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:46.098307      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:47.098682      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:48.098810      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:49.099508      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:50.099602      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:51.100776      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:52.101868      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:53.102363      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:54.102728      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:55.102635      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:56.103203      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:57.103730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:58.103862      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 14:59:59.104287      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:00.105127      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:01.105580      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:02.105581      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:03.105988      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:04.106752      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:05.106756      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:06.107820      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:07.108347      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:08.109068      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:09.109720      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:10.109607      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:11.110763      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:12.111170      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:13.111660      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:14.112627      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:15.112675      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:16.113864      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:17.114379      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:18.114709      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:19.115134      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:20.115654      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:21.116040      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:22.116232      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:23.116372      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:24.116645      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:25.117666      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:26.118263      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:27.118801      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:28.119606      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:29.120023      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:30.120383      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:31.120847      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:32.121516      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:33.121896      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:34.122078      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:35.124106      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:36.124705      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:37.125148      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:38.126041      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:39.126566      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:40.127298      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:41.127935      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:42.128225      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:43.128697      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:44.129533      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:45.131509      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:46.132769      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:47.133339      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:48.133809      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:49.134791      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:50.135606      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:51.136102      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:52.137145      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:53.137927      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:54.138791      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:55.138928      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:56.139132      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:57.139763      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:58.139935      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:00:59.140405      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:00.141127      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:01.141909      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:02.142448      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:03.142933      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:04.143875      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:05.144003      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:06.144447      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:07.144809      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:08.145759      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:09.146364      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:10.147224      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:11.147624      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:12.148934      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:13.149404      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:14.149857      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:15.150200      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:16.150840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:17.151206      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:18.151275      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:19.151679      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:20.152531      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:21.152737      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:22.153517      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:23.153824      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:24.154848      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:25.155752      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:26.155976      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:27.156310      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:28.156938      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:29.157841      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:30.158776      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:31.159701      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:32.160211      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:33.160864      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:34.161802      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:35.161962      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:36.162905      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:37.163720      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:38.164119      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:39.164684      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:40.165420      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:41.165875      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:42.166913      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:43.167448      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:44.168018      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:45.168693      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:46.168893      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:47.169018      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:48.170057      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:49.170736      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:50.171262      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:51.171569      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:52.172782      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:53.173151      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:54.174165      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:55.174397      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:56.175276      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:57.175815      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:58.176324      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:01:59.176895      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:00.177760      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:01.178225      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:02.179127      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:03.179834      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:04.179815      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:05.180192      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:06.181090      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:07.181929      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:08.182960      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:09.183517      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:10.184390      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:11.184808      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:12.185848      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:13.187017      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:14.188039      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:15.189952      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:16.190446      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:17.190890      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:18.191807      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:19.191958      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:20.191965      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:21.192296      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:22.192533      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:23.192754      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:24.192953      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:25.193337      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:26.193672      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:27.194240      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:28.194541      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:29.195024      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:30.195054      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:31.195385      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:32.195716      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:33.196826      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:34.197287      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:35.197569      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:36.197757      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:37.197904      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:38.198407      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:39.198779      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:40.199764      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:41.200127      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:42.200889      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:43.201930      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:44.202409      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:45.202323      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:46.203095      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:47.203540      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:48.204024      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:49.204145      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:50.204242      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:51.204821      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:52.205704      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:53.205952      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:54.207020      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:55.207826      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:56.208284      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:57.208632      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:58.208863      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:02:59.209149      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:00.209372      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:01.209900      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:02.210091      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:03.210875      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:04.211323      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:05.212070      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:06.212648      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:07.212999      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-023f1aae-acb6-4359-9197-498690274997 off the node k8sconformance-m02 @ 05/11/25 15:03:07.568
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-023f1aae-acb6-4359-9197-498690274997 @ 05/11/25 15:03:07.581
  I0511 15:03:07.584752 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-8129" for this suite. @ 05/11/25 15:03:07.588
• [304.210 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:54
  STEP: Creating a kubernetes client @ 05/11/25 15:03:07.594
  I0511 15:03:07.594067 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename downward-api @ 05/11/25 15:03:07.595
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:03:07.604
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:03:07.607
  STEP: Creating a pod to test downward API volume plugin @ 05/11/25 15:03:07.608
  E0511 15:03:08.213353      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:09.213743      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 15:03:09.622
  I0511 15:03:09.625264 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-e739a5c9-667c-4763-9ea2-53a498ea5c81 container client-container: <nil>
  STEP: delete the pod @ 05/11/25 15:03:09.641
  I0511 15:03:09.656094 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5374" for this suite. @ 05/11/25 15:03:09.659
• [2.071 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 05/11/25 15:03:09.665
  I0511 15:03:09.665406 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 15:03:09.666
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:03:09.673
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:03:09.676
  STEP: Creating projection with secret that has name projected-secret-test-798c34a0-a5b6-4d4a-b47f-1efd7c773f51 @ 05/11/25 15:03:09.679
  STEP: Creating a pod to test consume secrets @ 05/11/25 15:03:09.684
  E0511 15:03:10.213726      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:11.214214      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 15:03:11.7
  I0511 15:03:11.703108 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-projected-secrets-9f6ae9fa-8fa8-49fd-81df-67a1b24efd0b container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/11/25 15:03:11.71
  I0511 15:03:11.724120 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7635" for this suite. @ 05/11/25 15:03:11.726
• [2.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 05/11/25 15:03:11.731
  I0511 15:03:11.731269 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename daemonsets @ 05/11/25 15:03:11.732
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:03:11.74
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:03:11.743
  I0511 15:03:11.835130 26 daemon_set.go:208] Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 05/11/25 15:03:11.839
  I0511 15:03:11.843038 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 15:03:11.843085 26 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 05/11/25 15:03:11.843
  I0511 15:03:11.943588 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 15:03:11.943641 26 fixtures.go:131] Node k8sconformance-m02 is running 0 daemon pod, expected 1
  E0511 15:03:12.215277      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:03:12.944747 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 15:03:12.944807 26 fixtures.go:131] Node k8sconformance-m02 is running 0 daemon pod, expected 1
  E0511 15:03:13.216045      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:03:13.944752 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0511 15:03:13.944811 26 fixtures.go:136] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 05/11/25 15:03:13.947
  I0511 15:03:13.964323 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0511 15:03:13.964374 26 fixtures.go:136] Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  E0511 15:03:14.216840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:03:14.966323 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 15:03:14.966377 26 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 05/11/25 15:03:14.966
  I0511 15:03:15.068176 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 15:03:15.068251 26 fixtures.go:131] Node k8sconformance-m02 is running 0 daemon pod, expected 1
  E0511 15:03:15.219178      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:03:15.981256 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 15:03:15.981315 26 fixtures.go:131] Node k8sconformance-m02 is running 0 daemon pod, expected 1
  E0511 15:03:16.219510      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:03:16.982179 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0511 15:03:16.982235 26 fixtures.go:136] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 05/11/25 15:03:16.989
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-404, will wait for the garbage collector to delete the pods @ 05/11/25 15:03:16.989
  I0511 15:03:17.048996 26 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 7.075422ms
  I0511 15:03:17.149685 26 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.687539ms
  E0511 15:03:17.220276      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:18.220771      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:03:18.554910 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 15:03:18.554972 26 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0511 15:03:18.558036 26 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"31429"},"items":null}

  I0511 15:03:18.560341 26 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"31429"},"items":null}

  I0511 15:03:18.577048 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-404" for this suite. @ 05/11/25 15:03:18.581
• [6.855 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:167
  STEP: Creating a kubernetes client @ 05/11/25 15:03:18.586
  I0511 15:03:18.586612 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename disruption @ 05/11/25 15:03:18.587
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:03:18.598
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:03:18.601
  STEP: Waiting for the pdb to be processed @ 05/11/25 15:03:18.605
  E0511 15:03:19.221040      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:20.221938      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 05/11/25 15:03:20.61
  STEP: Waiting for all pods to be running @ 05/11/25 15:03:20.62
  I0511 15:03:20.623918 26 disruption.go:691] running pods: 0 < 1
  E0511 15:03:21.222146      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:22.222646      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 05/11/25 15:03:22.626
  STEP: Waiting for the pdb to be processed @ 05/11/25 15:03:22.636
  STEP: Patching PodDisruptionBudget status @ 05/11/25 15:03:22.643
  STEP: Waiting for the pdb to be processed @ 05/11/25 15:03:22.651
  I0511 15:03:22.653662 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-7834" for this suite. @ 05/11/25 15:03:22.656
• [4.076 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 05/11/25 15:03:22.662
  I0511 15:03:22.663019 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename tables @ 05/11/25 15:03:22.664
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:03:22.674
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:03:22.677
  I0511 15:03:22.682963 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-2175" for this suite. @ 05/11/25 15:03:22.758
• [0.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:612
  STEP: Creating a kubernetes client @ 05/11/25 15:03:22.766
  I0511 15:03:22.766835 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename security-context-test @ 05/11/25 15:03:22.767
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:03:22.779
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:03:22.782
  E0511 15:03:23.222666      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:24.223198      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:03:24.810893 26 security_context.go:619] Got logs for pod "busybox-privileged-false-6a7873aa-2ea8-4e3a-9b47-b91fd7c34646": "ip: RTNETLINK answers: Operation not permitted\n"
  I0511 15:03:24.811095 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-6493" for this suite. @ 05/11/25 15:03:24.814
• [2.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1759
  STEP: Creating a kubernetes client @ 05/11/25 15:03:24.82
  I0511 15:03:24.820406 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubectl @ 05/11/25 15:03:24.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:03:24.832
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:03:24.835
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/11/25 15:03:24.838
  I0511 15:03:24.838391 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-8035 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  I0511 15:03:24.885848 26 builder.go:146] stderr: ""
  I0511 15:03:24.885959 26 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 05/11/25 15:03:24.886
  I0511 15:03:24.890256 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-8035 delete pods e2e-test-httpd-pod'
  E0511 15:03:25.223295      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:26.223667      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:03:26.626996 26 builder.go:146] stderr: ""
  I0511 15:03:26.627056 26 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0511 15:03:26.627239 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8035" for this suite. @ 05/11/25 15:03:26.631
• [1.816 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:892
  STEP: Creating a kubernetes client @ 05/11/25 15:03:26.636
  I0511 15:03:26.636443 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename job @ 05/11/25 15:03:26.637
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:03:26.648
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:03:26.65
  STEP: Creating a job @ 05/11/25 15:03:26.653
  STEP: Ensuring active pods == parallelism @ 05/11/25 15:03:26.659
  E0511 15:03:27.223672      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:28.224672      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete a job @ 05/11/25 15:03:28.665
  STEP: deleting Job.batch foo in namespace job-3851, will wait for the garbage collector to delete the pods @ 05/11/25 15:03:28.665
  I0511 15:03:28.725209 26 resources.go:139] Deleting Job.batch foo took: 6.66205ms
  I0511 15:03:28.825625 26 resources.go:163] Terminating Job.batch foo pods took: 100.405928ms
  E0511 15:03:29.225060      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 05/11/25 15:03:29.726
  I0511 15:03:29.730967 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-3851" for this suite. @ 05/11/25 15:03:29.734
• [3.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:159
  STEP: Creating a kubernetes client @ 05/11/25 15:03:29.74
  I0511 15:03:29.740259 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename emptydir @ 05/11/25 15:03:29.741
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:03:29.753
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:03:29.757
  STEP: Creating a pod to test emptydir volume type on node default medium @ 05/11/25 15:03:29.76
  E0511 15:03:30.225659      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:31.225955      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:32.226391      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:33.227291      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 15:03:33.778
  I0511 15:03:33.780758 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-cdf69180-d5e8-4f4d-a9e8-d5e85a469cc1 container test-container: <nil>
  STEP: delete the pod @ 05/11/25 15:03:33.787
  I0511 15:03:33.801919 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4332" for this suite. @ 05/11/25 15:03:33.805
• [4.070 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:472
  STEP: Creating a kubernetes client @ 05/11/25 15:03:33.81
  I0511 15:03:33.810548 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename field-validation @ 05/11/25 15:03:33.811
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:03:33.821
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:03:33.824
  I0511 15:03:33.827386 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  E0511 15:03:34.227602      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:35.227994      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:36.228553      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:03:36.370539      26 warnings.go:110] "Warning: unknown field \"alpha\""
  I0511 15:03:36.370581      26 warnings.go:110] "Warning: unknown field \"beta\""
  I0511 15:03:36.370600      26 warnings.go:110] "Warning: unknown field \"delta\""
  I0511 15:03:36.370617      26 warnings.go:110] "Warning: unknown field \"epsilon\""
  I0511 15:03:36.370634      26 warnings.go:110] "Warning: unknown field \"gamma\""
  I0511 15:03:36.902988 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8437" for this suite. @ 05/11/25 15:03:36.905
• [3.101 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2222
  STEP: Creating a kubernetes client @ 05/11/25 15:03:36.911
  I0511 15:03:36.911912 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename services @ 05/11/25 15:03:36.912
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:03:36.923
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:03:36.926
  STEP: creating service in namespace services-4798 @ 05/11/25 15:03:36.929
  STEP: creating service affinity-nodeport in namespace services-4798 @ 05/11/25 15:03:36.929
  I0511 15:03:36.961045 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0511 15:03:37.228730      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:38.229154      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:03:39.000846 26 resource.go:361] Creating new exec pod
  E0511 15:03:39.230013      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:40.231603      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:03:41.018560 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-4798 exec execpod-affinitypwk2v -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  I0511 15:03:41.120395 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport (10.103.113.83) 80 port [tcp/http] succeeded!\n"
  I0511 15:03:41.120449 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 15:03:41.120553 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-4798 exec execpod-affinitypwk2v -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.103.113.83 80'
  I0511 15:03:41.215173 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.103.113.83 80\nConnection to 10.103.113.83 80 port [tcp/http] succeeded!\n"
  I0511 15:03:41.215202 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 15:03:41.215248 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-4798 exec execpod-affinitypwk2v -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.49.2 30423'
  E0511 15:03:41.232516      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:03:41.306554 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.49.2 30423\nConnection to 192.168.49.2 30423 port [tcp/*] succeeded!\n"
  I0511 15:03:41.306620 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 15:03:41.306726 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-4798 exec execpod-affinitypwk2v -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.49.3 30423'
  I0511 15:03:41.408082 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.49.3 30423\nConnection to 192.168.49.3 30423 port [tcp/*] succeeded!\n"
  I0511 15:03:41.408137 26 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0511 15:03:41.408220 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-4798 exec execpod-affinitypwk2v -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30423/ ; done'
  I0511 15:03:41.597320 26 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30423/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30423/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30423/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30423/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30423/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30423/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30423/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30423/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30423/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30423/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30423/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30423/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30423/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30423/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30423/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.49.2:30423/\n"
  I0511 15:03:41.597364 26 builder.go:147] stdout: "\naffinity-nodeport-85dffb5fc7-t4bcz\naffinity-nodeport-85dffb5fc7-t4bcz\naffinity-nodeport-85dffb5fc7-t4bcz\naffinity-nodeport-85dffb5fc7-t4bcz\naffinity-nodeport-85dffb5fc7-t4bcz\naffinity-nodeport-85dffb5fc7-t4bcz\naffinity-nodeport-85dffb5fc7-t4bcz\naffinity-nodeport-85dffb5fc7-t4bcz\naffinity-nodeport-85dffb5fc7-t4bcz\naffinity-nodeport-85dffb5fc7-t4bcz\naffinity-nodeport-85dffb5fc7-t4bcz\naffinity-nodeport-85dffb5fc7-t4bcz\naffinity-nodeport-85dffb5fc7-t4bcz\naffinity-nodeport-85dffb5fc7-t4bcz\naffinity-nodeport-85dffb5fc7-t4bcz\naffinity-nodeport-85dffb5fc7-t4bcz"
  I0511 15:03:41.597378 26 service.go:238] Received response from host: affinity-nodeport-85dffb5fc7-t4bcz
  I0511 15:03:41.597387 26 service.go:238] Received response from host: affinity-nodeport-85dffb5fc7-t4bcz
  I0511 15:03:41.597394 26 service.go:238] Received response from host: affinity-nodeport-85dffb5fc7-t4bcz
  I0511 15:03:41.597401 26 service.go:238] Received response from host: affinity-nodeport-85dffb5fc7-t4bcz
  I0511 15:03:41.597407 26 service.go:238] Received response from host: affinity-nodeport-85dffb5fc7-t4bcz
  I0511 15:03:41.597414 26 service.go:238] Received response from host: affinity-nodeport-85dffb5fc7-t4bcz
  I0511 15:03:41.597420 26 service.go:238] Received response from host: affinity-nodeport-85dffb5fc7-t4bcz
  I0511 15:03:41.597426 26 service.go:238] Received response from host: affinity-nodeport-85dffb5fc7-t4bcz
  I0511 15:03:41.597433 26 service.go:238] Received response from host: affinity-nodeport-85dffb5fc7-t4bcz
  I0511 15:03:41.597440 26 service.go:238] Received response from host: affinity-nodeport-85dffb5fc7-t4bcz
  I0511 15:03:41.597448 26 service.go:238] Received response from host: affinity-nodeport-85dffb5fc7-t4bcz
  I0511 15:03:41.597465 26 service.go:238] Received response from host: affinity-nodeport-85dffb5fc7-t4bcz
  I0511 15:03:41.597473 26 service.go:238] Received response from host: affinity-nodeport-85dffb5fc7-t4bcz
  I0511 15:03:41.597480 26 service.go:238] Received response from host: affinity-nodeport-85dffb5fc7-t4bcz
  I0511 15:03:41.597487 26 service.go:238] Received response from host: affinity-nodeport-85dffb5fc7-t4bcz
  I0511 15:03:41.597496 26 service.go:238] Received response from host: affinity-nodeport-85dffb5fc7-t4bcz
  I0511 15:03:41.597563 26 service.go:4352] Cleaning up the exec pod
  I0511 15:03:41.644026 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4798" for this suite. @ 05/11/25 15:03:41.655
• [4.750 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 05/11/25 15:03:41.661
  I0511 15:03:41.662023 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename container-runtime @ 05/11/25 15:03:41.663
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:03:41.671
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:03:41.673
  STEP: create the container @ 05/11/25 15:03:41.674
  I0511 15:03:41.680635      26 warnings.go:110] "Warning: metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]"
  STEP: wait for the container to reach Succeeded @ 05/11/25 15:03:41.68
  E0511 15:03:42.233534      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:43.233790      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:44.234683      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/11/25 15:03:44.695
  STEP: the container should be terminated @ 05/11/25 15:03:44.697
  STEP: the termination message should be set @ 05/11/25 15:03:44.697
  I0511 15:03:44.697584 26 runtime.go:167] Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 05/11/25 15:03:44.697
  I0511 15:03:44.712482 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1184" for this suite. @ 05/11/25 15:03:44.716
• [3.060 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:219
  STEP: Creating a kubernetes client @ 05/11/25 15:03:44.721
  I0511 15:03:44.721691 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename emptydir @ 05/11/25 15:03:44.722
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:03:44.735
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:03:44.737
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 05/11/25 15:03:44.74
  E0511 15:03:45.235400      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:46.235961      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:47.236857      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:48.237535      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 15:03:48.756
  I0511 15:03:48.759360 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-5eac6043-7e48-4dac-b851-ad9facc5297e container test-container: <nil>
  STEP: delete the pod @ 05/11/25 15:03:48.766
  I0511 15:03:48.783336 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5662" for this suite. @ 05/11/25 15:03:48.787
• [4.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:826
  STEP: Creating a kubernetes client @ 05/11/25 15:03:48.792
  I0511 15:03:48.792827 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename gc @ 05/11/25 15:03:48.793
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:03:48.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:03:48.806
  I0511 15:03:48.846804 26 garbage_collector.go:848] pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4bd8889e-f2b5-445d-a3b0-6bb3759d538a", Controller:(*bool)(0xc004b73b46), BlockOwnerDeletion:(*bool)(0xc004b73b47)}}
  I0511 15:03:48.853472 26 garbage_collector.go:852] pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"fb3ed912-c20b-417b-bb6b-fb22dd7e0cdc", Controller:(*bool)(0xc002071b3e), BlockOwnerDeletion:(*bool)(0xc002071b3f)}}
  I0511 15:03:48.860392 26 garbage_collector.go:856] pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b0f9a0f3-be31-46dd-a004-5d2df7ed78e4", Controller:(*bool)(0xc004a2aebe), BlockOwnerDeletion:(*bool)(0xc004a2aebf)}}
  E0511 15:03:49.237645      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:50.240744      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:51.241798      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:52.242313      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:53.242781      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:03:53.904347 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5627" for this suite. @ 05/11/25 15:03:53.906
• [5.120 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 05/11/25 15:03:53.912
  I0511 15:03:53.912772 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename podtemplate @ 05/11/25 15:03:53.913
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:03:53.922
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:03:53.924
  STEP: Create set of pod templates @ 05/11/25 15:03:53.926
  I0511 15:03:53.930963 26 podtemplates.go:143] created test-podtemplate-1
  I0511 15:03:53.935357 26 podtemplates.go:143] created test-podtemplate-2
  I0511 15:03:53.939705 26 podtemplates.go:143] created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 05/11/25 15:03:53.939
  STEP: delete collection of pod templates @ 05/11/25 15:03:53.941
  I0511 15:03:53.941955 26 podtemplates.go:158] requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 05/11/25 15:03:53.953
  I0511 15:03:53.953937 26 podtemplates.go:219] requesting list of pod templates to confirm quantity
  I0511 15:03:53.956655 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-2121" for this suite. @ 05/11/25 15:03:54.008
• [0.103 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:139
  STEP: Creating a kubernetes client @ 05/11/25 15:03:54.016
  I0511 15:03:54.016075 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename emptydir @ 05/11/25 15:03:54.017
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:03:54.026
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:03:54.029
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 05/11/25 15:03:54.032
  E0511 15:03:54.243689      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:55.243762      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 15:03:56.127
  I0511 15:03:56.130645 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-08968b4f-cec0-40dd-87e4-7ed6ba16cf26 container test-container: <nil>
  STEP: delete the pod @ 05/11/25 15:03:56.138
  I0511 15:03:56.152186 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4320" for this suite. @ 05/11/25 15:03:56.156
• [2.144 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 05/11/25 15:03:56.16
  I0511 15:03:56.160214 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename subpath @ 05/11/25 15:03:56.16
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:03:56.169
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:03:56.172
  STEP: Setting up data @ 05/11/25 15:03:56.174
  STEP: Creating pod pod-subpath-test-secret-vk7q @ 05/11/25 15:03:56.181
  STEP: Creating a pod to test atomic-volume-subpath @ 05/11/25 15:03:56.181
  E0511 15:03:56.244408      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:57.244829      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:58.244805      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:03:59.245648      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:00.246631      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:01.247618      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:02.248746      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:03.249124      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:04.250035      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:05.250859      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:06.251262      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:07.251769      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:08.252293      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:09.252746      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:10.253210      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:11.253853      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:12.254768      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:13.254790      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:14.255259      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:15.255580      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:16.256227      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:17.256671      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:18.256845      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:19.257643      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 15:04:20.249
  I0511 15:04:20.252280 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-subpath-test-secret-vk7q container test-container-subpath-secret-vk7q: <nil>
  E0511 15:04:20.258586      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the pod @ 05/11/25 15:04:20.267
  STEP: Deleting pod pod-subpath-test-secret-vk7q @ 05/11/25 15:04:20.279
  I0511 15:04:20.279621 26 delete.go:62] Deleting pod "pod-subpath-test-secret-vk7q" in namespace "subpath-6948"
  I0511 15:04:20.281021 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-6948" for this suite. @ 05/11/25 15:04:20.282
• [24.127 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 05/11/25 15:04:20.287
  I0511 15:04:20.287029 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 15:04:20.287
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:04:20.294
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:04:20.295
  STEP: Creating secret with name s-test-opt-del-91c1ee11-ba97-456d-925f-a6542cd6375d @ 05/11/25 15:04:20.385
  STEP: Creating secret with name s-test-opt-upd-a6c47b89-efd3-41e8-98f0-05487e7d349b @ 05/11/25 15:04:20.393
  STEP: Creating the pod @ 05/11/25 15:04:20.398
  E0511 15:04:21.258635      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:22.259652      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-91c1ee11-ba97-456d-925f-a6542cd6375d @ 05/11/25 15:04:22.429
  STEP: Updating secret s-test-opt-upd-a6c47b89-efd3-41e8-98f0-05487e7d349b @ 05/11/25 15:04:22.432
  STEP: Creating secret with name s-test-opt-create-593857f6-c8b7-46e9-bf7f-b0ad3e97d40a @ 05/11/25 15:04:22.437
  STEP: waiting to observe update in volume @ 05/11/25 15:04:22.44
  E0511 15:04:23.259853      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:24.260397      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:25.260390      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:26.260833      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:04:26.479475 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4662" for this suite. @ 05/11/25 15:04:26.483
• [6.202 seconds]
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:359
  STEP: Creating a kubernetes client @ 05/11/25 15:04:26.489
  I0511 15:04:26.489574 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/11/25 15:04:26.49
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:04:26.502
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:04:26.505
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 05/11/25 15:04:26.508
  I0511 15:04:26.508725 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  E0511 15:04:27.261163      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:04:27.648855 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  E0511 15:04:28.261268      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:29.262541      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:30.263571      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:31.264287      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:32.264520      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:04:32.293547 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-107" for this suite. @ 05/11/25 15:04:32.299
• [5.813 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:110
  STEP: Creating a kubernetes client @ 05/11/25 15:04:32.302
  I0511 15:04:32.302569 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubelet-test @ 05/11/25 15:04:32.303
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:04:32.311
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:04:32.313
  E0511 15:04:33.264802      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:34.265145      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:35.265948      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:36.266390      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:04:36.325449 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-5416" for this suite. @ 05/11/25 15:04:36.328
• [4.032 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Serial] [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:647
  STEP: Creating a kubernetes client @ 05/11/25 15:04:36.334
  I0511 15:04:36.334854 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename gc @ 05/11/25 15:04:36.335
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:04:36.345
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:04:36.348
  STEP: create the rc @ 05/11/25 15:04:36.43
  I0511 15:04:36.435972      26 warnings.go:110] "Warning: metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]"
  E0511 15:04:37.266697      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:38.267929      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:39.268699      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:40.269714      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:41.269993      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:42.270337      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the rc @ 05/11/25 15:04:42.439
  STEP: wait for the rc to be deleted @ 05/11/25 15:04:42.446
  E0511 15:04:43.270692      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:04:43.465265 26 garbage_collector.go:678] 80 pods remaining
  I0511 15:04:43.465553 26 garbage_collector.go:685] 80 pods has nil DeletionTimestamp
  I0511 15:04:43.465616 26 garbage_collector.go:686] 
  E0511 15:04:44.270786      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:04:44.458717 26 garbage_collector.go:678] 71 pods remaining
  I0511 15:04:44.458754 26 garbage_collector.go:685] 71 pods has nil DeletionTimestamp
  I0511 15:04:44.458763 26 garbage_collector.go:686] 
  E0511 15:04:45.270900      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:04:45.454708 26 garbage_collector.go:678] 60 pods remaining
  I0511 15:04:45.454751 26 garbage_collector.go:685] 60 pods has nil DeletionTimestamp
  I0511 15:04:45.454763 26 garbage_collector.go:686] 
  E0511 15:04:46.271753      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:04:46.456613 26 garbage_collector.go:678] 40 pods remaining
  I0511 15:04:46.456663 26 garbage_collector.go:685] 40 pods has nil DeletionTimestamp
  I0511 15:04:46.456678 26 garbage_collector.go:686] 
  E0511 15:04:47.271876      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:04:47.452754 26 garbage_collector.go:678] 31 pods remaining
  I0511 15:04:47.452783 26 garbage_collector.go:685] 31 pods has nil DeletionTimestamp
  I0511 15:04:47.452791 26 garbage_collector.go:686] 
  E0511 15:04:48.272737      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:04:48.451992 26 garbage_collector.go:678] 20 pods remaining
  I0511 15:04:48.452031 26 garbage_collector.go:685] 20 pods has nil DeletionTimestamp
  I0511 15:04:48.452042 26 garbage_collector.go:686] 
  E0511 15:04:49.273198      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/11/25 15:04:49.453
  I0511 15:04:49.591602 26 garbage_collector.go:273] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0511 15:04:49.591711 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-6059" for this suite. @ 05/11/25 15:04:49.593
• [13.263 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:270
  STEP: Creating a kubernetes client @ 05/11/25 15:04:49.597
  I0511 15:04:49.597624 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename apf @ 05/11/25 15:04:49.598
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:04:49.604
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:04:49.606
  STEP: getting /apis @ 05/11/25 15:04:49.608
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 05/11/25 15:04:49.61
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 05/11/25 15:04:49.61
  STEP: creating @ 05/11/25 15:04:49.611
  STEP: getting @ 05/11/25 15:04:49.62
  STEP: listing @ 05/11/25 15:04:49.622
  STEP: watching @ 05/11/25 15:04:49.623
  I0511 15:04:49.623883 26 flowcontrol.go:394] starting watch
  STEP: patching @ 05/11/25 15:04:49.624
  STEP: updating @ 05/11/25 15:04:49.628
  I0511 15:04:49.633520 26 flowcontrol.go:422] waiting for watch events with expected annotations
  I0511 15:04:49.633555 26 flowcontrol.go:438] missing expected annotations, waiting: map[string]string(nil)
  STEP: getting /status @ 05/11/25 15:04:49.633
  STEP: patching /status @ 05/11/25 15:04:49.635
  STEP: updating /status @ 05/11/25 15:04:49.638
  STEP: deleting @ 05/11/25 15:04:49.661
  STEP: deleting a collection @ 05/11/25 15:04:49.669
  I0511 15:04:49.683407 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-1106" for this suite. @ 05/11/25 15:04:49.694
• [0.103 seconds]
------------------------------
SSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 05/11/25 15:04:49.7
  I0511 15:04:49.700993 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename events @ 05/11/25 15:04:49.702
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:04:49.71
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:04:49.712
  STEP: creating a test event @ 05/11/25 15:04:49.715
  STEP: listing events in all namespaces @ 05/11/25 15:04:49.722
  STEP: listing events in test namespace @ 05/11/25 15:04:49.732
  STEP: listing events with field selection filtering on source @ 05/11/25 15:04:49.734
  STEP: listing events with field selection filtering on reportingController @ 05/11/25 15:04:49.736
  STEP: getting the test event @ 05/11/25 15:04:49.739
  STEP: patching the test event @ 05/11/25 15:04:49.74
  STEP: getting the test event @ 05/11/25 15:04:49.75
  STEP: updating the test event @ 05/11/25 15:04:49.751
  STEP: getting the test event @ 05/11/25 15:04:49.754
  STEP: deleting the test event @ 05/11/25 15:04:49.756
  STEP: listing events in all namespaces @ 05/11/25 15:04:49.76
  STEP: listing events in test namespace @ 05/11/25 15:04:49.77
  I0511 15:04:49.772702 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-2708" for this suite. @ 05/11/25 15:04:49.794
• [0.098 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:215
  STEP: Creating a kubernetes client @ 05/11/25 15:04:49.798
  I0511 15:04:49.798878 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename sched-preemption @ 05/11/25 15:04:49.799
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:04:49.808
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:04:49.811
  I0511 15:04:49.826084 26 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  E0511 15:04:50.273857      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:51.274301      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:52.275131      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:53.275431      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:54.275799      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:55.276663      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:56.277173      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:57.278109      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:58.278656      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:04:59.279266      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:00.280168      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:01.281100      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:02.281241      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:03.281957      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:04.282631      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:05.282880      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:06.283063      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:07.283861      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:08.284675      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:09.285044      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:10.286204      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:11.286530      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:12.286823      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:13.287085      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:14.288162      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:15.288665      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:16.288887      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:17.289267      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:18.289378      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:19.289792      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:20.289988      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:21.290380      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:22.290608      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:23.290992      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:24.291147      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:25.291968      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:26.292240      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:27.292785      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:28.292783      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:29.293093      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:30.293241      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:31.293783      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:32.294584      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:33.294805      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:34.295233      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:35.295657      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:36.296618      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:37.296726      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:38.296901      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:39.297420      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:40.298117      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:41.298566      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:42.299001      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:43.299719      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:44.300155      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:45.300189      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:46.301052      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:47.301398      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:48.301739      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:49.302006      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:05:49.831589 26 util.go:390] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 05/11/25 15:05:49.835
  STEP: Adding a custom resource @ 05/11/25 15:05:49.835
  I0511 15:05:49.855734 26 preemption.go:256] Created pod: pod0-0-sched-preemption-low-priority
  I0511 15:05:49.860910 26 preemption.go:256] Created pod: pod0-1-sched-preemption-medium-priority
  STEP: Adding a custom resource @ 05/11/25 15:05:49.86
  I0511 15:05:49.878272 26 preemption.go:256] Created pod: pod1-0-sched-preemption-medium-priority
  I0511 15:05:49.884889 26 preemption.go:256] Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 05/11/25 15:05:49.884
  E0511 15:05:50.302753      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:51.303840      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 05/11/25 15:05:51.903
  E0511 15:05:52.303912      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:53.304778      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Removing a custom resource @ 05/11/25 15:05:53.956
  STEP: Removing a custom resource @ 05/11/25 15:05:53.967
  I0511 15:05:53.979050 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-168" for this suite. @ 05/11/25 15:05:53.982
• [64.191 seconds]
------------------------------
S
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:97
  STEP: Creating a kubernetes client @ 05/11/25 15:05:53.989
  I0511 15:05:53.989824 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename secrets @ 05/11/25 15:05:53.991
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:05:54
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:05:54.004
  STEP: creating secret secrets-5276/secret-test-c2fca2c1-a423-48e8-8a0c-2bfda26404e7 @ 05/11/25 15:05:54.007
  STEP: Creating a pod to test consume secrets @ 05/11/25 15:05:54.011
  E0511 15:05:54.305012      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:55.305733      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:56.306818      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:57.307717      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 15:05:58.034
  I0511 15:05:58.036967 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-bfc39611-d857-418b-9c9c-dd8c7b43ef57 container env-test: <nil>
  STEP: delete the pod @ 05/11/25 15:05:58.049
  I0511 15:05:58.065977 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5276" for this suite. @ 05/11/25 15:05:58.069
• [4.085 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:99
  STEP: Creating a kubernetes client @ 05/11/25 15:05:58.075
  I0511 15:05:58.075127 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename projected @ 05/11/25 15:05:58.076
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:05:58.084
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:05:58.088
  STEP: Creating configMap with name projected-configmap-test-volume-map-69670c21-4246-4537-881c-e52d1a8bbf9a @ 05/11/25 15:05:58.09
  STEP: Creating a pod to test consume configMaps @ 05/11/25 15:05:58.094
  E0511 15:05:58.308608      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:05:59.308812      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:00.308932      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:01.309243      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 15:06:02.11
  I0511 15:06:02.112404 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-projected-configmaps-49b33302-26a3-456a-a4f6-f0d067b6391f container agnhost-container: <nil>
  STEP: delete the pod @ 05/11/25 15:06:02.116
  I0511 15:06:02.128031 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1960" for this suite. @ 05/11/25 15:06:02.129
• [4.058 seconds]
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:980
  STEP: Creating a kubernetes client @ 05/11/25 15:06:02.132
  I0511 15:06:02.132944 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename statefulset @ 05/11/25 15:06:02.133
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:06:02.138
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:06:02.14
  STEP: Creating service test in namespace statefulset-757 @ 05/11/25 15:06:02.142
  I0511 15:06:02.152234 26 wait.go:44] Found 0 stateful pods, waiting for 1
  E0511 15:06:02.309910      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:03.310431      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:04.310657      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:05.311060      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:06.311884      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:07.312629      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:08.313037      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:09.313486      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:10.313718      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:11.314261      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:06:12.156321 26 wait.go:54] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 05/11/25 15:06:12.161
  I0511 15:06:12.179853 26 wait.go:54] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0511 15:06:12.179913 26 wait.go:54] Waiting for pod test-ss-1 to enter Running - Ready=true, currently Pending - Ready=false
  E0511 15:06:12.315197      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:13.315654      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:14.315999      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:15.316136      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:16.316654      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:17.317077      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:18.317640      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:19.317629      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:20.318738      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:21.318976      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:06:22.178440 26 wait.go:54] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0511 15:06:22.178512 26 wait.go:54] Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 05/11/25 15:06:22.184
  STEP: Delete all of the StatefulSets @ 05/11/25 15:06:22.186
  STEP: Verify that StatefulSets have been deleted @ 05/11/25 15:06:22.195
  I0511 15:06:22.199222 26 statefulset.go:138] Deleting all statefulset in ns statefulset-757
  I0511 15:06:22.207388 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-757" for this suite. @ 05/11/25 15:06:22.213
• [20.089 seconds]
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:851
  STEP: Creating a kubernetes client @ 05/11/25 15:06:22.221
  I0511 15:06:22.221970 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename daemonsets @ 05/11/25 15:06:22.223
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:06:22.239
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:06:22.244
  STEP: Creating simple DaemonSet "daemon-set" @ 05/11/25 15:06:22.315
  E0511 15:06:22.319559      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/11/25 15:06:22.32
  I0511 15:06:22.415456 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 15:06:22.415496 26 fixtures.go:131] Node k8sconformance is running 0 daemon pod, expected 1
  E0511 15:06:23.319722      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:06:23.328434 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0511 15:06:23.328501 26 fixtures.go:131] Node k8sconformance is running 0 daemon pod, expected 1
  E0511 15:06:24.320503      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:06:24.328110 26 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0511 15:06:24.328144 26 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: listing all DaemonSets @ 05/11/25 15:06:24.329
  STEP: DeleteCollection of the DaemonSets @ 05/11/25 15:06:24.33
  STEP: Verify that ReplicaSets have been deleted @ 05/11/25 15:06:24.335
  I0511 15:06:24.347884 26 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"34205"},"items":null}

  I0511 15:06:24.350719 26 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"34205"},"items":[{"metadata":{"name":"daemon-set-chp2x","generateName":"daemon-set-","namespace":"daemonsets-9313","uid":"9b153c08-626b-4443-a3e1-ddfc04b741db","resourceVersion":"34204","generation":2,"creationTimestamp":"2025-05-11T15:06:22Z","deletionTimestamp":"2025-05-11T15:06:54Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"9f4489974","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"73199294-7dc2-46a1-b5af-c69a242ce0da","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2025-05-11T15:06:22Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"73199294-7dc2-46a1-b5af-c69a242ce0da\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2025-05-11T15:06:23Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.241\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-q2np6","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-q2np6","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"k8sconformance","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["k8sconformance"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-05-11T15:06:23Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-05-11T15:06:22Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-05-11T15:06:23Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-05-11T15:06:23Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-05-11T15:06:22Z"}],"hostIP":"192.168.49.2","hostIPs":[{"ip":"192.168.49.2"}],"podIP":"10.244.0.241","podIPs":[{"ip":"10.244.0.241"}],"startTime":"2025-05-11T15:06:22Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2025-05-11T15:06:22Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"docker://d6229794adcfef87d571d947ace757567e08580afea730a10c8ef9172213bfca","started":true,"resources":{},"volumeMounts":[{"name":"kube-api-access-q2np6","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}]}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-hvfgv","generateName":"daemon-set-","namespace":"daemonsets-9313","uid":"b387b015-45d4-4158-bc81-99c9e9f3cbbe","resourceVersion":"34205","generation":2,"creationTimestamp":"2025-05-11T15:06:22Z","deletionTimestamp":"2025-05-11T15:06:54Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"9f4489974","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"73199294-7dc2-46a1-b5af-c69a242ce0da","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2025-05-11T15:06:22Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"73199294-7dc2-46a1-b5af-c69a242ce0da\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2025-05-11T15:06:23Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.32\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-8gqnj","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-8gqnj","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"k8sconformance-m02","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["k8sconformance-m02"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-05-11T15:06:23Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-05-11T15:06:22Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-05-11T15:06:23Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-05-11T15:06:23Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-05-11T15:06:22Z"}],"hostIP":"192.168.49.3","hostIPs":[{"ip":"192.168.49.3"}],"podIP":"10.244.1.32","podIPs":[{"ip":"10.244.1.32"}],"startTime":"2025-05-11T15:06:22Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2025-05-11T15:06:22Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"docker://803fc6502dca38dce01a7afa53f3fc69119ac422dee546ec95ebb5049dd97fba","started":true,"resources":{},"volumeMounts":[{"name":"kube-api-access-8gqnj","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}]}],"qosClass":"BestEffort"}}]}

  I0511 15:06:24.430729 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-9313" for this suite. @ 05/11/25 15:06:24.432
• [2.216 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:89
  STEP: Creating a kubernetes client @ 05/11/25 15:06:24.438
  I0511 15:06:24.438377 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename emptydir @ 05/11/25 15:06:24.439
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:06:24.446
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:06:24.448
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 05/11/25 15:06:24.45
  E0511 15:06:25.320656      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:26.321731      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:27.322749      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:28.323713      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 15:06:28.469
  I0511 15:06:28.472089 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-13d3dba8-450e-405a-88e1-9ddb6ba5a0e9 container test-container: <nil>
  STEP: delete the pod @ 05/11/25 15:06:28.482
  I0511 15:06:28.496773 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4808" for this suite. @ 05/11/25 15:06:28.5
• [4.067 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:169
  STEP: Creating a kubernetes client @ 05/11/25 15:06:28.505
  I0511 15:06:28.505907 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename emptydir @ 05/11/25 15:06:28.507
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:06:28.522
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:06:28.526
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 05/11/25 15:06:28.528
  E0511 15:06:29.325485      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:30.325674      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:31.326219      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:32.326716      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 15:06:32.546
  I0511 15:06:32.549127 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-82e8aae2-7947-4b5b-bcd5-e07bc13bf86a container test-container: <nil>
  STEP: delete the pod @ 05/11/25 15:06:32.556
  I0511 15:06:32.571517 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1494" for this suite. @ 05/11/25 15:06:32.575
• [4.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
  STEP: Creating a kubernetes client @ 05/11/25 15:06:32.579
  I0511 15:06:32.579992 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename kubectl @ 05/11/25 15:06:32.581
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:06:32.588
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:06:32.591
  I0511 15:06:32.593627 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=kubectl-9460 version'
  I0511 15:06:32.632156 26 builder.go:146] stderr: ""
  I0511 15:06:32.632185 26 builder.go:147] stdout: "Client Version: v1.33.0\nKustomize Version: v5.6.0\nServer Version: v1.33.0\n"
  I0511 15:06:32.632330 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9460" for this suite. @ 05/11/25 15:06:32.676
• [0.102 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 05/11/25 15:06:32.682
  I0511 15:06:32.682497 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename secrets @ 05/11/25 15:06:32.683
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:06:32.694
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:06:32.698
  STEP: Creating secret with name secret-test-map-5addaf81-88be-41ea-a05e-986603311294 @ 05/11/25 15:06:32.702
  STEP: Creating a pod to test consume secrets @ 05/11/25 15:06:32.706
  E0511 15:06:33.327679      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:34.327887      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:35.328286      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:36.328734      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 15:06:36.727
  I0511 15:06:36.730309 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod pod-secrets-c81774f7-2ead-45cd-9ca5-15898db10533 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/11/25 15:06:36.736
  I0511 15:06:36.750161 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4596" for this suite. @ 05/11/25 15:06:36.753
• [4.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1387
  STEP: Creating a kubernetes client @ 05/11/25 15:06:36.76
  I0511 15:06:36.760473 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename services @ 05/11/25 15:06:36.761
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:06:36.769
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:06:36.772
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-7205 @ 05/11/25 15:06:36.775
  STEP: changing the ExternalName service to type=ClusterIP @ 05/11/25 15:06:36.779
  I0511 15:06:36.808660 26 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0511 15:06:37.329687      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:38.330687      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:06:38.812278 26 resource.go:361] Creating new exec pod
  E0511 15:06:39.331594      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:40.331811      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:06:40.830483 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-7205 exec execpodh246q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0511 15:06:40.925256 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service (10.102.17.230) 80 port [tcp/http] succeeded!\n"
  I0511 15:06:40.925297 26 builder.go:147] stdout: "externalname-service-5d764ffb79-7n5d2"
  I0511 15:06:40.925369 26 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4071347860 --namespace=services-7205 exec execpodh246q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.102.17.230 80'
  I0511 15:06:41.003749 26 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.102.17.230 80\nConnection to 10.102.17.230 80 port [tcp/http] succeeded!\n"
  I0511 15:06:41.003790 26 builder.go:147] stdout: "externalname-service-5d764ffb79-fvkxf"
  I0511 15:06:41.003865 26 service.go:1396] Cleaning up the ExternalName to ClusterIP test service
  I0511 15:06:41.021123 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7205" for this suite. @ 05/11/25 15:06:41.023
• [4.266 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:135
  STEP: Creating a kubernetes client @ 05/11/25 15:06:41.026
  I0511 15:06:41.026783 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename security-context @ 05/11/25 15:06:41.027
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:06:41.035
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:06:41.037
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 05/11/25 15:06:41.038
  E0511 15:06:41.332832      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:42.332871      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 15:06:43.051
  I0511 15:06:43.054741 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod security-context-15db5a57-66bd-4ece-b253-51b43f654ac1 container test-container: <nil>
  STEP: delete the pod @ 05/11/25 15:06:43.061
  I0511 15:06:43.077955 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-9218" for this suite. @ 05/11/25 15:06:43.081
• [2.059 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 05/11/25 15:06:43.086
  I0511 15:06:43.086840 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename watch @ 05/11/25 15:06:43.088
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:06:43.098
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:06:43.101
  STEP: creating a watch on configmaps @ 05/11/25 15:06:43.104
  STEP: creating a new configmap @ 05/11/25 15:06:43.105
  STEP: modifying the configmap once @ 05/11/25 15:06:43.109
  STEP: closing the watch once it receives two notifications @ 05/11/25 15:06:43.115
  I0511 15:06:43.115293 26 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7801  b99dd80a-4a8e-4bc3-b0da-caa65899b21e 34434 0 2025-05-11 15:06:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2025-05-11 15:06:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0511 15:06:43.115443 26 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7801  b99dd80a-4a8e-4bc3-b0da-caa65899b21e 34435 0 2025-05-11 15:06:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2025-05-11 15:06:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 05/11/25 15:06:43.115
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 05/11/25 15:06:43.122
  STEP: deleting the configmap @ 05/11/25 15:06:43.123
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 05/11/25 15:06:43.127
  I0511 15:06:43.127836 26 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7801  b99dd80a-4a8e-4bc3-b0da-caa65899b21e 34436 0 2025-05-11 15:06:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2025-05-11 15:06:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0511 15:06:43.128001 26 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7801  b99dd80a-4a8e-4bc3-b0da-caa65899b21e 34437 0 2025-05-11 15:06:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2025-05-11 15:06:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0511 15:06:43.128178 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-7801" for this suite. @ 05/11/25 15:06:43.183
• [0.102 seconds]
------------------------------
SSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 05/11/25 15:06:43.188
  I0511 15:06:43.188893 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename container-probe @ 05/11/25 15:06:43.189
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:06:43.2
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:06:43.203
  E0511 15:06:43.333452      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:44.333908      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:45.334290      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:46.334716      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:47.335773      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:48.336049      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:49.336168      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:50.336380      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:51.337440      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:52.338411      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:53.338989      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:54.339781      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:55.340676      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:56.341668      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:57.342177      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:58.342650      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:06:59.343711      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:00.344499      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:01.344909      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:02.345144      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:03.345744      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:04.346740      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:05.346771      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:06.347854      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:07.347983      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:08.348050      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:09.348159      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:10.348911      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:11.349571      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:12.349794      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:13.350647      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:14.350854      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:15.351283      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:16.351741      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:17.352781      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:18.353256      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:19.353578      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:20.354508      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:21.354646      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:22.354651      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:23.355902      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:24.356518      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:25.357280      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:26.357649      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:27.357785      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:28.358631      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:29.359437      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:30.359947      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:31.359950      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:32.360279      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:33.360815      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:34.361720      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:35.362081      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:36.362968      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:37.362987      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:38.363629      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:39.363932      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:40.363839      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:41.364906      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:42.365182      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:07:43.219511 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9437" for this suite. @ 05/11/25 15:07:43.222
• [60.040 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:222
  STEP: Creating a kubernetes client @ 05/11/25 15:07:43.229
  I0511 15:07:43.229121 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename downward-api @ 05/11/25 15:07:43.23
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:07:43.238
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:07:43.241
  STEP: Creating a pod to test downward API volume plugin @ 05/11/25 15:07:43.244
  E0511 15:07:43.365582      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:44.365659      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:45.366777      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:46.366981      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 15:07:47.263
  I0511 15:07:47.265803 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-d7c1f9eb-2cbb-4b60-8cbd-c570f19691b7 container client-container: <nil>
  STEP: delete the pod @ 05/11/25 15:07:47.272
  I0511 15:07:47.288749 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7564" for this suite. @ 05/11/25 15:07:47.292
• [4.068 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 05/11/25 15:07:47.298
  I0511 15:07:47.298439 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename replicaset @ 05/11/25 15:07:47.299
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:07:47.31
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:07:47.313
  STEP: Create a Replicaset @ 05/11/25 15:07:47.319
  STEP: Verify that the required pods have come up. @ 05/11/25 15:07:47.323
  I0511 15:07:47.325361 26 resource.go:81] Pod name sample-pod: Found 0 pods out of 1
  E0511 15:07:47.367870      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:48.368694      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:49.369071      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:50.369802      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:51.370267      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:07:52.326944 26 resource.go:81] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/11/25 15:07:52.326
  STEP: Getting /status @ 05/11/25 15:07:52.326
  I0511 15:07:52.328554 26 replica_set.go:649] Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 05/11/25 15:07:52.328
  I0511 15:07:52.334218 26 replica_set.go:669] updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 05/11/25 15:07:52.334
  I0511 15:07:52.335327 26 replica_set.go:695] Observed &ReplicaSet event: ADDED
  I0511 15:07:52.335407 26 replica_set.go:695] Observed &ReplicaSet event: MODIFIED
  I0511 15:07:52.335498 26 replica_set.go:695] Observed &ReplicaSet event: MODIFIED
  I0511 15:07:52.335590 26 replica_set.go:695] Observed &ReplicaSet event: MODIFIED
  I0511 15:07:52.335611 26 replica_set.go:688] Found replicaset test-rs in namespace replicaset-1329 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0511 15:07:52.335621 26 replica_set.go:699] Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 05/11/25 15:07:52.335
  I0511 15:07:52.335641 26 replica_set.go:703] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0511 15:07:52.338958 26 replica_set.go:707] Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 05/11/25 15:07:52.338
  I0511 15:07:52.339934 26 replica_set.go:731] Observed &ReplicaSet event: ADDED
  I0511 15:07:52.340002 26 replica_set.go:731] Observed &ReplicaSet event: MODIFIED
  I0511 15:07:52.340067 26 replica_set.go:731] Observed &ReplicaSet event: MODIFIED
  I0511 15:07:52.340170 26 replica_set.go:731] Observed &ReplicaSet event: MODIFIED
  I0511 15:07:52.340190 26 replica_set.go:727] Observed replicaset test-rs in namespace replicaset-1329 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0511 15:07:52.340255 26 replica_set.go:731] Observed &ReplicaSet event: MODIFIED
  I0511 15:07:52.340271 26 replica_set.go:724] Found replicaset test-rs in namespace replicaset-1329 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  I0511 15:07:52.340283 26 replica_set.go:735] Replicaset test-rs has a patched status
  I0511 15:07:52.340365 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-1329" for this suite. @ 05/11/25 15:07:52.342
• [5.048 seconds]
------------------------------
SSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 05/11/25 15:07:52.346
  I0511 15:07:52.346168 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename container-runtime @ 05/11/25 15:07:52.346
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:07:52.353
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:07:52.355
  STEP: create the container @ 05/11/25 15:07:52.356
  I0511 15:07:52.361685      26 warnings.go:110] "Warning: metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]"
  STEP: wait for the container to reach Succeeded @ 05/11/25 15:07:52.361
  E0511 15:07:52.370877      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:53.371095      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:54.371602      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:55.372095      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/11/25 15:07:55.375
  STEP: the container should be terminated @ 05/11/25 15:07:55.377
  STEP: the termination message should be set @ 05/11/25 15:07:55.377
  I0511 15:07:55.377578 26 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 05/11/25 15:07:55.377
  I0511 15:07:55.390697 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-3697" for this suite. @ 05/11/25 15:07:55.393
• [3.052 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:850
  STEP: Creating a kubernetes client @ 05/11/25 15:07:55.398
  I0511 15:07:55.398220 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename pods @ 05/11/25 15:07:55.399
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:07:55.406
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:07:55.407
  STEP: Create set of pods @ 05/11/25 15:07:55.413
  I0511 15:07:55.419603 26 pods.go:874] created test-pod-1
  I0511 15:07:55.425407 26 pods.go:874] created test-pod-2
  I0511 15:07:55.431432 26 pods.go:874] created test-pod-3
  STEP: waiting for all 3 pods to be running @ 05/11/25 15:07:55.431
  E0511 15:07:56.372340      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:07:57.372708      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 05/11/25 15:07:57.467
  I0511 15:07:57.557778 26 pods.go:1139] Pod quantity 3 is different from expected quantity 0
  E0511 15:07:58.372620      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:07:58.473183 26 pods.go:1139] Pod quantity 2 is different from expected quantity 0
  E0511 15:07:59.372929      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:07:59.472116 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9846" for this suite. @ 05/11/25 15:07:59.475
• [4.083 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 05/11/25 15:07:59.481
  I0511 15:07:59.481927 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename pods @ 05/11/25 15:07:59.482
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:07:59.491
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:07:59.495
  I0511 15:07:59.497434 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: creating the pod @ 05/11/25 15:07:59.497
  STEP: submitting the pod to kubernetes @ 05/11/25 15:07:59.497
  E0511 15:08:00.373016      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:08:01.373234      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: waiting for the container to be running @ 05/11/25 15:08:01.516
  I0511 15:08:01.531283 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2203" for this suite. @ 05/11/25 15:08:01.534
• [2.058 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Job should terminate job execution when the number of failed indexes exceeds maxFailedIndexes [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:643
  STEP: Creating a kubernetes client @ 05/11/25 15:08:01.54
  I0511 15:08:01.540565 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename job @ 05/11/25 15:08:01.541
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:08:01.55
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:08:01.553
  STEP: Creating an indexed job with backoffLimit per index and maxFailedIndexes @ 05/11/25 15:08:01.556
  STEP: Awaiting for the job to fail as the number of max failed indexes is exceeded @ 05/11/25 15:08:01.561
  E0511 15:08:02.373708      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:08:03.374206      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:08:04.374595      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:08:05.375161      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Verifying the Job status fields to ensure early termination of the job @ 05/11/25 15:08:05.575
  I0511 15:08:05.577238 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1360" for this suite. @ 05/11/25 15:08:05.58
• [4.045 seconds]
------------------------------
SSSS
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:153
  STEP: Creating a kubernetes client @ 05/11/25 15:08:05.586
  I0511 15:08:05.586168 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename dns @ 05/11/25 15:08:05.587
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:08:05.598
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:08:05.602
  STEP: Creating a test headless service @ 05/11/25 15:08:05.605
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6758.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service.dns-6758.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6758.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service.dns-6758.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6758.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/agnhost_udp@_http._tcp.dns-test-service.dns-6758.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6758.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/agnhost_tcp@_http._tcp.dns-test-service.dns-6758.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6758.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/agnhost_udp@_http._tcp.test-service-2.dns-6758.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6758.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/agnhost_tcp@_http._tcp.test-service-2.dns-6758.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 93.220.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.220.93_udp@PTR;check="$$(dig +tcp +noall +answer +search 93.220.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.220.93_tcp@PTR;sleep 1; done
   @ 05/11/25 15:08:05.628
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6758.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6758.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6758.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6758.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6758.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6758.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6758.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6758.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6758.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6758.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6758.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6758.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 93.220.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.220.93_udp@PTR;check="$$(dig +tcp +noall +answer +search 93.220.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.220.93_tcp@PTR;sleep 1; done
   @ 05/11/25 15:08:05.628
  STEP: creating a pod to probe DNS @ 05/11/25 15:08:05.628
  STEP: submitting the pod to kubernetes @ 05/11/25 15:08:05.628
  E0511 15:08:06.375557      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:08:07.375816      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/11/25 15:08:07.645
  STEP: looking for the results for each expected name from probers @ 05/11/25 15:08:07.646
  I0511 15:08:07.648785 26 dns_common.go:495] Unable to read agnhost_udp@dns-test-service.dns-6758.svc.cluster.local from pod dns-6758/dns-test-c97b8950-6691-486c-b583-5487b92ae7d5: the server could not find the requested resource (get pods dns-test-c97b8950-6691-486c-b583-5487b92ae7d5)
  I0511 15:08:07.650288 26 dns_common.go:495] Unable to read agnhost_tcp@dns-test-service.dns-6758.svc.cluster.local from pod dns-6758/dns-test-c97b8950-6691-486c-b583-5487b92ae7d5: the server could not find the requested resource (get pods dns-test-c97b8950-6691-486c-b583-5487b92ae7d5)
  I0511 15:08:07.651770 26 dns_common.go:495] Unable to read agnhost_udp@_http._tcp.dns-test-service.dns-6758.svc.cluster.local from pod dns-6758/dns-test-c97b8950-6691-486c-b583-5487b92ae7d5: the server could not find the requested resource (get pods dns-test-c97b8950-6691-486c-b583-5487b92ae7d5)
  I0511 15:08:07.653207 26 dns_common.go:495] Unable to read agnhost_tcp@_http._tcp.dns-test-service.dns-6758.svc.cluster.local from pod dns-6758/dns-test-c97b8950-6691-486c-b583-5487b92ae7d5: the server could not find the requested resource (get pods dns-test-c97b8950-6691-486c-b583-5487b92ae7d5)
  I0511 15:08:07.676221 26 dns_common.go:506] Lookups using dns-6758/dns-test-c97b8950-6691-486c-b583-5487b92ae7d5 failed for: [agnhost_udp@dns-test-service.dns-6758.svc.cluster.local agnhost_tcp@dns-test-service.dns-6758.svc.cluster.local agnhost_udp@_http._tcp.dns-test-service.dns-6758.svc.cluster.local agnhost_tcp@_http._tcp.dns-test-service.dns-6758.svc.cluster.local]

  I0511 15:08:07.680980 26 dns_common.go:514] Pod client logs for webserver: 
  I0511 15:08:07.685262 26 dns_common.go:514] Pod client logs for agnhost-querier: 
  I0511 15:08:07.689126 26 dns_common.go:514] Pod client logs for jessie-querier: 
  E0511 15:08:08.376073      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:08:09.376987      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:08:10.377157      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:08:11.378006      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:08:12.378516      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0511 15:08:12.687729 26 dns_common.go:546] DNS probes using dns-6758/dns-test-c97b8950-6691-486c-b583-5487b92ae7d5 succeeded

  STEP: deleting the pod @ 05/11/25 15:08:12.687
  STEP: deleting the test service @ 05/11/25 15:08:12.699
  STEP: deleting the test headless service @ 05/11/25 15:08:12.729
  I0511 15:08:12.736312 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-6758" for this suite. @ 05/11/25 15:08:12.738
• [7.159 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:250
  STEP: Creating a kubernetes client @ 05/11/25 15:08:12.744
  I0511 15:08:12.744818 26 util.go:453] >>> kubeConfig: /tmp/kubeconfig-4071347860
  STEP: Building a namespace api object, basename downward-api @ 05/11/25 15:08:12.745
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/11/25 15:08:12.752
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/11/25 15:08:12.756
  STEP: Creating a pod to test downward API volume plugin @ 05/11/25 15:08:12.758
  E0511 15:08:13.378575      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:08:14.378755      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:08:15.379713      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0511 15:08:16.379773      26 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/11/25 15:08:16.775
  I0511 15:08:16.778560 26 output.go:207] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-328b289a-40c4-4430-9e74-7642e0b09b49 container client-container: <nil>
  STEP: delete the pod @ 05/11/25 15:08:16.788
  I0511 15:08:16.801862 26 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7226" for this suite. @ 05/11/25 15:08:16.804
• [4.064 seconds]
------------------------------
S
------------------------------
[SynchronizedAfterSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:80
  I0511 15:08:16.809324 26 suites.go:34] Running AfterSuite actions on node 1
  I0511 15:08:16.809375 26 util.go:563] Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
k8s.io/kubernetes/test/e2e/e2e_test.go:157
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
k8s.io/kubernetes/test/e2e/framework/test_context.go:615
[ReportAfterSuite] PASSED [0.025 seconds]
------------------------------

Summarizing 1 Failure:
  [FAIL] [sig-cli] Kubectl client Update Demo [It] should create and stop a replication controller [Conformance] [sig-cli, Conformance]
  k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:2532

Ran 419 of 6731 Specs in 7277.003 seconds
FAIL! -- 418 Passed | 1 Failed | 0 Pending | 6312 Skipped
--- FAIL: TestE2E (7277.14s)
FAIL

Ginkgo ran 1 suite in 2h1m17.472406541s

Test Suite Failed
