I1106 01:13:45.773670      26 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-720122187
I1106 01:13:45.773843      26 e2e.go:92] Starting e2e run "e7d50d4e-0c55-4e4e-bc94-cc2595a4b5df" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1573002824 - Will randomize all specs
Will run 276 of 4897 specs

Nov  6 01:13:45.787: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 01:13:45.790: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Nov  6 01:13:49.290: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov  6 01:13:49.480: INFO: 11 / 11 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov  6 01:13:49.480: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Nov  6 01:13:49.480: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov  6 01:13:49.489: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Nov  6 01:13:49.489: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Nov  6 01:13:49.489: INFO: e2e test version: v1.16.2
Nov  6 01:13:49.490: INFO: kube-apiserver version: v1.16.2
Nov  6 01:13:49.490: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 01:13:49.495: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:13:49.496: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
Nov  6 01:13:49.572: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-c33e58da-7f01-4620-b5e1-73d4afb793bd
STEP: Creating configMap with name cm-test-opt-upd-249e6737-74c9-4513-a162-e3fcdc85ff1e
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-c33e58da-7f01-4620-b5e1-73d4afb793bd
STEP: Updating configmap cm-test-opt-upd-249e6737-74c9-4513-a162-e3fcdc85ff1e
STEP: Creating configMap with name cm-test-opt-create-dfd32dfc-5668-4692-888c-1f04d95daa60
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:14:01.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1775" for this suite.
Nov  6 01:14:29.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:14:29.847: INFO: namespace projected-1775 deletion completed in 28.113207805s

• [SLOW TEST:40.351 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:14:29.847: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 01:14:29.964: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Nov  6 01:14:29.982: INFO: Number of nodes with available pods: 0
Nov  6 01:14:29.983: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:14:30.988: INFO: Number of nodes with available pods: 0
Nov  6 01:14:30.988: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:14:31.988: INFO: Number of nodes with available pods: 0
Nov  6 01:14:31.988: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:14:32.988: INFO: Number of nodes with available pods: 0
Nov  6 01:14:32.988: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:14:33.988: INFO: Number of nodes with available pods: 0
Nov  6 01:14:33.988: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:14:34.988: INFO: Number of nodes with available pods: 0
Nov  6 01:14:34.988: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:14:35.988: INFO: Number of nodes with available pods: 0
Nov  6 01:14:35.988: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:14:36.989: INFO: Number of nodes with available pods: 0
Nov  6 01:14:36.989: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:14:37.989: INFO: Number of nodes with available pods: 0
Nov  6 01:14:37.989: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:14:39.843: INFO: Number of nodes with available pods: 0
Nov  6 01:14:39.843: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:14:39.995: INFO: Number of nodes with available pods: 0
Nov  6 01:14:39.995: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:14:40.987: INFO: Number of nodes with available pods: 0
Nov  6 01:14:40.987: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:14:42.013: INFO: Number of nodes with available pods: 1
Nov  6 01:14:42.013: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:14:42.988: INFO: Number of nodes with available pods: 1
Nov  6 01:14:42.988: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:14:43.988: INFO: Number of nodes with available pods: 2
Nov  6 01:14:43.988: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Nov  6 01:14:44.044: INFO: Wrong image for pod: daemon-set-bltlw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:44.044: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:45.065: INFO: Wrong image for pod: daemon-set-bltlw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:45.065: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:46.065: INFO: Wrong image for pod: daemon-set-bltlw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:46.065: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:47.064: INFO: Wrong image for pod: daemon-set-bltlw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:47.064: INFO: Pod daemon-set-bltlw is not available
Nov  6 01:14:47.064: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:48.078: INFO: Wrong image for pod: daemon-set-bltlw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:48.078: INFO: Pod daemon-set-bltlw is not available
Nov  6 01:14:48.078: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:49.065: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:49.065: INFO: Pod daemon-set-wt7bw is not available
Nov  6 01:14:50.065: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:50.065: INFO: Pod daemon-set-wt7bw is not available
Nov  6 01:14:51.065: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:51.065: INFO: Pod daemon-set-wt7bw is not available
Nov  6 01:14:52.066: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:52.066: INFO: Pod daemon-set-wt7bw is not available
Nov  6 01:14:53.065: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:53.065: INFO: Pod daemon-set-wt7bw is not available
Nov  6 01:14:54.064: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:54.064: INFO: Pod daemon-set-wt7bw is not available
Nov  6 01:14:55.065: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:55.065: INFO: Pod daemon-set-wt7bw is not available
Nov  6 01:14:56.064: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:56.065: INFO: Pod daemon-set-wt7bw is not available
Nov  6 01:14:57.084: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:57.084: INFO: Pod daemon-set-wt7bw is not available
Nov  6 01:14:58.084: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:14:58.084: INFO: Pod daemon-set-wt7bw is not available
Nov  6 01:14:59.064: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:15:00.066: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:15:00.066: INFO: Pod daemon-set-t74bk is not available
Nov  6 01:15:01.064: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:15:01.064: INFO: Pod daemon-set-t74bk is not available
Nov  6 01:15:02.065: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:15:02.065: INFO: Pod daemon-set-t74bk is not available
Nov  6 01:15:03.064: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:15:03.064: INFO: Pod daemon-set-t74bk is not available
Nov  6 01:15:04.592: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:15:04.592: INFO: Pod daemon-set-t74bk is not available
Nov  6 01:15:05.065: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:15:05.065: INFO: Pod daemon-set-t74bk is not available
Nov  6 01:15:06.064: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:15:06.064: INFO: Pod daemon-set-t74bk is not available
Nov  6 01:15:07.065: INFO: Wrong image for pod: daemon-set-t74bk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  6 01:15:07.065: INFO: Pod daemon-set-t74bk is not available
Nov  6 01:15:08.064: INFO: Pod daemon-set-vsv4g is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Nov  6 01:15:08.070: INFO: Number of nodes with available pods: 1
Nov  6 01:15:08.070: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:15:09.075: INFO: Number of nodes with available pods: 1
Nov  6 01:15:09.075: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:15:10.078: INFO: Number of nodes with available pods: 1
Nov  6 01:15:10.078: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:15:11.075: INFO: Number of nodes with available pods: 1
Nov  6 01:15:11.075: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:15:12.078: INFO: Number of nodes with available pods: 1
Nov  6 01:15:12.078: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:15:13.077: INFO: Number of nodes with available pods: 1
Nov  6 01:15:13.077: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:15:14.079: INFO: Number of nodes with available pods: 1
Nov  6 01:15:14.079: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:15:15.076: INFO: Number of nodes with available pods: 1
Nov  6 01:15:15.076: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:15:16.076: INFO: Number of nodes with available pods: 1
Nov  6 01:15:16.076: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:15:17.075: INFO: Number of nodes with available pods: 2
Nov  6 01:15:17.075: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9478, will wait for the garbage collector to delete the pods
Nov  6 01:15:17.140: INFO: Deleting DaemonSet.extensions daemon-set took: 4.00975ms
Nov  6 01:15:17.540: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.288067ms
Nov  6 01:15:21.642: INFO: Number of nodes with available pods: 0
Nov  6 01:15:21.642: INFO: Number of running nodes: 0, number of available pods: 0
Nov  6 01:15:21.644: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9478/daemonsets","resourceVersion":"852921"},"items":null}

Nov  6 01:15:21.646: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9478/pods","resourceVersion":"852921"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:15:21.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9478" for this suite.
Nov  6 01:15:27.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:15:27.720: INFO: namespace daemonsets-9478 deletion completed in 6.06653907s

• [SLOW TEST:57.873 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:15:27.720: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Nov  6 01:15:27.795: INFO: Waiting up to 5m0s for pod "client-containers-f8eb5270-c512-41cb-96d3-7d3f91ed146c" in namespace "containers-2605" to be "success or failure"
Nov  6 01:15:27.807: INFO: Pod "client-containers-f8eb5270-c512-41cb-96d3-7d3f91ed146c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.499719ms
Nov  6 01:15:29.810: INFO: Pod "client-containers-f8eb5270-c512-41cb-96d3-7d3f91ed146c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015428635s
Nov  6 01:15:31.812: INFO: Pod "client-containers-f8eb5270-c512-41cb-96d3-7d3f91ed146c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01751625s
Nov  6 01:15:33.815: INFO: Pod "client-containers-f8eb5270-c512-41cb-96d3-7d3f91ed146c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.020174094s
Nov  6 01:15:35.817: INFO: Pod "client-containers-f8eb5270-c512-41cb-96d3-7d3f91ed146c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.022523985s
Nov  6 01:15:37.832: INFO: Pod "client-containers-f8eb5270-c512-41cb-96d3-7d3f91ed146c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.037464442s
Nov  6 01:15:39.835: INFO: Pod "client-containers-f8eb5270-c512-41cb-96d3-7d3f91ed146c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.040153097s
STEP: Saw pod success
Nov  6 01:15:39.835: INFO: Pod "client-containers-f8eb5270-c512-41cb-96d3-7d3f91ed146c" satisfied condition "success or failure"
Nov  6 01:15:39.836: INFO: Trying to get logs from node apps-114 pod client-containers-f8eb5270-c512-41cb-96d3-7d3f91ed146c container test-container: <nil>
STEP: delete the pod
Nov  6 01:15:39.930: INFO: Waiting for pod client-containers-f8eb5270-c512-41cb-96d3-7d3f91ed146c to disappear
Nov  6 01:15:39.944: INFO: Pod client-containers-f8eb5270-c512-41cb-96d3-7d3f91ed146c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:15:39.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2605" for this suite.
Nov  6 01:15:45.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:15:46.000: INFO: namespace containers-2605 deletion completed in 6.054165725s

• [SLOW TEST:18.280 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:15:46.001: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov  6 01:15:50.594: INFO: Successfully updated pod "labelsupdated0180cda-13ff-457d-8a56-dc60c965074c"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:15:52.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5616" for this suite.
Nov  6 01:16:14.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:16:14.694: INFO: namespace projected-5616 deletion completed in 22.069708426s

• [SLOW TEST:28.693 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:16:14.694: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-7736149c-941f-48dc-982c-ff202c04c22a
STEP: Creating a pod to test consume secrets
Nov  6 01:16:14.761: INFO: Waiting up to 5m0s for pod "pod-secrets-e8e18c9c-fd74-4f95-8495-5e99c4d0530e" in namespace "secrets-6389" to be "success or failure"
Nov  6 01:16:14.810: INFO: Pod "pod-secrets-e8e18c9c-fd74-4f95-8495-5e99c4d0530e": Phase="Pending", Reason="", readiness=false. Elapsed: 49.114583ms
Nov  6 01:16:16.813: INFO: Pod "pod-secrets-e8e18c9c-fd74-4f95-8495-5e99c4d0530e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051220045s
Nov  6 01:16:18.815: INFO: Pod "pod-secrets-e8e18c9c-fd74-4f95-8495-5e99c4d0530e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053594744s
STEP: Saw pod success
Nov  6 01:16:18.815: INFO: Pod "pod-secrets-e8e18c9c-fd74-4f95-8495-5e99c4d0530e" satisfied condition "success or failure"
Nov  6 01:16:18.816: INFO: Trying to get logs from node apps-114 pod pod-secrets-e8e18c9c-fd74-4f95-8495-5e99c4d0530e container secret-volume-test: <nil>
STEP: delete the pod
Nov  6 01:16:18.847: INFO: Waiting for pod pod-secrets-e8e18c9c-fd74-4f95-8495-5e99c4d0530e to disappear
Nov  6 01:16:18.860: INFO: Pod pod-secrets-e8e18c9c-fd74-4f95-8495-5e99c4d0530e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:16:18.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6389" for this suite.
Nov  6 01:16:24.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:16:24.944: INFO: namespace secrets-6389 deletion completed in 6.082079746s

• [SLOW TEST:10.250 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:16:24.944: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Nov  6 01:16:25.043: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4451 /api/v1/namespaces/watch-4451/configmaps/e2e-watch-test-configmap-a 99ec3eab-bea1-428b-88c3-63c41cabcc27 853148 0 2019-11-06 01:16:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  6 01:16:25.043: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4451 /api/v1/namespaces/watch-4451/configmaps/e2e-watch-test-configmap-a 99ec3eab-bea1-428b-88c3-63c41cabcc27 853148 0 2019-11-06 01:16:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Nov  6 01:16:35.049: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4451 /api/v1/namespaces/watch-4451/configmaps/e2e-watch-test-configmap-a 99ec3eab-bea1-428b-88c3-63c41cabcc27 853163 0 2019-11-06 01:16:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov  6 01:16:35.049: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4451 /api/v1/namespaces/watch-4451/configmaps/e2e-watch-test-configmap-a 99ec3eab-bea1-428b-88c3-63c41cabcc27 853163 0 2019-11-06 01:16:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Nov  6 01:16:45.054: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4451 /api/v1/namespaces/watch-4451/configmaps/e2e-watch-test-configmap-a 99ec3eab-bea1-428b-88c3-63c41cabcc27 853180 0 2019-11-06 01:16:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  6 01:16:45.054: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4451 /api/v1/namespaces/watch-4451/configmaps/e2e-watch-test-configmap-a 99ec3eab-bea1-428b-88c3-63c41cabcc27 853180 0 2019-11-06 01:16:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Nov  6 01:16:55.059: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4451 /api/v1/namespaces/watch-4451/configmaps/e2e-watch-test-configmap-a 99ec3eab-bea1-428b-88c3-63c41cabcc27 853195 0 2019-11-06 01:16:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  6 01:16:55.059: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4451 /api/v1/namespaces/watch-4451/configmaps/e2e-watch-test-configmap-a 99ec3eab-bea1-428b-88c3-63c41cabcc27 853195 0 2019-11-06 01:16:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Nov  6 01:17:05.065: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4451 /api/v1/namespaces/watch-4451/configmaps/e2e-watch-test-configmap-b dc318d63-37c7-4491-867e-e505e0c82062 853210 0 2019-11-06 01:17:05 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  6 01:17:05.065: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4451 /api/v1/namespaces/watch-4451/configmaps/e2e-watch-test-configmap-b dc318d63-37c7-4491-867e-e505e0c82062 853210 0 2019-11-06 01:17:05 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Nov  6 01:17:15.070: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4451 /api/v1/namespaces/watch-4451/configmaps/e2e-watch-test-configmap-b dc318d63-37c7-4491-867e-e505e0c82062 853227 0 2019-11-06 01:17:05 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  6 01:17:15.070: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4451 /api/v1/namespaces/watch-4451/configmaps/e2e-watch-test-configmap-b dc318d63-37c7-4491-867e-e505e0c82062 853227 0 2019-11-06 01:17:05 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:17:25.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4451" for this suite.
Nov  6 01:17:31.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:17:31.161: INFO: namespace watch-4451 deletion completed in 6.086961549s

• [SLOW TEST:66.216 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:17:31.161: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:17:31.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6595" for this suite.
Nov  6 01:17:37.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:17:37.302: INFO: namespace custom-resource-definition-6595 deletion completed in 6.076536048s

• [SLOW TEST:6.141 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:17:37.302: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-035d49f4-3c4b-49e6-9c97-4eb77ff9c744
STEP: Creating a pod to test consume configMaps
Nov  6 01:17:37.352: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2beab312-ccb9-45b0-acd8-a77b87194cad" in namespace "projected-8711" to be "success or failure"
Nov  6 01:17:37.362: INFO: Pod "pod-projected-configmaps-2beab312-ccb9-45b0-acd8-a77b87194cad": Phase="Pending", Reason="", readiness=false. Elapsed: 10.868978ms
Nov  6 01:17:39.365: INFO: Pod "pod-projected-configmaps-2beab312-ccb9-45b0-acd8-a77b87194cad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013650179s
Nov  6 01:17:41.368: INFO: Pod "pod-projected-configmaps-2beab312-ccb9-45b0-acd8-a77b87194cad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016105541s
STEP: Saw pod success
Nov  6 01:17:41.368: INFO: Pod "pod-projected-configmaps-2beab312-ccb9-45b0-acd8-a77b87194cad" satisfied condition "success or failure"
Nov  6 01:17:41.369: INFO: Trying to get logs from node apps-114 pod pod-projected-configmaps-2beab312-ccb9-45b0-acd8-a77b87194cad container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  6 01:17:41.398: INFO: Waiting for pod pod-projected-configmaps-2beab312-ccb9-45b0-acd8-a77b87194cad to disappear
Nov  6 01:17:41.408: INFO: Pod pod-projected-configmaps-2beab312-ccb9-45b0-acd8-a77b87194cad no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:17:41.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8711" for this suite.
Nov  6 01:17:47.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:17:47.471: INFO: namespace projected-8711 deletion completed in 6.060073829s

• [SLOW TEST:10.168 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:17:47.471: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  6 01:17:47.514: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  6 01:17:47.521: INFO: Waiting for terminating namespaces to be deleted...
Nov  6 01:17:47.523: INFO: 
Logging pods the kubelet thinks is on node apps-113 before test
Nov  6 01:17:47.535: INFO: dashboard-session-cocktail-66658bd785-zl4lk from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container dashboard-session-01 ready: true, restart count 0
Nov  6 01:17:47.535: INFO: dashboard-cocktail-575c77f5bd-7xpz9 from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container cocktail-dashboard ready: true, restart count 0
Nov  6 01:17:47.535: INFO: api-cmdb-cocktail-7796b94f65-5x9kt from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container api-cmdb-01 ready: true, restart count 0
Nov  6 01:17:47.535: INFO: monitoring-db-cocktail-547dff6c7f-msc7q from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container db ready: true, restart count 0
Nov  6 01:17:47.535: INFO: calico-node-jv7rf from kube-system started at 2019-10-30 08:16:37 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container calico-node ready: true, restart count 0
Nov  6 01:17:47.535: INFO: addon-manager-7c8b9c74f6-9pllx from cocktail-addon started at 2019-10-30 08:17:39 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container addon-manager ready: true, restart count 0
Nov  6 01:17:47.535: INFO: batch-server-cocktail-55d57dff79-4qm6j from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container batch ready: true, restart count 0
Nov  6 01:17:47.535: INFO: build-api-cocktail-6d6f8dfbbc-jhq8w from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container build-api ready: true, restart count 0
Nov  6 01:17:47.535: INFO: sonobuoy-systemd-logs-daemon-set-a0ae98b6655c4fa6-tpjhf from sonobuoy started at 2019-11-06 01:13:06 +0000 UTC (2 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  6 01:17:47.535: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  6 01:17:47.535: INFO: kube-state-metrics-addon-7f48b7868b-jd4jx from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container kube-state-metrics-addon ready: true, restart count 0
Nov  6 01:17:47.535: INFO: nfs-client-provisioner-addon-566798455d-q7tw8 from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container nfs-client-provisioner-addon ready: true, restart count 0
Nov  6 01:17:47.535: INFO: cluster-health-checker-cocktail-58f4545c48-l9ncr from cocktail-system started at 2019-10-30 08:18:01 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container checker ready: true, restart count 0
Nov  6 01:17:47.535: INFO: cloud-metering-collector-cocktail-68bfd6cc67-q8tjh from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (3 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container cocktail-collector-aws ready: true, restart count 1
Nov  6 01:17:47.535: INFO: 	Container cocktail-collector-azure ready: true, restart count 0
Nov  6 01:17:47.535: INFO: 	Container cocktail-collector-google ready: true, restart count 1
Nov  6 01:17:47.535: INFO: alertmanager-addon-5967cc89f8-8bdvd from cocktail-addon started at 2019-10-30 08:19:27 +0000 UTC (2 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container alertmanager-addon ready: true, restart count 0
Nov  6 01:17:47.535: INFO: 	Container configmap-reload ready: true, restart count 0
Nov  6 01:17:47.535: INFO: dashboard-proxy-cocktail-5cfd96484-9qjjr from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container dashboard-proxy-01 ready: true, restart count 0
Nov  6 01:17:47.535: INFO: metrics-server-5d9d98df9f-qsw2s from kube-system started at 2019-10-30 08:17:01 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container metrics-server ready: true, restart count 0
Nov  6 01:17:47.535: INFO: nginx-ingress-addon-controller-7dcb6fc5ff-t4rlv from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container nginx-ingress-addon-controller ready: true, restart count 0
Nov  6 01:17:47.535: INFO: monitoring-collector-cocktail-5647c8b855-54jph from cocktail-system started at 2019-10-30 08:18:01 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container statcollector ready: true, restart count 4
Nov  6 01:17:47.535: INFO: api-server-cocktail-88f64f646-x67ld from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container api-server-01 ready: true, restart count 0
Nov  6 01:17:47.535: INFO: build-queue-cocktail-758498c967-slzk4 from cocktail-system started at 2019-10-30 08:19:23 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container nats-streaming ready: true, restart count 0
Nov  6 01:17:47.535: INFO: kube-controller-manager-apps-113 from kube-system started at 2019-10-30 08:16:38 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container kube-controller-manager ready: true, restart count 0
Nov  6 01:17:47.535: INFO: kube-scheduler-apps-113 from kube-system started at 2019-10-30 08:16:37 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container kube-scheduler ready: true, restart count 0
Nov  6 01:17:47.535: INFO: monitoring-cocktail-59d5ffc9fd-szdwh from cocktail-system started at 2019-10-30 08:18:03 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container monitoring-01 ready: true, restart count 0
Nov  6 01:17:47.535: INFO: kube-apiserver-apps-113 from kube-system started at 2019-10-30 08:16:37 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container kube-apiserver ready: true, restart count 0
Nov  6 01:17:47.535: INFO: disk-usage-exporter-addon-t758w from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container disk-usage-exporter-addon ready: true, restart count 0
Nov  6 01:17:47.535: INFO: kube-proxy-hdklg from kube-system started at 2019-10-30 08:16:08 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  6 01:17:47.535: INFO: coredns-7649fdbb4-fctcq from kube-system started at 2019-10-30 08:16:55 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container coredns ready: true, restart count 0
Nov  6 01:17:47.535: INFO: calico-kube-controllers-55754f75c-kxfjw from kube-system started at 2019-10-30 08:16:57 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov  6 01:17:47.535: INFO: node-exporter-addon-dqnzs from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container node-exporter-addon ready: true, restart count 0
Nov  6 01:17:47.535: INFO: monitoring-agent-njzizt-3-7657c68cd7-hwcqz from cocktail-addon started at 2019-10-30 09:24:28 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container statcollector ready: true, restart count 0
Nov  6 01:17:47.535: INFO: coredns-7649fdbb4-snqxg from kube-system started at 2019-10-30 08:16:56 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container coredns ready: true, restart count 0
Nov  6 01:17:47.535: INFO: dashboard-queue-cocktail-86b7c74d57-8wnfw from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container dashboard-queue ready: true, restart count 0
Nov  6 01:17:47.535: INFO: cloud-metering-cocktail-864ccb89c5-tsgj7 from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container cocktail-metering-api ready: true, restart count 0
Nov  6 01:17:47.535: INFO: prometheus-addon-5754fb587-t8m85 from cocktail-addon started at 2019-10-30 08:19:27 +0000 UTC (2 container statuses recorded)
Nov  6 01:17:47.535: INFO: 	Container configmap-reload ready: true, restart count 0
Nov  6 01:17:47.535: INFO: 	Container prometheus-addon ready: true, restart count 0
Nov  6 01:17:47.535: INFO: 
Logging pods the kubelet thinks is on node apps-114 before test
Nov  6 01:17:47.541: INFO: calico-node-cbzfz from kube-system started at 2019-10-30 10:45:39 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.541: INFO: 	Container calico-node ready: true, restart count 0
Nov  6 01:17:47.541: INFO: kube-proxy-nnw7s from kube-system started at 2019-10-30 10:45:39 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.541: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  6 01:17:47.541: INFO: node-exporter-addon-mkrw7 from cocktail-addon started at 2019-10-30 10:48:31 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.541: INFO: 	Container node-exporter-addon ready: true, restart count 0
Nov  6 01:17:47.541: INFO: disk-usage-exporter-addon-6rfvv from cocktail-addon started at 2019-10-30 10:48:31 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.541: INFO: 	Container disk-usage-exporter-addon ready: true, restart count 0
Nov  6 01:17:47.541: INFO: sonobuoy from sonobuoy started at 2019-11-06 01:12:56 +0000 UTC (1 container statuses recorded)
Nov  6 01:17:47.541: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  6 01:17:47.541: INFO: sonobuoy-e2e-job-e818bd6c45834cee from sonobuoy started at 2019-11-06 01:13:06 +0000 UTC (2 container statuses recorded)
Nov  6 01:17:47.541: INFO: 	Container e2e ready: true, restart count 0
Nov  6 01:17:47.541: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  6 01:17:47.541: INFO: sonobuoy-systemd-logs-daemon-set-a0ae98b6655c4fa6-gcqdr from sonobuoy started at 2019-11-06 01:13:06 +0000 UTC (2 container statuses recorded)
Nov  6 01:17:47.541: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  6 01:17:47.541: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node apps-113
STEP: verifying the node has the label node apps-114
Nov  6 01:17:47.603: INFO: Pod addon-manager-7c8b9c74f6-9pllx requesting resource cpu=100m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod alertmanager-addon-5967cc89f8-8bdvd requesting resource cpu=60m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod disk-usage-exporter-addon-6rfvv requesting resource cpu=100m on Node apps-114
Nov  6 01:17:47.603: INFO: Pod disk-usage-exporter-addon-t758w requesting resource cpu=100m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod kube-state-metrics-addon-7f48b7868b-jd4jx requesting resource cpu=150m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod monitoring-agent-njzizt-3-7657c68cd7-hwcqz requesting resource cpu=300m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod nfs-client-provisioner-addon-566798455d-q7tw8 requesting resource cpu=20m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod nginx-ingress-addon-controller-7dcb6fc5ff-t4rlv requesting resource cpu=0m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod node-exporter-addon-dqnzs requesting resource cpu=200m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod node-exporter-addon-mkrw7 requesting resource cpu=200m on Node apps-114
Nov  6 01:17:47.603: INFO: Pod prometheus-addon-5754fb587-t8m85 requesting resource cpu=520m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod api-cmdb-cocktail-7796b94f65-5x9kt requesting resource cpu=500m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod api-server-cocktail-88f64f646-x67ld requesting resource cpu=1500m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod batch-server-cocktail-55d57dff79-4qm6j requesting resource cpu=100m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod build-api-cocktail-6d6f8dfbbc-jhq8w requesting resource cpu=100m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod build-queue-cocktail-758498c967-slzk4 requesting resource cpu=250m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod cloud-metering-cocktail-864ccb89c5-tsgj7 requesting resource cpu=100m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod cloud-metering-collector-cocktail-68bfd6cc67-q8tjh requesting resource cpu=300m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod cluster-health-checker-cocktail-58f4545c48-l9ncr requesting resource cpu=50m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod dashboard-cocktail-575c77f5bd-7xpz9 requesting resource cpu=300m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod dashboard-proxy-cocktail-5cfd96484-9qjjr requesting resource cpu=200m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod dashboard-queue-cocktail-86b7c74d57-8wnfw requesting resource cpu=100m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod dashboard-session-cocktail-66658bd785-zl4lk requesting resource cpu=100m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod monitoring-cocktail-59d5ffc9fd-szdwh requesting resource cpu=150m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod monitoring-collector-cocktail-5647c8b855-54jph requesting resource cpu=200m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod monitoring-db-cocktail-547dff6c7f-msc7q requesting resource cpu=1000m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod calico-kube-controllers-55754f75c-kxfjw requesting resource cpu=0m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod calico-node-cbzfz requesting resource cpu=250m on Node apps-114
Nov  6 01:17:47.603: INFO: Pod calico-node-jv7rf requesting resource cpu=250m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod coredns-7649fdbb4-fctcq requesting resource cpu=100m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod coredns-7649fdbb4-snqxg requesting resource cpu=100m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod kube-apiserver-apps-113 requesting resource cpu=250m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod kube-controller-manager-apps-113 requesting resource cpu=200m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod kube-proxy-hdklg requesting resource cpu=0m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod kube-proxy-nnw7s requesting resource cpu=0m on Node apps-114
Nov  6 01:17:47.603: INFO: Pod kube-scheduler-apps-113 requesting resource cpu=100m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod metrics-server-5d9d98df9f-qsw2s requesting resource cpu=100m on Node apps-113
Nov  6 01:17:47.603: INFO: Pod sonobuoy requesting resource cpu=0m on Node apps-114
Nov  6 01:17:47.603: INFO: Pod sonobuoy-e2e-job-e818bd6c45834cee requesting resource cpu=0m on Node apps-114
Nov  6 01:17:47.603: INFO: Pod sonobuoy-systemd-logs-daemon-set-a0ae98b6655c4fa6-gcqdr requesting resource cpu=0m on Node apps-114
Nov  6 01:17:47.603: INFO: Pod sonobuoy-systemd-logs-daemon-set-a0ae98b6655c4fa6-tpjhf requesting resource cpu=0m on Node apps-113
STEP: Starting Pods to consume most of the cluster CPU.
Nov  6 01:17:47.603: INFO: Creating a pod which consumes cpu=350m on Node apps-113
Nov  6 01:17:47.607: INFO: Creating a pod which consumes cpu=5215m on Node apps-114
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-14c50da9-496b-48be-82e9-a2b7edfa9cef.15d46df4b3fbbc3d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8838/filler-pod-14c50da9-496b-48be-82e9-a2b7edfa9cef to apps-113]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-14c50da9-496b-48be-82e9-a2b7edfa9cef.15d46df508637a77], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-14c50da9-496b-48be-82e9-a2b7edfa9cef.15d46df580035084], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-14c50da9-496b-48be-82e9-a2b7edfa9cef.15d46df58d6248ac], Reason = [Created], Message = [Created container filler-pod-14c50da9-496b-48be-82e9-a2b7edfa9cef]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-14c50da9-496b-48be-82e9-a2b7edfa9cef.15d46df5acc1bd38], Reason = [Started], Message = [Started container filler-pod-14c50da9-496b-48be-82e9-a2b7edfa9cef]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9495ad0b-7d30-4b5e-93c6-b27aff462628.15d46df4b54cc9d8], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8838/filler-pod-9495ad0b-7d30-4b5e-93c6-b27aff462628 to apps-114]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9495ad0b-7d30-4b5e-93c6-b27aff462628.15d46df5018ab2c5], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9495ad0b-7d30-4b5e-93c6-b27aff462628.15d46df573710923], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9495ad0b-7d30-4b5e-93c6-b27aff462628.15d46df57acf65b1], Reason = [Created], Message = [Created container filler-pod-9495ad0b-7d30-4b5e-93c6-b27aff462628]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9495ad0b-7d30-4b5e-93c6-b27aff462628.15d46df58ec34380], Reason = [Started], Message = [Started container filler-pod-9495ad0b-7d30-4b5e-93c6-b27aff462628]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15d46df61b8554c2], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node apps-113
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node apps-114
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:17:54.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8838" for this suite.
Nov  6 01:18:00.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:18:00.775: INFO: namespace sched-pred-8838 deletion completed in 6.081988339s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:13.304 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:18:00.775: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-a1713c30-6787-40e7-ab80-167dfb137610
STEP: Creating a pod to test consume secrets
Nov  6 01:18:00.836: INFO: Waiting up to 5m0s for pod "pod-secrets-0e9d5186-1130-4526-b065-706a20d05c8c" in namespace "secrets-7640" to be "success or failure"
Nov  6 01:18:00.842: INFO: Pod "pod-secrets-0e9d5186-1130-4526-b065-706a20d05c8c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.42212ms
Nov  6 01:18:02.844: INFO: Pod "pod-secrets-0e9d5186-1130-4526-b065-706a20d05c8c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007843805s
Nov  6 01:18:04.847: INFO: Pod "pod-secrets-0e9d5186-1130-4526-b065-706a20d05c8c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010370094s
STEP: Saw pod success
Nov  6 01:18:04.847: INFO: Pod "pod-secrets-0e9d5186-1130-4526-b065-706a20d05c8c" satisfied condition "success or failure"
Nov  6 01:18:04.848: INFO: Trying to get logs from node apps-114 pod pod-secrets-0e9d5186-1130-4526-b065-706a20d05c8c container secret-volume-test: <nil>
STEP: delete the pod
Nov  6 01:18:04.869: INFO: Waiting for pod pod-secrets-0e9d5186-1130-4526-b065-706a20d05c8c to disappear
Nov  6 01:18:04.876: INFO: Pod pod-secrets-0e9d5186-1130-4526-b065-706a20d05c8c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:18:04.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7640" for this suite.
Nov  6 01:18:10.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:18:10.932: INFO: namespace secrets-7640 deletion completed in 6.053685101s

• [SLOW TEST:10.157 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:18:10.932: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Nov  6 01:18:11.725: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Nov  6 01:18:13.732: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708599891, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708599891, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708599891, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708599891, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  6 01:18:16.787: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 01:18:16.789: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:18:18.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-8555" for this suite.
Nov  6 01:18:24.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:18:24.219: INFO: namespace crd-webhook-8555 deletion completed in 6.072629514s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:13.294 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:18:24.226: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov  6 01:18:24.329: INFO: Number of nodes with available pods: 0
Nov  6 01:18:24.329: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:18:25.364: INFO: Number of nodes with available pods: 0
Nov  6 01:18:25.364: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:18:26.398: INFO: Number of nodes with available pods: 0
Nov  6 01:18:26.398: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:18:27.338: INFO: Number of nodes with available pods: 2
Nov  6 01:18:27.338: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Nov  6 01:18:27.364: INFO: Number of nodes with available pods: 1
Nov  6 01:18:27.364: INFO: Node apps-114 is running more than one daemon pod
Nov  6 01:18:28.369: INFO: Number of nodes with available pods: 1
Nov  6 01:18:28.369: INFO: Node apps-114 is running more than one daemon pod
Nov  6 01:18:29.422: INFO: Number of nodes with available pods: 1
Nov  6 01:18:29.422: INFO: Node apps-114 is running more than one daemon pod
Nov  6 01:18:30.370: INFO: Number of nodes with available pods: 1
Nov  6 01:18:30.370: INFO: Node apps-114 is running more than one daemon pod
Nov  6 01:18:31.369: INFO: Number of nodes with available pods: 1
Nov  6 01:18:31.369: INFO: Node apps-114 is running more than one daemon pod
Nov  6 01:18:32.370: INFO: Number of nodes with available pods: 1
Nov  6 01:18:32.370: INFO: Node apps-114 is running more than one daemon pod
Nov  6 01:18:33.369: INFO: Number of nodes with available pods: 1
Nov  6 01:18:33.369: INFO: Node apps-114 is running more than one daemon pod
Nov  6 01:18:34.370: INFO: Number of nodes with available pods: 2
Nov  6 01:18:34.370: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8477, will wait for the garbage collector to delete the pods
Nov  6 01:18:34.428: INFO: Deleting DaemonSet.extensions daemon-set took: 4.235012ms
Nov  6 01:18:34.828: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.172302ms
Nov  6 01:18:47.431: INFO: Number of nodes with available pods: 0
Nov  6 01:18:47.431: INFO: Number of running nodes: 0, number of available pods: 0
Nov  6 01:18:47.433: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8477/daemonsets","resourceVersion":"853660"},"items":null}

Nov  6 01:18:47.435: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8477/pods","resourceVersion":"853660"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:18:47.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8477" for this suite.
Nov  6 01:18:53.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:18:53.517: INFO: namespace daemonsets-8477 deletion completed in 6.072566699s

• [SLOW TEST:29.291 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:18:53.517: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  6 01:18:53.564: INFO: Waiting up to 5m0s for pod "downward-api-23c50d5a-3205-4e49-9df7-e90ba559e39d" in namespace "downward-api-3706" to be "success or failure"
Nov  6 01:18:53.581: INFO: Pod "downward-api-23c50d5a-3205-4e49-9df7-e90ba559e39d": Phase="Pending", Reason="", readiness=false. Elapsed: 17.214662ms
Nov  6 01:18:55.584: INFO: Pod "downward-api-23c50d5a-3205-4e49-9df7-e90ba559e39d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019991109s
Nov  6 01:18:57.587: INFO: Pod "downward-api-23c50d5a-3205-4e49-9df7-e90ba559e39d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022709505s
Nov  6 01:18:59.589: INFO: Pod "downward-api-23c50d5a-3205-4e49-9df7-e90ba559e39d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025013222s
Nov  6 01:19:01.592: INFO: Pod "downward-api-23c50d5a-3205-4e49-9df7-e90ba559e39d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.027740665s
STEP: Saw pod success
Nov  6 01:19:01.592: INFO: Pod "downward-api-23c50d5a-3205-4e49-9df7-e90ba559e39d" satisfied condition "success or failure"
Nov  6 01:19:01.593: INFO: Trying to get logs from node apps-114 pod downward-api-23c50d5a-3205-4e49-9df7-e90ba559e39d container dapi-container: <nil>
STEP: delete the pod
Nov  6 01:19:01.613: INFO: Waiting for pod downward-api-23c50d5a-3205-4e49-9df7-e90ba559e39d to disappear
Nov  6 01:19:01.621: INFO: Pod downward-api-23c50d5a-3205-4e49-9df7-e90ba559e39d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:19:01.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3706" for this suite.
Nov  6 01:19:07.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:19:07.679: INFO: namespace downward-api-3706 deletion completed in 6.055987544s

• [SLOW TEST:14.162 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:19:07.679: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-tlkn
STEP: Creating a pod to test atomic-volume-subpath
Nov  6 01:19:07.782: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-tlkn" in namespace "subpath-9281" to be "success or failure"
Nov  6 01:19:07.798: INFO: Pod "pod-subpath-test-configmap-tlkn": Phase="Pending", Reason="", readiness=false. Elapsed: 16.569722ms
Nov  6 01:19:09.801: INFO: Pod "pod-subpath-test-configmap-tlkn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019643308s
Nov  6 01:19:11.804: INFO: Pod "pod-subpath-test-configmap-tlkn": Phase="Running", Reason="", readiness=true. Elapsed: 4.02255112s
Nov  6 01:19:13.807: INFO: Pod "pod-subpath-test-configmap-tlkn": Phase="Running", Reason="", readiness=true. Elapsed: 6.02517619s
Nov  6 01:19:15.810: INFO: Pod "pod-subpath-test-configmap-tlkn": Phase="Running", Reason="", readiness=true. Elapsed: 8.027916547s
Nov  6 01:19:17.812: INFO: Pod "pod-subpath-test-configmap-tlkn": Phase="Running", Reason="", readiness=true. Elapsed: 10.030162514s
Nov  6 01:19:19.815: INFO: Pod "pod-subpath-test-configmap-tlkn": Phase="Running", Reason="", readiness=true. Elapsed: 12.033208013s
Nov  6 01:19:21.818: INFO: Pod "pod-subpath-test-configmap-tlkn": Phase="Running", Reason="", readiness=true. Elapsed: 14.035989833s
Nov  6 01:19:23.820: INFO: Pod "pod-subpath-test-configmap-tlkn": Phase="Running", Reason="", readiness=true. Elapsed: 16.038377865s
Nov  6 01:19:25.823: INFO: Pod "pod-subpath-test-configmap-tlkn": Phase="Running", Reason="", readiness=true. Elapsed: 18.040983607s
Nov  6 01:19:27.825: INFO: Pod "pod-subpath-test-configmap-tlkn": Phase="Running", Reason="", readiness=true. Elapsed: 20.043775765s
Nov  6 01:19:29.828: INFO: Pod "pod-subpath-test-configmap-tlkn": Phase="Running", Reason="", readiness=true. Elapsed: 22.046750315s
Nov  6 01:19:31.831: INFO: Pod "pod-subpath-test-configmap-tlkn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.049284326s
STEP: Saw pod success
Nov  6 01:19:31.831: INFO: Pod "pod-subpath-test-configmap-tlkn" satisfied condition "success or failure"
Nov  6 01:19:31.832: INFO: Trying to get logs from node apps-114 pod pod-subpath-test-configmap-tlkn container test-container-subpath-configmap-tlkn: <nil>
STEP: delete the pod
Nov  6 01:19:31.855: INFO: Waiting for pod pod-subpath-test-configmap-tlkn to disappear
Nov  6 01:19:31.862: INFO: Pod pod-subpath-test-configmap-tlkn no longer exists
STEP: Deleting pod pod-subpath-test-configmap-tlkn
Nov  6 01:19:31.862: INFO: Deleting pod "pod-subpath-test-configmap-tlkn" in namespace "subpath-9281"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:19:31.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9281" for this suite.
Nov  6 01:19:37.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:19:37.920: INFO: namespace subpath-9281 deletion completed in 6.054130382s

• [SLOW TEST:30.241 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:19:37.920: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  6 01:19:37.963: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a92cb62f-89a7-44e3-82a0-fc826255d50f" in namespace "projected-3583" to be "success or failure"
Nov  6 01:19:37.982: INFO: Pod "downwardapi-volume-a92cb62f-89a7-44e3-82a0-fc826255d50f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.227102ms
Nov  6 01:19:39.984: INFO: Pod "downwardapi-volume-a92cb62f-89a7-44e3-82a0-fc826255d50f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02100648s
Nov  6 01:19:41.987: INFO: Pod "downwardapi-volume-a92cb62f-89a7-44e3-82a0-fc826255d50f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023600257s
STEP: Saw pod success
Nov  6 01:19:41.987: INFO: Pod "downwardapi-volume-a92cb62f-89a7-44e3-82a0-fc826255d50f" satisfied condition "success or failure"
Nov  6 01:19:41.989: INFO: Trying to get logs from node apps-114 pod downwardapi-volume-a92cb62f-89a7-44e3-82a0-fc826255d50f container client-container: <nil>
STEP: delete the pod
Nov  6 01:19:42.005: INFO: Waiting for pod downwardapi-volume-a92cb62f-89a7-44e3-82a0-fc826255d50f to disappear
Nov  6 01:19:42.033: INFO: Pod downwardapi-volume-a92cb62f-89a7-44e3-82a0-fc826255d50f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:19:42.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3583" for this suite.
Nov  6 01:19:48.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:19:48.114: INFO: namespace projected-3583 deletion completed in 6.078231922s

• [SLOW TEST:10.194 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:19:48.114: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 01:19:48.200: INFO: (0) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 21.560005ms)
Nov  6 01:19:48.203: INFO: (1) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.742292ms)
Nov  6 01:19:48.206: INFO: (2) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.722588ms)
Nov  6 01:19:48.208: INFO: (3) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.313379ms)
Nov  6 01:19:48.211: INFO: (4) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.434735ms)
Nov  6 01:19:48.213: INFO: (5) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.340281ms)
Nov  6 01:19:48.215: INFO: (6) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.461467ms)
Nov  6 01:19:48.218: INFO: (7) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.217186ms)
Nov  6 01:19:48.220: INFO: (8) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.488841ms)
Nov  6 01:19:48.223: INFO: (9) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.428824ms)
Nov  6 01:19:48.225: INFO: (10) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.543739ms)
Nov  6 01:19:48.228: INFO: (11) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.434182ms)
Nov  6 01:19:48.230: INFO: (12) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.382896ms)
Nov  6 01:19:48.232: INFO: (13) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.301284ms)
Nov  6 01:19:48.235: INFO: (14) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.305507ms)
Nov  6 01:19:48.237: INFO: (15) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.326966ms)
Nov  6 01:19:48.239: INFO: (16) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.315742ms)
Nov  6 01:19:48.242: INFO: (17) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.397978ms)
Nov  6 01:19:48.244: INFO: (18) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.454371ms)
Nov  6 01:19:48.247: INFO: (19) /api/v1/nodes/apps-113:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.325977ms)
[AfterEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:19:48.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4634" for this suite.
Nov  6 01:19:54.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:19:54.347: INFO: namespace proxy-4634 deletion completed in 6.098069801s

• [SLOW TEST:6.233 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:19:54.347: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  6 01:19:54.405: INFO: Waiting up to 5m0s for pod "downwardapi-volume-49979179-4b03-4ebe-a0cb-4c49fcd5b9c6" in namespace "downward-api-7705" to be "success or failure"
Nov  6 01:19:54.450: INFO: Pod "downwardapi-volume-49979179-4b03-4ebe-a0cb-4c49fcd5b9c6": Phase="Pending", Reason="", readiness=false. Elapsed: 44.970256ms
Nov  6 01:19:56.453: INFO: Pod "downwardapi-volume-49979179-4b03-4ebe-a0cb-4c49fcd5b9c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048083609s
Nov  6 01:19:58.456: INFO: Pod "downwardapi-volume-49979179-4b03-4ebe-a0cb-4c49fcd5b9c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051132938s
STEP: Saw pod success
Nov  6 01:19:58.456: INFO: Pod "downwardapi-volume-49979179-4b03-4ebe-a0cb-4c49fcd5b9c6" satisfied condition "success or failure"
Nov  6 01:19:58.458: INFO: Trying to get logs from node apps-114 pod downwardapi-volume-49979179-4b03-4ebe-a0cb-4c49fcd5b9c6 container client-container: <nil>
STEP: delete the pod
Nov  6 01:19:58.475: INFO: Waiting for pod downwardapi-volume-49979179-4b03-4ebe-a0cb-4c49fcd5b9c6 to disappear
Nov  6 01:19:58.478: INFO: Pod downwardapi-volume-49979179-4b03-4ebe-a0cb-4c49fcd5b9c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:19:58.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7705" for this suite.
Nov  6 01:20:04.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:20:04.538: INFO: namespace downward-api-7705 deletion completed in 6.057159014s

• [SLOW TEST:10.191 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:20:04.538: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-7d86d800-5837-40ee-922c-8ce0d6ff3857
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:20:04.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7238" for this suite.
Nov  6 01:20:10.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:20:10.696: INFO: namespace secrets-7238 deletion completed in 6.072435972s

• [SLOW TEST:6.158 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:20:10.696: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov  6 01:20:10.803: INFO: Number of nodes with available pods: 0
Nov  6 01:20:10.803: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:20:11.808: INFO: Number of nodes with available pods: 0
Nov  6 01:20:11.808: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:20:12.808: INFO: Number of nodes with available pods: 0
Nov  6 01:20:12.808: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:20:13.808: INFO: Number of nodes with available pods: 2
Nov  6 01:20:13.808: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Nov  6 01:20:13.837: INFO: Number of nodes with available pods: 2
Nov  6 01:20:13.837: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9185, will wait for the garbage collector to delete the pods
Nov  6 01:20:14.913: INFO: Deleting DaemonSet.extensions daemon-set took: 5.762741ms
Nov  6 01:20:15.313: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.21356ms
Nov  6 01:20:18.115: INFO: Number of nodes with available pods: 0
Nov  6 01:20:18.115: INFO: Number of running nodes: 0, number of available pods: 0
Nov  6 01:20:18.117: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9185/daemonsets","resourceVersion":"854036"},"items":null}

Nov  6 01:20:18.118: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9185/pods","resourceVersion":"854036"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:20:18.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9185" for this suite.
Nov  6 01:20:24.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:20:24.187: INFO: namespace daemonsets-9185 deletion completed in 6.060776491s

• [SLOW TEST:13.491 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:20:24.187: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Nov  6 01:20:24.331: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-720122187 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:20:24.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3653" for this suite.
Nov  6 01:20:30.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:20:30.481: INFO: namespace kubectl-3653 deletion completed in 6.065022019s

• [SLOW TEST:6.294 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:20:30.481: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Nov  6 01:20:31.045: INFO: created pod pod-service-account-defaultsa
Nov  6 01:20:31.045: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov  6 01:20:31.064: INFO: created pod pod-service-account-mountsa
Nov  6 01:20:31.064: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov  6 01:20:31.071: INFO: created pod pod-service-account-nomountsa
Nov  6 01:20:31.071: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov  6 01:20:31.089: INFO: created pod pod-service-account-defaultsa-mountspec
Nov  6 01:20:31.089: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov  6 01:20:31.096: INFO: created pod pod-service-account-mountsa-mountspec
Nov  6 01:20:31.096: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov  6 01:20:31.146: INFO: created pod pod-service-account-nomountsa-mountspec
Nov  6 01:20:31.146: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov  6 01:20:31.155: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov  6 01:20:31.155: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov  6 01:20:31.172: INFO: created pod pod-service-account-mountsa-nomountspec
Nov  6 01:20:31.172: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov  6 01:20:31.179: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov  6 01:20:31.179: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:20:31.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4425" for this suite.
Nov  6 01:20:59.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:20:59.295: INFO: namespace svcaccounts-4425 deletion completed in 28.097113791s

• [SLOW TEST:28.814 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:20:59.296: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-4966/secret-test-ecdb3271-12b5-4bac-9db4-84ab142c96f5
STEP: Creating a pod to test consume secrets
Nov  6 01:20:59.389: INFO: Waiting up to 5m0s for pod "pod-configmaps-d24524a1-65a1-4dce-b60c-96dcf447bd67" in namespace "secrets-4966" to be "success or failure"
Nov  6 01:20:59.407: INFO: Pod "pod-configmaps-d24524a1-65a1-4dce-b60c-96dcf447bd67": Phase="Pending", Reason="", readiness=false. Elapsed: 17.701543ms
Nov  6 01:21:01.422: INFO: Pod "pod-configmaps-d24524a1-65a1-4dce-b60c-96dcf447bd67": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033107014s
Nov  6 01:21:03.425: INFO: Pod "pod-configmaps-d24524a1-65a1-4dce-b60c-96dcf447bd67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036067281s
STEP: Saw pod success
Nov  6 01:21:03.425: INFO: Pod "pod-configmaps-d24524a1-65a1-4dce-b60c-96dcf447bd67" satisfied condition "success or failure"
Nov  6 01:21:03.427: INFO: Trying to get logs from node apps-114 pod pod-configmaps-d24524a1-65a1-4dce-b60c-96dcf447bd67 container env-test: <nil>
STEP: delete the pod
Nov  6 01:21:03.458: INFO: Waiting for pod pod-configmaps-d24524a1-65a1-4dce-b60c-96dcf447bd67 to disappear
Nov  6 01:21:03.462: INFO: Pod pod-configmaps-d24524a1-65a1-4dce-b60c-96dcf447bd67 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:21:03.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4966" for this suite.
Nov  6 01:21:09.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:21:09.520: INFO: namespace secrets-4966 deletion completed in 6.054919058s

• [SLOW TEST:10.224 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:21:09.520: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-95551afd-7756-42c5-bcbd-114fa1e514e5
STEP: Creating secret with name secret-projected-all-test-volume-7771b1d3-ebcc-46ec-8f50-e607903a4172
STEP: Creating a pod to test Check all projections for projected volume plugin
Nov  6 01:21:09.607: INFO: Waiting up to 5m0s for pod "projected-volume-e1624432-a0d4-45b3-82a2-07cadfd1eb94" in namespace "projected-5346" to be "success or failure"
Nov  6 01:21:09.632: INFO: Pod "projected-volume-e1624432-a0d4-45b3-82a2-07cadfd1eb94": Phase="Pending", Reason="", readiness=false. Elapsed: 25.458048ms
Nov  6 01:21:11.635: INFO: Pod "projected-volume-e1624432-a0d4-45b3-82a2-07cadfd1eb94": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028064699s
Nov  6 01:21:13.638: INFO: Pod "projected-volume-e1624432-a0d4-45b3-82a2-07cadfd1eb94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030918907s
STEP: Saw pod success
Nov  6 01:21:13.638: INFO: Pod "projected-volume-e1624432-a0d4-45b3-82a2-07cadfd1eb94" satisfied condition "success or failure"
Nov  6 01:21:13.655: INFO: Trying to get logs from node apps-114 pod projected-volume-e1624432-a0d4-45b3-82a2-07cadfd1eb94 container projected-all-volume-test: <nil>
STEP: delete the pod
Nov  6 01:21:13.680: INFO: Waiting for pod projected-volume-e1624432-a0d4-45b3-82a2-07cadfd1eb94 to disappear
Nov  6 01:21:13.688: INFO: Pod projected-volume-e1624432-a0d4-45b3-82a2-07cadfd1eb94 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:21:13.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5346" for this suite.
Nov  6 01:21:19.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:21:19.748: INFO: namespace projected-5346 deletion completed in 6.057323545s

• [SLOW TEST:10.228 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:21:19.748: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Nov  6 01:21:19.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 create -f - --namespace=kubectl-3301'
Nov  6 01:21:21.951: INFO: stderr: ""
Nov  6 01:21:21.951: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  6 01:21:21.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3301'
Nov  6 01:21:22.032: INFO: stderr: ""
Nov  6 01:21:22.032: INFO: stdout: ""
STEP: Replicas for name=update-demo: expected=2 actual=0
Nov  6 01:21:27.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3301'
Nov  6 01:21:27.112: INFO: stderr: ""
Nov  6 01:21:27.112: INFO: stdout: "update-demo-nautilus-d7n6g update-demo-nautilus-ptqbw "
Nov  6 01:21:27.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-d7n6g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3301'
Nov  6 01:21:27.195: INFO: stderr: ""
Nov  6 01:21:27.195: INFO: stdout: ""
Nov  6 01:21:27.195: INFO: update-demo-nautilus-d7n6g is created but not running
Nov  6 01:21:32.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3301'
Nov  6 01:21:32.280: INFO: stderr: ""
Nov  6 01:21:32.280: INFO: stdout: "update-demo-nautilus-d7n6g update-demo-nautilus-ptqbw "
Nov  6 01:21:32.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-d7n6g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3301'
Nov  6 01:21:32.361: INFO: stderr: ""
Nov  6 01:21:32.361: INFO: stdout: "true"
Nov  6 01:21:32.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-d7n6g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3301'
Nov  6 01:21:32.442: INFO: stderr: ""
Nov  6 01:21:32.442: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  6 01:21:32.442: INFO: validating pod update-demo-nautilus-d7n6g
Nov  6 01:21:32.446: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  6 01:21:32.446: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  6 01:21:32.446: INFO: update-demo-nautilus-d7n6g is verified up and running
Nov  6 01:21:32.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-ptqbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3301'
Nov  6 01:21:32.524: INFO: stderr: ""
Nov  6 01:21:32.524: INFO: stdout: "true"
Nov  6 01:21:32.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-ptqbw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3301'
Nov  6 01:21:32.607: INFO: stderr: ""
Nov  6 01:21:32.607: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  6 01:21:32.607: INFO: validating pod update-demo-nautilus-ptqbw
Nov  6 01:21:32.611: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  6 01:21:32.611: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  6 01:21:32.611: INFO: update-demo-nautilus-ptqbw is verified up and running
STEP: rolling-update to new replication controller
Nov  6 01:21:32.613: INFO: scanned /root for discovery docs: <nil>
Nov  6 01:21:32.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-3301'
Nov  6 01:21:58.191: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov  6 01:21:58.191: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  6 01:21:58.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3301'
Nov  6 01:21:58.274: INFO: stderr: ""
Nov  6 01:21:58.274: INFO: stdout: "update-demo-kitten-d8bzg update-demo-kitten-gvtkl "
Nov  6 01:21:58.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-kitten-d8bzg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3301'
Nov  6 01:21:58.357: INFO: stderr: ""
Nov  6 01:21:58.357: INFO: stdout: "true"
Nov  6 01:21:58.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-kitten-d8bzg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3301'
Nov  6 01:21:58.435: INFO: stderr: ""
Nov  6 01:21:58.435: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov  6 01:21:58.435: INFO: validating pod update-demo-kitten-d8bzg
Nov  6 01:21:58.439: INFO: got data: {
  "image": "kitten.jpg"
}

Nov  6 01:21:58.439: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov  6 01:21:58.439: INFO: update-demo-kitten-d8bzg is verified up and running
Nov  6 01:21:58.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-kitten-gvtkl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3301'
Nov  6 01:21:58.525: INFO: stderr: ""
Nov  6 01:21:58.525: INFO: stdout: "true"
Nov  6 01:21:58.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-kitten-gvtkl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3301'
Nov  6 01:21:58.623: INFO: stderr: ""
Nov  6 01:21:58.623: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov  6 01:21:58.623: INFO: validating pod update-demo-kitten-gvtkl
Nov  6 01:21:58.626: INFO: got data: {
  "image": "kitten.jpg"
}

Nov  6 01:21:58.626: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov  6 01:21:58.627: INFO: update-demo-kitten-gvtkl is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:21:58.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3301" for this suite.
Nov  6 01:22:26.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:22:26.703: INFO: namespace kubectl-3301 deletion completed in 28.073461485s

• [SLOW TEST:66.955 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:22:26.703: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  6 01:22:26.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-6882'
Nov  6 01:22:26.826: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  6 01:22:26.826: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Nov  6 01:22:28.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 delete deployment e2e-test-httpd-deployment --namespace=kubectl-6882'
Nov  6 01:22:28.923: INFO: stderr: ""
Nov  6 01:22:28.923: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:22:28.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6882" for this suite.
Nov  6 01:22:56.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:22:56.980: INFO: namespace kubectl-6882 deletion completed in 28.054553813s

• [SLOW TEST:30.277 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:22:56.980: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Nov  6 01:22:57.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 create -f - --namespace=kubectl-5570'
Nov  6 01:22:57.286: INFO: stderr: ""
Nov  6 01:22:57.286: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  6 01:22:58.289: INFO: Selector matched 1 pods for map[app:redis]
Nov  6 01:22:58.289: INFO: Found 0 / 1
Nov  6 01:22:59.297: INFO: Selector matched 1 pods for map[app:redis]
Nov  6 01:22:59.297: INFO: Found 0 / 1
Nov  6 01:23:00.289: INFO: Selector matched 1 pods for map[app:redis]
Nov  6 01:23:00.289: INFO: Found 1 / 1
Nov  6 01:23:00.289: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Nov  6 01:23:00.291: INFO: Selector matched 1 pods for map[app:redis]
Nov  6 01:23:00.291: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  6 01:23:00.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 patch pod redis-master-96brz --namespace=kubectl-5570 -p {"metadata":{"annotations":{"x":"y"}}}'
Nov  6 01:23:00.376: INFO: stderr: ""
Nov  6 01:23:00.376: INFO: stdout: "pod/redis-master-96brz patched\n"
STEP: checking annotations
Nov  6 01:23:00.381: INFO: Selector matched 1 pods for map[app:redis]
Nov  6 01:23:00.381: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:23:00.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5570" for this suite.
Nov  6 01:23:28.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:23:28.462: INFO: namespace kubectl-5570 deletion completed in 28.078902443s

• [SLOW TEST:31.482 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:23:28.463: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-ec75aaf5-2ca9-4fcf-8104-af5dd4059940 in namespace container-probe-5075
Nov  6 01:23:34.540: INFO: Started pod test-webserver-ec75aaf5-2ca9-4fcf-8104-af5dd4059940 in namespace container-probe-5075
STEP: checking the pod's current state and verifying that restartCount is present
Nov  6 01:23:34.542: INFO: Initial restart count of pod test-webserver-ec75aaf5-2ca9-4fcf-8104-af5dd4059940 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:27:35.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5075" for this suite.
Nov  6 01:27:41.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:27:41.098: INFO: namespace container-probe-5075 deletion completed in 6.064607988s

• [SLOW TEST:252.635 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:27:41.098: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3640.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-3640.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3640.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-3640.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3640.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3640.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-3640.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3640.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-3640.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3640.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  6 01:28:01.212: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:01.215: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:01.217: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:01.219: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:01.226: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:01.228: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:01.230: INFO: Unable to read jessie_udp@dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:01.232: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:01.236: INFO: Lookups using dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local wheezy_udp@dns-test-service-2.dns-3640.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-3640.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local jessie_udp@dns-test-service-2.dns-3640.svc.cluster.local jessie_tcp@dns-test-service-2.dns-3640.svc.cluster.local]

Nov  6 01:28:06.240: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:06.242: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:06.244: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:06.246: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:06.253: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:06.255: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:06.257: INFO: Unable to read jessie_udp@dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:06.259: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:06.263: INFO: Lookups using dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local wheezy_udp@dns-test-service-2.dns-3640.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-3640.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local jessie_udp@dns-test-service-2.dns-3640.svc.cluster.local jessie_tcp@dns-test-service-2.dns-3640.svc.cluster.local]

Nov  6 01:28:11.239: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:11.242: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:11.244: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:11.246: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:11.253: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:11.255: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:11.257: INFO: Unable to read jessie_udp@dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:11.259: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:11.263: INFO: Lookups using dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local wheezy_udp@dns-test-service-2.dns-3640.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-3640.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local jessie_udp@dns-test-service-2.dns-3640.svc.cluster.local jessie_tcp@dns-test-service-2.dns-3640.svc.cluster.local]

Nov  6 01:28:16.239: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:16.241: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:16.244: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:16.246: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:16.252: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:16.254: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:16.256: INFO: Unable to read jessie_udp@dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:16.258: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-3640.svc.cluster.local from pod dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b: the server could not find the requested resource (get pods dns-test-7a718c92-056c-423c-9c29-685955fbd59b)
Nov  6 01:28:16.262: INFO: Lookups using dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local wheezy_udp@dns-test-service-2.dns-3640.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-3640.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3640.svc.cluster.local jessie_udp@dns-test-service-2.dns-3640.svc.cluster.local jessie_tcp@dns-test-service-2.dns-3640.svc.cluster.local]

Nov  6 01:28:21.262: INFO: DNS probes using dns-3640/dns-test-7a718c92-056c-423c-9c29-685955fbd59b succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:28:21.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3640" for this suite.
Nov  6 01:28:27.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:28:27.438: INFO: namespace dns-3640 deletion completed in 6.063835642s

• [SLOW TEST:46.340 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:28:27.439: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:28:32.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5493" for this suite.
Nov  6 01:28:38.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:28:38.690: INFO: namespace watch-5493 deletion completed in 6.140777635s

• [SLOW TEST:11.251 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:28:38.690: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  6 01:28:41.775: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:28:41.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6991" for this suite.
Nov  6 01:28:47.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:28:47.855: INFO: namespace container-runtime-6991 deletion completed in 6.054236139s

• [SLOW TEST:9.165 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:28:47.856: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-320b6d51-4b05-44bb-917a-a33f25535416
STEP: Creating a pod to test consume configMaps
Nov  6 01:28:47.958: INFO: Waiting up to 5m0s for pod "pod-configmaps-badd4a05-d781-4a3c-ab70-603f5343cebe" in namespace "configmap-8047" to be "success or failure"
Nov  6 01:28:48.007: INFO: Pod "pod-configmaps-badd4a05-d781-4a3c-ab70-603f5343cebe": Phase="Pending", Reason="", readiness=false. Elapsed: 48.707213ms
Nov  6 01:28:50.010: INFO: Pod "pod-configmaps-badd4a05-d781-4a3c-ab70-603f5343cebe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051768722s
Nov  6 01:28:52.013: INFO: Pod "pod-configmaps-badd4a05-d781-4a3c-ab70-603f5343cebe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054477232s
STEP: Saw pod success
Nov  6 01:28:52.013: INFO: Pod "pod-configmaps-badd4a05-d781-4a3c-ab70-603f5343cebe" satisfied condition "success or failure"
Nov  6 01:28:52.014: INFO: Trying to get logs from node apps-114 pod pod-configmaps-badd4a05-d781-4a3c-ab70-603f5343cebe container configmap-volume-test: <nil>
STEP: delete the pod
Nov  6 01:28:52.040: INFO: Waiting for pod pod-configmaps-badd4a05-d781-4a3c-ab70-603f5343cebe to disappear
Nov  6 01:28:52.055: INFO: Pod pod-configmaps-badd4a05-d781-4a3c-ab70-603f5343cebe no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:28:52.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8047" for this suite.
Nov  6 01:28:58.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:28:58.120: INFO: namespace configmap-8047 deletion completed in 6.062353902s

• [SLOW TEST:10.264 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:28:58.120: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov  6 01:28:58.164: INFO: Waiting up to 5m0s for pod "pod-35ebb968-5614-455d-baa5-d18fbdc4a804" in namespace "emptydir-7348" to be "success or failure"
Nov  6 01:28:58.174: INFO: Pod "pod-35ebb968-5614-455d-baa5-d18fbdc4a804": Phase="Pending", Reason="", readiness=false. Elapsed: 9.282744ms
Nov  6 01:29:00.176: INFO: Pod "pod-35ebb968-5614-455d-baa5-d18fbdc4a804": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011944326s
Nov  6 01:29:02.179: INFO: Pod "pod-35ebb968-5614-455d-baa5-d18fbdc4a804": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014788173s
STEP: Saw pod success
Nov  6 01:29:02.179: INFO: Pod "pod-35ebb968-5614-455d-baa5-d18fbdc4a804" satisfied condition "success or failure"
Nov  6 01:29:02.181: INFO: Trying to get logs from node apps-114 pod pod-35ebb968-5614-455d-baa5-d18fbdc4a804 container test-container: <nil>
STEP: delete the pod
Nov  6 01:29:02.200: INFO: Waiting for pod pod-35ebb968-5614-455d-baa5-d18fbdc4a804 to disappear
Nov  6 01:29:02.207: INFO: Pod pod-35ebb968-5614-455d-baa5-d18fbdc4a804 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:29:02.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7348" for this suite.
Nov  6 01:29:08.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:29:08.267: INFO: namespace emptydir-7348 deletion completed in 6.057542197s

• [SLOW TEST:10.147 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:29:08.267: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov  6 01:29:08.317: INFO: Waiting up to 5m0s for pod "pod-00903a25-9d45-4cfa-b603-5c6de701400c" in namespace "emptydir-2046" to be "success or failure"
Nov  6 01:29:08.330: INFO: Pod "pod-00903a25-9d45-4cfa-b603-5c6de701400c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.797397ms
Nov  6 01:29:10.333: INFO: Pod "pod-00903a25-9d45-4cfa-b603-5c6de701400c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015636185s
Nov  6 01:29:12.335: INFO: Pod "pod-00903a25-9d45-4cfa-b603-5c6de701400c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01796892s
Nov  6 01:29:14.337: INFO: Pod "pod-00903a25-9d45-4cfa-b603-5c6de701400c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020410137s
STEP: Saw pod success
Nov  6 01:29:14.337: INFO: Pod "pod-00903a25-9d45-4cfa-b603-5c6de701400c" satisfied condition "success or failure"
Nov  6 01:29:14.339: INFO: Trying to get logs from node apps-114 pod pod-00903a25-9d45-4cfa-b603-5c6de701400c container test-container: <nil>
STEP: delete the pod
Nov  6 01:29:14.365: INFO: Waiting for pod pod-00903a25-9d45-4cfa-b603-5c6de701400c to disappear
Nov  6 01:29:14.390: INFO: Pod pod-00903a25-9d45-4cfa-b603-5c6de701400c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:29:14.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2046" for this suite.
Nov  6 01:29:20.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:29:20.460: INFO: namespace emptydir-2046 deletion completed in 6.067321242s

• [SLOW TEST:12.193 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:29:20.461: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 01:29:20.509: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-616dc90a-7bcc-4981-96b1-83a792c3352c" in namespace "security-context-test-4197" to be "success or failure"
Nov  6 01:29:20.515: INFO: Pod "busybox-privileged-false-616dc90a-7bcc-4981-96b1-83a792c3352c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.51781ms
Nov  6 01:29:22.518: INFO: Pod "busybox-privileged-false-616dc90a-7bcc-4981-96b1-83a792c3352c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008997989s
Nov  6 01:29:24.521: INFO: Pod "busybox-privileged-false-616dc90a-7bcc-4981-96b1-83a792c3352c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012067845s
Nov  6 01:29:24.521: INFO: Pod "busybox-privileged-false-616dc90a-7bcc-4981-96b1-83a792c3352c" satisfied condition "success or failure"
Nov  6 01:29:24.526: INFO: Got logs for pod "busybox-privileged-false-616dc90a-7bcc-4981-96b1-83a792c3352c": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:29:24.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4197" for this suite.
Nov  6 01:29:30.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:29:30.609: INFO: namespace security-context-test-4197 deletion completed in 6.079898625s

• [SLOW TEST:10.148 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:29:30.609: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-5db82455-cbb0-4c10-9891-7122726ba286
STEP: Creating a pod to test consume configMaps
Nov  6 01:29:30.691: INFO: Waiting up to 5m0s for pod "pod-configmaps-73a211fe-5a1d-4614-9a0b-02176ae06126" in namespace "configmap-4097" to be "success or failure"
Nov  6 01:29:30.706: INFO: Pod "pod-configmaps-73a211fe-5a1d-4614-9a0b-02176ae06126": Phase="Pending", Reason="", readiness=false. Elapsed: 14.710947ms
Nov  6 01:29:32.708: INFO: Pod "pod-configmaps-73a211fe-5a1d-4614-9a0b-02176ae06126": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01707615s
Nov  6 01:29:34.711: INFO: Pod "pod-configmaps-73a211fe-5a1d-4614-9a0b-02176ae06126": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019839172s
STEP: Saw pod success
Nov  6 01:29:34.711: INFO: Pod "pod-configmaps-73a211fe-5a1d-4614-9a0b-02176ae06126" satisfied condition "success or failure"
Nov  6 01:29:34.713: INFO: Trying to get logs from node apps-114 pod pod-configmaps-73a211fe-5a1d-4614-9a0b-02176ae06126 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  6 01:29:34.740: INFO: Waiting for pod pod-configmaps-73a211fe-5a1d-4614-9a0b-02176ae06126 to disappear
Nov  6 01:29:34.757: INFO: Pod pod-configmaps-73a211fe-5a1d-4614-9a0b-02176ae06126 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:29:34.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4097" for this suite.
Nov  6 01:29:40.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:29:40.862: INFO: namespace configmap-4097 deletion completed in 6.103010262s

• [SLOW TEST:10.253 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:29:40.863: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-fhlj
STEP: Creating a pod to test atomic-volume-subpath
Nov  6 01:29:40.958: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-fhlj" in namespace "subpath-8687" to be "success or failure"
Nov  6 01:29:40.973: INFO: Pod "pod-subpath-test-configmap-fhlj": Phase="Pending", Reason="", readiness=false. Elapsed: 15.459073ms
Nov  6 01:29:42.976: INFO: Pod "pod-subpath-test-configmap-fhlj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017733137s
Nov  6 01:29:44.979: INFO: Pod "pod-subpath-test-configmap-fhlj": Phase="Running", Reason="", readiness=true. Elapsed: 4.020770091s
Nov  6 01:29:46.981: INFO: Pod "pod-subpath-test-configmap-fhlj": Phase="Running", Reason="", readiness=true. Elapsed: 6.023454725s
Nov  6 01:29:48.984: INFO: Pod "pod-subpath-test-configmap-fhlj": Phase="Running", Reason="", readiness=true. Elapsed: 8.026004415s
Nov  6 01:29:50.987: INFO: Pod "pod-subpath-test-configmap-fhlj": Phase="Running", Reason="", readiness=true. Elapsed: 10.028618016s
Nov  6 01:29:52.989: INFO: Pod "pod-subpath-test-configmap-fhlj": Phase="Running", Reason="", readiness=true. Elapsed: 12.031150011s
Nov  6 01:29:54.992: INFO: Pod "pod-subpath-test-configmap-fhlj": Phase="Running", Reason="", readiness=true. Elapsed: 14.033779006s
Nov  6 01:29:56.994: INFO: Pod "pod-subpath-test-configmap-fhlj": Phase="Running", Reason="", readiness=true. Elapsed: 16.03635177s
Nov  6 01:29:58.997: INFO: Pod "pod-subpath-test-configmap-fhlj": Phase="Running", Reason="", readiness=true. Elapsed: 18.039060902s
Nov  6 01:30:01.000: INFO: Pod "pod-subpath-test-configmap-fhlj": Phase="Running", Reason="", readiness=true. Elapsed: 20.041688175s
Nov  6 01:30:03.002: INFO: Pod "pod-subpath-test-configmap-fhlj": Phase="Running", Reason="", readiness=true. Elapsed: 22.044083571s
Nov  6 01:30:05.005: INFO: Pod "pod-subpath-test-configmap-fhlj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.046870089s
STEP: Saw pod success
Nov  6 01:30:05.005: INFO: Pod "pod-subpath-test-configmap-fhlj" satisfied condition "success or failure"
Nov  6 01:30:05.006: INFO: Trying to get logs from node apps-114 pod pod-subpath-test-configmap-fhlj container test-container-subpath-configmap-fhlj: <nil>
STEP: delete the pod
Nov  6 01:30:05.026: INFO: Waiting for pod pod-subpath-test-configmap-fhlj to disappear
Nov  6 01:30:05.033: INFO: Pod pod-subpath-test-configmap-fhlj no longer exists
STEP: Deleting pod pod-subpath-test-configmap-fhlj
Nov  6 01:30:05.033: INFO: Deleting pod "pod-subpath-test-configmap-fhlj" in namespace "subpath-8687"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:30:05.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8687" for this suite.
Nov  6 01:30:11.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:30:11.099: INFO: namespace subpath-8687 deletion completed in 6.061899453s

• [SLOW TEST:30.237 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:30:11.100: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 01:30:11.187: INFO: (0) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.584608ms)
Nov  6 01:30:11.190: INFO: (1) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.00157ms)
Nov  6 01:30:11.193: INFO: (2) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.564977ms)
Nov  6 01:30:11.195: INFO: (3) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.49584ms)
Nov  6 01:30:11.198: INFO: (4) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.526549ms)
Nov  6 01:30:11.200: INFO: (5) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.544983ms)
Nov  6 01:30:11.203: INFO: (6) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.355943ms)
Nov  6 01:30:11.205: INFO: (7) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.532553ms)
Nov  6 01:30:11.208: INFO: (8) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.450411ms)
Nov  6 01:30:11.211: INFO: (9) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.732465ms)
Nov  6 01:30:11.213: INFO: (10) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.615456ms)
Nov  6 01:30:11.216: INFO: (11) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.488804ms)
Nov  6 01:30:11.218: INFO: (12) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.445928ms)
Nov  6 01:30:11.221: INFO: (13) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.579273ms)
Nov  6 01:30:11.223: INFO: (14) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.484451ms)
Nov  6 01:30:11.226: INFO: (15) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.431223ms)
Nov  6 01:30:11.228: INFO: (16) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.267912ms)
Nov  6 01:30:11.230: INFO: (17) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.352409ms)
Nov  6 01:30:11.233: INFO: (18) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.352599ms)
Nov  6 01:30:11.235: INFO: (19) /api/v1/nodes/apps-113/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.473089ms)
[AfterEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:30:11.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2571" for this suite.
Nov  6 01:30:17.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:30:17.330: INFO: namespace proxy-2571 deletion completed in 6.092667956s

• [SLOW TEST:6.231 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:30:17.330: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-1345, will wait for the garbage collector to delete the pods
Nov  6 01:30:21.515: INFO: Deleting Job.batch foo took: 25.200029ms
Nov  6 01:30:21.916: INFO: Terminating Job.batch foo pods took: 400.20644ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:30:54.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1345" for this suite.
Nov  6 01:31:00.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:31:00.491: INFO: namespace job-1345 deletion completed in 6.068281168s

• [SLOW TEST:43.161 seconds]
[sig-apps] Job
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:31:00.492: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-c008e91b-2739-431d-a1cc-2641a423c505
STEP: Creating a pod to test consume configMaps
Nov  6 01:31:00.585: INFO: Waiting up to 5m0s for pod "pod-configmaps-dec824d5-421f-4a10-be0c-59b3e3d2fd0f" in namespace "configmap-8971" to be "success or failure"
Nov  6 01:31:00.590: INFO: Pod "pod-configmaps-dec824d5-421f-4a10-be0c-59b3e3d2fd0f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.283361ms
Nov  6 01:31:02.593: INFO: Pod "pod-configmaps-dec824d5-421f-4a10-be0c-59b3e3d2fd0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008018752s
Nov  6 01:31:04.596: INFO: Pod "pod-configmaps-dec824d5-421f-4a10-be0c-59b3e3d2fd0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010852324s
STEP: Saw pod success
Nov  6 01:31:04.596: INFO: Pod "pod-configmaps-dec824d5-421f-4a10-be0c-59b3e3d2fd0f" satisfied condition "success or failure"
Nov  6 01:31:04.597: INFO: Trying to get logs from node apps-114 pod pod-configmaps-dec824d5-421f-4a10-be0c-59b3e3d2fd0f container configmap-volume-test: <nil>
STEP: delete the pod
Nov  6 01:31:04.617: INFO: Waiting for pod pod-configmaps-dec824d5-421f-4a10-be0c-59b3e3d2fd0f to disappear
Nov  6 01:31:04.624: INFO: Pod pod-configmaps-dec824d5-421f-4a10-be0c-59b3e3d2fd0f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:31:04.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8971" for this suite.
Nov  6 01:31:10.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:31:10.682: INFO: namespace configmap-8971 deletion completed in 6.056353472s

• [SLOW TEST:10.191 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:31:10.683: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-f923cf13-ee26-4abf-8abc-c02c2a76d88f
STEP: Creating a pod to test consume secrets
Nov  6 01:31:10.743: INFO: Waiting up to 5m0s for pod "pod-secrets-7c3034fb-b6ad-466e-b4a1-bf794f0f2add" in namespace "secrets-229" to be "success or failure"
Nov  6 01:31:10.748: INFO: Pod "pod-secrets-7c3034fb-b6ad-466e-b4a1-bf794f0f2add": Phase="Pending", Reason="", readiness=false. Elapsed: 5.795199ms
Nov  6 01:31:12.751: INFO: Pod "pod-secrets-7c3034fb-b6ad-466e-b4a1-bf794f0f2add": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007995281s
Nov  6 01:31:14.754: INFO: Pod "pod-secrets-7c3034fb-b6ad-466e-b4a1-bf794f0f2add": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010965476s
STEP: Saw pod success
Nov  6 01:31:14.754: INFO: Pod "pod-secrets-7c3034fb-b6ad-466e-b4a1-bf794f0f2add" satisfied condition "success or failure"
Nov  6 01:31:14.755: INFO: Trying to get logs from node apps-114 pod pod-secrets-7c3034fb-b6ad-466e-b4a1-bf794f0f2add container secret-volume-test: <nil>
STEP: delete the pod
Nov  6 01:31:14.775: INFO: Waiting for pod pod-secrets-7c3034fb-b6ad-466e-b4a1-bf794f0f2add to disappear
Nov  6 01:31:14.782: INFO: Pod pod-secrets-7c3034fb-b6ad-466e-b4a1-bf794f0f2add no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:31:14.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-229" for this suite.
Nov  6 01:31:20.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:31:20.840: INFO: namespace secrets-229 deletion completed in 6.055770206s

• [SLOW TEST:10.158 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:31:20.841: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1327
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Nov  6 01:31:20.973: INFO: Found 0 stateful pods, waiting for 3
Nov  6 01:31:30.977: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  6 01:31:30.977: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  6 01:31:30.977: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov  6 01:31:30.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=statefulset-1327 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  6 01:31:33.021: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  6 01:31:33.021: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  6 01:31:33.021: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Nov  6 01:31:43.061: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Nov  6 01:31:53.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=statefulset-1327 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  6 01:31:53.346: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  6 01:31:53.346: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  6 01:31:53.346: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  6 01:32:03.359: INFO: Waiting for StatefulSet statefulset-1327/ss2 to complete update
Nov  6 01:32:03.359: INFO: Waiting for Pod statefulset-1327/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  6 01:32:03.359: INFO: Waiting for Pod statefulset-1327/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  6 01:32:03.359: INFO: Waiting for Pod statefulset-1327/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  6 01:32:13.364: INFO: Waiting for StatefulSet statefulset-1327/ss2 to complete update
Nov  6 01:32:13.364: INFO: Waiting for Pod statefulset-1327/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  6 01:32:13.364: INFO: Waiting for Pod statefulset-1327/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  6 01:32:23.363: INFO: Waiting for StatefulSet statefulset-1327/ss2 to complete update
Nov  6 01:32:23.364: INFO: Waiting for Pod statefulset-1327/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  6 01:32:33.404: INFO: Waiting for StatefulSet statefulset-1327/ss2 to complete update
Nov  6 01:32:33.404: INFO: Waiting for Pod statefulset-1327/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Nov  6 01:32:43.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=statefulset-1327 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  6 01:32:43.663: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  6 01:32:43.663: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  6 01:32:43.663: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  6 01:32:53.686: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Nov  6 01:33:03.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=statefulset-1327 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  6 01:33:03.987: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  6 01:33:03.987: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  6 01:33:03.987: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  6 01:33:13.999: INFO: Waiting for StatefulSet statefulset-1327/ss2 to complete update
Nov  6 01:33:13.999: INFO: Waiting for Pod statefulset-1327/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov  6 01:33:13.999: INFO: Waiting for Pod statefulset-1327/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov  6 01:33:24.004: INFO: Waiting for StatefulSet statefulset-1327/ss2 to complete update
Nov  6 01:33:24.004: INFO: Waiting for Pod statefulset-1327/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  6 01:33:34.006: INFO: Deleting all statefulset in ns statefulset-1327
Nov  6 01:33:34.024: INFO: Scaling statefulset ss2 to 0
Nov  6 01:33:54.069: INFO: Waiting for statefulset status.replicas updated to 0
Nov  6 01:33:54.071: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:33:54.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1327" for this suite.
Nov  6 01:34:00.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:34:00.159: INFO: namespace statefulset-1327 deletion completed in 6.06594089s

• [SLOW TEST:159.319 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:34:00.160: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Nov  6 01:34:00.243: INFO: Waiting up to 5m0s for pod "client-containers-4d70038a-14eb-4286-bbe2-dd512d73dc3b" in namespace "containers-6903" to be "success or failure"
Nov  6 01:34:00.248: INFO: Pod "client-containers-4d70038a-14eb-4286-bbe2-dd512d73dc3b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.726163ms
Nov  6 01:34:02.251: INFO: Pod "client-containers-4d70038a-14eb-4286-bbe2-dd512d73dc3b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007432266s
Nov  6 01:34:04.254: INFO: Pod "client-containers-4d70038a-14eb-4286-bbe2-dd512d73dc3b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010248216s
STEP: Saw pod success
Nov  6 01:34:04.254: INFO: Pod "client-containers-4d70038a-14eb-4286-bbe2-dd512d73dc3b" satisfied condition "success or failure"
Nov  6 01:34:04.255: INFO: Trying to get logs from node apps-114 pod client-containers-4d70038a-14eb-4286-bbe2-dd512d73dc3b container test-container: <nil>
STEP: delete the pod
Nov  6 01:34:04.292: INFO: Waiting for pod client-containers-4d70038a-14eb-4286-bbe2-dd512d73dc3b to disappear
Nov  6 01:34:04.298: INFO: Pod client-containers-4d70038a-14eb-4286-bbe2-dd512d73dc3b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:34:04.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6903" for this suite.
Nov  6 01:34:10.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:34:10.360: INFO: namespace containers-6903 deletion completed in 6.060519455s

• [SLOW TEST:10.201 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:34:10.361: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 01:34:10.432: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-88043bc4-c475-484f-a17c-fc8873443b88" in namespace "security-context-test-4719" to be "success or failure"
Nov  6 01:34:10.451: INFO: Pod "alpine-nnp-false-88043bc4-c475-484f-a17c-fc8873443b88": Phase="Pending", Reason="", readiness=false. Elapsed: 19.102335ms
Nov  6 01:34:12.453: INFO: Pod "alpine-nnp-false-88043bc4-c475-484f-a17c-fc8873443b88": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021815163s
Nov  6 01:34:14.456: INFO: Pod "alpine-nnp-false-88043bc4-c475-484f-a17c-fc8873443b88": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024560439s
Nov  6 01:34:16.459: INFO: Pod "alpine-nnp-false-88043bc4-c475-484f-a17c-fc8873443b88": Phase="Pending", Reason="", readiness=false. Elapsed: 6.027055105s
Nov  6 01:34:18.468: INFO: Pod "alpine-nnp-false-88043bc4-c475-484f-a17c-fc8873443b88": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.036100239s
Nov  6 01:34:18.468: INFO: Pod "alpine-nnp-false-88043bc4-c475-484f-a17c-fc8873443b88" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:34:18.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4719" for this suite.
Nov  6 01:34:24.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:34:24.551: INFO: namespace security-context-test-4719 deletion completed in 6.074607772s

• [SLOW TEST:14.190 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:34:24.551: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-1188
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1188 to expose endpoints map[]
Nov  6 01:34:24.648: INFO: Get endpoints failed (4.952069ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Nov  6 01:34:25.657: INFO: successfully validated that service multi-endpoint-test in namespace services-1188 exposes endpoints map[] (1.013261633s elapsed)
STEP: Creating pod pod1 in namespace services-1188
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1188 to expose endpoints map[pod1:[100]]
Nov  6 01:34:28.710: INFO: successfully validated that service multi-endpoint-test in namespace services-1188 exposes endpoints map[pod1:[100]] (3.036197614s elapsed)
STEP: Creating pod pod2 in namespace services-1188
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1188 to expose endpoints map[pod1:[100] pod2:[101]]
Nov  6 01:34:31.789: INFO: successfully validated that service multi-endpoint-test in namespace services-1188 exposes endpoints map[pod1:[100] pod2:[101]] (3.076116029s elapsed)
STEP: Deleting pod pod1 in namespace services-1188
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1188 to expose endpoints map[pod2:[101]]
Nov  6 01:34:32.828: INFO: successfully validated that service multi-endpoint-test in namespace services-1188 exposes endpoints map[pod2:[101]] (1.036258577s elapsed)
STEP: Deleting pod pod2 in namespace services-1188
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1188 to expose endpoints map[]
Nov  6 01:34:33.842: INFO: successfully validated that service multi-endpoint-test in namespace services-1188 exposes endpoints map[] (1.011395676s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:34:33.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1188" for this suite.
Nov  6 01:34:45.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:34:45.992: INFO: namespace services-1188 deletion completed in 12.07288456s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:21.441 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:34:45.992: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-1767/configmap-test-72caef0d-b62e-477f-8e80-b5d04fa70f90
STEP: Creating a pod to test consume configMaps
Nov  6 01:34:46.077: INFO: Waiting up to 5m0s for pod "pod-configmaps-cfbed5e4-5b95-4053-b489-0c005ad9c293" in namespace "configmap-1767" to be "success or failure"
Nov  6 01:34:46.094: INFO: Pod "pod-configmaps-cfbed5e4-5b95-4053-b489-0c005ad9c293": Phase="Pending", Reason="", readiness=false. Elapsed: 16.551312ms
Nov  6 01:34:48.096: INFO: Pod "pod-configmaps-cfbed5e4-5b95-4053-b489-0c005ad9c293": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018862062s
Nov  6 01:34:50.099: INFO: Pod "pod-configmaps-cfbed5e4-5b95-4053-b489-0c005ad9c293": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021314186s
STEP: Saw pod success
Nov  6 01:34:50.099: INFO: Pod "pod-configmaps-cfbed5e4-5b95-4053-b489-0c005ad9c293" satisfied condition "success or failure"
Nov  6 01:34:50.100: INFO: Trying to get logs from node apps-114 pod pod-configmaps-cfbed5e4-5b95-4053-b489-0c005ad9c293 container env-test: <nil>
STEP: delete the pod
Nov  6 01:34:50.128: INFO: Waiting for pod pod-configmaps-cfbed5e4-5b95-4053-b489-0c005ad9c293 to disappear
Nov  6 01:34:50.134: INFO: Pod pod-configmaps-cfbed5e4-5b95-4053-b489-0c005ad9c293 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:34:50.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1767" for this suite.
Nov  6 01:34:56.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:34:56.191: INFO: namespace configmap-1767 deletion completed in 6.054266958s

• [SLOW TEST:10.199 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:34:56.191: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-be40dafa-8b10-4851-86bf-86c03671d2f2
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-be40dafa-8b10-4851-86bf-86c03671d2f2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:36:18.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6662" for this suite.
Nov  6 01:36:30.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:36:30.661: INFO: namespace configmap-6662 deletion completed in 12.064548016s

• [SLOW TEST:94.470 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:36:30.661: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov  6 01:36:35.257: INFO: Successfully updated pod "annotationupdate8f8acf3f-5b77-46d5-8230-2151eee370f0"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:36:37.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8130" for this suite.
Nov  6 01:37:05.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:37:05.352: INFO: namespace downward-api-8130 deletion completed in 28.068900928s

• [SLOW TEST:34.690 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:37:05.352: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov  6 01:37:05.408: INFO: Waiting up to 5m0s for pod "pod-c82c9d21-b2fa-4933-8fbd-013f0c9c51f1" in namespace "emptydir-789" to be "success or failure"
Nov  6 01:37:05.415: INFO: Pod "pod-c82c9d21-b2fa-4933-8fbd-013f0c9c51f1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.805976ms
Nov  6 01:37:07.417: INFO: Pod "pod-c82c9d21-b2fa-4933-8fbd-013f0c9c51f1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009292801s
Nov  6 01:37:09.424: INFO: Pod "pod-c82c9d21-b2fa-4933-8fbd-013f0c9c51f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01552094s
STEP: Saw pod success
Nov  6 01:37:09.424: INFO: Pod "pod-c82c9d21-b2fa-4933-8fbd-013f0c9c51f1" satisfied condition "success or failure"
Nov  6 01:37:09.425: INFO: Trying to get logs from node apps-114 pod pod-c82c9d21-b2fa-4933-8fbd-013f0c9c51f1 container test-container: <nil>
STEP: delete the pod
Nov  6 01:37:09.447: INFO: Waiting for pod pod-c82c9d21-b2fa-4933-8fbd-013f0c9c51f1 to disappear
Nov  6 01:37:09.457: INFO: Pod pod-c82c9d21-b2fa-4933-8fbd-013f0c9c51f1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:37:09.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-789" for this suite.
Nov  6 01:37:15.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:37:15.519: INFO: namespace emptydir-789 deletion completed in 6.059206395s

• [SLOW TEST:10.167 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:37:15.519: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov  6 01:37:23.644: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  6 01:37:23.657: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  6 01:37:25.657: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  6 01:37:25.660: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  6 01:37:27.657: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  6 01:37:27.660: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:37:27.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8655" for this suite.
Nov  6 01:37:55.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:37:55.731: INFO: namespace container-lifecycle-hook-8655 deletion completed in 28.068504069s

• [SLOW TEST:40.212 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:37:55.731: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Nov  6 01:37:55.774: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 01:37:59.706: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:38:15.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4201" for this suite.
Nov  6 01:38:21.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:38:21.347: INFO: namespace crd-publish-openapi-4201 deletion completed in 6.068063232s

• [SLOW TEST:25.616 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:38:21.347: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-e9d66ca0-39af-4b95-b4ad-82fb8dd74ce7
STEP: Creating a pod to test consume secrets
Nov  6 01:38:21.407: INFO: Waiting up to 5m0s for pod "pod-secrets-4d155c03-ea06-411c-aa57-d0d2d48cf524" in namespace "secrets-203" to be "success or failure"
Nov  6 01:38:21.414: INFO: Pod "pod-secrets-4d155c03-ea06-411c-aa57-d0d2d48cf524": Phase="Pending", Reason="", readiness=false. Elapsed: 6.616082ms
Nov  6 01:38:23.417: INFO: Pod "pod-secrets-4d155c03-ea06-411c-aa57-d0d2d48cf524": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009262993s
Nov  6 01:38:25.420: INFO: Pod "pod-secrets-4d155c03-ea06-411c-aa57-d0d2d48cf524": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012120769s
STEP: Saw pod success
Nov  6 01:38:25.420: INFO: Pod "pod-secrets-4d155c03-ea06-411c-aa57-d0d2d48cf524" satisfied condition "success or failure"
Nov  6 01:38:25.421: INFO: Trying to get logs from node apps-114 pod pod-secrets-4d155c03-ea06-411c-aa57-d0d2d48cf524 container secret-volume-test: <nil>
STEP: delete the pod
Nov  6 01:38:25.441: INFO: Waiting for pod pod-secrets-4d155c03-ea06-411c-aa57-d0d2d48cf524 to disappear
Nov  6 01:38:25.447: INFO: Pod pod-secrets-4d155c03-ea06-411c-aa57-d0d2d48cf524 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:38:25.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-203" for this suite.
Nov  6 01:38:31.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:38:31.518: INFO: namespace secrets-203 deletion completed in 6.068467804s

• [SLOW TEST:10.171 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:38:31.519: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  6 01:38:31.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-9890'
Nov  6 01:38:31.655: INFO: stderr: ""
Nov  6 01:38:31.655: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Nov  6 01:38:36.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pod e2e-test-httpd-pod --namespace=kubectl-9890 -o json'
Nov  6 01:38:36.783: INFO: stderr: ""
Nov  6 01:38:36.783: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.38.96.78/32\"\n        },\n        \"creationTimestamp\": \"2019-11-06T01:38:31Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-9890\",\n        \"resourceVersion\": \"857505\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-9890/pods/e2e-test-httpd-pod\",\n        \"uid\": \"77ba067f-3b63-44dc-9483-019de8ca7ee7\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-9ts96\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"apps-114\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 30\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 30\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-9ts96\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-9ts96\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-06T01:38:31Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-06T01:38:33Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-06T01:38:33Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-06T01:38:31Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://f07d44d21164dcfebcedade55739e948094dcfd1dfa3d6daa9e8648c2eef8b21\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-11-06T01:38:33Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.1.114\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.38.96.78\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.38.96.78\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-11-06T01:38:31Z\"\n    }\n}\n"
STEP: replace the image in the pod
Nov  6 01:38:36.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 replace -f - --namespace=kubectl-9890'
Nov  6 01:38:37.107: INFO: stderr: ""
Nov  6 01:38:37.107: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Nov  6 01:38:37.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 delete pods e2e-test-httpd-pod --namespace=kubectl-9890'
Nov  6 01:38:40.093: INFO: stderr: ""
Nov  6 01:38:40.093: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:38:40.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9890" for this suite.
Nov  6 01:38:46.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:38:46.166: INFO: namespace kubectl-9890 deletion completed in 6.058854505s

• [SLOW TEST:14.647 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:38:46.166: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 01:38:46.282: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"98275713-41c3-4eb1-8b4c-80beece6737d", Controller:(*bool)(0xc0026d7072), BlockOwnerDeletion:(*bool)(0xc0026d7073)}}
Nov  6 01:38:46.298: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"56d97bcb-f2ff-4f5d-b7a9-49e4b6722aec", Controller:(*bool)(0xc001aa9e56), BlockOwnerDeletion:(*bool)(0xc001aa9e57)}}
Nov  6 01:38:46.315: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"778bcace-7d27-44e8-ae10-2fcf2213cd98", Controller:(*bool)(0xc0029cc1e2), BlockOwnerDeletion:(*bool)(0xc0029cc1e3)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:38:51.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-372" for this suite.
Nov  6 01:38:57.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:38:57.402: INFO: namespace gc-372 deletion completed in 6.065515079s

• [SLOW TEST:11.235 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:38:57.402: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  6 01:38:57.490: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3da7f87a-0beb-44d2-bfd4-6d4f97837070" in namespace "downward-api-8817" to be "success or failure"
Nov  6 01:38:57.507: INFO: Pod "downwardapi-volume-3da7f87a-0beb-44d2-bfd4-6d4f97837070": Phase="Pending", Reason="", readiness=false. Elapsed: 16.074141ms
Nov  6 01:38:59.509: INFO: Pod "downwardapi-volume-3da7f87a-0beb-44d2-bfd4-6d4f97837070": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018277722s
Nov  6 01:39:01.512: INFO: Pod "downwardapi-volume-3da7f87a-0beb-44d2-bfd4-6d4f97837070": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021249275s
STEP: Saw pod success
Nov  6 01:39:01.512: INFO: Pod "downwardapi-volume-3da7f87a-0beb-44d2-bfd4-6d4f97837070" satisfied condition "success or failure"
Nov  6 01:39:01.513: INFO: Trying to get logs from node apps-114 pod downwardapi-volume-3da7f87a-0beb-44d2-bfd4-6d4f97837070 container client-container: <nil>
STEP: delete the pod
Nov  6 01:39:01.541: INFO: Waiting for pod downwardapi-volume-3da7f87a-0beb-44d2-bfd4-6d4f97837070 to disappear
Nov  6 01:39:01.557: INFO: Pod downwardapi-volume-3da7f87a-0beb-44d2-bfd4-6d4f97837070 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:39:01.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8817" for this suite.
Nov  6 01:39:07.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:39:07.687: INFO: namespace downward-api-8817 deletion completed in 6.127548944s

• [SLOW TEST:10.285 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:39:07.687: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  6 01:39:07.741: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4ad3e723-811c-4616-b57c-fff462612471" in namespace "projected-7827" to be "success or failure"
Nov  6 01:39:07.772: INFO: Pod "downwardapi-volume-4ad3e723-811c-4616-b57c-fff462612471": Phase="Pending", Reason="", readiness=false. Elapsed: 31.605086ms
Nov  6 01:39:09.775: INFO: Pod "downwardapi-volume-4ad3e723-811c-4616-b57c-fff462612471": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034450617s
Nov  6 01:39:11.778: INFO: Pod "downwardapi-volume-4ad3e723-811c-4616-b57c-fff462612471": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037003421s
STEP: Saw pod success
Nov  6 01:39:11.778: INFO: Pod "downwardapi-volume-4ad3e723-811c-4616-b57c-fff462612471" satisfied condition "success or failure"
Nov  6 01:39:11.779: INFO: Trying to get logs from node apps-114 pod downwardapi-volume-4ad3e723-811c-4616-b57c-fff462612471 container client-container: <nil>
STEP: delete the pod
Nov  6 01:39:11.832: INFO: Waiting for pod downwardapi-volume-4ad3e723-811c-4616-b57c-fff462612471 to disappear
Nov  6 01:39:11.839: INFO: Pod downwardapi-volume-4ad3e723-811c-4616-b57c-fff462612471 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:39:11.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7827" for this suite.
Nov  6 01:39:17.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:39:17.897: INFO: namespace projected-7827 deletion completed in 6.056002392s

• [SLOW TEST:10.211 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:39:17.898: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  6 01:39:17.966: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a7e82dc3-abcd-4b12-8ef5-08c69961bb03" in namespace "projected-5446" to be "success or failure"
Nov  6 01:39:17.972: INFO: Pod "downwardapi-volume-a7e82dc3-abcd-4b12-8ef5-08c69961bb03": Phase="Pending", Reason="", readiness=false. Elapsed: 6.522911ms
Nov  6 01:39:19.989: INFO: Pod "downwardapi-volume-a7e82dc3-abcd-4b12-8ef5-08c69961bb03": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023028877s
Nov  6 01:39:21.992: INFO: Pod "downwardapi-volume-a7e82dc3-abcd-4b12-8ef5-08c69961bb03": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025757623s
STEP: Saw pod success
Nov  6 01:39:21.992: INFO: Pod "downwardapi-volume-a7e82dc3-abcd-4b12-8ef5-08c69961bb03" satisfied condition "success or failure"
Nov  6 01:39:21.993: INFO: Trying to get logs from node apps-114 pod downwardapi-volume-a7e82dc3-abcd-4b12-8ef5-08c69961bb03 container client-container: <nil>
STEP: delete the pod
Nov  6 01:39:22.041: INFO: Waiting for pod downwardapi-volume-a7e82dc3-abcd-4b12-8ef5-08c69961bb03 to disappear
Nov  6 01:39:22.056: INFO: Pod downwardapi-volume-a7e82dc3-abcd-4b12-8ef5-08c69961bb03 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:39:22.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5446" for this suite.
Nov  6 01:39:28.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:39:28.143: INFO: namespace projected-5446 deletion completed in 6.085213796s

• [SLOW TEST:10.246 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:39:28.144: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-185
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-185
Nov  6 01:39:28.232: INFO: Found 0 stateful pods, waiting for 1
Nov  6 01:39:38.235: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  6 01:39:38.264: INFO: Deleting all statefulset in ns statefulset-185
Nov  6 01:39:38.283: INFO: Scaling statefulset ss to 0
Nov  6 01:39:58.336: INFO: Waiting for statefulset status.replicas updated to 0
Nov  6 01:39:58.338: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:39:58.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-185" for this suite.
Nov  6 01:40:04.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:40:04.447: INFO: namespace statefulset-185 deletion completed in 6.072044433s

• [SLOW TEST:36.303 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:40:04.447: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-be3b912a-3805-486d-906b-8f9511084291 in namespace container-probe-9214
Nov  6 01:40:08.541: INFO: Started pod liveness-be3b912a-3805-486d-906b-8f9511084291 in namespace container-probe-9214
STEP: checking the pod's current state and verifying that restartCount is present
Nov  6 01:40:08.543: INFO: Initial restart count of pod liveness-be3b912a-3805-486d-906b-8f9511084291 is 0
Nov  6 01:40:26.569: INFO: Restart count of pod container-probe-9214/liveness-be3b912a-3805-486d-906b-8f9511084291 is now 1 (18.025705726s elapsed)
Nov  6 01:40:44.602: INFO: Restart count of pod container-probe-9214/liveness-be3b912a-3805-486d-906b-8f9511084291 is now 2 (36.058707585s elapsed)
Nov  6 01:41:06.633: INFO: Restart count of pod container-probe-9214/liveness-be3b912a-3805-486d-906b-8f9511084291 is now 3 (58.089992774s elapsed)
Nov  6 01:41:26.670: INFO: Restart count of pod container-probe-9214/liveness-be3b912a-3805-486d-906b-8f9511084291 is now 4 (1m18.126625317s elapsed)
Nov  6 01:42:26.762: INFO: Restart count of pod container-probe-9214/liveness-be3b912a-3805-486d-906b-8f9511084291 is now 5 (2m18.218698181s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:42:26.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9214" for this suite.
Nov  6 01:42:32.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:42:32.852: INFO: namespace container-probe-9214 deletion completed in 6.057443168s

• [SLOW TEST:148.405 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:42:32.852: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-836c3713-5b98-4234-b97e-2be6e32875ed
STEP: Creating a pod to test consume configMaps
Nov  6 01:42:32.912: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ab47564c-08c3-4813-8fe3-55c7c2bcb38d" in namespace "projected-883" to be "success or failure"
Nov  6 01:42:32.919: INFO: Pod "pod-projected-configmaps-ab47564c-08c3-4813-8fe3-55c7c2bcb38d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.513636ms
Nov  6 01:42:34.922: INFO: Pod "pod-projected-configmaps-ab47564c-08c3-4813-8fe3-55c7c2bcb38d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01028385s
Nov  6 01:42:36.926: INFO: Pod "pod-projected-configmaps-ab47564c-08c3-4813-8fe3-55c7c2bcb38d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013778787s
STEP: Saw pod success
Nov  6 01:42:36.926: INFO: Pod "pod-projected-configmaps-ab47564c-08c3-4813-8fe3-55c7c2bcb38d" satisfied condition "success or failure"
Nov  6 01:42:36.927: INFO: Trying to get logs from node apps-114 pod pod-projected-configmaps-ab47564c-08c3-4813-8fe3-55c7c2bcb38d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  6 01:42:36.987: INFO: Waiting for pod pod-projected-configmaps-ab47564c-08c3-4813-8fe3-55c7c2bcb38d to disappear
Nov  6 01:42:37.033: INFO: Pod pod-projected-configmaps-ab47564c-08c3-4813-8fe3-55c7c2bcb38d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:42:37.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-883" for this suite.
Nov  6 01:42:43.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:42:43.102: INFO: namespace projected-883 deletion completed in 6.066333128s

• [SLOW TEST:10.249 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:42:43.102: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-3d6e9af6-e103-4fc0-852c-842c539d22c2
STEP: Creating a pod to test consume configMaps
Nov  6 01:42:43.186: INFO: Waiting up to 5m0s for pod "pod-configmaps-680c3cb9-38d4-4260-b508-786deccbe803" in namespace "configmap-9332" to be "success or failure"
Nov  6 01:42:43.203: INFO: Pod "pod-configmaps-680c3cb9-38d4-4260-b508-786deccbe803": Phase="Pending", Reason="", readiness=false. Elapsed: 16.210247ms
Nov  6 01:42:45.206: INFO: Pod "pod-configmaps-680c3cb9-38d4-4260-b508-786deccbe803": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019370726s
Nov  6 01:42:47.216: INFO: Pod "pod-configmaps-680c3cb9-38d4-4260-b508-786deccbe803": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029401672s
STEP: Saw pod success
Nov  6 01:42:47.216: INFO: Pod "pod-configmaps-680c3cb9-38d4-4260-b508-786deccbe803" satisfied condition "success or failure"
Nov  6 01:42:47.218: INFO: Trying to get logs from node apps-114 pod pod-configmaps-680c3cb9-38d4-4260-b508-786deccbe803 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  6 01:42:47.238: INFO: Waiting for pod pod-configmaps-680c3cb9-38d4-4260-b508-786deccbe803 to disappear
Nov  6 01:42:47.245: INFO: Pod pod-configmaps-680c3cb9-38d4-4260-b508-786deccbe803 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:42:47.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9332" for this suite.
Nov  6 01:42:53.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:42:53.303: INFO: namespace configmap-9332 deletion completed in 6.054957521s

• [SLOW TEST:10.201 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:42:53.303: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Nov  6 01:42:53.375: INFO: Waiting up to 5m0s for pod "pod-e501fcda-003a-4eea-8a82-94434bd016da" in namespace "emptydir-4726" to be "success or failure"
Nov  6 01:42:53.379: INFO: Pod "pod-e501fcda-003a-4eea-8a82-94434bd016da": Phase="Pending", Reason="", readiness=false. Elapsed: 3.375219ms
Nov  6 01:42:55.382: INFO: Pod "pod-e501fcda-003a-4eea-8a82-94434bd016da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006715748s
Nov  6 01:42:57.385: INFO: Pod "pod-e501fcda-003a-4eea-8a82-94434bd016da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009655575s
STEP: Saw pod success
Nov  6 01:42:57.385: INFO: Pod "pod-e501fcda-003a-4eea-8a82-94434bd016da" satisfied condition "success or failure"
Nov  6 01:42:57.387: INFO: Trying to get logs from node apps-114 pod pod-e501fcda-003a-4eea-8a82-94434bd016da container test-container: <nil>
STEP: delete the pod
Nov  6 01:42:57.433: INFO: Waiting for pod pod-e501fcda-003a-4eea-8a82-94434bd016da to disappear
Nov  6 01:42:57.445: INFO: Pod pod-e501fcda-003a-4eea-8a82-94434bd016da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:42:57.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4726" for this suite.
Nov  6 01:43:03.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:43:03.504: INFO: namespace emptydir-4726 deletion completed in 6.055354695s

• [SLOW TEST:10.201 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:43:03.504: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Nov  6 01:43:11.616: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1303 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  6 01:43:11.616: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 01:43:11.787: INFO: Exec stderr: ""
Nov  6 01:43:11.787: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1303 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  6 01:43:11.787: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 01:43:11.979: INFO: Exec stderr: ""
Nov  6 01:43:11.979: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1303 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  6 01:43:11.979: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 01:43:12.147: INFO: Exec stderr: ""
Nov  6 01:43:12.147: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1303 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  6 01:43:12.147: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 01:43:12.343: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Nov  6 01:43:12.343: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1303 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  6 01:43:12.343: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 01:43:12.514: INFO: Exec stderr: ""
Nov  6 01:43:12.514: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1303 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  6 01:43:12.514: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 01:43:12.702: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Nov  6 01:43:12.702: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1303 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  6 01:43:12.702: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 01:43:12.845: INFO: Exec stderr: ""
Nov  6 01:43:12.845: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1303 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  6 01:43:12.845: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 01:43:13.036: INFO: Exec stderr: ""
Nov  6 01:43:13.036: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1303 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  6 01:43:13.036: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 01:43:13.208: INFO: Exec stderr: ""
Nov  6 01:43:13.208: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1303 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  6 01:43:13.208: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 01:43:13.403: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:43:13.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-1303" for this suite.
Nov  6 01:44:09.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:44:09.470: INFO: namespace e2e-kubelet-etc-hosts-1303 deletion completed in 56.063797471s

• [SLOW TEST:65.966 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:44:09.471: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-9262
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-9262
STEP: creating replication controller externalsvc in namespace services-9262
I1106 01:44:09.613729      26 runners.go:184] Created replication controller with name: externalsvc, namespace: services-9262, replica count: 2
I1106 01:44:12.664106      26 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Nov  6 01:44:12.707: INFO: Creating new exec pod
Nov  6 01:44:16.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=services-9262 execpodflw4r -- /bin/sh -x -c nslookup nodeport-service'
Nov  6 01:44:18.768: INFO: stderr: "+ nslookup nodeport-service\n"
Nov  6 01:44:18.768: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-9262.svc.cluster.local\tcanonical name = externalsvc.services-9262.svc.cluster.local.\nName:\texternalsvc.services-9262.svc.cluster.local\nAddress: 10.104.157.131\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-9262, will wait for the garbage collector to delete the pods
Nov  6 01:44:18.826: INFO: Deleting ReplicationController externalsvc took: 4.652224ms
Nov  6 01:44:19.226: INFO: Terminating ReplicationController externalsvc pods took: 400.182161ms
Nov  6 01:44:24.473: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:44:24.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9262" for this suite.
Nov  6 01:44:30.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:44:30.582: INFO: namespace services-9262 deletion completed in 6.074439118s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:21.112 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:44:30.582: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Nov  6 01:44:30.624: INFO: Waiting up to 1m0s for all nodes to be ready
Nov  6 01:45:30.643: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 01:45:30.656: INFO: Starting informer...
STEP: Starting pod...
Nov  6 01:45:30.863: INFO: Pod is running on apps-114. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Nov  6 01:45:30.887: INFO: Pod wasn't evicted. Proceeding
Nov  6 01:45:30.887: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Nov  6 01:46:45.912: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:46:45.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-4676" for this suite.
Nov  6 01:46:57.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:46:57.981: INFO: namespace taint-single-pod-4676 deletion completed in 12.066064319s

• [SLOW TEST:147.399 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:46:57.982: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  6 01:46:58.014: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  6 01:46:58.047: INFO: Waiting for terminating namespaces to be deleted...
Nov  6 01:46:58.049: INFO: 
Logging pods the kubelet thinks is on node apps-113 before test
Nov  6 01:46:58.060: INFO: dashboard-queue-cocktail-86b7c74d57-8wnfw from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container dashboard-queue ready: true, restart count 0
Nov  6 01:46:58.060: INFO: cloud-metering-cocktail-864ccb89c5-tsgj7 from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container cocktail-metering-api ready: true, restart count 0
Nov  6 01:46:58.060: INFO: prometheus-addon-5754fb587-t8m85 from cocktail-addon started at 2019-10-30 08:19:27 +0000 UTC (2 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container configmap-reload ready: true, restart count 0
Nov  6 01:46:58.060: INFO: 	Container prometheus-addon ready: true, restart count 0
Nov  6 01:46:58.060: INFO: monitoring-agent-njzizt-3-7657c68cd7-hwcqz from cocktail-addon started at 2019-10-30 09:24:28 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container statcollector ready: true, restart count 0
Nov  6 01:46:58.060: INFO: coredns-7649fdbb4-snqxg from kube-system started at 2019-10-30 08:16:56 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container coredns ready: true, restart count 0
Nov  6 01:46:58.060: INFO: addon-manager-7c8b9c74f6-9pllx from cocktail-addon started at 2019-10-30 08:17:39 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container addon-manager ready: true, restart count 0
Nov  6 01:46:58.060: INFO: batch-server-cocktail-55d57dff79-4qm6j from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container batch ready: true, restart count 0
Nov  6 01:46:58.060: INFO: build-api-cocktail-6d6f8dfbbc-jhq8w from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container build-api ready: true, restart count 0
Nov  6 01:46:58.060: INFO: dashboard-session-cocktail-66658bd785-zl4lk from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container dashboard-session-01 ready: true, restart count 0
Nov  6 01:46:58.060: INFO: dashboard-cocktail-575c77f5bd-7xpz9 from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container cocktail-dashboard ready: true, restart count 0
Nov  6 01:46:58.060: INFO: api-cmdb-cocktail-7796b94f65-5x9kt from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container api-cmdb-01 ready: true, restart count 0
Nov  6 01:46:58.060: INFO: monitoring-db-cocktail-547dff6c7f-msc7q from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container db ready: true, restart count 0
Nov  6 01:46:58.060: INFO: calico-node-jv7rf from kube-system started at 2019-10-30 08:16:37 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container calico-node ready: true, restart count 0
Nov  6 01:46:58.060: INFO: sonobuoy-systemd-logs-daemon-set-a0ae98b6655c4fa6-tpjhf from sonobuoy started at 2019-11-06 01:13:06 +0000 UTC (2 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  6 01:46:58.060: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  6 01:46:58.060: INFO: kube-state-metrics-addon-7f48b7868b-jd4jx from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container kube-state-metrics-addon ready: true, restart count 0
Nov  6 01:46:58.060: INFO: nfs-client-provisioner-addon-566798455d-q7tw8 from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container nfs-client-provisioner-addon ready: true, restart count 0
Nov  6 01:46:58.060: INFO: cloud-metering-collector-cocktail-68bfd6cc67-q8tjh from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (3 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container cocktail-collector-aws ready: true, restart count 1
Nov  6 01:46:58.060: INFO: 	Container cocktail-collector-azure ready: true, restart count 0
Nov  6 01:46:58.060: INFO: 	Container cocktail-collector-google ready: true, restart count 1
Nov  6 01:46:58.060: INFO: alertmanager-addon-5967cc89f8-8bdvd from cocktail-addon started at 2019-10-30 08:19:27 +0000 UTC (2 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container alertmanager-addon ready: true, restart count 0
Nov  6 01:46:58.060: INFO: 	Container configmap-reload ready: true, restart count 0
Nov  6 01:46:58.060: INFO: dashboard-proxy-cocktail-5cfd96484-9qjjr from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container dashboard-proxy-01 ready: true, restart count 0
Nov  6 01:46:58.060: INFO: cluster-health-checker-cocktail-58f4545c48-l9ncr from cocktail-system started at 2019-10-30 08:18:01 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container checker ready: true, restart count 0
Nov  6 01:46:58.060: INFO: nginx-ingress-addon-controller-7dcb6fc5ff-t4rlv from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container nginx-ingress-addon-controller ready: true, restart count 0
Nov  6 01:46:58.060: INFO: monitoring-collector-cocktail-5647c8b855-54jph from cocktail-system started at 2019-10-30 08:18:01 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container statcollector ready: true, restart count 4
Nov  6 01:46:58.060: INFO: api-server-cocktail-88f64f646-x67ld from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container api-server-01 ready: true, restart count 0
Nov  6 01:46:58.060: INFO: metrics-server-5d9d98df9f-qsw2s from kube-system started at 2019-10-30 08:17:01 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container metrics-server ready: true, restart count 0
Nov  6 01:46:58.060: INFO: kube-scheduler-apps-113 from kube-system started at 2019-10-30 08:16:37 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container kube-scheduler ready: true, restart count 0
Nov  6 01:46:58.060: INFO: monitoring-cocktail-59d5ffc9fd-szdwh from cocktail-system started at 2019-10-30 08:18:03 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container monitoring-01 ready: true, restart count 0
Nov  6 01:46:58.060: INFO: build-queue-cocktail-758498c967-slzk4 from cocktail-system started at 2019-10-30 08:19:23 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container nats-streaming ready: true, restart count 0
Nov  6 01:46:58.060: INFO: kube-controller-manager-apps-113 from kube-system started at 2019-10-30 08:16:38 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container kube-controller-manager ready: true, restart count 0
Nov  6 01:46:58.060: INFO: disk-usage-exporter-addon-t758w from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container disk-usage-exporter-addon ready: true, restart count 0
Nov  6 01:46:58.060: INFO: kube-apiserver-apps-113 from kube-system started at 2019-10-30 08:16:37 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container kube-apiserver ready: true, restart count 0
Nov  6 01:46:58.060: INFO: coredns-7649fdbb4-fctcq from kube-system started at 2019-10-30 08:16:55 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.060: INFO: 	Container coredns ready: true, restart count 0
Nov  6 01:46:58.061: INFO: calico-kube-controllers-55754f75c-kxfjw from kube-system started at 2019-10-30 08:16:57 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.061: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov  6 01:46:58.061: INFO: node-exporter-addon-dqnzs from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.061: INFO: 	Container node-exporter-addon ready: true, restart count 0
Nov  6 01:46:58.061: INFO: kube-proxy-hdklg from kube-system started at 2019-10-30 08:16:08 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.061: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  6 01:46:58.061: INFO: 
Logging pods the kubelet thinks is on node apps-114 before test
Nov  6 01:46:58.066: INFO: sonobuoy-systemd-logs-daemon-set-a0ae98b6655c4fa6-gcqdr from sonobuoy started at 2019-11-06 01:13:06 +0000 UTC (2 container statuses recorded)
Nov  6 01:46:58.066: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  6 01:46:58.066: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  6 01:46:58.066: INFO: node-exporter-addon-vzwg5 from cocktail-addon started at 2019-11-06 01:45:43 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.066: INFO: 	Container node-exporter-addon ready: true, restart count 0
Nov  6 01:46:58.066: INFO: sonobuoy-e2e-job-e818bd6c45834cee from sonobuoy started at 2019-11-06 01:13:06 +0000 UTC (2 container statuses recorded)
Nov  6 01:46:58.066: INFO: 	Container e2e ready: true, restart count 0
Nov  6 01:46:58.066: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  6 01:46:58.066: INFO: disk-usage-exporter-addon-zcv9w from cocktail-addon started at 2019-11-06 01:45:43 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.066: INFO: 	Container disk-usage-exporter-addon ready: true, restart count 0
Nov  6 01:46:58.066: INFO: calico-node-cbzfz from kube-system started at 2019-10-30 10:45:39 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.066: INFO: 	Container calico-node ready: true, restart count 0
Nov  6 01:46:58.066: INFO: kube-proxy-nnw7s from kube-system started at 2019-10-30 10:45:39 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.066: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  6 01:46:58.066: INFO: sonobuoy from sonobuoy started at 2019-11-06 01:12:56 +0000 UTC (1 container statuses recorded)
Nov  6 01:46:58.066: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d46f8c43bf1e3f], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d46f8c44b8db21], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:46:59.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9840" for this suite.
Nov  6 01:47:05.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:47:05.151: INFO: namespace sched-pred-9840 deletion completed in 6.065059036s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.169 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:47:05.151: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 01:47:09.258: INFO: Waiting up to 5m0s for pod "client-envvars-9e0153ae-d57b-48cb-bddb-c2dcf7eef495" in namespace "pods-4606" to be "success or failure"
Nov  6 01:47:09.265: INFO: Pod "client-envvars-9e0153ae-d57b-48cb-bddb-c2dcf7eef495": Phase="Pending", Reason="", readiness=false. Elapsed: 6.902742ms
Nov  6 01:47:11.268: INFO: Pod "client-envvars-9e0153ae-d57b-48cb-bddb-c2dcf7eef495": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0094973s
Nov  6 01:47:13.273: INFO: Pod "client-envvars-9e0153ae-d57b-48cb-bddb-c2dcf7eef495": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01401542s
STEP: Saw pod success
Nov  6 01:47:13.273: INFO: Pod "client-envvars-9e0153ae-d57b-48cb-bddb-c2dcf7eef495" satisfied condition "success or failure"
Nov  6 01:47:13.274: INFO: Trying to get logs from node apps-114 pod client-envvars-9e0153ae-d57b-48cb-bddb-c2dcf7eef495 container env3cont: <nil>
STEP: delete the pod
Nov  6 01:47:13.299: INFO: Waiting for pod client-envvars-9e0153ae-d57b-48cb-bddb-c2dcf7eef495 to disappear
Nov  6 01:47:13.333: INFO: Pod client-envvars-9e0153ae-d57b-48cb-bddb-c2dcf7eef495 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:47:13.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4606" for this suite.
Nov  6 01:47:25.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:47:25.403: INFO: namespace pods-4606 deletion completed in 12.067620785s

• [SLOW TEST:20.252 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:47:25.403: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Nov  6 01:47:35.504: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-720122187 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov  6 01:47:40.590: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:47:40.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5252" for this suite.
Nov  6 01:47:46.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:47:46.662: INFO: namespace pods-5252 deletion completed in 6.067744406s

• [SLOW TEST:21.259 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:47:46.662: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  6 01:47:48.106: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  6 01:47:50.113: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708601668, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708601668, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708601668, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708601668, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  6 01:47:53.131: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:47:53.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7141" for this suite.
Nov  6 01:47:59.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:47:59.228: INFO: namespace webhook-7141 deletion completed in 6.089780861s
STEP: Destroying namespace "webhook-7141-markers" for this suite.
Nov  6 01:48:05.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:48:05.294: INFO: namespace webhook-7141-markers deletion completed in 6.065801718s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.640 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:48:05.302: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  6 01:48:05.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-1618'
Nov  6 01:48:05.490: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  6 01:48:05.490: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Nov  6 01:48:05.515: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-spsc8]
Nov  6 01:48:05.515: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-spsc8" in namespace "kubectl-1618" to be "running and ready"
Nov  6 01:48:05.526: INFO: Pod "e2e-test-httpd-rc-spsc8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.385272ms
Nov  6 01:48:07.529: INFO: Pod "e2e-test-httpd-rc-spsc8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014312513s
Nov  6 01:48:09.533: INFO: Pod "e2e-test-httpd-rc-spsc8": Phase="Running", Reason="", readiness=true. Elapsed: 4.017923047s
Nov  6 01:48:09.533: INFO: Pod "e2e-test-httpd-rc-spsc8" satisfied condition "running and ready"
Nov  6 01:48:09.533: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-spsc8]
Nov  6 01:48:09.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 logs rc/e2e-test-httpd-rc --namespace=kubectl-1618'
Nov  6 01:48:09.633: INFO: stderr: ""
Nov  6 01:48:09.633: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.38.96.97. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.38.96.97. Set the 'ServerName' directive globally to suppress this message\n[Wed Nov 06 01:48:07.125168 2019] [mpm_event:notice] [pid 1:tid 140283203562344] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Wed Nov 06 01:48:07.125212 2019] [core:notice] [pid 1:tid 140283203562344] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Nov  6 01:48:09.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 delete rc e2e-test-httpd-rc --namespace=kubectl-1618'
Nov  6 01:48:09.741: INFO: stderr: ""
Nov  6 01:48:09.741: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:48:09.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1618" for this suite.
Nov  6 01:48:37.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:48:37.870: INFO: namespace kubectl-1618 deletion completed in 28.121566207s

• [SLOW TEST:32.568 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:48:37.870: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov  6 01:48:37.919: INFO: Waiting up to 5m0s for pod "pod-88630776-90df-4679-8ed9-69be16176691" in namespace "emptydir-9463" to be "success or failure"
Nov  6 01:48:37.955: INFO: Pod "pod-88630776-90df-4679-8ed9-69be16176691": Phase="Pending", Reason="", readiness=false. Elapsed: 36.413701ms
Nov  6 01:48:39.958: INFO: Pod "pod-88630776-90df-4679-8ed9-69be16176691": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039522568s
Nov  6 01:48:41.961: INFO: Pod "pod-88630776-90df-4679-8ed9-69be16176691": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042101157s
STEP: Saw pod success
Nov  6 01:48:41.961: INFO: Pod "pod-88630776-90df-4679-8ed9-69be16176691" satisfied condition "success or failure"
Nov  6 01:48:41.962: INFO: Trying to get logs from node apps-114 pod pod-88630776-90df-4679-8ed9-69be16176691 container test-container: <nil>
STEP: delete the pod
Nov  6 01:48:41.977: INFO: Waiting for pod pod-88630776-90df-4679-8ed9-69be16176691 to disappear
Nov  6 01:48:42.005: INFO: Pod pod-88630776-90df-4679-8ed9-69be16176691 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:48:42.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9463" for this suite.
Nov  6 01:48:48.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:48:48.075: INFO: namespace emptydir-9463 deletion completed in 6.068137027s

• [SLOW TEST:10.205 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:48:48.076: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  6 01:48:48.127: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aef4dc49-c799-490d-b57a-c44394cfe64f" in namespace "projected-2975" to be "success or failure"
Nov  6 01:48:48.141: INFO: Pod "downwardapi-volume-aef4dc49-c799-490d-b57a-c44394cfe64f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.711884ms
Nov  6 01:48:50.144: INFO: Pod "downwardapi-volume-aef4dc49-c799-490d-b57a-c44394cfe64f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01696098s
Nov  6 01:48:52.155: INFO: Pod "downwardapi-volume-aef4dc49-c799-490d-b57a-c44394cfe64f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027406373s
STEP: Saw pod success
Nov  6 01:48:52.155: INFO: Pod "downwardapi-volume-aef4dc49-c799-490d-b57a-c44394cfe64f" satisfied condition "success or failure"
Nov  6 01:48:52.156: INFO: Trying to get logs from node apps-114 pod downwardapi-volume-aef4dc49-c799-490d-b57a-c44394cfe64f container client-container: <nil>
STEP: delete the pod
Nov  6 01:48:52.177: INFO: Waiting for pod downwardapi-volume-aef4dc49-c799-490d-b57a-c44394cfe64f to disappear
Nov  6 01:48:52.184: INFO: Pod downwardapi-volume-aef4dc49-c799-490d-b57a-c44394cfe64f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:48:52.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2975" for this suite.
Nov  6 01:48:58.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:48:58.243: INFO: namespace projected-2975 deletion completed in 6.056095349s

• [SLOW TEST:10.168 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:48:58.244: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Nov  6 01:48:58.334: INFO: Waiting up to 5m0s for pod "var-expansion-10579d01-40b7-4489-b656-c337281426a3" in namespace "var-expansion-9392" to be "success or failure"
Nov  6 01:48:58.342: INFO: Pod "var-expansion-10579d01-40b7-4489-b656-c337281426a3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.759364ms
Nov  6 01:49:00.346: INFO: Pod "var-expansion-10579d01-40b7-4489-b656-c337281426a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011606303s
Nov  6 01:49:02.349: INFO: Pod "var-expansion-10579d01-40b7-4489-b656-c337281426a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014536786s
STEP: Saw pod success
Nov  6 01:49:02.349: INFO: Pod "var-expansion-10579d01-40b7-4489-b656-c337281426a3" satisfied condition "success or failure"
Nov  6 01:49:02.351: INFO: Trying to get logs from node apps-114 pod var-expansion-10579d01-40b7-4489-b656-c337281426a3 container dapi-container: <nil>
STEP: delete the pod
Nov  6 01:49:02.418: INFO: Waiting for pod var-expansion-10579d01-40b7-4489-b656-c337281426a3 to disappear
Nov  6 01:49:02.425: INFO: Pod var-expansion-10579d01-40b7-4489-b656-c337281426a3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:49:02.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9392" for this suite.
Nov  6 01:49:08.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:49:08.483: INFO: namespace var-expansion-9392 deletion completed in 6.054801513s

• [SLOW TEST:10.239 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:49:08.483: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  6 01:49:08.560: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  6 01:49:08.572: INFO: Waiting for terminating namespaces to be deleted...
Nov  6 01:49:08.574: INFO: 
Logging pods the kubelet thinks is on node apps-113 before test
Nov  6 01:49:08.585: INFO: kube-state-metrics-addon-7f48b7868b-jd4jx from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.585: INFO: 	Container kube-state-metrics-addon ready: true, restart count 0
Nov  6 01:49:08.585: INFO: nfs-client-provisioner-addon-566798455d-q7tw8 from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.585: INFO: 	Container nfs-client-provisioner-addon ready: true, restart count 0
Nov  6 01:49:08.585: INFO: cluster-health-checker-cocktail-58f4545c48-l9ncr from cocktail-system started at 2019-10-30 08:18:01 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.585: INFO: 	Container checker ready: true, restart count 0
Nov  6 01:49:08.585: INFO: cloud-metering-collector-cocktail-68bfd6cc67-q8tjh from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (3 container statuses recorded)
Nov  6 01:49:08.585: INFO: 	Container cocktail-collector-aws ready: true, restart count 1
Nov  6 01:49:08.585: INFO: 	Container cocktail-collector-azure ready: true, restart count 0
Nov  6 01:49:08.585: INFO: 	Container cocktail-collector-google ready: true, restart count 1
Nov  6 01:49:08.585: INFO: alertmanager-addon-5967cc89f8-8bdvd from cocktail-addon started at 2019-10-30 08:19:27 +0000 UTC (2 container statuses recorded)
Nov  6 01:49:08.585: INFO: 	Container alertmanager-addon ready: true, restart count 0
Nov  6 01:49:08.585: INFO: 	Container configmap-reload ready: true, restart count 0
Nov  6 01:49:08.585: INFO: dashboard-proxy-cocktail-5cfd96484-9qjjr from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.585: INFO: 	Container dashboard-proxy-01 ready: true, restart count 0
Nov  6 01:49:08.585: INFO: metrics-server-5d9d98df9f-qsw2s from kube-system started at 2019-10-30 08:17:01 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.585: INFO: 	Container metrics-server ready: true, restart count 0
Nov  6 01:49:08.585: INFO: nginx-ingress-addon-controller-7dcb6fc5ff-t4rlv from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.585: INFO: 	Container nginx-ingress-addon-controller ready: true, restart count 0
Nov  6 01:49:08.585: INFO: monitoring-collector-cocktail-5647c8b855-54jph from cocktail-system started at 2019-10-30 08:18:01 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.585: INFO: 	Container statcollector ready: true, restart count 4
Nov  6 01:49:08.585: INFO: api-server-cocktail-88f64f646-x67ld from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.585: INFO: 	Container api-server-01 ready: true, restart count 0
Nov  6 01:49:08.585: INFO: kube-controller-manager-apps-113 from kube-system started at 2019-10-30 08:16:38 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.585: INFO: 	Container kube-controller-manager ready: true, restart count 0
Nov  6 01:49:08.585: INFO: kube-scheduler-apps-113 from kube-system started at 2019-10-30 08:16:37 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.585: INFO: 	Container kube-scheduler ready: true, restart count 0
Nov  6 01:49:08.585: INFO: monitoring-cocktail-59d5ffc9fd-szdwh from cocktail-system started at 2019-10-30 08:18:03 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.585: INFO: 	Container monitoring-01 ready: true, restart count 0
Nov  6 01:49:08.585: INFO: build-queue-cocktail-758498c967-slzk4 from cocktail-system started at 2019-10-30 08:19:23 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.585: INFO: 	Container nats-streaming ready: true, restart count 0
Nov  6 01:49:08.585: INFO: kube-apiserver-apps-113 from kube-system started at 2019-10-30 08:16:37 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.585: INFO: 	Container kube-apiserver ready: true, restart count 0
Nov  6 01:49:08.585: INFO: disk-usage-exporter-addon-t758w from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.586: INFO: 	Container disk-usage-exporter-addon ready: true, restart count 0
Nov  6 01:49:08.586: INFO: kube-proxy-hdklg from kube-system started at 2019-10-30 08:16:08 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.586: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  6 01:49:08.586: INFO: coredns-7649fdbb4-fctcq from kube-system started at 2019-10-30 08:16:55 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.586: INFO: 	Container coredns ready: true, restart count 0
Nov  6 01:49:08.586: INFO: calico-kube-controllers-55754f75c-kxfjw from kube-system started at 2019-10-30 08:16:57 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.586: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov  6 01:49:08.586: INFO: node-exporter-addon-dqnzs from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.586: INFO: 	Container node-exporter-addon ready: true, restart count 0
Nov  6 01:49:08.586: INFO: coredns-7649fdbb4-snqxg from kube-system started at 2019-10-30 08:16:56 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.586: INFO: 	Container coredns ready: true, restart count 0
Nov  6 01:49:08.586: INFO: dashboard-queue-cocktail-86b7c74d57-8wnfw from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.586: INFO: 	Container dashboard-queue ready: true, restart count 0
Nov  6 01:49:08.586: INFO: cloud-metering-cocktail-864ccb89c5-tsgj7 from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.586: INFO: 	Container cocktail-metering-api ready: true, restart count 0
Nov  6 01:49:08.586: INFO: prometheus-addon-5754fb587-t8m85 from cocktail-addon started at 2019-10-30 08:19:27 +0000 UTC (2 container statuses recorded)
Nov  6 01:49:08.586: INFO: 	Container configmap-reload ready: true, restart count 0
Nov  6 01:49:08.586: INFO: 	Container prometheus-addon ready: true, restart count 0
Nov  6 01:49:08.586: INFO: monitoring-agent-njzizt-3-7657c68cd7-hwcqz from cocktail-addon started at 2019-10-30 09:24:28 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.586: INFO: 	Container statcollector ready: true, restart count 0
Nov  6 01:49:08.586: INFO: api-cmdb-cocktail-7796b94f65-5x9kt from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.586: INFO: 	Container api-cmdb-01 ready: true, restart count 0
Nov  6 01:49:08.586: INFO: monitoring-db-cocktail-547dff6c7f-msc7q from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.586: INFO: 	Container db ready: true, restart count 0
Nov  6 01:49:08.586: INFO: calico-node-jv7rf from kube-system started at 2019-10-30 08:16:37 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.586: INFO: 	Container calico-node ready: true, restart count 0
Nov  6 01:49:08.586: INFO: addon-manager-7c8b9c74f6-9pllx from cocktail-addon started at 2019-10-30 08:17:39 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.586: INFO: 	Container addon-manager ready: true, restart count 0
Nov  6 01:49:08.586: INFO: batch-server-cocktail-55d57dff79-4qm6j from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.586: INFO: 	Container batch ready: true, restart count 0
Nov  6 01:49:08.586: INFO: build-api-cocktail-6d6f8dfbbc-jhq8w from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.586: INFO: 	Container build-api ready: true, restart count 0
Nov  6 01:49:08.586: INFO: dashboard-session-cocktail-66658bd785-zl4lk from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.586: INFO: 	Container dashboard-session-01 ready: true, restart count 0
Nov  6 01:49:08.586: INFO: dashboard-cocktail-575c77f5bd-7xpz9 from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.586: INFO: 	Container cocktail-dashboard ready: true, restart count 0
Nov  6 01:49:08.586: INFO: sonobuoy-systemd-logs-daemon-set-a0ae98b6655c4fa6-tpjhf from sonobuoy started at 2019-11-06 01:13:06 +0000 UTC (2 container statuses recorded)
Nov  6 01:49:08.586: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  6 01:49:08.586: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  6 01:49:08.586: INFO: 
Logging pods the kubelet thinks is on node apps-114 before test
Nov  6 01:49:08.596: INFO: sonobuoy-systemd-logs-daemon-set-a0ae98b6655c4fa6-gcqdr from sonobuoy started at 2019-11-06 01:13:06 +0000 UTC (2 container statuses recorded)
Nov  6 01:49:08.596: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  6 01:49:08.596: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  6 01:49:08.596: INFO: node-exporter-addon-vzwg5 from cocktail-addon started at 2019-11-06 01:45:43 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.596: INFO: 	Container node-exporter-addon ready: true, restart count 0
Nov  6 01:49:08.596: INFO: sonobuoy-e2e-job-e818bd6c45834cee from sonobuoy started at 2019-11-06 01:13:06 +0000 UTC (2 container statuses recorded)
Nov  6 01:49:08.596: INFO: 	Container e2e ready: true, restart count 0
Nov  6 01:49:08.596: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  6 01:49:08.596: INFO: disk-usage-exporter-addon-zcv9w from cocktail-addon started at 2019-11-06 01:45:43 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.596: INFO: 	Container disk-usage-exporter-addon ready: true, restart count 0
Nov  6 01:49:08.596: INFO: calico-node-cbzfz from kube-system started at 2019-10-30 10:45:39 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.596: INFO: 	Container calico-node ready: true, restart count 0
Nov  6 01:49:08.596: INFO: kube-proxy-nnw7s from kube-system started at 2019-10-30 10:45:39 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.596: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  6 01:49:08.596: INFO: sonobuoy from sonobuoy started at 2019-11-06 01:12:56 +0000 UTC (1 container statuses recorded)
Nov  6 01:49:08.596: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-a1e5fbdd-e0dc-4040-91cb-3a7c84d03bcc 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-a1e5fbdd-e0dc-4040-91cb-3a7c84d03bcc off the node apps-114
STEP: verifying the node doesn't have the label kubernetes.io/e2e-a1e5fbdd-e0dc-4040-91cb-3a7c84d03bcc
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:54:16.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-797" for this suite.
Nov  6 01:54:44.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:54:44.864: INFO: namespace sched-pred-797 deletion completed in 28.084520833s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:336.381 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:54:44.864: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov  6 01:54:44.938: INFO: Waiting up to 5m0s for pod "pod-8f36cb4d-1056-41fc-b17d-e79ecea0a7f5" in namespace "emptydir-6919" to be "success or failure"
Nov  6 01:54:44.955: INFO: Pod "pod-8f36cb4d-1056-41fc-b17d-e79ecea0a7f5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.860916ms
Nov  6 01:54:46.958: INFO: Pod "pod-8f36cb4d-1056-41fc-b17d-e79ecea0a7f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019820366s
Nov  6 01:54:48.960: INFO: Pod "pod-8f36cb4d-1056-41fc-b17d-e79ecea0a7f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0224058s
STEP: Saw pod success
Nov  6 01:54:48.960: INFO: Pod "pod-8f36cb4d-1056-41fc-b17d-e79ecea0a7f5" satisfied condition "success or failure"
Nov  6 01:54:48.962: INFO: Trying to get logs from node apps-114 pod pod-8f36cb4d-1056-41fc-b17d-e79ecea0a7f5 container test-container: <nil>
STEP: delete the pod
Nov  6 01:54:48.988: INFO: Waiting for pod pod-8f36cb4d-1056-41fc-b17d-e79ecea0a7f5 to disappear
Nov  6 01:54:48.995: INFO: Pod pod-8f36cb4d-1056-41fc-b17d-e79ecea0a7f5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:54:48.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6919" for this suite.
Nov  6 01:54:55.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:54:55.054: INFO: namespace emptydir-6919 deletion completed in 6.057213924s

• [SLOW TEST:10.191 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:54:55.055: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov  6 01:54:55.103: INFO: Waiting up to 5m0s for pod "pod-c9f50b76-4a09-4f14-b9ef-7badf67b13cb" in namespace "emptydir-6816" to be "success or failure"
Nov  6 01:54:55.112: INFO: Pod "pod-c9f50b76-4a09-4f14-b9ef-7badf67b13cb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.096111ms
Nov  6 01:54:57.114: INFO: Pod "pod-c9f50b76-4a09-4f14-b9ef-7badf67b13cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010480292s
Nov  6 01:54:59.117: INFO: Pod "pod-c9f50b76-4a09-4f14-b9ef-7badf67b13cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013531113s
STEP: Saw pod success
Nov  6 01:54:59.117: INFO: Pod "pod-c9f50b76-4a09-4f14-b9ef-7badf67b13cb" satisfied condition "success or failure"
Nov  6 01:54:59.119: INFO: Trying to get logs from node apps-114 pod pod-c9f50b76-4a09-4f14-b9ef-7badf67b13cb container test-container: <nil>
STEP: delete the pod
Nov  6 01:54:59.144: INFO: Waiting for pod pod-c9f50b76-4a09-4f14-b9ef-7badf67b13cb to disappear
Nov  6 01:54:59.153: INFO: Pod pod-c9f50b76-4a09-4f14-b9ef-7badf67b13cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:54:59.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6816" for this suite.
Nov  6 01:55:05.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:55:05.212: INFO: namespace emptydir-6816 deletion completed in 6.056297108s

• [SLOW TEST:10.157 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:55:05.212: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 01:55:05.277: INFO: Create a RollingUpdate DaemonSet
Nov  6 01:55:05.279: INFO: Check that daemon pods launch on every node of the cluster
Nov  6 01:55:05.301: INFO: Number of nodes with available pods: 0
Nov  6 01:55:05.301: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:55:06.330: INFO: Number of nodes with available pods: 0
Nov  6 01:55:06.330: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:55:07.307: INFO: Number of nodes with available pods: 0
Nov  6 01:55:07.307: INFO: Node apps-113 is running more than one daemon pod
Nov  6 01:55:08.307: INFO: Number of nodes with available pods: 2
Nov  6 01:55:08.307: INFO: Number of running nodes: 2, number of available pods: 2
Nov  6 01:55:08.307: INFO: Update the DaemonSet to trigger a rollout
Nov  6 01:55:08.311: INFO: Updating DaemonSet daemon-set
Nov  6 01:55:18.328: INFO: Roll back the DaemonSet before rollout is complete
Nov  6 01:55:18.333: INFO: Updating DaemonSet daemon-set
Nov  6 01:55:18.333: INFO: Make sure DaemonSet rollback is complete
Nov  6 01:55:18.337: INFO: Wrong image for pod: daemon-set-jmmnf. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov  6 01:55:18.337: INFO: Pod daemon-set-jmmnf is not available
Nov  6 01:55:19.359: INFO: Wrong image for pod: daemon-set-jmmnf. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov  6 01:55:19.359: INFO: Pod daemon-set-jmmnf is not available
Nov  6 01:55:20.359: INFO: Pod daemon-set-mqb2g is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6252, will wait for the garbage collector to delete the pods
Nov  6 01:55:20.447: INFO: Deleting DaemonSet.extensions daemon-set took: 29.086106ms
Nov  6 01:55:20.847: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.208665ms
Nov  6 01:55:23.849: INFO: Number of nodes with available pods: 0
Nov  6 01:55:23.849: INFO: Number of running nodes: 0, number of available pods: 0
Nov  6 01:55:23.851: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6252/daemonsets","resourceVersion":"860164"},"items":null}

Nov  6 01:55:23.853: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6252/pods","resourceVersion":"860164"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:55:23.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6252" for this suite.
Nov  6 01:55:29.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:55:29.951: INFO: namespace daemonsets-6252 deletion completed in 6.07404746s

• [SLOW TEST:24.738 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:55:29.951: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:55:34.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9611" for this suite.
Nov  6 01:55:46.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:55:46.151: INFO: namespace containers-9611 deletion completed in 12.097139183s

• [SLOW TEST:16.200 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:55:46.151: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:56:02.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4210" for this suite.
Nov  6 01:56:08.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:56:08.524: INFO: namespace resourcequota-4210 deletion completed in 6.172461424s

• [SLOW TEST:22.373 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:56:08.524: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Nov  6 01:56:08.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 create -f - --namespace=kubectl-6080'
Nov  6 01:56:10.604: INFO: stderr: ""
Nov  6 01:56:10.604: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  6 01:56:10.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6080'
Nov  6 01:56:10.691: INFO: stderr: ""
Nov  6 01:56:10.691: INFO: stdout: "update-demo-nautilus-7vxlk update-demo-nautilus-qw2hx "
Nov  6 01:56:10.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-7vxlk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6080'
Nov  6 01:56:10.794: INFO: stderr: ""
Nov  6 01:56:10.794: INFO: stdout: ""
Nov  6 01:56:10.794: INFO: update-demo-nautilus-7vxlk is created but not running
Nov  6 01:56:15.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6080'
Nov  6 01:56:15.879: INFO: stderr: ""
Nov  6 01:56:15.879: INFO: stdout: "update-demo-nautilus-7vxlk update-demo-nautilus-qw2hx "
Nov  6 01:56:15.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-7vxlk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6080'
Nov  6 01:56:15.961: INFO: stderr: ""
Nov  6 01:56:15.961: INFO: stdout: "true"
Nov  6 01:56:15.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-7vxlk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6080'
Nov  6 01:56:16.039: INFO: stderr: ""
Nov  6 01:56:16.039: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  6 01:56:16.039: INFO: validating pod update-demo-nautilus-7vxlk
Nov  6 01:56:16.042: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  6 01:56:16.042: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  6 01:56:16.042: INFO: update-demo-nautilus-7vxlk is verified up and running
Nov  6 01:56:16.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-qw2hx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6080'
Nov  6 01:56:16.124: INFO: stderr: ""
Nov  6 01:56:16.124: INFO: stdout: "true"
Nov  6 01:56:16.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-qw2hx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6080'
Nov  6 01:56:16.207: INFO: stderr: ""
Nov  6 01:56:16.207: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  6 01:56:16.207: INFO: validating pod update-demo-nautilus-qw2hx
Nov  6 01:56:16.210: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  6 01:56:16.210: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  6 01:56:16.210: INFO: update-demo-nautilus-qw2hx is verified up and running
STEP: scaling down the replication controller
Nov  6 01:56:16.212: INFO: scanned /root for discovery docs: <nil>
Nov  6 01:56:16.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-6080'
Nov  6 01:56:17.317: INFO: stderr: ""
Nov  6 01:56:17.318: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  6 01:56:17.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6080'
Nov  6 01:56:17.404: INFO: stderr: ""
Nov  6 01:56:17.404: INFO: stdout: "update-demo-nautilus-7vxlk update-demo-nautilus-qw2hx "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov  6 01:56:22.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6080'
Nov  6 01:56:22.491: INFO: stderr: ""
Nov  6 01:56:22.491: INFO: stdout: "update-demo-nautilus-7vxlk update-demo-nautilus-qw2hx "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov  6 01:56:27.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6080'
Nov  6 01:56:27.577: INFO: stderr: ""
Nov  6 01:56:27.577: INFO: stdout: "update-demo-nautilus-7vxlk "
Nov  6 01:56:27.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-7vxlk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6080'
Nov  6 01:56:27.660: INFO: stderr: ""
Nov  6 01:56:27.660: INFO: stdout: "true"
Nov  6 01:56:27.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-7vxlk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6080'
Nov  6 01:56:27.743: INFO: stderr: ""
Nov  6 01:56:27.743: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  6 01:56:27.743: INFO: validating pod update-demo-nautilus-7vxlk
Nov  6 01:56:27.746: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  6 01:56:27.746: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  6 01:56:27.746: INFO: update-demo-nautilus-7vxlk is verified up and running
STEP: scaling up the replication controller
Nov  6 01:56:27.748: INFO: scanned /root for discovery docs: <nil>
Nov  6 01:56:27.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-6080'
Nov  6 01:56:28.850: INFO: stderr: ""
Nov  6 01:56:28.850: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  6 01:56:28.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6080'
Nov  6 01:56:28.932: INFO: stderr: ""
Nov  6 01:56:28.932: INFO: stdout: "update-demo-nautilus-795n2 update-demo-nautilus-7vxlk "
Nov  6 01:56:28.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-795n2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6080'
Nov  6 01:56:29.017: INFO: stderr: ""
Nov  6 01:56:29.017: INFO: stdout: ""
Nov  6 01:56:29.017: INFO: update-demo-nautilus-795n2 is created but not running
Nov  6 01:56:34.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6080'
Nov  6 01:56:34.098: INFO: stderr: ""
Nov  6 01:56:34.098: INFO: stdout: "update-demo-nautilus-795n2 update-demo-nautilus-7vxlk "
Nov  6 01:56:34.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-795n2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6080'
Nov  6 01:56:34.175: INFO: stderr: ""
Nov  6 01:56:34.175: INFO: stdout: "true"
Nov  6 01:56:34.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-795n2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6080'
Nov  6 01:56:34.257: INFO: stderr: ""
Nov  6 01:56:34.257: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  6 01:56:34.257: INFO: validating pod update-demo-nautilus-795n2
Nov  6 01:56:34.260: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  6 01:56:34.260: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  6 01:56:34.260: INFO: update-demo-nautilus-795n2 is verified up and running
Nov  6 01:56:34.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-7vxlk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6080'
Nov  6 01:56:34.342: INFO: stderr: ""
Nov  6 01:56:34.342: INFO: stdout: "true"
Nov  6 01:56:34.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-7vxlk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6080'
Nov  6 01:56:34.426: INFO: stderr: ""
Nov  6 01:56:34.426: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  6 01:56:34.426: INFO: validating pod update-demo-nautilus-7vxlk
Nov  6 01:56:34.429: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  6 01:56:34.429: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  6 01:56:34.429: INFO: update-demo-nautilus-7vxlk is verified up and running
STEP: using delete to clean up resources
Nov  6 01:56:34.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 delete --grace-period=0 --force -f - --namespace=kubectl-6080'
Nov  6 01:56:34.529: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  6 01:56:34.530: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  6 01:56:34.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6080'
Nov  6 01:56:34.637: INFO: stderr: "No resources found in kubectl-6080 namespace.\n"
Nov  6 01:56:34.637: INFO: stdout: ""
Nov  6 01:56:34.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -l name=update-demo --namespace=kubectl-6080 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  6 01:56:34.721: INFO: stderr: ""
Nov  6 01:56:34.721: INFO: stdout: "update-demo-nautilus-795n2\nupdate-demo-nautilus-7vxlk\n"
Nov  6 01:56:35.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6080'
Nov  6 01:56:35.307: INFO: stderr: "No resources found in kubectl-6080 namespace.\n"
Nov  6 01:56:35.307: INFO: stdout: ""
Nov  6 01:56:35.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -l name=update-demo --namespace=kubectl-6080 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  6 01:56:35.398: INFO: stderr: ""
Nov  6 01:56:35.398: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:56:35.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6080" for this suite.
Nov  6 01:56:41.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:56:41.477: INFO: namespace kubectl-6080 deletion completed in 6.076524459s

• [SLOW TEST:32.953 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:56:41.477: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:56:45.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4717" for this suite.
Nov  6 01:56:51.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:56:51.726: INFO: namespace emptydir-wrapper-4717 deletion completed in 6.088886447s

• [SLOW TEST:10.249 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:56:51.727: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Nov  6 01:56:51.800: INFO: Waiting up to 5m0s for pod "pod-b492c51f-f405-4736-8ca8-c308f11edc55" in namespace "emptydir-4712" to be "success or failure"
Nov  6 01:56:51.812: INFO: Pod "pod-b492c51f-f405-4736-8ca8-c308f11edc55": Phase="Pending", Reason="", readiness=false. Elapsed: 12.086617ms
Nov  6 01:56:53.814: INFO: Pod "pod-b492c51f-f405-4736-8ca8-c308f11edc55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014409731s
Nov  6 01:56:55.817: INFO: Pod "pod-b492c51f-f405-4736-8ca8-c308f11edc55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017642548s
STEP: Saw pod success
Nov  6 01:56:55.817: INFO: Pod "pod-b492c51f-f405-4736-8ca8-c308f11edc55" satisfied condition "success or failure"
Nov  6 01:56:55.819: INFO: Trying to get logs from node apps-114 pod pod-b492c51f-f405-4736-8ca8-c308f11edc55 container test-container: <nil>
STEP: delete the pod
Nov  6 01:56:55.838: INFO: Waiting for pod pod-b492c51f-f405-4736-8ca8-c308f11edc55 to disappear
Nov  6 01:56:55.845: INFO: Pod pod-b492c51f-f405-4736-8ca8-c308f11edc55 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:56:55.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4712" for this suite.
Nov  6 01:57:01.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:57:01.957: INFO: namespace emptydir-4712 deletion completed in 6.109653503s

• [SLOW TEST:10.230 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:57:01.957: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-908.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-908.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-908.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-908.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-908.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-908.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-908.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-908.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-908.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-908.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-908.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 172.27.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.27.172_udp@PTR;check="$$(dig +tcp +noall +answer +search 172.27.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.27.172_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-908.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-908.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-908.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-908.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-908.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-908.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-908.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-908.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-908.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-908.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-908.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 172.27.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.27.172_udp@PTR;check="$$(dig +tcp +noall +answer +search 172.27.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.27.172_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  6 01:57:06.111: INFO: Unable to read wheezy_udp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:06.113: INFO: Unable to read wheezy_tcp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:06.115: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:06.117: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:06.133: INFO: Unable to read jessie_udp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:06.135: INFO: Unable to read jessie_tcp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:06.137: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:06.139: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:06.151: INFO: Lookups using dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38 failed for: [wheezy_udp@dns-test-service.dns-908.svc.cluster.local wheezy_tcp@dns-test-service.dns-908.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local jessie_udp@dns-test-service.dns-908.svc.cluster.local jessie_tcp@dns-test-service.dns-908.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local]

Nov  6 01:57:11.154: INFO: Unable to read wheezy_udp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:11.156: INFO: Unable to read wheezy_tcp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:11.158: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:11.160: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:11.178: INFO: Unable to read jessie_udp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:11.181: INFO: Unable to read jessie_tcp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:11.183: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:11.185: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:11.198: INFO: Lookups using dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38 failed for: [wheezy_udp@dns-test-service.dns-908.svc.cluster.local wheezy_tcp@dns-test-service.dns-908.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local jessie_udp@dns-test-service.dns-908.svc.cluster.local jessie_tcp@dns-test-service.dns-908.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local]

Nov  6 01:57:16.154: INFO: Unable to read wheezy_udp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:16.156: INFO: Unable to read wheezy_tcp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:16.158: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:16.161: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:16.175: INFO: Unable to read jessie_udp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:16.177: INFO: Unable to read jessie_tcp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:16.179: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:16.181: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:16.194: INFO: Lookups using dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38 failed for: [wheezy_udp@dns-test-service.dns-908.svc.cluster.local wheezy_tcp@dns-test-service.dns-908.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local jessie_udp@dns-test-service.dns-908.svc.cluster.local jessie_tcp@dns-test-service.dns-908.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local]

Nov  6 01:57:21.154: INFO: Unable to read wheezy_udp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:21.156: INFO: Unable to read wheezy_tcp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:21.159: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:21.161: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:21.176: INFO: Unable to read jessie_udp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:21.178: INFO: Unable to read jessie_tcp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:21.180: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:21.183: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:21.196: INFO: Lookups using dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38 failed for: [wheezy_udp@dns-test-service.dns-908.svc.cluster.local wheezy_tcp@dns-test-service.dns-908.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local jessie_udp@dns-test-service.dns-908.svc.cluster.local jessie_tcp@dns-test-service.dns-908.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local]

Nov  6 01:57:26.154: INFO: Unable to read wheezy_udp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:26.156: INFO: Unable to read wheezy_tcp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:26.158: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:26.161: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:26.175: INFO: Unable to read jessie_udp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:26.177: INFO: Unable to read jessie_tcp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:26.180: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:26.182: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:26.194: INFO: Lookups using dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38 failed for: [wheezy_udp@dns-test-service.dns-908.svc.cluster.local wheezy_tcp@dns-test-service.dns-908.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local jessie_udp@dns-test-service.dns-908.svc.cluster.local jessie_tcp@dns-test-service.dns-908.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local]

Nov  6 01:57:31.154: INFO: Unable to read wheezy_udp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:31.156: INFO: Unable to read wheezy_tcp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:31.158: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:31.160: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:31.175: INFO: Unable to read jessie_udp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:31.177: INFO: Unable to read jessie_tcp@dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:31.179: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:31.181: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local from pod dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38: the server could not find the requested resource (get pods dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38)
Nov  6 01:57:31.208: INFO: Lookups using dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38 failed for: [wheezy_udp@dns-test-service.dns-908.svc.cluster.local wheezy_tcp@dns-test-service.dns-908.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local jessie_udp@dns-test-service.dns-908.svc.cluster.local jessie_tcp@dns-test-service.dns-908.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-908.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-908.svc.cluster.local]

Nov  6 01:57:36.195: INFO: DNS probes using dns-908/dns-test-34d753c5-7803-40f6-b1fc-8dde5fe72e38 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:57:36.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-908" for this suite.
Nov  6 01:57:42.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:57:42.445: INFO: namespace dns-908 deletion completed in 6.06284544s

• [SLOW TEST:40.488 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:57:42.445: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-8637/configmap-test-e587b783-e522-4ad3-8afc-c76df07cd2bc
STEP: Creating a pod to test consume configMaps
Nov  6 01:57:42.508: INFO: Waiting up to 5m0s for pod "pod-configmaps-83821f24-53e2-4d53-8842-7df4d4e6741d" in namespace "configmap-8637" to be "success or failure"
Nov  6 01:57:42.515: INFO: Pod "pod-configmaps-83821f24-53e2-4d53-8842-7df4d4e6741d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.27527ms
Nov  6 01:57:44.517: INFO: Pod "pod-configmaps-83821f24-53e2-4d53-8842-7df4d4e6741d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009030895s
Nov  6 01:57:46.521: INFO: Pod "pod-configmaps-83821f24-53e2-4d53-8842-7df4d4e6741d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012287988s
STEP: Saw pod success
Nov  6 01:57:46.521: INFO: Pod "pod-configmaps-83821f24-53e2-4d53-8842-7df4d4e6741d" satisfied condition "success or failure"
Nov  6 01:57:46.522: INFO: Trying to get logs from node apps-114 pod pod-configmaps-83821f24-53e2-4d53-8842-7df4d4e6741d container env-test: <nil>
STEP: delete the pod
Nov  6 01:57:46.549: INFO: Waiting for pod pod-configmaps-83821f24-53e2-4d53-8842-7df4d4e6741d to disappear
Nov  6 01:57:46.580: INFO: Pod pod-configmaps-83821f24-53e2-4d53-8842-7df4d4e6741d no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:57:46.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8637" for this suite.
Nov  6 01:57:52.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:57:52.646: INFO: namespace configmap-8637 deletion completed in 6.064150076s

• [SLOW TEST:10.201 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:57:52.647: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-22b72215-80c9-43a0-b640-4227b61e5aa6
STEP: Creating a pod to test consume configMaps
Nov  6 01:57:52.708: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4c2164b1-790e-4bab-824f-71b66419d723" in namespace "projected-882" to be "success or failure"
Nov  6 01:57:52.714: INFO: Pod "pod-projected-configmaps-4c2164b1-790e-4bab-824f-71b66419d723": Phase="Pending", Reason="", readiness=false. Elapsed: 6.698846ms
Nov  6 01:57:54.718: INFO: Pod "pod-projected-configmaps-4c2164b1-790e-4bab-824f-71b66419d723": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00979041s
Nov  6 01:57:56.720: INFO: Pod "pod-projected-configmaps-4c2164b1-790e-4bab-824f-71b66419d723": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012758059s
STEP: Saw pod success
Nov  6 01:57:56.721: INFO: Pod "pod-projected-configmaps-4c2164b1-790e-4bab-824f-71b66419d723" satisfied condition "success or failure"
Nov  6 01:57:56.722: INFO: Trying to get logs from node apps-114 pod pod-projected-configmaps-4c2164b1-790e-4bab-824f-71b66419d723 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  6 01:57:56.764: INFO: Waiting for pod pod-projected-configmaps-4c2164b1-790e-4bab-824f-71b66419d723 to disappear
Nov  6 01:57:56.773: INFO: Pod pod-projected-configmaps-4c2164b1-790e-4bab-824f-71b66419d723 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:57:56.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-882" for this suite.
Nov  6 01:58:02.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:58:02.871: INFO: namespace projected-882 deletion completed in 6.096046522s

• [SLOW TEST:10.225 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:58:02.871: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-5pkb
STEP: Creating a pod to test atomic-volume-subpath
Nov  6 01:58:02.941: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-5pkb" in namespace "subpath-4421" to be "success or failure"
Nov  6 01:58:02.971: INFO: Pod "pod-subpath-test-secret-5pkb": Phase="Pending", Reason="", readiness=false. Elapsed: 29.971696ms
Nov  6 01:58:04.974: INFO: Pod "pod-subpath-test-secret-5pkb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032746575s
Nov  6 01:58:06.976: INFO: Pod "pod-subpath-test-secret-5pkb": Phase="Running", Reason="", readiness=true. Elapsed: 4.035360226s
Nov  6 01:58:08.980: INFO: Pod "pod-subpath-test-secret-5pkb": Phase="Running", Reason="", readiness=true. Elapsed: 6.03872287s
Nov  6 01:58:10.983: INFO: Pod "pod-subpath-test-secret-5pkb": Phase="Running", Reason="", readiness=true. Elapsed: 8.04146135s
Nov  6 01:58:12.985: INFO: Pod "pod-subpath-test-secret-5pkb": Phase="Running", Reason="", readiness=true. Elapsed: 10.043953983s
Nov  6 01:58:14.988: INFO: Pod "pod-subpath-test-secret-5pkb": Phase="Running", Reason="", readiness=true. Elapsed: 12.046699818s
Nov  6 01:58:16.990: INFO: Pod "pod-subpath-test-secret-5pkb": Phase="Running", Reason="", readiness=true. Elapsed: 14.049001523s
Nov  6 01:58:18.993: INFO: Pod "pod-subpath-test-secret-5pkb": Phase="Running", Reason="", readiness=true. Elapsed: 16.051660716s
Nov  6 01:58:20.995: INFO: Pod "pod-subpath-test-secret-5pkb": Phase="Running", Reason="", readiness=true. Elapsed: 18.053963732s
Nov  6 01:58:22.998: INFO: Pod "pod-subpath-test-secret-5pkb": Phase="Running", Reason="", readiness=true. Elapsed: 20.056881036s
Nov  6 01:58:25.001: INFO: Pod "pod-subpath-test-secret-5pkb": Phase="Running", Reason="", readiness=true. Elapsed: 22.060297134s
Nov  6 01:58:27.004: INFO: Pod "pod-subpath-test-secret-5pkb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.062868571s
STEP: Saw pod success
Nov  6 01:58:27.004: INFO: Pod "pod-subpath-test-secret-5pkb" satisfied condition "success or failure"
Nov  6 01:58:27.006: INFO: Trying to get logs from node apps-114 pod pod-subpath-test-secret-5pkb container test-container-subpath-secret-5pkb: <nil>
STEP: delete the pod
Nov  6 01:58:27.032: INFO: Waiting for pod pod-subpath-test-secret-5pkb to disappear
Nov  6 01:58:27.039: INFO: Pod pod-subpath-test-secret-5pkb no longer exists
STEP: Deleting pod pod-subpath-test-secret-5pkb
Nov  6 01:58:27.039: INFO: Deleting pod "pod-subpath-test-secret-5pkb" in namespace "subpath-4421"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:58:27.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4421" for this suite.
Nov  6 01:58:33.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:58:33.097: INFO: namespace subpath-4421 deletion completed in 6.053794396s

• [SLOW TEST:30.226 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:58:33.098: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  6 01:58:33.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-1725'
Nov  6 01:58:33.256: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  6 01:58:33.256: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Nov  6 01:58:35.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 delete deployment e2e-test-httpd-deployment --namespace=kubectl-1725'
Nov  6 01:58:35.449: INFO: stderr: ""
Nov  6 01:58:35.449: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:58:35.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1725" for this suite.
Nov  6 01:58:47.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:58:47.514: INFO: namespace kubectl-1725 deletion completed in 12.06207695s

• [SLOW TEST:14.416 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:58:47.514: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 01:58:47.597: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov  6 01:58:52.600: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  6 01:58:52.600: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  6 01:58:52.618: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-3610 /apis/apps/v1/namespaces/deployment-3610/deployments/test-cleanup-deployment 60633a15-b452-46e0-953a-1d47e500554d 860999 1 2019-11-06 01:58:52 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00346b638 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Nov  6 01:58:52.670: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Nov  6 01:58:52.670: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Nov  6 01:58:52.670: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-3610 /apis/apps/v1/namespaces/deployment-3610/replicasets/test-cleanup-controller 91304e04-0a7b-420d-ac0c-c9c97eeaa812 861000 1 2019-11-06 01:58:47 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 60633a15-b452-46e0-953a-1d47e500554d 0xc00346ba37 0xc00346ba38}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00346ba98 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  6 01:58:52.672: INFO: Pod "test-cleanup-controller-4rtd5" is available:
&Pod{ObjectMeta:{test-cleanup-controller-4rtd5 test-cleanup-controller- deployment-3610 /api/v1/namespaces/deployment-3610/pods/test-cleanup-controller-4rtd5 8ad96a53-0202-4d98-b458-c98981953130 860992 0 2019-11-06 01:58:47 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/podIP:10.38.96.119/32] [{apps/v1 ReplicaSet test-cleanup-controller 91304e04-0a7b-420d-ac0c-c9c97eeaa812 0xc00346be17 0xc00346be18}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cdtpk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cdtpk,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cdtpk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 01:58:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 01:58:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 01:58:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 01:58:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.114,PodIP:10.38.96.119,StartTime:2019-11-06 01:58:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-06 01:58:49 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://813712f3a9c1a9b8be0792cf4c53cc98fedbf7a205ef4ff3f1951fcf9417f05e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.38.96.119,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:58:52.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3610" for this suite.
Nov  6 01:58:58.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:58:58.781: INFO: namespace deployment-3610 deletion completed in 6.099302241s

• [SLOW TEST:11.267 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:58:58.782: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-ac9b58f2-2e03-4525-b254-ca524cec202f
STEP: Creating a pod to test consume secrets
Nov  6 01:58:58.841: INFO: Waiting up to 5m0s for pod "pod-secrets-29af631c-11d1-4eb6-9116-a58bbfa61eee" in namespace "secrets-3862" to be "success or failure"
Nov  6 01:58:58.848: INFO: Pod "pod-secrets-29af631c-11d1-4eb6-9116-a58bbfa61eee": Phase="Pending", Reason="", readiness=false. Elapsed: 6.877811ms
Nov  6 01:59:00.850: INFO: Pod "pod-secrets-29af631c-11d1-4eb6-9116-a58bbfa61eee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009504667s
Nov  6 01:59:02.853: INFO: Pod "pod-secrets-29af631c-11d1-4eb6-9116-a58bbfa61eee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01238675s
STEP: Saw pod success
Nov  6 01:59:02.853: INFO: Pod "pod-secrets-29af631c-11d1-4eb6-9116-a58bbfa61eee" satisfied condition "success or failure"
Nov  6 01:59:02.855: INFO: Trying to get logs from node apps-114 pod pod-secrets-29af631c-11d1-4eb6-9116-a58bbfa61eee container secret-env-test: <nil>
STEP: delete the pod
Nov  6 01:59:02.883: INFO: Waiting for pod pod-secrets-29af631c-11d1-4eb6-9116-a58bbfa61eee to disappear
Nov  6 01:59:02.889: INFO: Pod pod-secrets-29af631c-11d1-4eb6-9116-a58bbfa61eee no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:59:02.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3862" for this suite.
Nov  6 01:59:08.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:59:08.949: INFO: namespace secrets-3862 deletion completed in 6.056506581s

• [SLOW TEST:10.166 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:59:08.949: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Nov  6 01:59:08.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 create -f - --namespace=kubectl-3631'
Nov  6 01:59:09.243: INFO: stderr: ""
Nov  6 01:59:09.243: INFO: stdout: "pod/pause created\n"
Nov  6 01:59:09.243: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov  6 01:59:09.244: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-3631" to be "running and ready"
Nov  6 01:59:09.257: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 13.323857ms
Nov  6 01:59:11.259: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015441602s
Nov  6 01:59:13.262: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.018222071s
Nov  6 01:59:13.262: INFO: Pod "pause" satisfied condition "running and ready"
Nov  6 01:59:13.262: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Nov  6 01:59:13.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 label pods pause testing-label=testing-label-value --namespace=kubectl-3631'
Nov  6 01:59:13.351: INFO: stderr: ""
Nov  6 01:59:13.351: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Nov  6 01:59:13.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pod pause -L testing-label --namespace=kubectl-3631'
Nov  6 01:59:13.436: INFO: stderr: ""
Nov  6 01:59:13.436: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Nov  6 01:59:13.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 label pods pause testing-label- --namespace=kubectl-3631'
Nov  6 01:59:13.518: INFO: stderr: ""
Nov  6 01:59:13.518: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Nov  6 01:59:13.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pod pause -L testing-label --namespace=kubectl-3631'
Nov  6 01:59:13.605: INFO: stderr: ""
Nov  6 01:59:13.605: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Nov  6 01:59:13.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 delete --grace-period=0 --force -f - --namespace=kubectl-3631'
Nov  6 01:59:13.732: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  6 01:59:13.732: INFO: stdout: "pod \"pause\" force deleted\n"
Nov  6 01:59:13.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get rc,svc -l name=pause --no-headers --namespace=kubectl-3631'
Nov  6 01:59:13.828: INFO: stderr: "No resources found in kubectl-3631 namespace.\n"
Nov  6 01:59:13.828: INFO: stdout: ""
Nov  6 01:59:13.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -l name=pause --namespace=kubectl-3631 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  6 01:59:13.914: INFO: stderr: ""
Nov  6 01:59:13.914: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:59:13.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3631" for this suite.
Nov  6 01:59:19.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:59:19.976: INFO: namespace kubectl-3631 deletion completed in 6.058572354s

• [SLOW TEST:11.027 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:59:19.976: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-6878
STEP: creating replication controller nodeport-test in namespace services-6878
I1106 01:59:20.082142      26 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-6878, replica count: 2
Nov  6 01:59:23.132: INFO: Creating new exec pod
I1106 01:59:23.132572      26 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  6 01:59:28.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=services-6878 execpod45xgg -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Nov  6 01:59:28.440: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Nov  6 01:59:28.440: INFO: stdout: ""
Nov  6 01:59:28.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=services-6878 execpod45xgg -- /bin/sh -x -c nc -zv -t -w 2 10.102.25.229 80'
Nov  6 01:59:28.686: INFO: stderr: "+ nc -zv -t -w 2 10.102.25.229 80\nConnection to 10.102.25.229 80 port [tcp/http] succeeded!\n"
Nov  6 01:59:28.686: INFO: stdout: ""
Nov  6 01:59:28.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=services-6878 execpod45xgg -- /bin/sh -x -c nc -zv -t -w 2 192.168.1.113 32676'
Nov  6 01:59:28.961: INFO: stderr: "+ nc -zv -t -w 2 192.168.1.113 32676\nConnection to 192.168.1.113 32676 port [tcp/32676] succeeded!\n"
Nov  6 01:59:28.961: INFO: stdout: ""
Nov  6 01:59:28.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=services-6878 execpod45xgg -- /bin/sh -x -c nc -zv -t -w 2 192.168.1.114 32676'
Nov  6 01:59:29.225: INFO: stderr: "+ nc -zv -t -w 2 192.168.1.114 32676\nConnection to 192.168.1.114 32676 port [tcp/32676] succeeded!\n"
Nov  6 01:59:29.225: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:59:29.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6878" for this suite.
Nov  6 01:59:35.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:59:35.294: INFO: namespace services-6878 deletion completed in 6.065694249s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:15.319 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:59:35.295: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 01:59:35.343: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 01:59:36.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4634" for this suite.
Nov  6 01:59:42.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 01:59:42.489: INFO: namespace custom-resource-definition-4634 deletion completed in 6.078305603s

• [SLOW TEST:7.194 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 01:59:42.489: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2596
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-2596
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2596
Nov  6 01:59:42.590: INFO: Found 0 stateful pods, waiting for 1
Nov  6 01:59:52.593: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Nov  6 01:59:52.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=statefulset-2596 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  6 01:59:52.874: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  6 01:59:52.874: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  6 01:59:52.874: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  6 01:59:52.877: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov  6 02:00:02.880: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  6 02:00:02.880: INFO: Waiting for statefulset status.replicas updated to 0
Nov  6 02:00:02.900: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Nov  6 02:00:02.900: INFO: ss-0  apps-114  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  }]
Nov  6 02:00:02.900: INFO: 
Nov  6 02:00:02.900: INFO: StatefulSet ss has not reached scale 3, at 1
Nov  6 02:00:03.917: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.986272749s
Nov  6 02:00:04.920: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.969314353s
Nov  6 02:00:05.926: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.965846794s
Nov  6 02:00:06.929: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.960427593s
Nov  6 02:00:07.932: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.957268313s
Nov  6 02:00:08.936: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.953707362s
Nov  6 02:00:09.940: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.950306081s
Nov  6 02:00:10.943: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.946406553s
Nov  6 02:00:11.946: INFO: Verifying statefulset ss doesn't scale past 3 for another 943.056473ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2596
Nov  6 02:00:12.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=statefulset-2596 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  6 02:00:13.180: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  6 02:00:13.180: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  6 02:00:13.180: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  6 02:00:13.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=statefulset-2596 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  6 02:00:13.483: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov  6 02:00:13.483: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  6 02:00:13.483: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  6 02:00:13.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=statefulset-2596 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  6 02:00:13.739: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov  6 02:00:13.739: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  6 02:00:13.739: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  6 02:00:13.742: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  6 02:00:13.742: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  6 02:00:13.742: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Nov  6 02:00:13.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=statefulset-2596 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  6 02:00:13.994: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  6 02:00:13.994: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  6 02:00:13.994: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  6 02:00:13.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=statefulset-2596 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  6 02:00:14.269: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  6 02:00:14.269: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  6 02:00:14.269: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  6 02:00:14.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=statefulset-2596 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  6 02:00:14.583: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  6 02:00:14.583: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  6 02:00:14.583: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  6 02:00:14.584: INFO: Waiting for statefulset status.replicas updated to 0
Nov  6 02:00:14.600: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Nov  6 02:00:24.605: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  6 02:00:24.605: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  6 02:00:24.605: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  6 02:00:24.625: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Nov  6 02:00:24.625: INFO: ss-0  apps-114  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  }]
Nov  6 02:00:24.625: INFO: ss-1  apps-114  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:24.625: INFO: ss-2  apps-114  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:24.625: INFO: 
Nov  6 02:00:24.625: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  6 02:00:25.629: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Nov  6 02:00:25.629: INFO: ss-0  apps-114  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  }]
Nov  6 02:00:25.629: INFO: ss-1  apps-114  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:25.629: INFO: ss-2  apps-114  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:25.629: INFO: 
Nov  6 02:00:25.629: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  6 02:00:26.632: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Nov  6 02:00:26.632: INFO: ss-0  apps-114  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  }]
Nov  6 02:00:26.632: INFO: ss-1  apps-114  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:26.632: INFO: ss-2  apps-114  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:26.632: INFO: 
Nov  6 02:00:26.632: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  6 02:00:27.635: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Nov  6 02:00:27.635: INFO: ss-0  apps-114  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  }]
Nov  6 02:00:27.636: INFO: ss-1  apps-114  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:27.636: INFO: ss-2  apps-114  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:27.636: INFO: 
Nov  6 02:00:27.636: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  6 02:00:28.639: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Nov  6 02:00:28.639: INFO: ss-0  apps-114  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  }]
Nov  6 02:00:28.639: INFO: ss-1  apps-114  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:28.639: INFO: ss-2  apps-114  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:28.639: INFO: 
Nov  6 02:00:28.639: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  6 02:00:29.642: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Nov  6 02:00:29.642: INFO: ss-0  apps-114  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  }]
Nov  6 02:00:29.642: INFO: ss-1  apps-114  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:29.642: INFO: ss-2  apps-114  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:29.642: INFO: 
Nov  6 02:00:29.642: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  6 02:00:30.645: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Nov  6 02:00:30.645: INFO: ss-0  apps-114  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  }]
Nov  6 02:00:30.645: INFO: ss-1  apps-114  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:30.645: INFO: ss-2  apps-114  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:30.645: INFO: 
Nov  6 02:00:30.645: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  6 02:00:31.648: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Nov  6 02:00:31.648: INFO: ss-0  apps-114  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  }]
Nov  6 02:00:31.648: INFO: ss-1  apps-114  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:31.648: INFO: ss-2  apps-114  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:31.648: INFO: 
Nov  6 02:00:31.648: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  6 02:00:32.651: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Nov  6 02:00:32.651: INFO: ss-0  apps-114  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 01:59:42 +0000 UTC  }]
Nov  6 02:00:32.651: INFO: ss-1  apps-114  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:32.651: INFO: ss-2  apps-114  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:32.651: INFO: 
Nov  6 02:00:32.651: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  6 02:00:33.668: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Nov  6 02:00:33.668: INFO: ss-1  apps-114  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:33.668: INFO: ss-2  apps-114  Running  0s     [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-06 02:00:02 +0000 UTC  }]
Nov  6 02:00:33.668: INFO: 
Nov  6 02:00:33.668: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2596
Nov  6 02:00:34.675: INFO: Scaling statefulset ss to 0
Nov  6 02:00:34.720: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  6 02:00:34.722: INFO: Deleting all statefulset in ns statefulset-2596
Nov  6 02:00:34.724: INFO: Scaling statefulset ss to 0
Nov  6 02:00:34.729: INFO: Waiting for statefulset status.replicas updated to 0
Nov  6 02:00:34.730: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:00:34.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2596" for this suite.
Nov  6 02:00:40.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:00:40.814: INFO: namespace statefulset-2596 deletion completed in 6.069134015s

• [SLOW TEST:58.325 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:00:40.815: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Nov  6 02:00:40.851: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:01:04.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3603" for this suite.
Nov  6 02:01:10.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:01:10.183: INFO: namespace crd-publish-openapi-3603 deletion completed in 6.080547014s

• [SLOW TEST:29.368 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:01:10.183: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-f1a05344-6ec8-4eda-b7c4-a24f0f2385cd
Nov  6 02:01:10.276: INFO: Pod name my-hostname-basic-f1a05344-6ec8-4eda-b7c4-a24f0f2385cd: Found 0 pods out of 1
Nov  6 02:01:15.280: INFO: Pod name my-hostname-basic-f1a05344-6ec8-4eda-b7c4-a24f0f2385cd: Found 1 pods out of 1
Nov  6 02:01:15.280: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-f1a05344-6ec8-4eda-b7c4-a24f0f2385cd" are running
Nov  6 02:01:15.282: INFO: Pod "my-hostname-basic-f1a05344-6ec8-4eda-b7c4-a24f0f2385cd-6r6jl" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-06 02:01:10 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-06 02:01:12 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-06 02:01:12 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-06 02:01:10 +0000 UTC Reason: Message:}])
Nov  6 02:01:15.282: INFO: Trying to dial the pod
Nov  6 02:01:20.290: INFO: Controller my-hostname-basic-f1a05344-6ec8-4eda-b7c4-a24f0f2385cd: Got expected result from replica 1 [my-hostname-basic-f1a05344-6ec8-4eda-b7c4-a24f0f2385cd-6r6jl]: "my-hostname-basic-f1a05344-6ec8-4eda-b7c4-a24f0f2385cd-6r6jl", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:01:20.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7950" for this suite.
Nov  6 02:01:26.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:01:26.361: INFO: namespace replication-controller-7950 deletion completed in 6.068773632s

• [SLOW TEST:16.179 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:01:26.362: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  6 02:01:29.433: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:01:29.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1255" for this suite.
Nov  6 02:01:35.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:01:35.537: INFO: namespace container-runtime-1255 deletion completed in 6.076282123s

• [SLOW TEST:9.176 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:01:35.538: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-2989
I1106 02:01:35.622263      26 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2989, replica count: 1
I1106 02:01:36.672719      26 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1106 02:01:37.672943      26 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1106 02:01:38.673173      26 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  6 02:01:38.819: INFO: Created: latency-svc-g6fk6
Nov  6 02:01:38.828: INFO: Got endpoints: latency-svc-g6fk6 [55.005397ms]
Nov  6 02:01:38.861: INFO: Created: latency-svc-ck84q
Nov  6 02:01:38.869: INFO: Got endpoints: latency-svc-ck84q [41.146758ms]
Nov  6 02:01:38.885: INFO: Created: latency-svc-kd4qw
Nov  6 02:01:38.936: INFO: Got endpoints: latency-svc-kd4qw [107.445659ms]
Nov  6 02:01:38.947: INFO: Created: latency-svc-fwmkz
Nov  6 02:01:38.955: INFO: Got endpoints: latency-svc-fwmkz [126.937414ms]
Nov  6 02:01:38.969: INFO: Created: latency-svc-x86cj
Nov  6 02:01:38.981: INFO: Got endpoints: latency-svc-x86cj [151.71136ms]
Nov  6 02:01:38.994: INFO: Created: latency-svc-2gb99
Nov  6 02:01:38.998: INFO: Got endpoints: latency-svc-2gb99 [168.933853ms]
Nov  6 02:01:39.019: INFO: Created: latency-svc-bnbv4
Nov  6 02:01:39.024: INFO: Got endpoints: latency-svc-bnbv4 [194.880317ms]
Nov  6 02:01:39.095: INFO: Created: latency-svc-8tgpz
Nov  6 02:01:39.111: INFO: Got endpoints: latency-svc-8tgpz [281.657827ms]
Nov  6 02:01:39.136: INFO: Created: latency-svc-wjhhc
Nov  6 02:01:39.145: INFO: Got endpoints: latency-svc-wjhhc [315.47581ms]
Nov  6 02:01:39.161: INFO: Created: latency-svc-54mnh
Nov  6 02:01:39.170: INFO: Got endpoints: latency-svc-54mnh [341.214643ms]
Nov  6 02:01:39.242: INFO: Created: latency-svc-s8gmr
Nov  6 02:01:39.245: INFO: Got endpoints: latency-svc-s8gmr [415.329881ms]
Nov  6 02:01:39.294: INFO: Created: latency-svc-6vnqw
Nov  6 02:01:39.331: INFO: Got endpoints: latency-svc-6vnqw [160.095056ms]
Nov  6 02:01:39.407: INFO: Created: latency-svc-mlhpp
Nov  6 02:01:39.415: INFO: Got endpoints: latency-svc-mlhpp [585.344592ms]
Nov  6 02:01:39.444: INFO: Created: latency-svc-gz72j
Nov  6 02:01:39.449: INFO: Got endpoints: latency-svc-gz72j [619.785296ms]
Nov  6 02:01:39.469: INFO: Created: latency-svc-t2hhn
Nov  6 02:01:39.475: INFO: Got endpoints: latency-svc-t2hhn [645.208251ms]
Nov  6 02:01:39.494: INFO: Created: latency-svc-xjcwx
Nov  6 02:01:39.502: INFO: Got endpoints: latency-svc-xjcwx [672.902023ms]
Nov  6 02:01:39.607: INFO: Created: latency-svc-jw9dg
Nov  6 02:01:39.636: INFO: Got endpoints: latency-svc-jw9dg [806.887969ms]
Nov  6 02:01:39.637: INFO: Created: latency-svc-cj9v9
Nov  6 02:01:39.652: INFO: Got endpoints: latency-svc-cj9v9 [783.001235ms]
Nov  6 02:01:39.669: INFO: Created: latency-svc-gvjmh
Nov  6 02:01:39.686: INFO: Got endpoints: latency-svc-gvjmh [749.756957ms]
Nov  6 02:01:39.702: INFO: Created: latency-svc-xqf8q
Nov  6 02:01:39.791: INFO: Got endpoints: latency-svc-xqf8q [835.409043ms]
Nov  6 02:01:39.793: INFO: Created: latency-svc-qrkqp
Nov  6 02:01:39.808: INFO: Got endpoints: latency-svc-qrkqp [826.757125ms]
Nov  6 02:01:39.837: INFO: Created: latency-svc-24fw4
Nov  6 02:01:39.842: INFO: Got endpoints: latency-svc-24fw4 [843.853167ms]
Nov  6 02:01:39.869: INFO: Created: latency-svc-4j7m8
Nov  6 02:01:39.877: INFO: Got endpoints: latency-svc-4j7m8 [852.52705ms]
Nov  6 02:01:40.107: INFO: Created: latency-svc-wq2r7
Nov  6 02:01:40.110: INFO: Got endpoints: latency-svc-wq2r7 [999.802785ms]
Nov  6 02:01:40.146: INFO: Created: latency-svc-z6mtg
Nov  6 02:01:40.154: INFO: Got endpoints: latency-svc-z6mtg [1.009515361s]
Nov  6 02:01:40.169: INFO: Created: latency-svc-5jpdp
Nov  6 02:01:40.180: INFO: Got endpoints: latency-svc-5jpdp [935.046415ms]
Nov  6 02:01:40.194: INFO: Created: latency-svc-dqj62
Nov  6 02:01:40.206: INFO: Got endpoints: latency-svc-dqj62 [875.497012ms]
Nov  6 02:01:40.282: INFO: Created: latency-svc-dl69b
Nov  6 02:01:40.286: INFO: Got endpoints: latency-svc-dl69b [870.965862ms]
Nov  6 02:01:40.320: INFO: Created: latency-svc-8vqd4
Nov  6 02:01:40.325: INFO: Got endpoints: latency-svc-8vqd4 [876.235374ms]
Nov  6 02:01:40.345: INFO: Created: latency-svc-w77jc
Nov  6 02:01:40.362: INFO: Got endpoints: latency-svc-w77jc [886.970696ms]
Nov  6 02:01:40.479: INFO: Created: latency-svc-mv5jb
Nov  6 02:01:40.484: INFO: Got endpoints: latency-svc-mv5jb [981.296199ms]
Nov  6 02:01:40.512: INFO: Created: latency-svc-dkkqz
Nov  6 02:01:40.523: INFO: Got endpoints: latency-svc-dkkqz [886.30912ms]
Nov  6 02:01:40.536: INFO: Created: latency-svc-l64xd
Nov  6 02:01:40.546: INFO: Got endpoints: latency-svc-l64xd [893.995946ms]
Nov  6 02:01:40.569: INFO: Created: latency-svc-qs9xt
Nov  6 02:01:40.657: INFO: Got endpoints: latency-svc-qs9xt [971.289413ms]
Nov  6 02:01:40.659: INFO: Created: latency-svc-l6dr4
Nov  6 02:01:40.673: INFO: Got endpoints: latency-svc-l6dr4 [882.399947ms]
Nov  6 02:01:40.695: INFO: Created: latency-svc-l4rl7
Nov  6 02:01:40.699: INFO: Got endpoints: latency-svc-l4rl7 [891.514878ms]
Nov  6 02:01:40.720: INFO: Created: latency-svc-5ff5r
Nov  6 02:01:40.725: INFO: Got endpoints: latency-svc-5ff5r [883.350822ms]
Nov  6 02:01:40.744: INFO: Created: latency-svc-6m57m
Nov  6 02:01:40.751: INFO: Got endpoints: latency-svc-6m57m [874.459811ms]
Nov  6 02:01:40.840: INFO: Created: latency-svc-mt7jv
Nov  6 02:01:40.843: INFO: Got endpoints: latency-svc-mt7jv [732.954289ms]
Nov  6 02:01:40.870: INFO: Created: latency-svc-lzwpj
Nov  6 02:01:40.878: INFO: Got endpoints: latency-svc-lzwpj [724.083826ms]
Nov  6 02:01:40.895: INFO: Created: latency-svc-pjdxh
Nov  6 02:01:40.906: INFO: Got endpoints: latency-svc-pjdxh [726.520363ms]
Nov  6 02:01:40.920: INFO: Created: latency-svc-rkfc8
Nov  6 02:01:40.932: INFO: Got endpoints: latency-svc-rkfc8 [725.692668ms]
Nov  6 02:01:41.015: INFO: Created: latency-svc-fhrjm
Nov  6 02:01:41.019: INFO: Got endpoints: latency-svc-fhrjm [733.131884ms]
Nov  6 02:01:41.053: INFO: Created: latency-svc-27hmt
Nov  6 02:01:41.058: INFO: Got endpoints: latency-svc-27hmt [732.989234ms]
Nov  6 02:01:41.079: INFO: Created: latency-svc-xw27k
Nov  6 02:01:41.085: INFO: Got endpoints: latency-svc-xw27k [722.913904ms]
Nov  6 02:01:41.105: INFO: Created: latency-svc-mh2nv
Nov  6 02:01:41.111: INFO: Got endpoints: latency-svc-mh2nv [627.116568ms]
Nov  6 02:01:41.198: INFO: Created: latency-svc-v648c
Nov  6 02:01:41.202: INFO: Got endpoints: latency-svc-v648c [679.434797ms]
Nov  6 02:01:41.228: INFO: Created: latency-svc-z2hnd
Nov  6 02:01:41.237: INFO: Got endpoints: latency-svc-z2hnd [690.57581ms]
Nov  6 02:01:41.253: INFO: Created: latency-svc-4z7w2
Nov  6 02:01:41.263: INFO: Got endpoints: latency-svc-4z7w2 [606.168805ms]
Nov  6 02:01:41.279: INFO: Created: latency-svc-k9bcv
Nov  6 02:01:41.282: INFO: Got endpoints: latency-svc-k9bcv [608.362609ms]
Nov  6 02:01:41.382: INFO: Created: latency-svc-hv9rd
Nov  6 02:01:41.386: INFO: Got endpoints: latency-svc-hv9rd [686.526099ms]
Nov  6 02:01:41.462: INFO: Created: latency-svc-tqn2n
Nov  6 02:01:41.468: INFO: Got endpoints: latency-svc-tqn2n [742.526015ms]
Nov  6 02:01:41.541: INFO: Created: latency-svc-vrjnt
Nov  6 02:01:41.544: INFO: Got endpoints: latency-svc-vrjnt [792.588977ms]
Nov  6 02:01:41.578: INFO: Created: latency-svc-ns7rs
Nov  6 02:01:41.586: INFO: Got endpoints: latency-svc-ns7rs [742.427511ms]
Nov  6 02:01:41.603: INFO: Created: latency-svc-kbkb8
Nov  6 02:01:41.612: INFO: Got endpoints: latency-svc-kbkb8 [733.839135ms]
Nov  6 02:01:41.628: INFO: Created: latency-svc-z4rs2
Nov  6 02:01:41.638: INFO: Got endpoints: latency-svc-z4rs2 [731.916786ms]
Nov  6 02:01:41.723: INFO: Created: latency-svc-d29c4
Nov  6 02:01:41.727: INFO: Got endpoints: latency-svc-d29c4 [794.908675ms]
Nov  6 02:01:41.761: INFO: Created: latency-svc-s7k2r
Nov  6 02:01:41.766: INFO: Got endpoints: latency-svc-s7k2r [747.435903ms]
Nov  6 02:01:41.787: INFO: Created: latency-svc-kwhtg
Nov  6 02:01:41.792: INFO: Got endpoints: latency-svc-kwhtg [733.676973ms]
Nov  6 02:01:41.812: INFO: Created: latency-svc-bntth
Nov  6 02:01:41.818: INFO: Got endpoints: latency-svc-bntth [733.467189ms]
Nov  6 02:01:41.900: INFO: Created: latency-svc-kldm4
Nov  6 02:01:41.902: INFO: Got endpoints: latency-svc-kldm4 [791.169284ms]
Nov  6 02:01:41.945: INFO: Created: latency-svc-hxwk7
Nov  6 02:01:41.956: INFO: Got endpoints: latency-svc-hxwk7 [754.115058ms]
Nov  6 02:01:41.970: INFO: Created: latency-svc-vk4qm
Nov  6 02:01:41.980: INFO: Got endpoints: latency-svc-vk4qm [742.718014ms]
Nov  6 02:01:42.075: INFO: Created: latency-svc-8hn7r
Nov  6 02:01:42.089: INFO: Got endpoints: latency-svc-8hn7r [825.433393ms]
Nov  6 02:01:42.103: INFO: Created: latency-svc-8lmjh
Nov  6 02:01:42.115: INFO: Got endpoints: latency-svc-8lmjh [833.448749ms]
Nov  6 02:01:42.129: INFO: Created: latency-svc-t45g6
Nov  6 02:01:42.133: INFO: Got endpoints: latency-svc-t45g6 [747.035121ms]
Nov  6 02:01:42.153: INFO: Created: latency-svc-s2ksz
Nov  6 02:01:42.160: INFO: Got endpoints: latency-svc-s2ksz [691.969834ms]
Nov  6 02:01:42.249: INFO: Created: latency-svc-4mbjk
Nov  6 02:01:42.252: INFO: Got endpoints: latency-svc-4mbjk [708.542126ms]
Nov  6 02:01:42.295: INFO: Created: latency-svc-cqhqq
Nov  6 02:01:42.312: INFO: Got endpoints: latency-svc-cqhqq [726.026769ms]
Nov  6 02:01:42.329: INFO: Created: latency-svc-bmst5
Nov  6 02:01:42.346: INFO: Got endpoints: latency-svc-bmst5 [733.299364ms]
Nov  6 02:01:42.457: INFO: Created: latency-svc-ktbpb
Nov  6 02:01:42.460: INFO: Got endpoints: latency-svc-ktbpb [821.904561ms]
Nov  6 02:01:42.487: INFO: Created: latency-svc-qbw24
Nov  6 02:01:42.498: INFO: Got endpoints: latency-svc-qbw24 [771.173502ms]
Nov  6 02:01:42.512: INFO: Created: latency-svc-x2g68
Nov  6 02:01:42.516: INFO: Got endpoints: latency-svc-x2g68 [749.821139ms]
Nov  6 02:01:42.538: INFO: Created: latency-svc-qpr7t
Nov  6 02:01:42.543: INFO: Got endpoints: latency-svc-qpr7t [750.784607ms]
Nov  6 02:01:42.648: INFO: Created: latency-svc-hmqbg
Nov  6 02:01:42.652: INFO: Got endpoints: latency-svc-hmqbg [833.763541ms]
Nov  6 02:01:42.679: INFO: Created: latency-svc-n9l7c
Nov  6 02:01:42.686: INFO: Got endpoints: latency-svc-n9l7c [784.478732ms]
Nov  6 02:01:42.703: INFO: Created: latency-svc-65wlj
Nov  6 02:01:42.712: INFO: Got endpoints: latency-svc-65wlj [756.061219ms]
Nov  6 02:01:42.729: INFO: Created: latency-svc-vqmp9
Nov  6 02:01:42.739: INFO: Got endpoints: latency-svc-vqmp9 [758.969621ms]
Nov  6 02:01:42.807: INFO: Created: latency-svc-jwcmg
Nov  6 02:01:42.810: INFO: Got endpoints: latency-svc-jwcmg [720.88472ms]
Nov  6 02:01:42.845: INFO: Created: latency-svc-65d9h
Nov  6 02:01:42.862: INFO: Got endpoints: latency-svc-65d9h [746.568032ms]
Nov  6 02:01:42.879: INFO: Created: latency-svc-s65ld
Nov  6 02:01:42.895: INFO: Got endpoints: latency-svc-s65ld [762.302332ms]
Nov  6 02:01:42.982: INFO: Created: latency-svc-xr6wn
Nov  6 02:01:42.985: INFO: Got endpoints: latency-svc-xr6wn [825.199888ms]
Nov  6 02:01:43.021: INFO: Created: latency-svc-n7sxv
Nov  6 02:01:43.029: INFO: Got endpoints: latency-svc-n7sxv [776.57878ms]
Nov  6 02:01:43.048: INFO: Created: latency-svc-t7wmx
Nov  6 02:01:43.079: INFO: Created: latency-svc-jg99m
Nov  6 02:01:43.080: INFO: Got endpoints: latency-svc-t7wmx [767.663102ms]
Nov  6 02:01:43.157: INFO: Got endpoints: latency-svc-jg99m [811.605564ms]
Nov  6 02:01:43.160: INFO: Created: latency-svc-c8sfr
Nov  6 02:01:43.174: INFO: Got endpoints: latency-svc-c8sfr [713.444253ms]
Nov  6 02:01:43.203: INFO: Created: latency-svc-qcrng
Nov  6 02:01:43.208: INFO: Got endpoints: latency-svc-qcrng [710.027512ms]
Nov  6 02:01:43.221: INFO: Created: latency-svc-bbm2d
Nov  6 02:01:43.225: INFO: Got endpoints: latency-svc-bbm2d [708.365491ms]
Nov  6 02:01:43.255: INFO: Created: latency-svc-pck8f
Nov  6 02:01:43.349: INFO: Got endpoints: latency-svc-pck8f [805.847886ms]
Nov  6 02:01:43.351: INFO: Created: latency-svc-v8jxz
Nov  6 02:01:43.387: INFO: Got endpoints: latency-svc-v8jxz [735.46839ms]
Nov  6 02:01:43.404: INFO: Created: latency-svc-8w2qg
Nov  6 02:01:43.420: INFO: Got endpoints: latency-svc-8w2qg [733.925731ms]
Nov  6 02:01:43.438: INFO: Created: latency-svc-xb425
Nov  6 02:01:43.515: INFO: Got endpoints: latency-svc-xb425 [802.559679ms]
Nov  6 02:01:43.518: INFO: Created: latency-svc-kc2j2
Nov  6 02:01:43.531: INFO: Got endpoints: latency-svc-kc2j2 [792.302547ms]
Nov  6 02:01:43.549: INFO: Created: latency-svc-m4wfm
Nov  6 02:01:43.557: INFO: Got endpoints: latency-svc-m4wfm [747.036593ms]
Nov  6 02:01:43.570: INFO: Created: latency-svc-87h5l
Nov  6 02:01:43.574: INFO: Got endpoints: latency-svc-87h5l [712.506879ms]
Nov  6 02:01:43.604: INFO: Created: latency-svc-7m6gn
Nov  6 02:01:43.609: INFO: Got endpoints: latency-svc-7m6gn [713.488068ms]
Nov  6 02:01:43.690: INFO: Created: latency-svc-mkwpf
Nov  6 02:01:43.693: INFO: Got endpoints: latency-svc-mkwpf [708.035996ms]
Nov  6 02:01:43.737: INFO: Created: latency-svc-n7lqf
Nov  6 02:01:43.754: INFO: Got endpoints: latency-svc-n7lqf [725.245787ms]
Nov  6 02:01:43.771: INFO: Created: latency-svc-kbqc4
Nov  6 02:01:43.778: INFO: Got endpoints: latency-svc-kbqc4 [698.659395ms]
Nov  6 02:01:43.848: INFO: Created: latency-svc-nfj62
Nov  6 02:01:43.851: INFO: Got endpoints: latency-svc-nfj62 [693.768092ms]
Nov  6 02:01:43.879: INFO: Created: latency-svc-kt9nf
Nov  6 02:01:43.890: INFO: Got endpoints: latency-svc-kt9nf [716.660226ms]
Nov  6 02:01:43.905: INFO: Created: latency-svc-f5j5g
Nov  6 02:01:43.916: INFO: Got endpoints: latency-svc-f5j5g [707.935764ms]
Nov  6 02:01:43.938: INFO: Created: latency-svc-6skvb
Nov  6 02:01:44.023: INFO: Got endpoints: latency-svc-6skvb [798.77355ms]
Nov  6 02:01:44.023: INFO: Created: latency-svc-rgx99
Nov  6 02:01:44.028: INFO: Got endpoints: latency-svc-rgx99 [679.006794ms]
Nov  6 02:01:44.064: INFO: Created: latency-svc-rfqpb
Nov  6 02:01:44.069: INFO: Got endpoints: latency-svc-rfqpb [681.904851ms]
Nov  6 02:01:44.088: INFO: Created: latency-svc-qq8mj
Nov  6 02:01:44.096: INFO: Got endpoints: latency-svc-qq8mj [676.036017ms]
Nov  6 02:01:44.113: INFO: Created: latency-svc-cv4p2
Nov  6 02:01:44.124: INFO: Got endpoints: latency-svc-cv4p2 [608.539677ms]
Nov  6 02:01:44.198: INFO: Created: latency-svc-znnj5
Nov  6 02:01:44.202: INFO: Got endpoints: latency-svc-znnj5 [670.752911ms]
Nov  6 02:01:44.238: INFO: Created: latency-svc-xldbg
Nov  6 02:01:44.249: INFO: Got endpoints: latency-svc-xldbg [692.207767ms]
Nov  6 02:01:44.263: INFO: Created: latency-svc-nrlpq
Nov  6 02:01:44.279: INFO: Got endpoints: latency-svc-nrlpq [704.867368ms]
Nov  6 02:01:44.373: INFO: Created: latency-svc-929vk
Nov  6 02:01:44.377: INFO: Got endpoints: latency-svc-929vk [767.784985ms]
Nov  6 02:01:44.413: INFO: Created: latency-svc-9f558
Nov  6 02:01:44.419: INFO: Got endpoints: latency-svc-9f558 [726.30289ms]
Nov  6 02:01:44.438: INFO: Created: latency-svc-brf4w
Nov  6 02:01:44.444: INFO: Got endpoints: latency-svc-brf4w [690.230651ms]
Nov  6 02:01:44.464: INFO: Created: latency-svc-pxbm5
Nov  6 02:01:44.472: INFO: Got endpoints: latency-svc-pxbm5 [693.299614ms]
Nov  6 02:01:44.565: INFO: Created: latency-svc-gl6tz
Nov  6 02:01:44.588: INFO: Created: latency-svc-2khh7
Nov  6 02:01:44.588: INFO: Got endpoints: latency-svc-gl6tz [737.252905ms]
Nov  6 02:01:44.597: INFO: Got endpoints: latency-svc-2khh7 [707.083251ms]
Nov  6 02:01:44.613: INFO: Created: latency-svc-k4ns2
Nov  6 02:01:44.616: INFO: Got endpoints: latency-svc-k4ns2 [700.27057ms]
Nov  6 02:01:44.646: INFO: Created: latency-svc-fqxhm
Nov  6 02:01:44.651: INFO: Got endpoints: latency-svc-fqxhm [627.596838ms]
Nov  6 02:01:44.732: INFO: Created: latency-svc-dhpmv
Nov  6 02:01:44.735: INFO: Got endpoints: latency-svc-dhpmv [707.404776ms]
Nov  6 02:01:44.773: INFO: Created: latency-svc-crvb6
Nov  6 02:01:44.778: INFO: Got endpoints: latency-svc-crvb6 [708.297899ms]
Nov  6 02:01:44.797: INFO: Created: latency-svc-rp9cp
Nov  6 02:01:44.804: INFO: Got endpoints: latency-svc-rp9cp [707.792146ms]
Nov  6 02:01:44.822: INFO: Created: latency-svc-ml2dn
Nov  6 02:01:44.907: INFO: Got endpoints: latency-svc-ml2dn [783.345057ms]
Nov  6 02:01:44.912: INFO: Created: latency-svc-sdqwf
Nov  6 02:01:44.931: INFO: Got endpoints: latency-svc-sdqwf [728.595536ms]
Nov  6 02:01:44.947: INFO: Created: latency-svc-znnnc
Nov  6 02:01:44.958: INFO: Got endpoints: latency-svc-znnnc [708.318876ms]
Nov  6 02:01:44.971: INFO: Created: latency-svc-twd5q
Nov  6 02:01:44.976: INFO: Got endpoints: latency-svc-twd5q [696.684539ms]
Nov  6 02:01:44.996: INFO: Created: latency-svc-7d6lv
Nov  6 02:01:45.002: INFO: Got endpoints: latency-svc-7d6lv [625.785189ms]
Nov  6 02:01:45.091: INFO: Created: latency-svc-6w57v
Nov  6 02:01:45.103: INFO: Got endpoints: latency-svc-6w57v [684.157455ms]
Nov  6 02:01:45.122: INFO: Created: latency-svc-kb6xw
Nov  6 02:01:45.129: INFO: Got endpoints: latency-svc-kb6xw [684.150063ms]
Nov  6 02:01:45.146: INFO: Created: latency-svc-n5dqz
Nov  6 02:01:45.155: INFO: Got endpoints: latency-svc-n5dqz [683.178121ms]
Nov  6 02:01:45.172: INFO: Created: latency-svc-j7wkr
Nov  6 02:01:45.181: INFO: Got endpoints: latency-svc-j7wkr [592.629468ms]
Nov  6 02:01:45.265: INFO: Created: latency-svc-ngzzx
Nov  6 02:01:45.268: INFO: Got endpoints: latency-svc-ngzzx [670.767351ms]
Nov  6 02:01:45.305: INFO: Created: latency-svc-95qdm
Nov  6 02:01:45.316: INFO: Got endpoints: latency-svc-95qdm [700.0499ms]
Nov  6 02:01:45.330: INFO: Created: latency-svc-kkb29
Nov  6 02:01:45.338: INFO: Got endpoints: latency-svc-kkb29 [687.01595ms]
Nov  6 02:01:45.440: INFO: Created: latency-svc-2zskp
Nov  6 02:01:45.445: INFO: Got endpoints: latency-svc-2zskp [709.491917ms]
Nov  6 02:01:45.480: INFO: Created: latency-svc-gtkcd
Nov  6 02:01:45.487: INFO: Got endpoints: latency-svc-gtkcd [709.128919ms]
Nov  6 02:01:45.515: INFO: Created: latency-svc-7vzjk
Nov  6 02:01:45.522: INFO: Got endpoints: latency-svc-7vzjk [717.933196ms]
Nov  6 02:01:45.598: INFO: Created: latency-svc-6zrgt
Nov  6 02:01:45.614: INFO: Got endpoints: latency-svc-6zrgt [707.420427ms]
Nov  6 02:01:45.630: INFO: Created: latency-svc-krcxb
Nov  6 02:01:45.640: INFO: Got endpoints: latency-svc-krcxb [709.330686ms]
Nov  6 02:01:45.655: INFO: Created: latency-svc-5g79w
Nov  6 02:01:45.666: INFO: Got endpoints: latency-svc-5g79w [708.017656ms]
Nov  6 02:01:45.680: INFO: Created: latency-svc-qx7ms
Nov  6 02:01:45.782: INFO: Got endpoints: latency-svc-qx7ms [805.618841ms]
Nov  6 02:01:45.783: INFO: Created: latency-svc-hnf8k
Nov  6 02:01:45.793: INFO: Got endpoints: latency-svc-hnf8k [790.641466ms]
Nov  6 02:01:45.814: INFO: Created: latency-svc-p2n4j
Nov  6 02:01:45.820: INFO: Got endpoints: latency-svc-p2n4j [716.327269ms]
Nov  6 02:01:45.838: INFO: Created: latency-svc-kg44g
Nov  6 02:01:45.846: INFO: Got endpoints: latency-svc-kg44g [717.192396ms]
Nov  6 02:01:45.863: INFO: Created: latency-svc-7g54g
Nov  6 02:01:45.872: INFO: Got endpoints: latency-svc-7g54g [717.497702ms]
Nov  6 02:01:45.948: INFO: Created: latency-svc-rc2dw
Nov  6 02:01:45.952: INFO: Got endpoints: latency-svc-rc2dw [770.795628ms]
Nov  6 02:01:45.981: INFO: Created: latency-svc-mfljk
Nov  6 02:01:45.990: INFO: Got endpoints: latency-svc-mfljk [722.111593ms]
Nov  6 02:01:46.006: INFO: Created: latency-svc-jzrf4
Nov  6 02:01:46.017: INFO: Got endpoints: latency-svc-jzrf4 [700.381038ms]
Nov  6 02:01:46.039: INFO: Created: latency-svc-gmmvm
Nov  6 02:01:46.132: INFO: Got endpoints: latency-svc-gmmvm [793.441447ms]
Nov  6 02:01:46.134: INFO: Created: latency-svc-plp5m
Nov  6 02:01:46.144: INFO: Got endpoints: latency-svc-plp5m [698.795711ms]
Nov  6 02:01:46.164: INFO: Created: latency-svc-zfj9f
Nov  6 02:01:46.170: INFO: Got endpoints: latency-svc-zfj9f [682.694311ms]
Nov  6 02:01:46.188: INFO: Created: latency-svc-dkr9s
Nov  6 02:01:46.198: INFO: Got endpoints: latency-svc-dkr9s [675.764835ms]
Nov  6 02:01:46.213: INFO: Created: latency-svc-n4b4q
Nov  6 02:01:46.224: INFO: Got endpoints: latency-svc-n4b4q [609.21992ms]
Nov  6 02:01:46.307: INFO: Created: latency-svc-vdgzl
Nov  6 02:01:46.314: INFO: Got endpoints: latency-svc-vdgzl [673.782029ms]
Nov  6 02:01:46.339: INFO: Created: latency-svc-qlkkm
Nov  6 02:01:46.350: INFO: Got endpoints: latency-svc-qlkkm [684.131567ms]
Nov  6 02:01:46.364: INFO: Created: latency-svc-m97kc
Nov  6 02:01:46.367: INFO: Got endpoints: latency-svc-m97kc [585.547219ms]
Nov  6 02:01:46.405: INFO: Created: latency-svc-mlx5z
Nov  6 02:01:46.490: INFO: Got endpoints: latency-svc-mlx5z [696.750129ms]
Nov  6 02:01:46.492: INFO: Created: latency-svc-tmvmf
Nov  6 02:01:46.503: INFO: Got endpoints: latency-svc-tmvmf [683.278953ms]
Nov  6 02:01:46.522: INFO: Created: latency-svc-9rxlg
Nov  6 02:01:46.530: INFO: Got endpoints: latency-svc-9rxlg [683.726776ms]
Nov  6 02:01:46.547: INFO: Created: latency-svc-b58rc
Nov  6 02:01:46.556: INFO: Got endpoints: latency-svc-b58rc [683.446994ms]
Nov  6 02:01:46.572: INFO: Created: latency-svc-mffxw
Nov  6 02:01:46.583: INFO: Got endpoints: latency-svc-mffxw [631.421238ms]
Nov  6 02:01:46.673: INFO: Created: latency-svc-t7vk6
Nov  6 02:01:46.676: INFO: Got endpoints: latency-svc-t7vk6 [686.007668ms]
Nov  6 02:01:46.706: INFO: Created: latency-svc-jdd9b
Nov  6 02:01:46.709: INFO: Got endpoints: latency-svc-jdd9b [692.369279ms]
Nov  6 02:01:46.739: INFO: Created: latency-svc-rl4lg
Nov  6 02:01:46.744: INFO: Got endpoints: latency-svc-rl4lg [612.15718ms]
Nov  6 02:01:46.774: INFO: Created: latency-svc-gmfnv
Nov  6 02:01:46.857: INFO: Got endpoints: latency-svc-gmfnv [713.57466ms]
Nov  6 02:01:46.858: INFO: Created: latency-svc-n7ssh
Nov  6 02:01:46.880: INFO: Got endpoints: latency-svc-n7ssh [710.599261ms]
Nov  6 02:01:46.914: INFO: Created: latency-svc-hxdxr
Nov  6 02:01:46.921: INFO: Got endpoints: latency-svc-hxdxr [722.971225ms]
Nov  6 02:01:46.939: INFO: Created: latency-svc-jbb9z
Nov  6 02:01:47.048: INFO: Got endpoints: latency-svc-jbb9z [824.683871ms]
Nov  6 02:01:47.050: INFO: Created: latency-svc-2sr94
Nov  6 02:01:47.067: INFO: Got endpoints: latency-svc-2sr94 [753.081297ms]
Nov  6 02:01:47.081: INFO: Created: latency-svc-pvg7g
Nov  6 02:01:47.092: INFO: Got endpoints: latency-svc-pvg7g [742.282806ms]
Nov  6 02:01:47.106: INFO: Created: latency-svc-lhvxx
Nov  6 02:01:47.114: INFO: Got endpoints: latency-svc-lhvxx [747.194406ms]
Nov  6 02:01:47.139: INFO: Created: latency-svc-tngrt
Nov  6 02:01:47.144: INFO: Got endpoints: latency-svc-tngrt [654.233903ms]
Nov  6 02:01:47.224: INFO: Created: latency-svc-rc7t9
Nov  6 02:01:47.226: INFO: Got endpoints: latency-svc-rc7t9 [723.084896ms]
Nov  6 02:01:47.256: INFO: Created: latency-svc-bgmlq
Nov  6 02:01:47.263: INFO: Got endpoints: latency-svc-bgmlq [733.331494ms]
Nov  6 02:01:47.281: INFO: Created: latency-svc-4qc45
Nov  6 02:01:47.289: INFO: Got endpoints: latency-svc-4qc45 [732.910547ms]
Nov  6 02:01:47.306: INFO: Created: latency-svc-77g26
Nov  6 02:01:47.315: INFO: Got endpoints: latency-svc-77g26 [732.126785ms]
Nov  6 02:01:47.390: INFO: Created: latency-svc-wws4g
Nov  6 02:01:47.394: INFO: Got endpoints: latency-svc-wws4g [717.953982ms]
Nov  6 02:01:47.425: INFO: Created: latency-svc-5kqz7
Nov  6 02:01:47.427: INFO: Got endpoints: latency-svc-5kqz7 [717.439015ms]
Nov  6 02:01:47.456: INFO: Created: latency-svc-57mcn
Nov  6 02:01:47.461: INFO: Got endpoints: latency-svc-57mcn [717.022252ms]
Nov  6 02:01:47.482: INFO: Created: latency-svc-nsqjr
Nov  6 02:01:47.486: INFO: Got endpoints: latency-svc-nsqjr [629.158366ms]
Nov  6 02:01:47.575: INFO: Created: latency-svc-tmksq
Nov  6 02:01:47.579: INFO: Got endpoints: latency-svc-tmksq [698.369993ms]
Nov  6 02:01:47.607: INFO: Created: latency-svc-9ml7q
Nov  6 02:01:47.615: INFO: Got endpoints: latency-svc-9ml7q [694.31064ms]
Nov  6 02:01:47.632: INFO: Created: latency-svc-kjk6p
Nov  6 02:01:47.640: INFO: Got endpoints: latency-svc-kjk6p [591.190184ms]
Nov  6 02:01:47.657: INFO: Created: latency-svc-md79s
Nov  6 02:01:47.665: INFO: Got endpoints: latency-svc-md79s [598.440226ms]
Nov  6 02:01:47.740: INFO: Created: latency-svc-4nvrf
Nov  6 02:01:47.743: INFO: Got endpoints: latency-svc-4nvrf [650.892928ms]
Nov  6 02:01:47.774: INFO: Created: latency-svc-5h4x9
Nov  6 02:01:47.777: INFO: Got endpoints: latency-svc-5h4x9 [662.530421ms]
Nov  6 02:01:47.807: INFO: Created: latency-svc-mhmvf
Nov  6 02:01:47.812: INFO: Got endpoints: latency-svc-mhmvf [668.197375ms]
Nov  6 02:01:47.832: INFO: Created: latency-svc-94p7n
Nov  6 02:01:47.837: INFO: Got endpoints: latency-svc-94p7n [611.101426ms]
Nov  6 02:01:47.923: INFO: Created: latency-svc-4wvr6
Nov  6 02:01:47.927: INFO: Got endpoints: latency-svc-4wvr6 [663.630367ms]
Nov  6 02:01:47.966: INFO: Created: latency-svc-454mj
Nov  6 02:01:47.972: INFO: Got endpoints: latency-svc-454mj [683.448662ms]
Nov  6 02:01:47.991: INFO: Created: latency-svc-tswrh
Nov  6 02:01:47.999: INFO: Got endpoints: latency-svc-tswrh [683.539957ms]
Nov  6 02:01:48.016: INFO: Created: latency-svc-pnrjz
Nov  6 02:01:48.106: INFO: Got endpoints: latency-svc-pnrjz [711.600534ms]
Nov  6 02:01:48.108: INFO: Created: latency-svc-k7dgc
Nov  6 02:01:48.117: INFO: Got endpoints: latency-svc-k7dgc [690.358783ms]
Nov  6 02:01:48.132: INFO: Created: latency-svc-5k664
Nov  6 02:01:48.140: INFO: Got endpoints: latency-svc-5k664 [678.982373ms]
Nov  6 02:01:48.159: INFO: Created: latency-svc-2jb7s
Nov  6 02:01:48.163: INFO: Got endpoints: latency-svc-2jb7s [676.101782ms]
Nov  6 02:01:48.182: INFO: Created: latency-svc-rrtd5
Nov  6 02:01:48.188: INFO: Got endpoints: latency-svc-rrtd5 [609.327703ms]
Nov  6 02:01:48.273: INFO: Created: latency-svc-m5dw8
Nov  6 02:01:48.276: INFO: Got endpoints: latency-svc-m5dw8 [660.60205ms]
Nov  6 02:01:48.307: INFO: Created: latency-svc-f62s8
Nov  6 02:01:48.315: INFO: Got endpoints: latency-svc-f62s8 [675.571445ms]
Nov  6 02:01:48.332: INFO: Created: latency-svc-sckc6
Nov  6 02:01:48.341: INFO: Got endpoints: latency-svc-sckc6 [676.114132ms]
Nov  6 02:01:48.357: INFO: Created: latency-svc-2w7rx
Nov  6 02:01:48.368: INFO: Got endpoints: latency-svc-2w7rx [624.47105ms]
Nov  6 02:01:48.440: INFO: Created: latency-svc-8mnh2
Nov  6 02:01:48.444: INFO: Got endpoints: latency-svc-8mnh2 [666.825008ms]
Nov  6 02:01:48.483: INFO: Created: latency-svc-t2q2d
Nov  6 02:01:48.487: INFO: Got endpoints: latency-svc-t2q2d [674.936082ms]
Nov  6 02:01:48.487: INFO: Latencies: [41.146758ms 107.445659ms 126.937414ms 151.71136ms 160.095056ms 168.933853ms 194.880317ms 281.657827ms 315.47581ms 341.214643ms 415.329881ms 585.344592ms 585.547219ms 591.190184ms 592.629468ms 598.440226ms 606.168805ms 608.362609ms 608.539677ms 609.21992ms 609.327703ms 611.101426ms 612.15718ms 619.785296ms 624.47105ms 625.785189ms 627.116568ms 627.596838ms 629.158366ms 631.421238ms 645.208251ms 650.892928ms 654.233903ms 660.60205ms 662.530421ms 663.630367ms 666.825008ms 668.197375ms 670.752911ms 670.767351ms 672.902023ms 673.782029ms 674.936082ms 675.571445ms 675.764835ms 676.036017ms 676.101782ms 676.114132ms 678.982373ms 679.006794ms 679.434797ms 681.904851ms 682.694311ms 683.178121ms 683.278953ms 683.446994ms 683.448662ms 683.539957ms 683.726776ms 684.131567ms 684.150063ms 684.157455ms 686.007668ms 686.526099ms 687.01595ms 690.230651ms 690.358783ms 690.57581ms 691.969834ms 692.207767ms 692.369279ms 693.299614ms 693.768092ms 694.31064ms 696.684539ms 696.750129ms 698.369993ms 698.659395ms 698.795711ms 700.0499ms 700.27057ms 700.381038ms 704.867368ms 707.083251ms 707.404776ms 707.420427ms 707.792146ms 707.935764ms 708.017656ms 708.035996ms 708.297899ms 708.318876ms 708.365491ms 708.542126ms 709.128919ms 709.330686ms 709.491917ms 710.027512ms 710.599261ms 711.600534ms 712.506879ms 713.444253ms 713.488068ms 713.57466ms 716.327269ms 716.660226ms 717.022252ms 717.192396ms 717.439015ms 717.497702ms 717.933196ms 717.953982ms 720.88472ms 722.111593ms 722.913904ms 722.971225ms 723.084896ms 724.083826ms 725.245787ms 725.692668ms 726.026769ms 726.30289ms 726.520363ms 728.595536ms 731.916786ms 732.126785ms 732.910547ms 732.954289ms 732.989234ms 733.131884ms 733.299364ms 733.331494ms 733.467189ms 733.676973ms 733.839135ms 733.925731ms 735.46839ms 737.252905ms 742.282806ms 742.427511ms 742.526015ms 742.718014ms 746.568032ms 747.035121ms 747.036593ms 747.194406ms 747.435903ms 749.756957ms 749.821139ms 750.784607ms 753.081297ms 754.115058ms 756.061219ms 758.969621ms 762.302332ms 767.663102ms 767.784985ms 770.795628ms 771.173502ms 776.57878ms 783.001235ms 783.345057ms 784.478732ms 790.641466ms 791.169284ms 792.302547ms 792.588977ms 793.441447ms 794.908675ms 798.77355ms 802.559679ms 805.618841ms 805.847886ms 806.887969ms 811.605564ms 821.904561ms 824.683871ms 825.199888ms 825.433393ms 826.757125ms 833.448749ms 833.763541ms 835.409043ms 843.853167ms 852.52705ms 870.965862ms 874.459811ms 875.497012ms 876.235374ms 882.399947ms 883.350822ms 886.30912ms 886.970696ms 891.514878ms 893.995946ms 935.046415ms 971.289413ms 981.296199ms 999.802785ms 1.009515361s]
Nov  6 02:01:48.487: INFO: 50 %ile: 712.506879ms
Nov  6 02:01:48.487: INFO: 90 %ile: 833.448749ms
Nov  6 02:01:48.487: INFO: 99 %ile: 999.802785ms
Nov  6 02:01:48.487: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:01:48.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-2989" for this suite.
Nov  6 02:02:16.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:02:16.555: INFO: namespace svc-latency-2989 deletion completed in 28.058791462s

• [SLOW TEST:41.018 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:02:16.556: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-651
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-651
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-651
Nov  6 02:02:16.632: INFO: Found 0 stateful pods, waiting for 1
Nov  6 02:02:26.636: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Nov  6 02:02:26.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=statefulset-651 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  6 02:02:26.906: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  6 02:02:26.906: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  6 02:02:26.906: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  6 02:02:26.909: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov  6 02:02:36.912: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  6 02:02:36.912: INFO: Waiting for statefulset status.replicas updated to 0
Nov  6 02:02:36.929: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999973s
Nov  6 02:02:37.933: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.988504808s
Nov  6 02:02:38.935: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.985431559s
Nov  6 02:02:39.939: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.982672962s
Nov  6 02:02:40.942: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.978993157s
Nov  6 02:02:41.945: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.976071038s
Nov  6 02:02:42.948: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.973045332s
Nov  6 02:02:43.951: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.970171138s
Nov  6 02:02:44.954: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.967178861s
Nov  6 02:02:45.957: INFO: Verifying statefulset ss doesn't scale past 1 for another 964.102123ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-651
Nov  6 02:02:46.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=statefulset-651 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  6 02:02:47.201: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  6 02:02:47.201: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  6 02:02:47.201: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  6 02:02:47.214: INFO: Found 1 stateful pods, waiting for 3
Nov  6 02:02:57.218: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  6 02:02:57.218: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  6 02:02:57.218: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Nov  6 02:02:57.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=statefulset-651 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  6 02:02:57.467: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  6 02:02:57.467: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  6 02:02:57.467: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  6 02:02:57.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=statefulset-651 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  6 02:02:57.733: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  6 02:02:57.733: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  6 02:02:57.733: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  6 02:02:57.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=statefulset-651 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  6 02:02:58.021: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  6 02:02:58.021: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  6 02:02:58.021: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  6 02:02:58.021: INFO: Waiting for statefulset status.replicas updated to 0
Nov  6 02:02:58.023: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Nov  6 02:03:08.029: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  6 02:03:08.029: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  6 02:03:08.029: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  6 02:03:08.039: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999969s
Nov  6 02:03:09.043: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993567999s
Nov  6 02:03:10.047: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98988096s
Nov  6 02:03:11.050: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986149299s
Nov  6 02:03:12.053: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982663321s
Nov  6 02:03:13.057: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.979559946s
Nov  6 02:03:14.060: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.976162542s
Nov  6 02:03:15.064: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.972563317s
Nov  6 02:03:16.067: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.969013437s
Nov  6 02:03:17.070: INFO: Verifying statefulset ss doesn't scale past 3 for another 965.896652ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-651
Nov  6 02:03:18.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=statefulset-651 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  6 02:03:18.341: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  6 02:03:18.341: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  6 02:03:18.341: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  6 02:03:18.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=statefulset-651 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  6 02:03:18.603: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  6 02:03:18.603: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  6 02:03:18.603: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  6 02:03:18.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=statefulset-651 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  6 02:03:18.851: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  6 02:03:18.851: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  6 02:03:18.851: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  6 02:03:18.851: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  6 02:03:38.861: INFO: Deleting all statefulset in ns statefulset-651
Nov  6 02:03:38.863: INFO: Scaling statefulset ss to 0
Nov  6 02:03:38.868: INFO: Waiting for statefulset status.replicas updated to 0
Nov  6 02:03:38.870: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:03:38.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-651" for this suite.
Nov  6 02:03:44.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:03:44.989: INFO: namespace statefulset-651 deletion completed in 6.096522658s

• [SLOW TEST:88.434 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:03:44.989: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-a2e3e26d-16fc-4014-a9f3-6e69bf660388
STEP: Creating a pod to test consume secrets
Nov  6 02:03:45.049: INFO: Waiting up to 5m0s for pod "pod-secrets-5b2ff042-42f2-466a-8ab7-e8bc1a6bc432" in namespace "secrets-5906" to be "success or failure"
Nov  6 02:03:45.062: INFO: Pod "pod-secrets-5b2ff042-42f2-466a-8ab7-e8bc1a6bc432": Phase="Pending", Reason="", readiness=false. Elapsed: 13.748256ms
Nov  6 02:03:47.065: INFO: Pod "pod-secrets-5b2ff042-42f2-466a-8ab7-e8bc1a6bc432": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016099721s
Nov  6 02:03:49.068: INFO: Pod "pod-secrets-5b2ff042-42f2-466a-8ab7-e8bc1a6bc432": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019153631s
STEP: Saw pod success
Nov  6 02:03:49.068: INFO: Pod "pod-secrets-5b2ff042-42f2-466a-8ab7-e8bc1a6bc432" satisfied condition "success or failure"
Nov  6 02:03:49.070: INFO: Trying to get logs from node apps-114 pod pod-secrets-5b2ff042-42f2-466a-8ab7-e8bc1a6bc432 container secret-volume-test: <nil>
STEP: delete the pod
Nov  6 02:03:49.082: INFO: Waiting for pod pod-secrets-5b2ff042-42f2-466a-8ab7-e8bc1a6bc432 to disappear
Nov  6 02:03:49.089: INFO: Pod pod-secrets-5b2ff042-42f2-466a-8ab7-e8bc1a6bc432 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:03:49.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5906" for this suite.
Nov  6 02:03:55.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:03:55.148: INFO: namespace secrets-5906 deletion completed in 6.056406343s

• [SLOW TEST:10.159 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:03:55.148: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Nov  6 02:03:56.280: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Nov  6 02:03:58.287: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708602636, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708602636, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708602636, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708602636, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  6 02:04:01.320: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:04:01.323: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:04:02.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-4602" for this suite.
Nov  6 02:04:08.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:04:08.542: INFO: namespace crd-webhook-4602 deletion completed in 6.083243486s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:13.401 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:04:08.549: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-8057e960-e365-4267-be37-6a41c82fd37a
STEP: Creating a pod to test consume secrets
Nov  6 02:04:08.659: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e05baaf5-d6b3-4e5c-b4e7-aec65f0b2972" in namespace "projected-2797" to be "success or failure"
Nov  6 02:04:08.666: INFO: Pod "pod-projected-secrets-e05baaf5-d6b3-4e5c-b4e7-aec65f0b2972": Phase="Pending", Reason="", readiness=false. Elapsed: 6.682158ms
Nov  6 02:04:10.668: INFO: Pod "pod-projected-secrets-e05baaf5-d6b3-4e5c-b4e7-aec65f0b2972": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009269214s
Nov  6 02:04:12.671: INFO: Pod "pod-projected-secrets-e05baaf5-d6b3-4e5c-b4e7-aec65f0b2972": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011736886s
STEP: Saw pod success
Nov  6 02:04:12.671: INFO: Pod "pod-projected-secrets-e05baaf5-d6b3-4e5c-b4e7-aec65f0b2972" satisfied condition "success or failure"
Nov  6 02:04:12.673: INFO: Trying to get logs from node apps-114 pod pod-projected-secrets-e05baaf5-d6b3-4e5c-b4e7-aec65f0b2972 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  6 02:04:12.704: INFO: Waiting for pod pod-projected-secrets-e05baaf5-d6b3-4e5c-b4e7-aec65f0b2972 to disappear
Nov  6 02:04:12.716: INFO: Pod pod-projected-secrets-e05baaf5-d6b3-4e5c-b4e7-aec65f0b2972 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:04:12.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2797" for this suite.
Nov  6 02:04:18.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:04:18.774: INFO: namespace projected-2797 deletion completed in 6.055327745s

• [SLOW TEST:10.225 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:04:18.774: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Nov  6 02:04:18.842: INFO: Waiting up to 5m0s for pod "var-expansion-2c58aa78-9fe4-4035-8261-6536cf6f1177" in namespace "var-expansion-7599" to be "success or failure"
Nov  6 02:04:18.849: INFO: Pod "var-expansion-2c58aa78-9fe4-4035-8261-6536cf6f1177": Phase="Pending", Reason="", readiness=false. Elapsed: 6.967046ms
Nov  6 02:04:20.852: INFO: Pod "var-expansion-2c58aa78-9fe4-4035-8261-6536cf6f1177": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009311577s
Nov  6 02:04:22.854: INFO: Pod "var-expansion-2c58aa78-9fe4-4035-8261-6536cf6f1177": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012028215s
STEP: Saw pod success
Nov  6 02:04:22.854: INFO: Pod "var-expansion-2c58aa78-9fe4-4035-8261-6536cf6f1177" satisfied condition "success or failure"
Nov  6 02:04:22.856: INFO: Trying to get logs from node apps-114 pod var-expansion-2c58aa78-9fe4-4035-8261-6536cf6f1177 container dapi-container: <nil>
STEP: delete the pod
Nov  6 02:04:22.875: INFO: Waiting for pod var-expansion-2c58aa78-9fe4-4035-8261-6536cf6f1177 to disappear
Nov  6 02:04:22.883: INFO: Pod var-expansion-2c58aa78-9fe4-4035-8261-6536cf6f1177 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:04:22.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7599" for this suite.
Nov  6 02:04:28.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:04:28.955: INFO: namespace var-expansion-7599 deletion completed in 6.070457577s

• [SLOW TEST:10.181 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:04:28.955: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-6d79a9e6-7143-4b26-a1f6-c3956f308910
STEP: Creating a pod to test consume configMaps
Nov  6 02:04:29.028: INFO: Waiting up to 5m0s for pod "pod-configmaps-482e0dbc-805d-49a5-84f3-87462b23be48" in namespace "configmap-1256" to be "success or failure"
Nov  6 02:04:29.041: INFO: Pod "pod-configmaps-482e0dbc-805d-49a5-84f3-87462b23be48": Phase="Pending", Reason="", readiness=false. Elapsed: 13.716707ms
Nov  6 02:04:31.044: INFO: Pod "pod-configmaps-482e0dbc-805d-49a5-84f3-87462b23be48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01599263s
Nov  6 02:04:33.046: INFO: Pod "pod-configmaps-482e0dbc-805d-49a5-84f3-87462b23be48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018799793s
STEP: Saw pod success
Nov  6 02:04:33.046: INFO: Pod "pod-configmaps-482e0dbc-805d-49a5-84f3-87462b23be48" satisfied condition "success or failure"
Nov  6 02:04:33.049: INFO: Trying to get logs from node apps-114 pod pod-configmaps-482e0dbc-805d-49a5-84f3-87462b23be48 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  6 02:04:33.067: INFO: Waiting for pod pod-configmaps-482e0dbc-805d-49a5-84f3-87462b23be48 to disappear
Nov  6 02:04:33.080: INFO: Pod pod-configmaps-482e0dbc-805d-49a5-84f3-87462b23be48 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:04:33.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1256" for this suite.
Nov  6 02:04:39.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:04:39.172: INFO: namespace configmap-1256 deletion completed in 6.089927065s

• [SLOW TEST:10.217 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:04:39.172: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov  6 02:04:39.226: INFO: Waiting up to 5m0s for pod "pod-68105075-6f69-4ed7-8c51-546e6925f108" in namespace "emptydir-5382" to be "success or failure"
Nov  6 02:04:39.233: INFO: Pod "pod-68105075-6f69-4ed7-8c51-546e6925f108": Phase="Pending", Reason="", readiness=false. Elapsed: 6.675529ms
Nov  6 02:04:41.235: INFO: Pod "pod-68105075-6f69-4ed7-8c51-546e6925f108": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00928714s
Nov  6 02:04:43.238: INFO: Pod "pod-68105075-6f69-4ed7-8c51-546e6925f108": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011695467s
STEP: Saw pod success
Nov  6 02:04:43.238: INFO: Pod "pod-68105075-6f69-4ed7-8c51-546e6925f108" satisfied condition "success or failure"
Nov  6 02:04:43.239: INFO: Trying to get logs from node apps-114 pod pod-68105075-6f69-4ed7-8c51-546e6925f108 container test-container: <nil>
STEP: delete the pod
Nov  6 02:04:43.268: INFO: Waiting for pod pod-68105075-6f69-4ed7-8c51-546e6925f108 to disappear
Nov  6 02:04:43.274: INFO: Pod pod-68105075-6f69-4ed7-8c51-546e6925f108 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:04:43.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5382" for this suite.
Nov  6 02:04:49.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:04:49.332: INFO: namespace emptydir-5382 deletion completed in 6.055251014s

• [SLOW TEST:10.160 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:04:49.332: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:04:49.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1604" for this suite.
Nov  6 02:05:17.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:05:17.507: INFO: namespace pods-1604 deletion completed in 28.076562413s

• [SLOW TEST:28.175 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:05:17.508: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:05:43.595: INFO: Container started at 2019-11-06 02:05:19 +0000 UTC, pod became ready at 2019-11-06 02:05:42 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:05:43.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1198" for this suite.
Nov  6 02:05:55.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:05:55.669: INFO: namespace container-probe-1198 deletion completed in 12.071211089s

• [SLOW TEST:38.161 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:05:55.669: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Nov  6 02:05:55.716: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Nov  6 02:05:55.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 create -f - --namespace=kubectl-3539'
Nov  6 02:05:56.145: INFO: stderr: ""
Nov  6 02:05:56.145: INFO: stdout: "service/redis-slave created\n"
Nov  6 02:05:56.145: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Nov  6 02:05:56.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 create -f - --namespace=kubectl-3539'
Nov  6 02:05:56.469: INFO: stderr: ""
Nov  6 02:05:56.469: INFO: stdout: "service/redis-master created\n"
Nov  6 02:05:56.470: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov  6 02:05:56.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 create -f - --namespace=kubectl-3539'
Nov  6 02:05:56.794: INFO: stderr: ""
Nov  6 02:05:56.794: INFO: stdout: "service/frontend created\n"
Nov  6 02:05:56.795: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Nov  6 02:05:56.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 create -f - --namespace=kubectl-3539'
Nov  6 02:05:57.060: INFO: stderr: ""
Nov  6 02:05:57.060: INFO: stdout: "deployment.apps/frontend created\n"
Nov  6 02:05:57.060: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov  6 02:05:57.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 create -f - --namespace=kubectl-3539'
Nov  6 02:05:57.354: INFO: stderr: ""
Nov  6 02:05:57.354: INFO: stdout: "deployment.apps/redis-master created\n"
Nov  6 02:05:57.354: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Nov  6 02:05:57.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 create -f - --namespace=kubectl-3539'
Nov  6 02:05:57.630: INFO: stderr: ""
Nov  6 02:05:57.630: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Nov  6 02:05:57.630: INFO: Waiting for all frontend pods to be Running.
Nov  6 02:06:27.682: INFO: Waiting for frontend to serve content.
Nov  6 02:06:27.707: INFO: Trying to add a new entry to the guestbook.
Nov  6 02:06:27.719: INFO: Verifying that added entry can be retrieved.
Nov  6 02:06:27.727: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov  6 02:06:32.739: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov  6 02:06:37.750: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov  6 02:06:42.763: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov  6 02:06:47.775: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov  6 02:06:52.787: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov  6 02:06:57.799: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Nov  6 02:07:02.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 delete --grace-period=0 --force -f - --namespace=kubectl-3539'
Nov  6 02:07:05.007: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  6 02:07:05.007: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Nov  6 02:07:05.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 delete --grace-period=0 --force -f - --namespace=kubectl-3539'
Nov  6 02:07:05.156: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  6 02:07:05.156: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov  6 02:07:05.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 delete --grace-period=0 --force -f - --namespace=kubectl-3539'
Nov  6 02:07:05.317: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  6 02:07:05.317: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov  6 02:07:05.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 delete --grace-period=0 --force -f - --namespace=kubectl-3539'
Nov  6 02:07:05.447: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  6 02:07:05.447: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov  6 02:07:05.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 delete --grace-period=0 --force -f - --namespace=kubectl-3539'
Nov  6 02:07:05.581: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  6 02:07:05.581: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov  6 02:07:05.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 delete --grace-period=0 --force -f - --namespace=kubectl-3539'
Nov  6 02:07:05.672: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  6 02:07:05.672: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:07:05.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3539" for this suite.
Nov  6 02:07:17.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:07:17.730: INFO: namespace kubectl-3539 deletion completed in 12.05500853s

• [SLOW TEST:82.061 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:07:17.730: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Nov  6 02:07:57.827: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1106 02:07:57.827753      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:07:57.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4623" for this suite.
Nov  6 02:08:05.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:08:05.898: INFO: namespace gc-4623 deletion completed in 8.068438125s

• [SLOW TEST:48.168 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:08:05.898: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Nov  6 02:08:05.941: INFO: namespace kubectl-1007
Nov  6 02:08:05.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 create -f - --namespace=kubectl-1007'
Nov  6 02:08:06.260: INFO: stderr: ""
Nov  6 02:08:06.260: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  6 02:08:07.263: INFO: Selector matched 1 pods for map[app:redis]
Nov  6 02:08:07.263: INFO: Found 0 / 1
Nov  6 02:08:08.264: INFO: Selector matched 1 pods for map[app:redis]
Nov  6 02:08:08.264: INFO: Found 0 / 1
Nov  6 02:08:09.264: INFO: Selector matched 1 pods for map[app:redis]
Nov  6 02:08:09.264: INFO: Found 1 / 1
Nov  6 02:08:09.264: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  6 02:08:09.274: INFO: Selector matched 1 pods for map[app:redis]
Nov  6 02:08:09.274: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  6 02:08:09.274: INFO: wait on redis-master startup in kubectl-1007 
Nov  6 02:08:09.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 logs redis-master-w5xwr redis-master --namespace=kubectl-1007'
Nov  6 02:08:09.401: INFO: stderr: ""
Nov  6 02:08:09.401: INFO: stdout: "1:C 06 Nov 2019 02:08:07.901 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 06 Nov 2019 02:08:07.901 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 06 Nov 2019 02:08:07.901 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 06 Nov 2019 02:08:07.903 * Running mode=standalone, port=6379.\n1:M 06 Nov 2019 02:08:07.903 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 06 Nov 2019 02:08:07.903 # Server initialized\n1:M 06 Nov 2019 02:08:07.903 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 06 Nov 2019 02:08:07.903 * Ready to accept connections\n"
STEP: exposing RC
Nov  6 02:08:09.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-1007'
Nov  6 02:08:09.529: INFO: stderr: ""
Nov  6 02:08:09.529: INFO: stdout: "service/rm2 exposed\n"
Nov  6 02:08:09.535: INFO: Service rm2 in namespace kubectl-1007 found.
STEP: exposing service
Nov  6 02:08:11.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-1007'
Nov  6 02:08:11.713: INFO: stderr: ""
Nov  6 02:08:11.713: INFO: stdout: "service/rm3 exposed\n"
Nov  6 02:08:11.727: INFO: Service rm3 in namespace kubectl-1007 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:08:13.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1007" for this suite.
Nov  6 02:08:25.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:08:25.814: INFO: namespace kubectl-1007 deletion completed in 12.079893496s

• [SLOW TEST:19.916 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:08:25.814: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-fdfd1af9-0c99-4cb3-8871-87f4613f9b67
STEP: Creating a pod to test consume configMaps
Nov  6 02:08:25.879: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c0f717d9-07fa-4820-9f16-c238493a93bb" in namespace "projected-9613" to be "success or failure"
Nov  6 02:08:25.886: INFO: Pod "pod-projected-configmaps-c0f717d9-07fa-4820-9f16-c238493a93bb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.786985ms
Nov  6 02:08:27.888: INFO: Pod "pod-projected-configmaps-c0f717d9-07fa-4820-9f16-c238493a93bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00926251s
Nov  6 02:08:29.891: INFO: Pod "pod-projected-configmaps-c0f717d9-07fa-4820-9f16-c238493a93bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012052237s
STEP: Saw pod success
Nov  6 02:08:29.891: INFO: Pod "pod-projected-configmaps-c0f717d9-07fa-4820-9f16-c238493a93bb" satisfied condition "success or failure"
Nov  6 02:08:29.893: INFO: Trying to get logs from node apps-114 pod pod-projected-configmaps-c0f717d9-07fa-4820-9f16-c238493a93bb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  6 02:08:29.946: INFO: Waiting for pod pod-projected-configmaps-c0f717d9-07fa-4820-9f16-c238493a93bb to disappear
Nov  6 02:08:29.961: INFO: Pod pod-projected-configmaps-c0f717d9-07fa-4820-9f16-c238493a93bb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:08:29.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9613" for this suite.
Nov  6 02:08:35.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:08:36.023: INFO: namespace projected-9613 deletion completed in 6.059056902s

• [SLOW TEST:10.209 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:08:36.023: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  6 02:08:36.081: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ea87248c-7fa0-4624-b823-afd2027d8f95" in namespace "projected-5152" to be "success or failure"
Nov  6 02:08:36.086: INFO: Pod "downwardapi-volume-ea87248c-7fa0-4624-b823-afd2027d8f95": Phase="Pending", Reason="", readiness=false. Elapsed: 5.277344ms
Nov  6 02:08:38.089: INFO: Pod "downwardapi-volume-ea87248c-7fa0-4624-b823-afd2027d8f95": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008144888s
Nov  6 02:08:40.092: INFO: Pod "downwardapi-volume-ea87248c-7fa0-4624-b823-afd2027d8f95": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010804092s
STEP: Saw pod success
Nov  6 02:08:40.092: INFO: Pod "downwardapi-volume-ea87248c-7fa0-4624-b823-afd2027d8f95" satisfied condition "success or failure"
Nov  6 02:08:40.093: INFO: Trying to get logs from node apps-114 pod downwardapi-volume-ea87248c-7fa0-4624-b823-afd2027d8f95 container client-container: <nil>
STEP: delete the pod
Nov  6 02:08:40.113: INFO: Waiting for pod downwardapi-volume-ea87248c-7fa0-4624-b823-afd2027d8f95 to disappear
Nov  6 02:08:40.119: INFO: Pod downwardapi-volume-ea87248c-7fa0-4624-b823-afd2027d8f95 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:08:40.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5152" for this suite.
Nov  6 02:08:46.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:08:46.180: INFO: namespace projected-5152 deletion completed in 6.058553823s

• [SLOW TEST:10.157 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:08:46.181: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-5880
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-5880
STEP: Deleting pre-stop pod
Nov  6 02:08:59.321: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:08:59.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-5880" for this suite.
Nov  6 02:09:43.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:09:43.412: INFO: namespace prestop-5880 deletion completed in 44.075464962s

• [SLOW TEST:57.232 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:09:43.412: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Nov  6 02:09:43.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 api-versions'
Nov  6 02:09:43.652: INFO: stderr: ""
Nov  6 02:09:43.652: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:09:43.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2707" for this suite.
Nov  6 02:09:49.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:09:49.709: INFO: namespace kubectl-2707 deletion completed in 6.054052569s

• [SLOW TEST:6.297 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:09:49.710: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:09:49.792: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov  6 02:09:53.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-1466 create -f -'
Nov  6 02:09:55.960: INFO: stderr: ""
Nov  6 02:09:55.960: INFO: stdout: "e2e-test-crd-publish-openapi-9470-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov  6 02:09:55.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-1466 delete e2e-test-crd-publish-openapi-9470-crds test-cr'
Nov  6 02:09:56.062: INFO: stderr: ""
Nov  6 02:09:56.062: INFO: stdout: "e2e-test-crd-publish-openapi-9470-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Nov  6 02:09:56.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-1466 apply -f -'
Nov  6 02:09:56.352: INFO: stderr: ""
Nov  6 02:09:56.352: INFO: stdout: "e2e-test-crd-publish-openapi-9470-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov  6 02:09:56.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-1466 delete e2e-test-crd-publish-openapi-9470-crds test-cr'
Nov  6 02:09:56.454: INFO: stderr: ""
Nov  6 02:09:56.454: INFO: stdout: "e2e-test-crd-publish-openapi-9470-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Nov  6 02:09:56.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 explain e2e-test-crd-publish-openapi-9470-crds'
Nov  6 02:09:56.716: INFO: stderr: ""
Nov  6 02:09:56.716: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9470-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:10:00.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1466" for this suite.
Nov  6 02:10:06.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:10:06.655: INFO: namespace crd-publish-openapi-1466 deletion completed in 6.064323252s

• [SLOW TEST:16.945 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:10:06.655: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:10:37.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6231" for this suite.
Nov  6 02:10:43.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:10:43.918: INFO: namespace namespaces-6231 deletion completed in 6.056843811s
STEP: Destroying namespace "nsdeletetest-5047" for this suite.
Nov  6 02:10:43.920: INFO: Namespace nsdeletetest-5047 was already deleted
STEP: Destroying namespace "nsdeletetest-8160" for this suite.
Nov  6 02:10:49.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:10:50.022: INFO: namespace nsdeletetest-8160 deletion completed in 6.102151591s

• [SLOW TEST:43.367 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:10:50.023: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Nov  6 02:10:54.081: INFO: &Pod{ObjectMeta:{send-events-63e35c65-cb01-4b1d-8e66-34a4cd5753c9  events-7987 /api/v1/namespaces/events-7987/pods/send-events-63e35c65-cb01-4b1d-8e66-34a4cd5753c9 0bb6a22f-0cd1-4409-b0df-7a2c8437218b 865057 0 2019-11-06 02:10:50 +0000 UTC <nil> <nil> map[name:foo time:64811518] map[cni.projectcalico.org/podIP:10.38.96.105/32] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-d96k2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-d96k2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-d96k2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:10:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:10:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:10:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:10:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.114,PodIP:10.38.96.105,StartTime:2019-11-06 02:10:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-06 02:10:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://164e0a5473374028894e7267ffe85736d2eaac2aae997af496b8462821252e8d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.38.96.105,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Nov  6 02:10:56.085: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Nov  6 02:10:58.087: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:10:58.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7987" for this suite.
Nov  6 02:11:42.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:11:42.167: INFO: namespace events-7987 deletion completed in 44.060774461s

• [SLOW TEST:52.144 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:11:42.167: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-b1784e15-4dce-408a-a420-d39cd2b7c52a
STEP: Creating a pod to test consume secrets
Nov  6 02:11:42.227: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6647d4f7-3bf8-46fd-bfee-148c3b0b963d" in namespace "projected-7711" to be "success or failure"
Nov  6 02:11:42.239: INFO: Pod "pod-projected-secrets-6647d4f7-3bf8-46fd-bfee-148c3b0b963d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.341483ms
Nov  6 02:11:44.242: INFO: Pod "pod-projected-secrets-6647d4f7-3bf8-46fd-bfee-148c3b0b963d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015021921s
Nov  6 02:11:46.244: INFO: Pod "pod-projected-secrets-6647d4f7-3bf8-46fd-bfee-148c3b0b963d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017565833s
STEP: Saw pod success
Nov  6 02:11:46.244: INFO: Pod "pod-projected-secrets-6647d4f7-3bf8-46fd-bfee-148c3b0b963d" satisfied condition "success or failure"
Nov  6 02:11:46.246: INFO: Trying to get logs from node apps-114 pod pod-projected-secrets-6647d4f7-3bf8-46fd-bfee-148c3b0b963d container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  6 02:11:46.268: INFO: Waiting for pod pod-projected-secrets-6647d4f7-3bf8-46fd-bfee-148c3b0b963d to disappear
Nov  6 02:11:46.304: INFO: Pod pod-projected-secrets-6647d4f7-3bf8-46fd-bfee-148c3b0b963d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:11:46.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7711" for this suite.
Nov  6 02:11:52.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:11:52.375: INFO: namespace projected-7711 deletion completed in 6.068099306s

• [SLOW TEST:10.208 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:11:52.376: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  6 02:11:52.428: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c1a40da3-a2fa-4f77-8d17-b93c0e042c9f" in namespace "downward-api-1538" to be "success or failure"
Nov  6 02:11:52.434: INFO: Pod "downwardapi-volume-c1a40da3-a2fa-4f77-8d17-b93c0e042c9f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.444051ms
Nov  6 02:11:54.437: INFO: Pod "downwardapi-volume-c1a40da3-a2fa-4f77-8d17-b93c0e042c9f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008886792s
Nov  6 02:11:56.439: INFO: Pod "downwardapi-volume-c1a40da3-a2fa-4f77-8d17-b93c0e042c9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011730551s
STEP: Saw pod success
Nov  6 02:11:56.440: INFO: Pod "downwardapi-volume-c1a40da3-a2fa-4f77-8d17-b93c0e042c9f" satisfied condition "success or failure"
Nov  6 02:11:56.441: INFO: Trying to get logs from node apps-114 pod downwardapi-volume-c1a40da3-a2fa-4f77-8d17-b93c0e042c9f container client-container: <nil>
STEP: delete the pod
Nov  6 02:11:56.462: INFO: Waiting for pod downwardapi-volume-c1a40da3-a2fa-4f77-8d17-b93c0e042c9f to disappear
Nov  6 02:11:56.468: INFO: Pod downwardapi-volume-c1a40da3-a2fa-4f77-8d17-b93c0e042c9f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:11:56.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1538" for this suite.
Nov  6 02:12:02.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:12:02.530: INFO: namespace downward-api-1538 deletion completed in 6.060424357s

• [SLOW TEST:10.155 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:12:02.531: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:12:02.597: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Nov  6 02:12:06.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-6756 create -f -'
Nov  6 02:12:08.263: INFO: stderr: ""
Nov  6 02:12:08.263: INFO: stdout: "e2e-test-crd-publish-openapi-1026-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov  6 02:12:08.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-6756 delete e2e-test-crd-publish-openapi-1026-crds test-foo'
Nov  6 02:12:08.361: INFO: stderr: ""
Nov  6 02:12:08.361: INFO: stdout: "e2e-test-crd-publish-openapi-1026-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Nov  6 02:12:08.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-6756 apply -f -'
Nov  6 02:12:08.631: INFO: stderr: ""
Nov  6 02:12:08.631: INFO: stdout: "e2e-test-crd-publish-openapi-1026-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov  6 02:12:08.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-6756 delete e2e-test-crd-publish-openapi-1026-crds test-foo'
Nov  6 02:12:08.727: INFO: stderr: ""
Nov  6 02:12:08.727: INFO: stdout: "e2e-test-crd-publish-openapi-1026-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Nov  6 02:12:08.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-6756 create -f -'
Nov  6 02:12:09.011: INFO: rc: 1
Nov  6 02:12:09.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-6756 apply -f -'
Nov  6 02:12:09.308: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Nov  6 02:12:09.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-6756 create -f -'
Nov  6 02:12:09.570: INFO: rc: 1
Nov  6 02:12:09.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-6756 apply -f -'
Nov  6 02:12:09.860: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Nov  6 02:12:09.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 explain e2e-test-crd-publish-openapi-1026-crds'
Nov  6 02:12:10.146: INFO: stderr: ""
Nov  6 02:12:10.146: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1026-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Nov  6 02:12:10.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 explain e2e-test-crd-publish-openapi-1026-crds.metadata'
Nov  6 02:12:10.431: INFO: stderr: ""
Nov  6 02:12:10.431: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1026-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Nov  6 02:12:10.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 explain e2e-test-crd-publish-openapi-1026-crds.spec'
Nov  6 02:12:10.709: INFO: stderr: ""
Nov  6 02:12:10.709: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1026-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Nov  6 02:12:10.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 explain e2e-test-crd-publish-openapi-1026-crds.spec.bars'
Nov  6 02:12:10.998: INFO: stderr: ""
Nov  6 02:12:10.998: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1026-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Nov  6 02:12:10.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 explain e2e-test-crd-publish-openapi-1026-crds.spec.bars2'
Nov  6 02:12:11.264: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:12:15.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6756" for this suite.
Nov  6 02:12:21.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:12:21.251: INFO: namespace crd-publish-openapi-6756 deletion completed in 6.063695419s

• [SLOW TEST:18.721 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:12:21.252: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:12:21.302: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:12:21.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1501" for this suite.
Nov  6 02:12:27.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:12:27.934: INFO: namespace custom-resource-definition-1501 deletion completed in 6.06584425s

• [SLOW TEST:6.682 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:12:27.934: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:12:33.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6436" for this suite.
Nov  6 02:12:45.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:12:45.136: INFO: namespace replication-controller-6436 deletion completed in 12.070841821s

• [SLOW TEST:17.202 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:12:45.136: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  6 02:12:45.211: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0593bfd0-3a64-438c-be1f-ee5919e461bd" in namespace "downward-api-2026" to be "success or failure"
Nov  6 02:12:45.223: INFO: Pod "downwardapi-volume-0593bfd0-3a64-438c-be1f-ee5919e461bd": Phase="Pending", Reason="", readiness=false. Elapsed: 12.521417ms
Nov  6 02:12:47.226: INFO: Pod "downwardapi-volume-0593bfd0-3a64-438c-be1f-ee5919e461bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015216486s
Nov  6 02:12:49.229: INFO: Pod "downwardapi-volume-0593bfd0-3a64-438c-be1f-ee5919e461bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018579341s
STEP: Saw pod success
Nov  6 02:12:49.229: INFO: Pod "downwardapi-volume-0593bfd0-3a64-438c-be1f-ee5919e461bd" satisfied condition "success or failure"
Nov  6 02:12:49.231: INFO: Trying to get logs from node apps-114 pod downwardapi-volume-0593bfd0-3a64-438c-be1f-ee5919e461bd container client-container: <nil>
STEP: delete the pod
Nov  6 02:12:49.252: INFO: Waiting for pod downwardapi-volume-0593bfd0-3a64-438c-be1f-ee5919e461bd to disappear
Nov  6 02:12:49.259: INFO: Pod downwardapi-volume-0593bfd0-3a64-438c-be1f-ee5919e461bd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:12:49.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2026" for this suite.
Nov  6 02:12:55.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:12:55.322: INFO: namespace downward-api-2026 deletion completed in 6.060908799s

• [SLOW TEST:10.187 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:12:55.323: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Nov  6 02:12:55.369: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-8230" to be "success or failure"
Nov  6 02:12:55.375: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.706895ms
Nov  6 02:12:57.378: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009581417s
Nov  6 02:12:59.382: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013157813s
STEP: Saw pod success
Nov  6 02:12:59.382: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Nov  6 02:12:59.384: INFO: Trying to get logs from node apps-114 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Nov  6 02:12:59.417: INFO: Waiting for pod pod-host-path-test to disappear
Nov  6 02:12:59.452: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:12:59.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-8230" for this suite.
Nov  6 02:13:05.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:13:05.530: INFO: namespace hostpath-8230 deletion completed in 6.075156346s

• [SLOW TEST:10.207 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:13:05.530: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-3578a803-9948-4220-ac4e-ed30ada0a485
STEP: Creating a pod to test consume secrets
Nov  6 02:13:05.611: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dce595bb-7556-4aad-a469-ddd6c2d9ec16" in namespace "projected-4901" to be "success or failure"
Nov  6 02:13:05.617: INFO: Pod "pod-projected-secrets-dce595bb-7556-4aad-a469-ddd6c2d9ec16": Phase="Pending", Reason="", readiness=false. Elapsed: 6.829583ms
Nov  6 02:13:07.620: INFO: Pod "pod-projected-secrets-dce595bb-7556-4aad-a469-ddd6c2d9ec16": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009206767s
Nov  6 02:13:09.623: INFO: Pod "pod-projected-secrets-dce595bb-7556-4aad-a469-ddd6c2d9ec16": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012419168s
STEP: Saw pod success
Nov  6 02:13:09.623: INFO: Pod "pod-projected-secrets-dce595bb-7556-4aad-a469-ddd6c2d9ec16" satisfied condition "success or failure"
Nov  6 02:13:09.625: INFO: Trying to get logs from node apps-114 pod pod-projected-secrets-dce595bb-7556-4aad-a469-ddd6c2d9ec16 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  6 02:13:09.643: INFO: Waiting for pod pod-projected-secrets-dce595bb-7556-4aad-a469-ddd6c2d9ec16 to disappear
Nov  6 02:13:09.657: INFO: Pod pod-projected-secrets-dce595bb-7556-4aad-a469-ddd6c2d9ec16 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:13:09.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4901" for this suite.
Nov  6 02:13:15.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:13:15.718: INFO: namespace projected-4901 deletion completed in 6.058914558s

• [SLOW TEST:10.188 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:13:15.718: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  6 02:13:15.786: INFO: Waiting up to 5m0s for pod "downward-api-15485bba-1a98-42e6-b9a3-97ae73eeef4a" in namespace "downward-api-3871" to be "success or failure"
Nov  6 02:13:15.792: INFO: Pod "downward-api-15485bba-1a98-42e6-b9a3-97ae73eeef4a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.50586ms
Nov  6 02:13:17.795: INFO: Pod "downward-api-15485bba-1a98-42e6-b9a3-97ae73eeef4a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009295053s
Nov  6 02:13:19.798: INFO: Pod "downward-api-15485bba-1a98-42e6-b9a3-97ae73eeef4a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011993966s
STEP: Saw pod success
Nov  6 02:13:19.798: INFO: Pod "downward-api-15485bba-1a98-42e6-b9a3-97ae73eeef4a" satisfied condition "success or failure"
Nov  6 02:13:19.799: INFO: Trying to get logs from node apps-114 pod downward-api-15485bba-1a98-42e6-b9a3-97ae73eeef4a container dapi-container: <nil>
STEP: delete the pod
Nov  6 02:13:19.819: INFO: Waiting for pod downward-api-15485bba-1a98-42e6-b9a3-97ae73eeef4a to disappear
Nov  6 02:13:19.826: INFO: Pod downward-api-15485bba-1a98-42e6-b9a3-97ae73eeef4a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:13:19.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3871" for this suite.
Nov  6 02:13:25.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:13:25.893: INFO: namespace downward-api-3871 deletion completed in 6.065263474s

• [SLOW TEST:10.175 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:13:25.893: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-9457
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-9457
I1106 02:13:26.019042      26 runners.go:184] Created replication controller with name: externalname-service, namespace: services-9457, replica count: 2
I1106 02:13:29.069482      26 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  6 02:13:29.069: INFO: Creating new exec pod
Nov  6 02:13:34.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=services-9457 execpodj2fsw -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Nov  6 02:13:34.357: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov  6 02:13:34.357: INFO: stdout: ""
Nov  6 02:13:34.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=services-9457 execpodj2fsw -- /bin/sh -x -c nc -zv -t -w 2 10.100.127.173 80'
Nov  6 02:13:34.609: INFO: stderr: "+ nc -zv -t -w 2 10.100.127.173 80\nConnection to 10.100.127.173 80 port [tcp/http] succeeded!\n"
Nov  6 02:13:34.609: INFO: stdout: ""
Nov  6 02:13:34.609: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:13:34.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9457" for this suite.
Nov  6 02:13:40.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:13:40.828: INFO: namespace services-9457 deletion completed in 6.058813762s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:14.935 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:13:40.828: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov  6 02:13:48.996: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  6 02:13:49.012: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  6 02:13:51.012: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  6 02:13:51.015: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  6 02:13:53.012: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  6 02:13:53.014: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:13:53.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8533" for this suite.
Nov  6 02:14:21.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:14:21.085: INFO: namespace container-lifecycle-hook-8533 deletion completed in 28.06290612s

• [SLOW TEST:40.257 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:14:21.086: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:14:21.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6308" for this suite.
Nov  6 02:14:27.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:14:27.261: INFO: namespace resourcequota-6308 deletion completed in 6.056941944s

• [SLOW TEST:6.176 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:14:27.262: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-4a44c4be-8c79-4368-8466-5e6cfe7e802b
STEP: Creating a pod to test consume configMaps
Nov  6 02:14:27.321: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ef27421e-4a5f-4192-8d90-cd6da17d6bf0" in namespace "projected-529" to be "success or failure"
Nov  6 02:14:27.334: INFO: Pod "pod-projected-configmaps-ef27421e-4a5f-4192-8d90-cd6da17d6bf0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.899233ms
Nov  6 02:14:29.337: INFO: Pod "pod-projected-configmaps-ef27421e-4a5f-4192-8d90-cd6da17d6bf0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01582054s
Nov  6 02:14:31.340: INFO: Pod "pod-projected-configmaps-ef27421e-4a5f-4192-8d90-cd6da17d6bf0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018718155s
STEP: Saw pod success
Nov  6 02:14:31.340: INFO: Pod "pod-projected-configmaps-ef27421e-4a5f-4192-8d90-cd6da17d6bf0" satisfied condition "success or failure"
Nov  6 02:14:31.341: INFO: Trying to get logs from node apps-114 pod pod-projected-configmaps-ef27421e-4a5f-4192-8d90-cd6da17d6bf0 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  6 02:14:31.362: INFO: Waiting for pod pod-projected-configmaps-ef27421e-4a5f-4192-8d90-cd6da17d6bf0 to disappear
Nov  6 02:14:31.369: INFO: Pod pod-projected-configmaps-ef27421e-4a5f-4192-8d90-cd6da17d6bf0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:14:31.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-529" for this suite.
Nov  6 02:14:37.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:14:37.451: INFO: namespace projected-529 deletion completed in 6.079191505s

• [SLOW TEST:10.189 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:14:37.451: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8191.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8191.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8191.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8191.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  6 02:14:41.555: INFO: DNS probes using dns-test-ab16ff33-a267-4da1-a415-6171c396caa2 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8191.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8191.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8191.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8191.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  6 02:14:45.611: INFO: File wheezy_udp@dns-test-service-3.dns-8191.svc.cluster.local from pod  dns-8191/dns-test-267b338d-3ad2-4874-b2a8-085eb6d00638 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov  6 02:14:45.613: INFO: File jessie_udp@dns-test-service-3.dns-8191.svc.cluster.local from pod  dns-8191/dns-test-267b338d-3ad2-4874-b2a8-085eb6d00638 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov  6 02:14:45.613: INFO: Lookups using dns-8191/dns-test-267b338d-3ad2-4874-b2a8-085eb6d00638 failed for: [wheezy_udp@dns-test-service-3.dns-8191.svc.cluster.local jessie_udp@dns-test-service-3.dns-8191.svc.cluster.local]

Nov  6 02:14:50.619: INFO: DNS probes using dns-test-267b338d-3ad2-4874-b2a8-085eb6d00638 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8191.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8191.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8191.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8191.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  6 02:14:54.787: INFO: DNS probes using dns-test-99437000-02b5-4e85-bc3b-e995fac5fef0 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:14:54.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8191" for this suite.
Nov  6 02:15:00.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:15:00.967: INFO: namespace dns-8191 deletion completed in 6.064319255s

• [SLOW TEST:23.516 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:15:00.967: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:15:05.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6304" for this suite.
Nov  6 02:15:11.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:15:11.136: INFO: namespace kubelet-test-6304 deletion completed in 6.078345121s

• [SLOW TEST:10.169 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:15:11.136: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-ppt8k in namespace proxy-6867
I1106 02:15:11.241313      26 runners.go:184] Created replication controller with name: proxy-service-ppt8k, namespace: proxy-6867, replica count: 1
I1106 02:15:12.291656      26 runners.go:184] proxy-service-ppt8k Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1106 02:15:13.291877      26 runners.go:184] proxy-service-ppt8k Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1106 02:15:14.292085      26 runners.go:184] proxy-service-ppt8k Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1106 02:15:15.292273      26 runners.go:184] proxy-service-ppt8k Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1106 02:15:16.292446      26 runners.go:184] proxy-service-ppt8k Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1106 02:15:17.292669      26 runners.go:184] proxy-service-ppt8k Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1106 02:15:18.292857      26 runners.go:184] proxy-service-ppt8k Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1106 02:15:19.293037      26 runners.go:184] proxy-service-ppt8k Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  6 02:15:19.295: INFO: setup took 8.084619456s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Nov  6 02:15:19.299: INFO: (0) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 3.292236ms)
Nov  6 02:15:19.299: INFO: (0) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 3.724966ms)
Nov  6 02:15:19.299: INFO: (0) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 3.659545ms)
Nov  6 02:15:19.300: INFO: (0) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 4.654821ms)
Nov  6 02:15:19.300: INFO: (0) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 5.005987ms)
Nov  6 02:15:19.301: INFO: (0) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 5.120837ms)
Nov  6 02:15:19.304: INFO: (0) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 8.293312ms)
Nov  6 02:15:19.304: INFO: (0) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 8.294658ms)
Nov  6 02:15:19.304: INFO: (0) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 8.362088ms)
Nov  6 02:15:19.304: INFO: (0) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 8.881784ms)
Nov  6 02:15:19.304: INFO: (0) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 8.912175ms)
Nov  6 02:15:19.306: INFO: (0) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 10.230935ms)
Nov  6 02:15:19.306: INFO: (0) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 10.247377ms)
Nov  6 02:15:19.306: INFO: (0) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 10.279124ms)
Nov  6 02:15:19.306: INFO: (0) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 10.356455ms)
Nov  6 02:15:19.309: INFO: (0) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 13.336114ms)
Nov  6 02:15:19.314: INFO: (1) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 4.93341ms)
Nov  6 02:15:19.315: INFO: (1) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 5.72598ms)
Nov  6 02:15:19.315: INFO: (1) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 5.595715ms)
Nov  6 02:15:19.315: INFO: (1) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 5.521808ms)
Nov  6 02:15:19.315: INFO: (1) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 5.999963ms)
Nov  6 02:15:19.315: INFO: (1) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 5.910255ms)
Nov  6 02:15:19.315: INFO: (1) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 5.906173ms)
Nov  6 02:15:19.315: INFO: (1) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 6.128946ms)
Nov  6 02:15:19.316: INFO: (1) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 6.240788ms)
Nov  6 02:15:19.316: INFO: (1) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 6.738727ms)
Nov  6 02:15:19.316: INFO: (1) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 6.816052ms)
Nov  6 02:15:19.316: INFO: (1) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 6.827114ms)
Nov  6 02:15:19.316: INFO: (1) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 7.219308ms)
Nov  6 02:15:19.317: INFO: (1) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 7.20307ms)
Nov  6 02:15:19.317: INFO: (1) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 7.429024ms)
Nov  6 02:15:19.318: INFO: (1) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 8.984121ms)
Nov  6 02:15:19.320: INFO: (2) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 2.050099ms)
Nov  6 02:15:19.323: INFO: (2) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 4.172167ms)
Nov  6 02:15:19.323: INFO: (2) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 4.516699ms)
Nov  6 02:15:19.323: INFO: (2) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 4.461086ms)
Nov  6 02:15:19.323: INFO: (2) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 4.447819ms)
Nov  6 02:15:19.323: INFO: (2) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 4.492082ms)
Nov  6 02:15:19.323: INFO: (2) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 4.575693ms)
Nov  6 02:15:19.323: INFO: (2) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 4.618792ms)
Nov  6 02:15:19.323: INFO: (2) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 4.79216ms)
Nov  6 02:15:19.323: INFO: (2) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 5.007186ms)
Nov  6 02:15:19.324: INFO: (2) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 5.395443ms)
Nov  6 02:15:19.324: INFO: (2) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 5.673012ms)
Nov  6 02:15:19.324: INFO: (2) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 5.592129ms)
Nov  6 02:15:19.324: INFO: (2) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 5.678321ms)
Nov  6 02:15:19.324: INFO: (2) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 5.789265ms)
Nov  6 02:15:19.324: INFO: (2) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 5.898014ms)
Nov  6 02:15:19.330: INFO: (3) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 6.099615ms)
Nov  6 02:15:19.330: INFO: (3) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 6.037846ms)
Nov  6 02:15:19.330: INFO: (3) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 6.157435ms)
Nov  6 02:15:19.330: INFO: (3) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 6.172231ms)
Nov  6 02:15:19.330: INFO: (3) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 6.291426ms)
Nov  6 02:15:19.331: INFO: (3) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 6.09205ms)
Nov  6 02:15:19.331: INFO: (3) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 6.239798ms)
Nov  6 02:15:19.331: INFO: (3) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 6.624873ms)
Nov  6 02:15:19.331: INFO: (3) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 6.698534ms)
Nov  6 02:15:19.331: INFO: (3) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 6.905056ms)
Nov  6 02:15:19.331: INFO: (3) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 6.877936ms)
Nov  6 02:15:19.331: INFO: (3) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 6.983212ms)
Nov  6 02:15:19.331: INFO: (3) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 7.023027ms)
Nov  6 02:15:19.331: INFO: (3) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 6.951006ms)
Nov  6 02:15:19.331: INFO: (3) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 6.984576ms)
Nov  6 02:15:19.331: INFO: (3) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 7.103756ms)
Nov  6 02:15:19.334: INFO: (4) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 2.915314ms)
Nov  6 02:15:19.335: INFO: (4) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 3.07088ms)
Nov  6 02:15:19.335: INFO: (4) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 3.424399ms)
Nov  6 02:15:19.335: INFO: (4) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 3.491773ms)
Nov  6 02:15:19.335: INFO: (4) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 3.663521ms)
Nov  6 02:15:19.335: INFO: (4) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 3.641606ms)
Nov  6 02:15:19.335: INFO: (4) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 3.89501ms)
Nov  6 02:15:19.335: INFO: (4) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 3.878001ms)
Nov  6 02:15:19.336: INFO: (4) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 4.069642ms)
Nov  6 02:15:19.336: INFO: (4) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 4.107628ms)
Nov  6 02:15:19.336: INFO: (4) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 4.572461ms)
Nov  6 02:15:19.337: INFO: (4) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 5.974768ms)
Nov  6 02:15:19.338: INFO: (4) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 5.961762ms)
Nov  6 02:15:19.338: INFO: (4) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 5.999891ms)
Nov  6 02:15:19.338: INFO: (4) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 5.989633ms)
Nov  6 02:15:19.338: INFO: (4) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 6.255625ms)
Nov  6 02:15:19.342: INFO: (5) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 4.000504ms)
Nov  6 02:15:19.342: INFO: (5) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 3.995304ms)
Nov  6 02:15:19.343: INFO: (5) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 5.460475ms)
Nov  6 02:15:19.343: INFO: (5) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 5.511958ms)
Nov  6 02:15:19.344: INFO: (5) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 5.644124ms)
Nov  6 02:15:19.344: INFO: (5) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 5.556334ms)
Nov  6 02:15:19.344: INFO: (5) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 5.811533ms)
Nov  6 02:15:19.344: INFO: (5) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 5.825358ms)
Nov  6 02:15:19.344: INFO: (5) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 6.060935ms)
Nov  6 02:15:19.344: INFO: (5) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 6.246352ms)
Nov  6 02:15:19.344: INFO: (5) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 6.189889ms)
Nov  6 02:15:19.344: INFO: (5) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 6.214238ms)
Nov  6 02:15:19.344: INFO: (5) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 6.12151ms)
Nov  6 02:15:19.344: INFO: (5) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 6.202344ms)
Nov  6 02:15:19.344: INFO: (5) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 6.543419ms)
Nov  6 02:15:19.344: INFO: (5) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 6.392031ms)
Nov  6 02:15:19.346: INFO: (6) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 2.024847ms)
Nov  6 02:15:19.347: INFO: (6) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 2.184582ms)
Nov  6 02:15:19.347: INFO: (6) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 2.192751ms)
Nov  6 02:15:19.348: INFO: (6) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 3.524359ms)
Nov  6 02:15:19.349: INFO: (6) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 4.043706ms)
Nov  6 02:15:19.349: INFO: (6) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 4.117841ms)
Nov  6 02:15:19.349: INFO: (6) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 3.972373ms)
Nov  6 02:15:19.349: INFO: (6) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 4.260584ms)
Nov  6 02:15:19.349: INFO: (6) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 4.243454ms)
Nov  6 02:15:19.349: INFO: (6) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 4.165853ms)
Nov  6 02:15:19.349: INFO: (6) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 4.281008ms)
Nov  6 02:15:19.349: INFO: (6) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 4.312837ms)
Nov  6 02:15:19.349: INFO: (6) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 4.300777ms)
Nov  6 02:15:19.349: INFO: (6) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 4.602029ms)
Nov  6 02:15:19.349: INFO: (6) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 4.518612ms)
Nov  6 02:15:19.349: INFO: (6) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 4.714997ms)
Nov  6 02:15:19.354: INFO: (7) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 4.129482ms)
Nov  6 02:15:19.354: INFO: (7) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 4.253052ms)
Nov  6 02:15:19.354: INFO: (7) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 4.311796ms)
Nov  6 02:15:19.354: INFO: (7) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 4.290023ms)
Nov  6 02:15:19.354: INFO: (7) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 4.44337ms)
Nov  6 02:15:19.354: INFO: (7) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 4.469264ms)
Nov  6 02:15:19.354: INFO: (7) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 4.659774ms)
Nov  6 02:15:19.354: INFO: (7) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 4.631139ms)
Nov  6 02:15:19.354: INFO: (7) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 4.682907ms)
Nov  6 02:15:19.354: INFO: (7) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 4.613776ms)
Nov  6 02:15:19.354: INFO: (7) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 5.115303ms)
Nov  6 02:15:19.355: INFO: (7) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 5.448311ms)
Nov  6 02:15:19.356: INFO: (7) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 6.345962ms)
Nov  6 02:15:19.356: INFO: (7) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 6.458144ms)
Nov  6 02:15:19.356: INFO: (7) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 6.384121ms)
Nov  6 02:15:19.356: INFO: (7) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 6.458266ms)
Nov  6 02:15:19.359: INFO: (8) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 3.570218ms)
Nov  6 02:15:19.360: INFO: (8) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 3.706012ms)
Nov  6 02:15:19.360: INFO: (8) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 3.874447ms)
Nov  6 02:15:19.360: INFO: (8) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 4.600876ms)
Nov  6 02:15:19.360: INFO: (8) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 4.651731ms)
Nov  6 02:15:19.361: INFO: (8) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 4.738301ms)
Nov  6 02:15:19.361: INFO: (8) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 4.602554ms)
Nov  6 02:15:19.361: INFO: (8) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 4.66212ms)
Nov  6 02:15:19.361: INFO: (8) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 4.659519ms)
Nov  6 02:15:19.361: INFO: (8) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 4.601988ms)
Nov  6 02:15:19.361: INFO: (8) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 4.679416ms)
Nov  6 02:15:19.361: INFO: (8) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 4.766308ms)
Nov  6 02:15:19.361: INFO: (8) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 4.81076ms)
Nov  6 02:15:19.361: INFO: (8) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 4.811877ms)
Nov  6 02:15:19.361: INFO: (8) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 4.975584ms)
Nov  6 02:15:19.361: INFO: (8) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 5.479241ms)
Nov  6 02:15:19.366: INFO: (9) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 4.167263ms)
Nov  6 02:15:19.366: INFO: (9) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 4.159413ms)
Nov  6 02:15:19.366: INFO: (9) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 4.140108ms)
Nov  6 02:15:19.366: INFO: (9) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 4.163315ms)
Nov  6 02:15:19.366: INFO: (9) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 4.192828ms)
Nov  6 02:15:19.366: INFO: (9) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 4.217183ms)
Nov  6 02:15:19.366: INFO: (9) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 4.251615ms)
Nov  6 02:15:19.366: INFO: (9) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 4.183783ms)
Nov  6 02:15:19.366: INFO: (9) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 4.359211ms)
Nov  6 02:15:19.366: INFO: (9) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 4.523194ms)
Nov  6 02:15:19.371: INFO: (9) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 9.685593ms)
Nov  6 02:15:19.372: INFO: (9) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 9.955575ms)
Nov  6 02:15:19.372: INFO: (9) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 10.071282ms)
Nov  6 02:15:19.372: INFO: (9) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 10.061686ms)
Nov  6 02:15:19.372: INFO: (9) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 9.912933ms)
Nov  6 02:15:19.372: INFO: (9) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 10.079996ms)
Nov  6 02:15:19.375: INFO: (10) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 3.081196ms)
Nov  6 02:15:19.376: INFO: (10) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 4.091894ms)
Nov  6 02:15:19.377: INFO: (10) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 4.952969ms)
Nov  6 02:15:19.377: INFO: (10) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 4.978656ms)
Nov  6 02:15:19.377: INFO: (10) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 5.110896ms)
Nov  6 02:15:19.377: INFO: (10) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 5.049493ms)
Nov  6 02:15:19.377: INFO: (10) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 5.311993ms)
Nov  6 02:15:19.377: INFO: (10) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 5.256516ms)
Nov  6 02:15:19.377: INFO: (10) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 5.372042ms)
Nov  6 02:15:19.377: INFO: (10) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 5.449587ms)
Nov  6 02:15:19.377: INFO: (10) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 5.700257ms)
Nov  6 02:15:19.377: INFO: (10) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 5.741367ms)
Nov  6 02:15:19.377: INFO: (10) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 5.794464ms)
Nov  6 02:15:19.378: INFO: (10) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 5.73415ms)
Nov  6 02:15:19.378: INFO: (10) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 5.853913ms)
Nov  6 02:15:19.378: INFO: (10) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 5.893686ms)
Nov  6 02:15:19.381: INFO: (11) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 3.132986ms)
Nov  6 02:15:19.381: INFO: (11) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 3.633659ms)
Nov  6 02:15:19.381: INFO: (11) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 3.584802ms)
Nov  6 02:15:19.381: INFO: (11) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 3.68132ms)
Nov  6 02:15:19.382: INFO: (11) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 3.921369ms)
Nov  6 02:15:19.382: INFO: (11) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 3.937209ms)
Nov  6 02:15:19.382: INFO: (11) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 3.960828ms)
Nov  6 02:15:19.382: INFO: (11) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 4.319362ms)
Nov  6 02:15:19.382: INFO: (11) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 4.304465ms)
Nov  6 02:15:19.382: INFO: (11) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 4.27292ms)
Nov  6 02:15:19.384: INFO: (11) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 6.665692ms)
Nov  6 02:15:19.385: INFO: (11) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 6.974274ms)
Nov  6 02:15:19.385: INFO: (11) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 6.960622ms)
Nov  6 02:15:19.385: INFO: (11) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 7.285579ms)
Nov  6 02:15:19.385: INFO: (11) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 7.31464ms)
Nov  6 02:15:19.385: INFO: (11) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 7.387409ms)
Nov  6 02:15:19.388: INFO: (12) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 2.881831ms)
Nov  6 02:15:19.389: INFO: (12) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 4.209462ms)
Nov  6 02:15:19.390: INFO: (12) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 4.056672ms)
Nov  6 02:15:19.390: INFO: (12) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 3.925439ms)
Nov  6 02:15:19.390: INFO: (12) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 4.232125ms)
Nov  6 02:15:19.390: INFO: (12) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 4.215292ms)
Nov  6 02:15:19.390: INFO: (12) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 4.107317ms)
Nov  6 02:15:19.390: INFO: (12) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 4.843524ms)
Nov  6 02:15:19.391: INFO: (12) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 4.96106ms)
Nov  6 02:15:19.391: INFO: (12) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 5.129177ms)
Nov  6 02:15:19.391: INFO: (12) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 5.681821ms)
Nov  6 02:15:19.391: INFO: (12) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 5.658894ms)
Nov  6 02:15:19.391: INFO: (12) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 5.543299ms)
Nov  6 02:15:19.391: INFO: (12) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 5.449973ms)
Nov  6 02:15:19.391: INFO: (12) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 5.513414ms)
Nov  6 02:15:19.391: INFO: (12) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 5.554908ms)
Nov  6 02:15:19.393: INFO: (13) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 2.323354ms)
Nov  6 02:15:19.394: INFO: (13) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 2.212363ms)
Nov  6 02:15:19.395: INFO: (13) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 3.765473ms)
Nov  6 02:15:19.395: INFO: (13) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 4.012812ms)
Nov  6 02:15:19.395: INFO: (13) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 4.043406ms)
Nov  6 02:15:19.396: INFO: (13) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 4.487622ms)
Nov  6 02:15:19.396: INFO: (13) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 4.027851ms)
Nov  6 02:15:19.396: INFO: (13) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 4.428017ms)
Nov  6 02:15:19.396: INFO: (13) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 4.509835ms)
Nov  6 02:15:19.396: INFO: (13) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 4.753634ms)
Nov  6 02:15:19.396: INFO: (13) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 4.362564ms)
Nov  6 02:15:19.396: INFO: (13) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 4.561166ms)
Nov  6 02:15:19.396: INFO: (13) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 4.63689ms)
Nov  6 02:15:19.396: INFO: (13) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 4.797442ms)
Nov  6 02:15:19.396: INFO: (13) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 4.932131ms)
Nov  6 02:15:19.396: INFO: (13) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 4.88265ms)
Nov  6 02:15:19.398: INFO: (14) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 2.03971ms)
Nov  6 02:15:19.399: INFO: (14) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 2.044842ms)
Nov  6 02:15:19.399: INFO: (14) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 2.125026ms)
Nov  6 02:15:19.400: INFO: (14) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 3.267434ms)
Nov  6 02:15:19.400: INFO: (14) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 3.294101ms)
Nov  6 02:15:19.400: INFO: (14) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 3.469298ms)
Nov  6 02:15:19.400: INFO: (14) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 3.641629ms)
Nov  6 02:15:19.400: INFO: (14) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 3.557424ms)
Nov  6 02:15:19.400: INFO: (14) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 3.602049ms)
Nov  6 02:15:19.400: INFO: (14) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 3.786875ms)
Nov  6 02:15:19.401: INFO: (14) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 4.889617ms)
Nov  6 02:15:19.401: INFO: (14) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 4.904568ms)
Nov  6 02:15:19.402: INFO: (14) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 5.229971ms)
Nov  6 02:15:19.402: INFO: (14) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 5.230769ms)
Nov  6 02:15:19.402: INFO: (14) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 5.195198ms)
Nov  6 02:15:19.402: INFO: (14) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 5.346971ms)
Nov  6 02:15:19.407: INFO: (15) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 4.778262ms)
Nov  6 02:15:19.407: INFO: (15) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 4.68109ms)
Nov  6 02:15:19.407: INFO: (15) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 4.881864ms)
Nov  6 02:15:19.407: INFO: (15) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 4.703256ms)
Nov  6 02:15:19.407: INFO: (15) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 4.797865ms)
Nov  6 02:15:19.407: INFO: (15) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 5.172665ms)
Nov  6 02:15:19.407: INFO: (15) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 5.040019ms)
Nov  6 02:15:19.407: INFO: (15) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 5.081376ms)
Nov  6 02:15:19.407: INFO: (15) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 5.195495ms)
Nov  6 02:15:19.407: INFO: (15) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 5.378662ms)
Nov  6 02:15:19.408: INFO: (15) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 5.551839ms)
Nov  6 02:15:19.408: INFO: (15) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 5.46624ms)
Nov  6 02:15:19.408: INFO: (15) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 5.878359ms)
Nov  6 02:15:19.408: INFO: (15) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 5.868577ms)
Nov  6 02:15:19.408: INFO: (15) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 5.862043ms)
Nov  6 02:15:19.409: INFO: (15) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 6.503369ms)
Nov  6 02:15:19.412: INFO: (16) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 2.894098ms)
Nov  6 02:15:19.412: INFO: (16) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 3.240865ms)
Nov  6 02:15:19.412: INFO: (16) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 3.332494ms)
Nov  6 02:15:19.412: INFO: (16) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 3.592656ms)
Nov  6 02:15:19.413: INFO: (16) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 3.803582ms)
Nov  6 02:15:19.413: INFO: (16) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 3.743929ms)
Nov  6 02:15:19.413: INFO: (16) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 3.833356ms)
Nov  6 02:15:19.413: INFO: (16) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 3.989979ms)
Nov  6 02:15:19.413: INFO: (16) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 3.902168ms)
Nov  6 02:15:19.413: INFO: (16) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 4.088231ms)
Nov  6 02:15:19.413: INFO: (16) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 4.239755ms)
Nov  6 02:15:19.413: INFO: (16) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 4.305256ms)
Nov  6 02:15:19.413: INFO: (16) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 4.258248ms)
Nov  6 02:15:19.414: INFO: (16) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 5.394748ms)
Nov  6 02:15:19.414: INFO: (16) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 5.492007ms)
Nov  6 02:15:19.415: INFO: (16) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 6.440272ms)
Nov  6 02:15:19.419: INFO: (17) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 3.567198ms)
Nov  6 02:15:19.419: INFO: (17) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 3.47345ms)
Nov  6 02:15:19.419: INFO: (17) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 3.656047ms)
Nov  6 02:15:19.419: INFO: (17) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 4.023198ms)
Nov  6 02:15:19.419: INFO: (17) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 3.975197ms)
Nov  6 02:15:19.419: INFO: (17) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 4.129619ms)
Nov  6 02:15:19.420: INFO: (17) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 4.693123ms)
Nov  6 02:15:19.420: INFO: (17) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 4.874225ms)
Nov  6 02:15:19.421: INFO: (17) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 5.40851ms)
Nov  6 02:15:19.421: INFO: (17) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 5.513349ms)
Nov  6 02:15:19.421: INFO: (17) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 5.942014ms)
Nov  6 02:15:19.422: INFO: (17) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 6.306106ms)
Nov  6 02:15:19.422: INFO: (17) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 6.17349ms)
Nov  6 02:15:19.422: INFO: (17) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 6.227133ms)
Nov  6 02:15:19.422: INFO: (17) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 6.265315ms)
Nov  6 02:15:19.422: INFO: (17) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 6.166328ms)
Nov  6 02:15:19.426: INFO: (18) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 3.983487ms)
Nov  6 02:15:19.426: INFO: (18) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 3.836062ms)
Nov  6 02:15:19.426: INFO: (18) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 3.701652ms)
Nov  6 02:15:19.426: INFO: (18) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 3.307922ms)
Nov  6 02:15:19.427: INFO: (18) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 4.643701ms)
Nov  6 02:15:19.427: INFO: (18) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 3.958575ms)
Nov  6 02:15:19.427: INFO: (18) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 4.448426ms)
Nov  6 02:15:19.427: INFO: (18) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 4.190816ms)
Nov  6 02:15:19.427: INFO: (18) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 4.513824ms)
Nov  6 02:15:19.427: INFO: (18) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 4.747552ms)
Nov  6 02:15:19.427: INFO: (18) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 5.366067ms)
Nov  6 02:15:19.427: INFO: (18) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 5.170636ms)
Nov  6 02:15:19.427: INFO: (18) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 4.959203ms)
Nov  6 02:15:19.427: INFO: (18) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 4.573704ms)
Nov  6 02:15:19.427: INFO: (18) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 4.898328ms)
Nov  6 02:15:19.427: INFO: (18) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 5.382494ms)
Nov  6 02:15:19.432: INFO: (19) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname2/proxy/: bar (200; 4.695415ms)
Nov  6 02:15:19.432: INFO: (19) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 4.928136ms)
Nov  6 02:15:19.433: INFO: (19) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm/proxy/rewriteme">test</a> (200; 5.171543ms)
Nov  6 02:15:19.433: INFO: (19) /api/v1/namespaces/proxy-6867/services/http:proxy-service-ppt8k:portname1/proxy/: foo (200; 5.182343ms)
Nov  6 02:15:19.433: INFO: (19) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname2/proxy/: bar (200; 5.781583ms)
Nov  6 02:15:19.433: INFO: (19) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname2/proxy/: tls qux (200; 5.823274ms)
Nov  6 02:15:19.433: INFO: (19) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:162/proxy/: bar (200; 5.795286ms)
Nov  6 02:15:19.433: INFO: (19) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:443/proxy/tlsrewritem... (200; 5.77431ms)
Nov  6 02:15:19.433: INFO: (19) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:460/proxy/: tls baz (200; 5.766834ms)
Nov  6 02:15:19.433: INFO: (19) /api/v1/namespaces/proxy-6867/services/proxy-service-ppt8k:portname1/proxy/: foo (200; 5.752711ms)
Nov  6 02:15:19.434: INFO: (19) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">... (200; 6.154114ms)
Nov  6 02:15:19.434: INFO: (19) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 6.105504ms)
Nov  6 02:15:19.434: INFO: (19) /api/v1/namespaces/proxy-6867/pods/https:proxy-service-ppt8k-tz8sm:462/proxy/: tls qux (200; 6.083773ms)
Nov  6 02:15:19.434: INFO: (19) /api/v1/namespaces/proxy-6867/services/https:proxy-service-ppt8k:tlsportname1/proxy/: tls baz (200; 6.167242ms)
Nov  6 02:15:19.434: INFO: (19) /api/v1/namespaces/proxy-6867/pods/http:proxy-service-ppt8k-tz8sm:160/proxy/: foo (200; 6.336015ms)
Nov  6 02:15:19.434: INFO: (19) /api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/: <a href="/api/v1/namespaces/proxy-6867/pods/proxy-service-ppt8k-tz8sm:1080/proxy/rewriteme">test<... (200; 6.49849ms)
STEP: deleting ReplicationController proxy-service-ppt8k in namespace proxy-6867, will wait for the garbage collector to delete the pods
Nov  6 02:15:19.489: INFO: Deleting ReplicationController proxy-service-ppt8k took: 3.627558ms
Nov  6 02:15:19.890: INFO: Terminating ReplicationController proxy-service-ppt8k pods took: 400.217444ms
[AfterEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:15:33.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6867" for this suite.
Nov  6 02:15:39.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:15:39.749: INFO: namespace proxy-6867 deletion completed in 6.05643278s

• [SLOW TEST:28.614 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:15:39.749: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  6 02:15:39.843: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40575768-17ec-47e8-8b7a-02c054768760" in namespace "downward-api-1178" to be "success or failure"
Nov  6 02:15:39.850: INFO: Pod "downwardapi-volume-40575768-17ec-47e8-8b7a-02c054768760": Phase="Pending", Reason="", readiness=false. Elapsed: 6.837084ms
Nov  6 02:15:41.852: INFO: Pod "downwardapi-volume-40575768-17ec-47e8-8b7a-02c054768760": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009221966s
Nov  6 02:15:43.855: INFO: Pod "downwardapi-volume-40575768-17ec-47e8-8b7a-02c054768760": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01209359s
STEP: Saw pod success
Nov  6 02:15:43.855: INFO: Pod "downwardapi-volume-40575768-17ec-47e8-8b7a-02c054768760" satisfied condition "success or failure"
Nov  6 02:15:43.857: INFO: Trying to get logs from node apps-114 pod downwardapi-volume-40575768-17ec-47e8-8b7a-02c054768760 container client-container: <nil>
STEP: delete the pod
Nov  6 02:15:43.887: INFO: Waiting for pod downwardapi-volume-40575768-17ec-47e8-8b7a-02c054768760 to disappear
Nov  6 02:15:43.914: INFO: Pod downwardapi-volume-40575768-17ec-47e8-8b7a-02c054768760 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:15:43.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1178" for this suite.
Nov  6 02:15:49.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:15:49.987: INFO: namespace downward-api-1178 deletion completed in 6.070207667s

• [SLOW TEST:10.237 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:15:49.987: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Nov  6 02:15:50.041: INFO: Pod name pod-release: Found 0 pods out of 1
Nov  6 02:15:55.044: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:15:56.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4063" for this suite.
Nov  6 02:16:02.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:16:02.195: INFO: namespace replication-controller-4063 deletion completed in 6.130535654s

• [SLOW TEST:12.208 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:16:02.195: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-2604
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  6 02:16:02.234: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  6 02:16:32.352: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.38.96.127 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2604 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  6 02:16:32.352: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 02:16:33.501: INFO: Found all expected endpoints: [netserver-0]
Nov  6 02:16:33.503: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.47.0.40 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2604 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  6 02:16:33.503: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 02:16:34.681: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:16:34.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2604" for this suite.
Nov  6 02:16:46.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:16:46.754: INFO: namespace pod-network-test-2604 deletion completed in 12.06873872s

• [SLOW TEST:44.559 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:16:46.754: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  6 02:16:48.200: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  6 02:16:50.206: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603408, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603408, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603408, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603408, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  6 02:16:53.236: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:16:53.238: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-924-crds.webhook.example.com via the AdmissionRegistration API
Nov  6 02:16:53.827: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:16:54.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2182" for this suite.
Nov  6 02:17:00.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:17:00.628: INFO: namespace webhook-2182 deletion completed in 6.088184348s
STEP: Destroying namespace "webhook-2182-markers" for this suite.
Nov  6 02:17:06.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:17:06.694: INFO: namespace webhook-2182-markers deletion completed in 6.066185471s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.948 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:17:06.702: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:17:06.754: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-beea78c8-3319-4614-9eb9-fbd16b4f9842" in namespace "security-context-test-5739" to be "success or failure"
Nov  6 02:17:06.761: INFO: Pod "busybox-readonly-false-beea78c8-3319-4614-9eb9-fbd16b4f9842": Phase="Pending", Reason="", readiness=false. Elapsed: 6.948968ms
Nov  6 02:17:08.764: INFO: Pod "busybox-readonly-false-beea78c8-3319-4614-9eb9-fbd16b4f9842": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009945902s
Nov  6 02:17:10.766: INFO: Pod "busybox-readonly-false-beea78c8-3319-4614-9eb9-fbd16b4f9842": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012351984s
Nov  6 02:17:10.766: INFO: Pod "busybox-readonly-false-beea78c8-3319-4614-9eb9-fbd16b4f9842" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:17:10.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5739" for this suite.
Nov  6 02:17:16.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:17:16.843: INFO: namespace security-context-test-5739 deletion completed in 6.073948117s

• [SLOW TEST:10.140 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:17:16.843: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:17:16.920: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Nov  6 02:17:18.995: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:17:20.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7396" for this suite.
Nov  6 02:17:26.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:17:26.071: INFO: namespace replication-controller-7396 deletion completed in 6.063108456s

• [SLOW TEST:9.229 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:17:26.072: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov  6 02:17:30.640: INFO: Successfully updated pod "pod-update-activedeadlineseconds-9f2331a9-dcba-4b51-9f73-6a47f22372f5"
Nov  6 02:17:30.640: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-9f2331a9-dcba-4b51-9f73-6a47f22372f5" in namespace "pods-6257" to be "terminated due to deadline exceeded"
Nov  6 02:17:30.653: INFO: Pod "pod-update-activedeadlineseconds-9f2331a9-dcba-4b51-9f73-6a47f22372f5": Phase="Running", Reason="", readiness=true. Elapsed: 12.666145ms
Nov  6 02:17:32.655: INFO: Pod "pod-update-activedeadlineseconds-9f2331a9-dcba-4b51-9f73-6a47f22372f5": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.014802798s
Nov  6 02:17:32.655: INFO: Pod "pod-update-activedeadlineseconds-9f2331a9-dcba-4b51-9f73-6a47f22372f5" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:17:32.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6257" for this suite.
Nov  6 02:17:38.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:17:38.729: INFO: namespace pods-6257 deletion completed in 6.071397925s

• [SLOW TEST:12.657 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:17:38.729: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Nov  6 02:17:39.419: INFO: Pod name wrapped-volume-race-4f6a14d3-5a1d-40ab-8958-1ef7a98b0b5a: Found 0 pods out of 5
Nov  6 02:17:44.425: INFO: Pod name wrapped-volume-race-4f6a14d3-5a1d-40ab-8958-1ef7a98b0b5a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-4f6a14d3-5a1d-40ab-8958-1ef7a98b0b5a in namespace emptydir-wrapper-7682, will wait for the garbage collector to delete the pods
Nov  6 02:17:58.508: INFO: Deleting ReplicationController wrapped-volume-race-4f6a14d3-5a1d-40ab-8958-1ef7a98b0b5a took: 10.525853ms
Nov  6 02:17:58.908: INFO: Terminating ReplicationController wrapped-volume-race-4f6a14d3-5a1d-40ab-8958-1ef7a98b0b5a pods took: 400.137807ms
STEP: Creating RC which spawns configmap-volume pods
Nov  6 02:18:37.476: INFO: Pod name wrapped-volume-race-ee0a9a78-a84d-430a-88cc-cc36f44b7b0b: Found 0 pods out of 5
Nov  6 02:18:42.481: INFO: Pod name wrapped-volume-race-ee0a9a78-a84d-430a-88cc-cc36f44b7b0b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-ee0a9a78-a84d-430a-88cc-cc36f44b7b0b in namespace emptydir-wrapper-7682, will wait for the garbage collector to delete the pods
Nov  6 02:18:56.586: INFO: Deleting ReplicationController wrapped-volume-race-ee0a9a78-a84d-430a-88cc-cc36f44b7b0b took: 39.53252ms
Nov  6 02:18:56.986: INFO: Terminating ReplicationController wrapped-volume-race-ee0a9a78-a84d-430a-88cc-cc36f44b7b0b pods took: 400.229676ms
STEP: Creating RC which spawns configmap-volume pods
Nov  6 02:19:39.547: INFO: Pod name wrapped-volume-race-bb34fba7-8c40-4da0-82fc-878419e78496: Found 0 pods out of 5
Nov  6 02:19:44.553: INFO: Pod name wrapped-volume-race-bb34fba7-8c40-4da0-82fc-878419e78496: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-bb34fba7-8c40-4da0-82fc-878419e78496 in namespace emptydir-wrapper-7682, will wait for the garbage collector to delete the pods
Nov  6 02:20:00.718: INFO: Deleting ReplicationController wrapped-volume-race-bb34fba7-8c40-4da0-82fc-878419e78496 took: 4.194135ms
Nov  6 02:20:01.118: INFO: Terminating ReplicationController wrapped-volume-race-bb34fba7-8c40-4da0-82fc-878419e78496 pods took: 400.198539ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:20:39.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7682" for this suite.
Nov  6 02:20:47.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:20:47.847: INFO: namespace emptydir-wrapper-7682 deletion completed in 8.057124934s

• [SLOW TEST:189.118 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:20:47.848: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov  6 02:20:47.934: INFO: Waiting up to 5m0s for pod "pod-f7833dd8-b960-4ab0-b127-7025af70157a" in namespace "emptydir-5777" to be "success or failure"
Nov  6 02:20:47.949: INFO: Pod "pod-f7833dd8-b960-4ab0-b127-7025af70157a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.753846ms
Nov  6 02:20:49.952: INFO: Pod "pod-f7833dd8-b960-4ab0-b127-7025af70157a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017817353s
Nov  6 02:20:51.955: INFO: Pod "pod-f7833dd8-b960-4ab0-b127-7025af70157a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020363545s
STEP: Saw pod success
Nov  6 02:20:51.955: INFO: Pod "pod-f7833dd8-b960-4ab0-b127-7025af70157a" satisfied condition "success or failure"
Nov  6 02:20:51.956: INFO: Trying to get logs from node apps-114 pod pod-f7833dd8-b960-4ab0-b127-7025af70157a container test-container: <nil>
STEP: delete the pod
Nov  6 02:20:51.975: INFO: Waiting for pod pod-f7833dd8-b960-4ab0-b127-7025af70157a to disappear
Nov  6 02:20:51.982: INFO: Pod pod-f7833dd8-b960-4ab0-b127-7025af70157a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:20:51.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5777" for this suite.
Nov  6 02:20:57.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:20:58.041: INFO: namespace emptydir-5777 deletion completed in 6.05670894s

• [SLOW TEST:10.194 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:20:58.041: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-5aa1a9ea-579d-4a2f-850c-bb05567048bb
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:21:02.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7702" for this suite.
Nov  6 02:21:14.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:21:14.231: INFO: namespace configmap-7702 deletion completed in 12.107042428s

• [SLOW TEST:16.190 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:21:14.231: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  6 02:21:15.016: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  6 02:21:17.022: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603675, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603675, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603675, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603675, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  6 02:21:20.047: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:21:20.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9310" for this suite.
Nov  6 02:21:26.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:21:26.316: INFO: namespace webhook-9310 deletion completed in 6.106421673s
STEP: Destroying namespace "webhook-9310-markers" for this suite.
Nov  6 02:21:32.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:21:32.410: INFO: namespace webhook-9310-markers deletion completed in 6.094311323s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.186 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:21:32.417: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Nov  6 02:21:32.456: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Nov  6 02:21:33.368: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Nov  6 02:21:35.514: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  6 02:21:37.517: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  6 02:21:39.516: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  6 02:21:41.516: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  6 02:21:43.517: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  6 02:21:45.517: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  6 02:21:47.517: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  6 02:21:49.517: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603693, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  6 02:21:52.641: INFO: Waited 1.118959729s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:21:53.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-6547" for this suite.
Nov  6 02:21:59.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:21:59.370: INFO: namespace aggregator-6547 deletion completed in 6.182522366s

• [SLOW TEST:26.952 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:21:59.370: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  6 02:22:00.433: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  6 02:22:02.439: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603720, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603720, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603720, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708603720, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  6 02:22:05.474: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:22:15.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-202" for this suite.
Nov  6 02:22:21.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:22:21.716: INFO: namespace webhook-202 deletion completed in 6.069019691s
STEP: Destroying namespace "webhook-202-markers" for this suite.
Nov  6 02:22:27.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:22:27.780: INFO: namespace webhook-202-markers deletion completed in 6.064034395s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.418 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:22:27.788: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Nov  6 02:22:27.896: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8474 /api/v1/namespaces/watch-8474/configmaps/e2e-watch-test-resource-version b4e2a4c8-b6b0-4d1c-a1f3-f9fc9a2fdcb7 868440 0 2019-11-06 02:22:27 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  6 02:22:27.896: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8474 /api/v1/namespaces/watch-8474/configmaps/e2e-watch-test-resource-version b4e2a4c8-b6b0-4d1c-a1f3-f9fc9a2fdcb7 868441 0 2019-11-06 02:22:27 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:22:27.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8474" for this suite.
Nov  6 02:22:34.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:22:34.094: INFO: namespace watch-8474 deletion completed in 6.18690818s

• [SLOW TEST:6.306 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:22:34.094: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-48d8241b-71af-4f38-a80a-6ad6b7173278 in namespace container-probe-5570
Nov  6 02:22:38.192: INFO: Started pod busybox-48d8241b-71af-4f38-a80a-6ad6b7173278 in namespace container-probe-5570
STEP: checking the pod's current state and verifying that restartCount is present
Nov  6 02:22:38.193: INFO: Initial restart count of pod busybox-48d8241b-71af-4f38-a80a-6ad6b7173278 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:26:38.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5570" for this suite.
Nov  6 02:26:44.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:26:44.685: INFO: namespace container-probe-5570 deletion completed in 6.067017999s

• [SLOW TEST:250.591 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:26:44.685: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-5610
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  6 02:26:44.727: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  6 02:27:04.805: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.38.96.81:8080/dial?request=hostName&protocol=http&host=10.47.0.56&port=8080&tries=1'] Namespace:pod-network-test-5610 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  6 02:27:04.805: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 02:27:04.984: INFO: Waiting for endpoints: map[]
Nov  6 02:27:04.987: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.38.96.81:8080/dial?request=hostName&protocol=http&host=10.38.96.80&port=8080&tries=1'] Namespace:pod-network-test-5610 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  6 02:27:04.987: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 02:27:05.196: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:27:05.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5610" for this suite.
Nov  6 02:27:17.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:27:17.291: INFO: namespace pod-network-test-5610 deletion completed in 12.071358652s

• [SLOW TEST:32.605 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:27:17.291: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-3085cb05-c3ef-48df-956e-67a5095a721b
STEP: Creating a pod to test consume secrets
Nov  6 02:27:17.471: INFO: Waiting up to 5m0s for pod "pod-secrets-7893c6cb-4cfd-4f2b-a53e-0e254ac30057" in namespace "secrets-9594" to be "success or failure"
Nov  6 02:27:17.475: INFO: Pod "pod-secrets-7893c6cb-4cfd-4f2b-a53e-0e254ac30057": Phase="Pending", Reason="", readiness=false. Elapsed: 3.836453ms
Nov  6 02:27:19.478: INFO: Pod "pod-secrets-7893c6cb-4cfd-4f2b-a53e-0e254ac30057": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006947694s
Nov  6 02:27:21.481: INFO: Pod "pod-secrets-7893c6cb-4cfd-4f2b-a53e-0e254ac30057": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009983255s
STEP: Saw pod success
Nov  6 02:27:21.482: INFO: Pod "pod-secrets-7893c6cb-4cfd-4f2b-a53e-0e254ac30057" satisfied condition "success or failure"
Nov  6 02:27:21.483: INFO: Trying to get logs from node apps-114 pod pod-secrets-7893c6cb-4cfd-4f2b-a53e-0e254ac30057 container secret-volume-test: <nil>
STEP: delete the pod
Nov  6 02:27:21.522: INFO: Waiting for pod pod-secrets-7893c6cb-4cfd-4f2b-a53e-0e254ac30057 to disappear
Nov  6 02:27:21.525: INFO: Pod pod-secrets-7893c6cb-4cfd-4f2b-a53e-0e254ac30057 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:27:21.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9594" for this suite.
Nov  6 02:27:27.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:27:27.615: INFO: namespace secrets-9594 deletion completed in 6.071560569s
STEP: Destroying namespace "secret-namespace-2952" for this suite.
Nov  6 02:27:33.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:27:33.689: INFO: namespace secret-namespace-2952 deletion completed in 6.073594121s

• [SLOW TEST:16.397 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:27:33.689: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  6 02:27:33.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-8405'
Nov  6 02:27:35.609: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  6 02:27:35.609: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Nov  6 02:27:35.619: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Nov  6 02:27:35.626: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Nov  6 02:27:35.654: INFO: scanned /root for discovery docs: <nil>
Nov  6 02:27:35.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-8405'
Nov  6 02:27:51.512: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov  6 02:27:51.512: INFO: stdout: "Created e2e-test-httpd-rc-ece48cfb71ea37efbc7cf245ddd0a8f3\nScaling up e2e-test-httpd-rc-ece48cfb71ea37efbc7cf245ddd0a8f3 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-ece48cfb71ea37efbc7cf245ddd0a8f3 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-ece48cfb71ea37efbc7cf245ddd0a8f3 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Nov  6 02:27:51.512: INFO: stdout: "Created e2e-test-httpd-rc-ece48cfb71ea37efbc7cf245ddd0a8f3\nScaling up e2e-test-httpd-rc-ece48cfb71ea37efbc7cf245ddd0a8f3 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-ece48cfb71ea37efbc7cf245ddd0a8f3 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-ece48cfb71ea37efbc7cf245ddd0a8f3 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Nov  6 02:27:51.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-8405'
Nov  6 02:27:51.599: INFO: stderr: ""
Nov  6 02:27:51.599: INFO: stdout: "e2e-test-httpd-rc-d8fmj e2e-test-httpd-rc-ece48cfb71ea37efbc7cf245ddd0a8f3-ghwvz "
STEP: Replicas for run=e2e-test-httpd-rc: expected=1 actual=2
Nov  6 02:27:56.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-8405'
Nov  6 02:27:56.688: INFO: stderr: ""
Nov  6 02:27:56.688: INFO: stdout: "e2e-test-httpd-rc-ece48cfb71ea37efbc7cf245ddd0a8f3-ghwvz "
Nov  6 02:27:56.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods e2e-test-httpd-rc-ece48cfb71ea37efbc7cf245ddd0a8f3-ghwvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8405'
Nov  6 02:27:56.774: INFO: stderr: ""
Nov  6 02:27:56.774: INFO: stdout: "true"
Nov  6 02:27:56.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods e2e-test-httpd-rc-ece48cfb71ea37efbc7cf245ddd0a8f3-ghwvz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8405'
Nov  6 02:27:56.857: INFO: stderr: ""
Nov  6 02:27:56.857: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Nov  6 02:27:56.857: INFO: e2e-test-httpd-rc-ece48cfb71ea37efbc7cf245ddd0a8f3-ghwvz is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Nov  6 02:27:56.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 delete rc e2e-test-httpd-rc --namespace=kubectl-8405'
Nov  6 02:27:56.943: INFO: stderr: ""
Nov  6 02:27:56.943: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:27:56.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8405" for this suite.
Nov  6 02:28:08.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:28:09.001: INFO: namespace kubectl-8405 deletion completed in 12.055594472s

• [SLOW TEST:35.313 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:28:09.002: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov  6 02:28:13.577: INFO: Successfully updated pod "annotationupdate4898469c-c7bc-4b32-9609-5051d9d6564f"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:28:15.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-395" for this suite.
Nov  6 02:28:43.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:28:43.677: INFO: namespace projected-395 deletion completed in 28.06719149s

• [SLOW TEST:34.675 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:28:43.677: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-2415baae-1b42-45de-b4e0-89f735084a92
STEP: Creating a pod to test consume configMaps
Nov  6 02:28:43.751: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f532ff6c-7a27-48af-9e5f-617049bbdc41" in namespace "projected-7880" to be "success or failure"
Nov  6 02:28:43.758: INFO: Pod "pod-projected-configmaps-f532ff6c-7a27-48af-9e5f-617049bbdc41": Phase="Pending", Reason="", readiness=false. Elapsed: 7.04285ms
Nov  6 02:28:45.761: INFO: Pod "pod-projected-configmaps-f532ff6c-7a27-48af-9e5f-617049bbdc41": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009741114s
Nov  6 02:28:47.764: INFO: Pod "pod-projected-configmaps-f532ff6c-7a27-48af-9e5f-617049bbdc41": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012312985s
STEP: Saw pod success
Nov  6 02:28:47.764: INFO: Pod "pod-projected-configmaps-f532ff6c-7a27-48af-9e5f-617049bbdc41" satisfied condition "success or failure"
Nov  6 02:28:47.765: INFO: Trying to get logs from node apps-114 pod pod-projected-configmaps-f532ff6c-7a27-48af-9e5f-617049bbdc41 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  6 02:28:47.791: INFO: Waiting for pod pod-projected-configmaps-f532ff6c-7a27-48af-9e5f-617049bbdc41 to disappear
Nov  6 02:28:47.800: INFO: Pod pod-projected-configmaps-f532ff6c-7a27-48af-9e5f-617049bbdc41 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:28:47.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7880" for this suite.
Nov  6 02:28:53.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:28:53.858: INFO: namespace projected-7880 deletion completed in 6.055912733s

• [SLOW TEST:10.181 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:28:53.858: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:28:53.933: INFO: Creating deployment "webserver-deployment"
Nov  6 02:28:53.942: INFO: Waiting for observed generation 1
Nov  6 02:28:55.952: INFO: Waiting for all required pods to come up
Nov  6 02:28:55.955: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Nov  6 02:29:03.961: INFO: Waiting for deployment "webserver-deployment" to complete
Nov  6 02:29:03.966: INFO: Updating deployment "webserver-deployment" with a non-existent image
Nov  6 02:29:03.970: INFO: Updating deployment webserver-deployment
Nov  6 02:29:03.970: INFO: Waiting for observed generation 2
Nov  6 02:29:05.993: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov  6 02:29:05.994: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov  6 02:29:05.996: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov  6 02:29:06.000: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov  6 02:29:06.000: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov  6 02:29:06.002: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov  6 02:29:06.005: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Nov  6 02:29:06.005: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Nov  6 02:29:06.009: INFO: Updating deployment webserver-deployment
Nov  6 02:29:06.009: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Nov  6 02:29:06.028: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov  6 02:29:06.041: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  6 02:29:06.125: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-1403 /apis/apps/v1/namespaces/deployment-1403/deployments/webserver-deployment 0aad38ad-c7ce-4020-9840-c3e33c5a4241 869575 3 2019-11-06 02:28:53 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000ea1a58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-11-06 02:29:04 +0000 UTC,LastTransitionTime:2019-11-06 02:28:53 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-11-06 02:29:06 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Nov  6 02:29:06.138: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-1403 /apis/apps/v1/namespaces/deployment-1403/replicasets/webserver-deployment-c7997dcc8 dd743175-27b4-41d8-ac4e-d145442ca11c 869566 3 2019-11-06 02:29:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 0aad38ad-c7ce-4020-9840-c3e33c5a4241 0xc003d747a7 0xc003d747a8}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003d74818 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  6 02:29:06.138: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Nov  6 02:29:06.138: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-1403 /apis/apps/v1/namespaces/deployment-1403/replicasets/webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 869607 3 2019-11-06 02:28:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 0aad38ad-c7ce-4020-9840-c3e33c5a4241 0xc003d746e7 0xc003d746e8}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003d74748 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Nov  6 02:29:06.156: INFO: Pod "webserver-deployment-595b5b9587-2gc45" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2gc45 webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-2gc45 befda2f7-5bbf-4e01-a567-6dd094b43823 869476 0 2019-11-06 02:28:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.38.96.95/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc000ea1ee7 0xc000ea1ee8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:28:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:28:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.114,PodIP:10.38.96.95,StartTime:2019-11-06 02:28:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-06 02:29:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://ef4b7a245a8b8852e2de553d19a3052efbc3d31917f929929e5b1d89f0425d0f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.38.96.95,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.156: INFO: Pod "webserver-deployment-595b5b9587-2tc79" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2tc79 webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-2tc79 c67791ee-e81f-4a9c-a723-68c0a5babd39 869582 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc003acc157 0xc003acc158}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.156: INFO: Pod "webserver-deployment-595b5b9587-4zv2z" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4zv2z webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-4zv2z 0a96f536-4697-42a4-811c-0af43538dd00 869578 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc003acc270 0xc003acc271}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.156: INFO: Pod "webserver-deployment-595b5b9587-5jc2g" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-5jc2g webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-5jc2g 45ac560d-ce5d-410f-9cd6-2513f9b44e5b 869479 0 2019-11-06 02:28:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.38.96.93/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc003acc390 0xc003acc391}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:28:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:28:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.114,PodIP:10.38.96.93,StartTime:2019-11-06 02:28:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-06 02:28:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://fa550a1c50545b6c98872784d3ce9a93bc44da33fa87aa08c552dc7a6f6ff659,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.38.96.93,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.156: INFO: Pod "webserver-deployment-595b5b9587-646sk" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-646sk webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-646sk b0e239e7-29c7-4e5a-9c3e-df08f48753ea 869489 0 2019-11-06 02:28:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.38.96.64/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc003acc517 0xc003acc518}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:28:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:28:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.114,PodIP:10.38.96.64,StartTime:2019-11-06 02:28:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-06 02:29:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://581a5771dedc9f0d0f088f38ed6c124e89e0b14cf418d49eef244241fc5cb7fd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.38.96.64,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.157: INFO: Pod "webserver-deployment-595b5b9587-662fh" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-662fh webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-662fh ac196397-eee8-4751-aafd-52a6c4687576 869618 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc003acc697 0xc003acc698}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.157: INFO: Pod "webserver-deployment-595b5b9587-698xd" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-698xd webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-698xd b1f818b1-9b1d-4c5f-9d48-c11a11603cd9 869600 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc003acc7b0 0xc003acc7b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.157: INFO: Pod "webserver-deployment-595b5b9587-b64hl" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-b64hl webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-b64hl ef606ce9-d708-4cbc-bcec-3c2aadb33c19 869472 0 2019-11-06 02:28:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.38.96.94/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc003acc8d0 0xc003acc8d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:28:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:28:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.114,PodIP:10.38.96.94,StartTime:2019-11-06 02:28:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-06 02:29:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://3cb92aa8fef2e2ab0d11f0cc3365cf513dc22cd75f9f3713c12fbdf92f42ee30,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.38.96.94,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.157: INFO: Pod "webserver-deployment-595b5b9587-bmncb" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-bmncb webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-bmncb ec825541-611a-4352-ac3a-39fdbbba1e4c 869619 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc003acca47 0xc003acca48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.157: INFO: Pod "webserver-deployment-595b5b9587-cj6sd" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-cj6sd webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-cj6sd 6b04cbb5-a7cb-410c-b64a-26a5618fd9c5 869617 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc003accb60 0xc003accb61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.157: INFO: Pod "webserver-deployment-595b5b9587-fkd2f" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-fkd2f webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-fkd2f 9e3787ab-8af2-470e-ba79-1f8430446465 869614 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc003accc70 0xc003accc71}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.158: INFO: Pod "webserver-deployment-595b5b9587-fnfmd" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-fnfmd webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-fnfmd 35dc428f-f4ef-40ce-9ae4-b937986f34b0 869598 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc003accd80 0xc003accd81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.158: INFO: Pod "webserver-deployment-595b5b9587-gzpsz" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gzpsz webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-gzpsz e59b99c4-a582-429c-b796-61a9b3f6ab8b 869599 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc003acce90 0xc003acce91}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.158: INFO: Pod "webserver-deployment-595b5b9587-htlzz" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-htlzz webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-htlzz b92fbbf7-24e3-47fa-bc66-704c44339e98 869470 0 2019-11-06 02:28:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.38.96.87/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc003accfc0 0xc003accfc1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:28:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:28:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.114,PodIP:10.38.96.87,StartTime:2019-11-06 02:28:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-06 02:28:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://dffa71d07f5b8fda8167db8558eb888ecc75304c44ee8c3d7f391881f71ee245,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.38.96.87,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.158: INFO: Pod "webserver-deployment-595b5b9587-lz462" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-lz462 webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-lz462 de1e9cbb-a9e7-4573-8f04-a66d898b2f97 869616 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc003acd137 0xc003acd138}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.158: INFO: Pod "webserver-deployment-595b5b9587-mppqp" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mppqp webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-mppqp 34155a93-bee5-4e40-b683-51c6d36b10bf 869425 0 2019-11-06 02:28:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.38.96.85/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc003acd280 0xc003acd281}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:28:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:28:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:28:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:28:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.114,PodIP:10.38.96.85,StartTime:2019-11-06 02:28:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-06 02:28:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://19eb5a51521cc5239c998088a949f565ecb7620e13b06ea73f7e55abc8794c6a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.38.96.85,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.158: INFO: Pod "webserver-deployment-595b5b9587-qsz5p" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-qsz5p webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-qsz5p 19d484d6-5ba9-4365-ae87-d10bb619e982 869467 0 2019-11-06 02:28:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.38.96.96/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc003acd407 0xc003acd408}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:28:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:28:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.114,PodIP:10.38.96.96,StartTime:2019-11-06 02:28:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-06 02:28:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://acd1eb3c716473f90417fc802cc29b6ec1749c5fae74799a26b26a9f040daa92,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.38.96.96,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.158: INFO: Pod "webserver-deployment-595b5b9587-rgltc" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rgltc webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-rgltc 601fc4b4-756e-4cd5-ac85-99f1b7898944 869603 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc003acd5b7 0xc003acd5b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.159: INFO: Pod "webserver-deployment-595b5b9587-sb55c" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-sb55c webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-sb55c bdeed912-976e-4693-9a18-99ff36850d01 869613 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc003acd6d0 0xc003acd6d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.114,PodIP:,StartTime:2019-11-06 02:29:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.159: INFO: Pod "webserver-deployment-595b5b9587-t8cn8" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-t8cn8 webserver-deployment-595b5b9587- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-595b5b9587-t8cn8 0133a399-f85e-43f5-8985-2f02e9be86a5 869484 0 2019-11-06 02:28:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.38.96.91/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 41921b36-6406-4e19-9a64-ae2472e43709 0xc003acd857 0xc003acd858}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:28:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:28:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.114,PodIP:10.38.96.91,StartTime:2019-11-06 02:28:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-06 02:28:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://f0a477d2b6392da553c07d0f9ebb3b5db795701d3951bb1af9970bfed8eb6f37,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.38.96.91,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.159: INFO: Pod "webserver-deployment-c7997dcc8-625wj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-625wj webserver-deployment-c7997dcc8- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-c7997dcc8-625wj 8c06f001-4d6b-4191-88e2-2194f035f873 869630 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd743175-27b4-41d8-ac4e-d145442ca11c 0xc003acda47 0xc003acda48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.159: INFO: Pod "webserver-deployment-c7997dcc8-72xjb" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-72xjb webserver-deployment-c7997dcc8- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-c7997dcc8-72xjb 41577a56-6d9a-466d-b5ba-8c5a79ed3702 869621 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd743175-27b4-41d8-ac4e-d145442ca11c 0xc003acdb70 0xc003acdb71}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.159: INFO: Pod "webserver-deployment-c7997dcc8-8nqkz" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-8nqkz webserver-deployment-c7997dcc8- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-c7997dcc8-8nqkz 9c753156-3e45-4ca1-8519-c742c4394e68 869581 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd743175-27b4-41d8-ac4e-d145442ca11c 0xc003acdc90 0xc003acdc91}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.160: INFO: Pod "webserver-deployment-c7997dcc8-cdssc" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-cdssc webserver-deployment-c7997dcc8- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-c7997dcc8-cdssc 09f2b6b8-7953-4b8f-a938-bf30605496ad 869527 0 2019-11-06 02:29:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd743175-27b4-41d8-ac4e-d145442ca11c 0xc003acddd0 0xc003acddd1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.114,PodIP:,StartTime:2019-11-06 02:29:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.160: INFO: Pod "webserver-deployment-c7997dcc8-grk5t" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-grk5t webserver-deployment-c7997dcc8- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-c7997dcc8-grk5t 3b00a6a5-aae8-4b21-8404-9e70ddbe6be1 869553 0 2019-11-06 02:29:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd743175-27b4-41d8-ac4e-d145442ca11c 0xc003acdf47 0xc003acdf48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.114,PodIP:,StartTime:2019-11-06 02:29:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.160: INFO: Pod "webserver-deployment-c7997dcc8-kcgh2" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-kcgh2 webserver-deployment-c7997dcc8- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-c7997dcc8-kcgh2 3509b45b-a0c2-4b7b-b64d-2d86730bf7ca 869539 0 2019-11-06 02:29:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd743175-27b4-41d8-ac4e-d145442ca11c 0xc0062560d7 0xc0062560d8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.114,PodIP:,StartTime:2019-11-06 02:29:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.160: INFO: Pod "webserver-deployment-c7997dcc8-pmkvt" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-pmkvt webserver-deployment-c7997dcc8- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-c7997dcc8-pmkvt f4866fc4-8d04-4a4d-92d3-15a86681d37a 869620 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd743175-27b4-41d8-ac4e-d145442ca11c 0xc006256267 0xc006256268}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.160: INFO: Pod "webserver-deployment-c7997dcc8-r72nh" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-r72nh webserver-deployment-c7997dcc8- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-c7997dcc8-r72nh 2c5a78cd-521f-45ee-86ed-7149e776a65f 869548 0 2019-11-06 02:29:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd743175-27b4-41d8-ac4e-d145442ca11c 0xc0062563a0 0xc0062563a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.114,PodIP:,StartTime:2019-11-06 02:29:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.160: INFO: Pod "webserver-deployment-c7997dcc8-rclp9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-rclp9 webserver-deployment-c7997dcc8- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-c7997dcc8-rclp9 9e9b1fb5-54c2-4560-a963-caaa359b2ae8 869612 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd743175-27b4-41d8-ac4e-d145442ca11c 0xc006256547 0xc006256548}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.161: INFO: Pod "webserver-deployment-c7997dcc8-rwkrv" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-rwkrv webserver-deployment-c7997dcc8- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-c7997dcc8-rwkrv 1446ac5e-61c3-467a-aad3-ab4fa38005ff 869602 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd743175-27b4-41d8-ac4e-d145442ca11c 0xc006256670 0xc006256671}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.161: INFO: Pod "webserver-deployment-c7997dcc8-sh62q" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-sh62q webserver-deployment-c7997dcc8- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-c7997dcc8-sh62q b4c60d03-d0fc-48f8-96a7-d935a184e2f5 869554 0 2019-11-06 02:29:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd743175-27b4-41d8-ac4e-d145442ca11c 0xc006256790 0xc006256791}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.114,PodIP:,StartTime:2019-11-06 02:29:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.161: INFO: Pod "webserver-deployment-c7997dcc8-tmwrw" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-tmwrw webserver-deployment-c7997dcc8- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-c7997dcc8-tmwrw d5644be5-988a-488d-8b92-630d2147a18a 869601 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd743175-27b4-41d8-ac4e-d145442ca11c 0xc006256977 0xc006256978}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  6 02:29:06.161: INFO: Pod "webserver-deployment-c7997dcc8-tqc6v" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-tqc6v webserver-deployment-c7997dcc8- deployment-1403 /api/v1/namespaces/deployment-1403/pods/webserver-deployment-c7997dcc8-tqc6v b1cd9d03-2d47-43ae-8029-eb6512060ae4 869622 0 2019-11-06 02:29:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd743175-27b4-41d8-ac4e-d145442ca11c 0xc006256aa0 0xc006256aa1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:29:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:29:06.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1403" for this suite.
Nov  6 02:29:14.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:29:14.271: INFO: namespace deployment-1403 deletion completed in 8.087269993s

• [SLOW TEST:20.412 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:29:14.271: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:29:14.318: INFO: Creating ReplicaSet my-hostname-basic-0e8a2931-9646-4475-bff4-059c0d396244
Nov  6 02:29:14.348: INFO: Pod name my-hostname-basic-0e8a2931-9646-4475-bff4-059c0d396244: Found 0 pods out of 1
Nov  6 02:29:19.351: INFO: Pod name my-hostname-basic-0e8a2931-9646-4475-bff4-059c0d396244: Found 1 pods out of 1
Nov  6 02:29:19.351: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-0e8a2931-9646-4475-bff4-059c0d396244" is running
Nov  6 02:29:27.355: INFO: Pod "my-hostname-basic-0e8a2931-9646-4475-bff4-059c0d396244-2l6qp" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-06 02:29:14 +0000 UTC Reason: Message:}])
Nov  6 02:29:27.355: INFO: Trying to dial the pod
Nov  6 02:29:32.363: INFO: Controller my-hostname-basic-0e8a2931-9646-4475-bff4-059c0d396244: Got expected result from replica 1 [my-hostname-basic-0e8a2931-9646-4475-bff4-059c0d396244-2l6qp]: "my-hostname-basic-0e8a2931-9646-4475-bff4-059c0d396244-2l6qp", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:29:32.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8069" for this suite.
Nov  6 02:29:38.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:29:38.436: INFO: namespace replicaset-8069 deletion completed in 6.070880536s

• [SLOW TEST:24.165 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:29:38.437: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:29:38.515: INFO: Waiting up to 5m0s for pod "busybox-user-65534-e7fef0b4-f45f-4038-95af-8525ed11aa47" in namespace "security-context-test-2015" to be "success or failure"
Nov  6 02:29:38.522: INFO: Pod "busybox-user-65534-e7fef0b4-f45f-4038-95af-8525ed11aa47": Phase="Pending", Reason="", readiness=false. Elapsed: 6.804699ms
Nov  6 02:29:40.525: INFO: Pod "busybox-user-65534-e7fef0b4-f45f-4038-95af-8525ed11aa47": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010095147s
Nov  6 02:29:42.528: INFO: Pod "busybox-user-65534-e7fef0b4-f45f-4038-95af-8525ed11aa47": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012746781s
Nov  6 02:29:42.528: INFO: Pod "busybox-user-65534-e7fef0b4-f45f-4038-95af-8525ed11aa47" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:29:42.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2015" for this suite.
Nov  6 02:29:48.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:29:48.597: INFO: namespace security-context-test-2015 deletion completed in 6.066478943s

• [SLOW TEST:10.160 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:29:48.597: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  6 02:29:49.434: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  6 02:29:51.441: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604189, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604189, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604189, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604189, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  6 02:29:54.485: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:29:54.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8431" for this suite.
Nov  6 02:30:00.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:30:00.707: INFO: namespace webhook-8431 deletion completed in 6.066496826s
STEP: Destroying namespace "webhook-8431-markers" for this suite.
Nov  6 02:30:06.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:30:06.809: INFO: namespace webhook-8431-markers deletion completed in 6.102405868s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.222 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:30:06.820: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:30:20.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7850" for this suite.
Nov  6 02:30:26.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:30:26.089: INFO: namespace resourcequota-7850 deletion completed in 6.085212349s

• [SLOW TEST:19.270 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:30:26.090: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:30:30.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5881" for this suite.
Nov  6 02:31:14.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:31:14.267: INFO: namespace kubelet-test-5881 deletion completed in 44.068307341s

• [SLOW TEST:48.177 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:31:14.268: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-9804a021-dc14-4e45-b38e-c50b9fba622c
STEP: Creating secret with name s-test-opt-upd-6fafae08-9061-4c92-8849-afd759bb28d2
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-9804a021-dc14-4e45-b38e-c50b9fba622c
STEP: Updating secret s-test-opt-upd-6fafae08-9061-4c92-8849-afd759bb28d2
STEP: Creating secret with name s-test-opt-create-e2e0e957-1570-4831-a48f-08ab7468ee18
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:31:22.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-580" for this suite.
Nov  6 02:31:50.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:31:50.546: INFO: namespace projected-580 deletion completed in 28.074288533s

• [SLOW TEST:36.279 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:31:50.546: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-4177
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4177 to expose endpoints map[]
Nov  6 02:31:50.640: INFO: Get endpoints failed (11.049424ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Nov  6 02:31:51.642: INFO: successfully validated that service endpoint-test2 in namespace services-4177 exposes endpoints map[] (1.013168214s elapsed)
STEP: Creating pod pod1 in namespace services-4177
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4177 to expose endpoints map[pod1:[80]]
Nov  6 02:31:54.679: INFO: successfully validated that service endpoint-test2 in namespace services-4177 exposes endpoints map[pod1:[80]] (3.033364914s elapsed)
STEP: Creating pod pod2 in namespace services-4177
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4177 to expose endpoints map[pod1:[80] pod2:[80]]
Nov  6 02:31:57.727: INFO: successfully validated that service endpoint-test2 in namespace services-4177 exposes endpoints map[pod1:[80] pod2:[80]] (3.045133852s elapsed)
STEP: Deleting pod pod1 in namespace services-4177
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4177 to expose endpoints map[pod2:[80]]
Nov  6 02:31:58.754: INFO: successfully validated that service endpoint-test2 in namespace services-4177 exposes endpoints map[pod2:[80]] (1.024291543s elapsed)
STEP: Deleting pod pod2 in namespace services-4177
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4177 to expose endpoints map[]
Nov  6 02:31:59.769: INFO: successfully validated that service endpoint-test2 in namespace services-4177 exposes endpoints map[] (1.011730325s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:31:59.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4177" for this suite.
Nov  6 02:32:05.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:32:05.909: INFO: namespace services-4177 deletion completed in 6.065715884s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:15.363 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:32:05.910: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:32:09.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1795" for this suite.
Nov  6 02:32:54.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:32:54.073: INFO: namespace kubelet-test-1795 deletion completed in 44.092367558s

• [SLOW TEST:48.163 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:32:54.073: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov  6 02:32:54.114: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:32:58.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7828" for this suite.
Nov  6 02:33:04.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:33:04.524: INFO: namespace init-container-7828 deletion completed in 6.107323212s

• [SLOW TEST:10.451 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:33:04.524: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Nov  6 02:33:04.564: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:33:25.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-469" for this suite.
Nov  6 02:33:31.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:33:31.859: INFO: namespace crd-publish-openapi-469 deletion completed in 6.062706089s

• [SLOW TEST:27.335 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:33:31.859: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  6 02:33:31.934: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8fca3ca7-9afb-42d1-a4b5-83e14247684a" in namespace "projected-2050" to be "success or failure"
Nov  6 02:33:31.941: INFO: Pod "downwardapi-volume-8fca3ca7-9afb-42d1-a4b5-83e14247684a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.832961ms
Nov  6 02:33:33.949: INFO: Pod "downwardapi-volume-8fca3ca7-9afb-42d1-a4b5-83e14247684a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014503822s
Nov  6 02:33:35.952: INFO: Pod "downwardapi-volume-8fca3ca7-9afb-42d1-a4b5-83e14247684a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017098584s
STEP: Saw pod success
Nov  6 02:33:35.952: INFO: Pod "downwardapi-volume-8fca3ca7-9afb-42d1-a4b5-83e14247684a" satisfied condition "success or failure"
Nov  6 02:33:35.953: INFO: Trying to get logs from node apps-114 pod downwardapi-volume-8fca3ca7-9afb-42d1-a4b5-83e14247684a container client-container: <nil>
STEP: delete the pod
Nov  6 02:33:35.981: INFO: Waiting for pod downwardapi-volume-8fca3ca7-9afb-42d1-a4b5-83e14247684a to disappear
Nov  6 02:33:35.991: INFO: Pod downwardapi-volume-8fca3ca7-9afb-42d1-a4b5-83e14247684a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:33:35.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2050" for this suite.
Nov  6 02:33:42.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:33:42.080: INFO: namespace projected-2050 deletion completed in 6.086731895s

• [SLOW TEST:10.221 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:33:42.081: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  6 02:33:45.151: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:33:45.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8681" for this suite.
Nov  6 02:33:51.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:33:51.269: INFO: namespace container-runtime-8681 deletion completed in 6.068572412s

• [SLOW TEST:9.188 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:33:51.269: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:33:51.324: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov  6 02:33:56.327: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  6 02:33:56.328: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov  6 02:33:58.330: INFO: Creating deployment "test-rollover-deployment"
Nov  6 02:33:58.355: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov  6 02:34:00.360: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov  6 02:34:00.364: INFO: Ensure that both replica sets have 1 created replica
Nov  6 02:34:00.367: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov  6 02:34:00.371: INFO: Updating deployment test-rollover-deployment
Nov  6 02:34:00.371: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov  6 02:34:02.418: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov  6 02:34:02.421: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov  6 02:34:02.424: INFO: all replica sets need to contain the pod-template-hash label
Nov  6 02:34:02.424: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604438, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604438, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604440, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604438, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  6 02:34:04.430: INFO: all replica sets need to contain the pod-template-hash label
Nov  6 02:34:04.430: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604438, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604438, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604442, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604438, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  6 02:34:06.430: INFO: all replica sets need to contain the pod-template-hash label
Nov  6 02:34:06.430: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604438, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604438, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604442, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604438, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  6 02:34:08.430: INFO: all replica sets need to contain the pod-template-hash label
Nov  6 02:34:08.430: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604438, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604438, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604442, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604438, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  6 02:34:10.430: INFO: all replica sets need to contain the pod-template-hash label
Nov  6 02:34:10.430: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604438, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604438, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604442, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604438, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  6 02:34:12.430: INFO: all replica sets need to contain the pod-template-hash label
Nov  6 02:34:12.430: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604438, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604438, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604442, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604438, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  6 02:34:14.430: INFO: 
Nov  6 02:34:14.430: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  6 02:34:14.435: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-8626 /apis/apps/v1/namespaces/deployment-8626/deployments/test-rollover-deployment 3ea9f926-61fe-4a28-9671-3dee2d32e16a 870938 2 2019-11-06 02:33:58 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0064d2568 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-11-06 02:33:58 +0000 UTC,LastTransitionTime:2019-11-06 02:33:58 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-11-06 02:34:12 +0000 UTC,LastTransitionTime:2019-11-06 02:33:58 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov  6 02:34:14.437: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-8626 /apis/apps/v1/namespaces/deployment-8626/replicasets/test-rollover-deployment-7d7dc6548c ded61e63-40e2-4079-a741-8201b20f0581 870926 2 2019-11-06 02:34:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 3ea9f926-61fe-4a28-9671-3dee2d32e16a 0xc007d77457 0xc007d77458}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc007d774b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  6 02:34:14.437: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov  6 02:34:14.437: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-8626 /apis/apps/v1/namespaces/deployment-8626/replicasets/test-rollover-controller f10744d9-c37e-4b32-8174-5d0946696085 870937 2 2019-11-06 02:33:51 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 3ea9f926-61fe-4a28-9671-3dee2d32e16a 0xc007d77387 0xc007d77388}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc007d773e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  6 02:34:14.437: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-8626 /apis/apps/v1/namespaces/deployment-8626/replicasets/test-rollover-deployment-f6c94f66c 1ac5aac4-f316-4caa-a31d-07dae6711f26 870887 2 2019-11-06 02:33:58 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 3ea9f926-61fe-4a28-9671-3dee2d32e16a 0xc007d77520 0xc007d77521}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc007d77598 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  6 02:34:14.439: INFO: Pod "test-rollover-deployment-7d7dc6548c-btkst" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-btkst test-rollover-deployment-7d7dc6548c- deployment-8626 /api/v1/namespaces/deployment-8626/pods/test-rollover-deployment-7d7dc6548c-btkst e90122bf-ab4a-407c-b772-8269429f8433 870907 0 2019-11-06 02:34:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[cni.projectcalico.org/podIP:10.38.96.118/32] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c ded61e63-40e2-4079-a741-8201b20f0581 0xc007d77c27 0xc007d77c28}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7vs5d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7vs5d,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7vs5d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:34:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:34:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:34:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 02:34:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.114,PodIP:10.38.96.118,StartTime:2019-11-06 02:34:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-06 02:34:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://0498daed3e4a0635cd303ec146aa7a8f0da4c4d3c7b13da6676078f2dd316419,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.38.96.118,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:34:14.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8626" for this suite.
Nov  6 02:34:20.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:34:20.520: INFO: namespace deployment-8626 deletion completed in 6.07817897s

• [SLOW TEST:29.251 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:34:20.520: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Nov  6 02:34:20.602: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7758 /api/v1/namespaces/watch-7758/configmaps/e2e-watch-test-watch-closed bcde3303-4bff-4a0c-8529-ef3212e04504 870994 0 2019-11-06 02:34:20 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  6 02:34:20.602: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7758 /api/v1/namespaces/watch-7758/configmaps/e2e-watch-test-watch-closed bcde3303-4bff-4a0c-8529-ef3212e04504 870995 0 2019-11-06 02:34:20 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Nov  6 02:34:20.618: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7758 /api/v1/namespaces/watch-7758/configmaps/e2e-watch-test-watch-closed bcde3303-4bff-4a0c-8529-ef3212e04504 870996 0 2019-11-06 02:34:20 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  6 02:34:20.618: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7758 /api/v1/namespaces/watch-7758/configmaps/e2e-watch-test-watch-closed bcde3303-4bff-4a0c-8529-ef3212e04504 870997 0 2019-11-06 02:34:20 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:34:20.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7758" for this suite.
Nov  6 02:34:26.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:34:26.690: INFO: namespace watch-7758 deletion completed in 6.064394601s

• [SLOW TEST:6.169 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:34:26.690: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:34:26.725: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Creating first CR 
Nov  6 02:34:27.435: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-06T02:34:27Z generation:1 name:name1 resourceVersion:871024 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:0f383c24-79c6-428a-9343-56723436b17d] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Nov  6 02:34:37.439: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-06T02:34:37Z generation:1 name:name2 resourceVersion:871039 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:9eee0ce9-ba7f-4683-a709-3c0b56de361f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Nov  6 02:34:47.443: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-06T02:34:27Z generation:2 name:name1 resourceVersion:871054 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:0f383c24-79c6-428a-9343-56723436b17d] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Nov  6 02:34:57.448: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-06T02:34:37Z generation:2 name:name2 resourceVersion:871070 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:9eee0ce9-ba7f-4683-a709-3c0b56de361f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Nov  6 02:35:07.453: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-06T02:34:27Z generation:2 name:name1 resourceVersion:871085 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:0f383c24-79c6-428a-9343-56723436b17d] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Nov  6 02:35:17.458: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-06T02:34:37Z generation:2 name:name2 resourceVersion:871101 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:9eee0ce9-ba7f-4683-a709-3c0b56de361f] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:35:27.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-4582" for this suite.
Nov  6 02:35:34.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:35:34.063: INFO: namespace crd-watch-4582 deletion completed in 6.094905383s

• [SLOW TEST:67.373 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:35:34.064: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov  6 02:35:34.141: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:35:38.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3715" for this suite.
Nov  6 02:36:06.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:36:06.658: INFO: namespace init-container-3715 deletion completed in 28.062947175s

• [SLOW TEST:32.594 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:36:06.658: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:36:22.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9866" for this suite.
Nov  6 02:36:28.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:36:28.839: INFO: namespace resourcequota-9866 deletion completed in 6.063576775s

• [SLOW TEST:22.181 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:36:28.840: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  6 02:36:29.674: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  6 02:36:31.681: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604589, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604589, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604589, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604589, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  6 02:36:34.708: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Nov  6 02:36:38.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 attach --namespace=webhook-9769 to-be-attached-pod -i -c=container1'
Nov  6 02:36:38.898: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:36:38.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9769" for this suite.
Nov  6 02:36:50.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:36:50.965: INFO: namespace webhook-9769 deletion completed in 12.056169102s
STEP: Destroying namespace "webhook-9769-markers" for this suite.
Nov  6 02:36:56.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:36:57.026: INFO: namespace webhook-9769-markers deletion completed in 6.061128231s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.194 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:36:57.034: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  6 02:36:57.784: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  6 02:36:59.791: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604617, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604617, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604617, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604617, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  6 02:37:02.825: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Nov  6 02:37:02.840: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:37:02.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5470" for this suite.
Nov  6 02:37:08.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:37:08.959: INFO: namespace webhook-5470 deletion completed in 6.053278137s
STEP: Destroying namespace "webhook-5470-markers" for this suite.
Nov  6 02:37:14.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:37:15.031: INFO: namespace webhook-5470-markers deletion completed in 6.072815819s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.007 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:37:15.040: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:37:15.077: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:37:19.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8562" for this suite.
Nov  6 02:38:05.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:38:05.223: INFO: namespace pods-8562 deletion completed in 46.078516891s

• [SLOW TEST:50.183 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:38:05.224: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov  6 02:38:05.270: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:38:08.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8433" for this suite.
Nov  6 02:38:14.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:38:14.859: INFO: namespace init-container-8433 deletion completed in 6.081262595s

• [SLOW TEST:9.636 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:38:14.859: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-9162
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-9162
STEP: Creating statefulset with conflicting port in namespace statefulset-9162
STEP: Waiting until pod test-pod will start running in namespace statefulset-9162
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9162
Nov  6 02:38:20.981: INFO: Observed stateful pod in namespace: statefulset-9162, name: ss-0, uid: 0fff5423-4567-4ef9-bcac-328fb95b998c, status phase: Pending. Waiting for statefulset controller to delete.
Nov  6 02:38:21.164: INFO: Observed stateful pod in namespace: statefulset-9162, name: ss-0, uid: 0fff5423-4567-4ef9-bcac-328fb95b998c, status phase: Failed. Waiting for statefulset controller to delete.
Nov  6 02:38:21.224: INFO: Observed stateful pod in namespace: statefulset-9162, name: ss-0, uid: 0fff5423-4567-4ef9-bcac-328fb95b998c, status phase: Failed. Waiting for statefulset controller to delete.
Nov  6 02:38:21.237: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9162
STEP: Removing pod with conflicting port in namespace statefulset-9162
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9162 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  6 02:38:25.317: INFO: Deleting all statefulset in ns statefulset-9162
Nov  6 02:38:25.318: INFO: Scaling statefulset ss to 0
Nov  6 02:38:35.340: INFO: Waiting for statefulset status.replicas updated to 0
Nov  6 02:38:35.342: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:38:35.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9162" for this suite.
Nov  6 02:38:41.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:38:41.452: INFO: namespace statefulset-9162 deletion completed in 6.094244201s

• [SLOW TEST:26.592 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:38:41.452: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-eca2e131-c36c-4f26-ad24-b793f4eb95bb
STEP: Creating secret with name s-test-opt-upd-ec376604-1cfa-49a3-9f15-25b3605c0cd1
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-eca2e131-c36c-4f26-ad24-b793f4eb95bb
STEP: Updating secret s-test-opt-upd-ec376604-1cfa-49a3-9f15-25b3605c0cd1
STEP: Creating secret with name s-test-opt-create-d452d23f-5430-4b89-8a51-b8a72338278e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:40:07.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-873" for this suite.
Nov  6 02:40:26.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:40:26.052: INFO: namespace secrets-873 deletion completed in 18.067889612s

• [SLOW TEST:104.600 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:40:26.052: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:40:26.095: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:40:32.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2456" for this suite.
Nov  6 02:40:38.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:40:38.615: INFO: namespace custom-resource-definition-2456 deletion completed in 6.067506681s

• [SLOW TEST:12.563 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:40:38.615: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  6 02:40:39.402: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  6 02:40:41.409: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604839, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604839, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604839, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604839, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  6 02:40:44.437: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:40:44.440: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6359-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:40:45.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8530" for this suite.
Nov  6 02:40:51.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:40:51.686: INFO: namespace webhook-8530 deletion completed in 6.066394967s
STEP: Destroying namespace "webhook-8530-markers" for this suite.
Nov  6 02:40:57.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:40:57.755: INFO: namespace webhook-8530-markers deletion completed in 6.068467765s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.147 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:40:57.762: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  6 02:40:58.970: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  6 02:41:00.977: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604858, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604858, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604859, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708604858, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  6 02:41:04.021: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:41:04.023: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5047-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:41:05.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6241" for this suite.
Nov  6 02:41:11.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:41:11.387: INFO: namespace webhook-6241 deletion completed in 6.067790217s
STEP: Destroying namespace "webhook-6241-markers" for this suite.
Nov  6 02:41:17.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:41:17.468: INFO: namespace webhook-6241-markers deletion completed in 6.080838804s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.714 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:41:17.476: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  6 02:41:17.562: INFO: Waiting up to 5m0s for pod "downward-api-17c95295-c067-4b92-b85a-b465ec566c5c" in namespace "downward-api-1241" to be "success or failure"
Nov  6 02:41:17.565: INFO: Pod "downward-api-17c95295-c067-4b92-b85a-b465ec566c5c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.680889ms
Nov  6 02:41:19.567: INFO: Pod "downward-api-17c95295-c067-4b92-b85a-b465ec566c5c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005576178s
Nov  6 02:41:21.570: INFO: Pod "downward-api-17c95295-c067-4b92-b85a-b465ec566c5c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008249566s
STEP: Saw pod success
Nov  6 02:41:21.570: INFO: Pod "downward-api-17c95295-c067-4b92-b85a-b465ec566c5c" satisfied condition "success or failure"
Nov  6 02:41:21.572: INFO: Trying to get logs from node apps-114 pod downward-api-17c95295-c067-4b92-b85a-b465ec566c5c container dapi-container: <nil>
STEP: delete the pod
Nov  6 02:41:21.626: INFO: Waiting for pod downward-api-17c95295-c067-4b92-b85a-b465ec566c5c to disappear
Nov  6 02:41:21.640: INFO: Pod downward-api-17c95295-c067-4b92-b85a-b465ec566c5c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:41:21.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1241" for this suite.
Nov  6 02:41:27.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:41:27.701: INFO: namespace downward-api-1241 deletion completed in 6.059002596s

• [SLOW TEST:10.226 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:41:27.701: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Nov  6 02:41:58.282: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1106 02:41:58.282555      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  6 02:41:58.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9508" for this suite.
Nov  6 02:42:04.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:42:04.347: INFO: namespace gc-9508 deletion completed in 6.06300105s

• [SLOW TEST:36.646 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:42:04.347: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:42:04.382: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov  6 02:42:08.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-1871 create -f -'
Nov  6 02:42:10.849: INFO: stderr: ""
Nov  6 02:42:10.849: INFO: stdout: "e2e-test-crd-publish-openapi-7471-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov  6 02:42:10.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-1871 delete e2e-test-crd-publish-openapi-7471-crds test-cr'
Nov  6 02:42:10.940: INFO: stderr: ""
Nov  6 02:42:10.940: INFO: stdout: "e2e-test-crd-publish-openapi-7471-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Nov  6 02:42:10.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-1871 apply -f -'
Nov  6 02:42:11.210: INFO: stderr: ""
Nov  6 02:42:11.210: INFO: stdout: "e2e-test-crd-publish-openapi-7471-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov  6 02:42:11.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-1871 delete e2e-test-crd-publish-openapi-7471-crds test-cr'
Nov  6 02:42:11.307: INFO: stderr: ""
Nov  6 02:42:11.307: INFO: stdout: "e2e-test-crd-publish-openapi-7471-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Nov  6 02:42:11.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 explain e2e-test-crd-publish-openapi-7471-crds'
Nov  6 02:42:11.567: INFO: stderr: ""
Nov  6 02:42:11.567: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7471-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:42:15.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1871" for this suite.
Nov  6 02:42:21.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:42:21.530: INFO: namespace crd-publish-openapi-1871 deletion completed in 6.070363727s

• [SLOW TEST:17.183 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:42:21.531: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:42:21.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 version'
Nov  6 02:42:21.758: INFO: stderr: ""
Nov  6 02:42:21.758: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.2\", GitCommit:\"c97fe5036ef3df2967d086711e6c0c405941e14b\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:18:23Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.2\", GitCommit:\"c97fe5036ef3df2967d086711e6c0c405941e14b\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:09:08Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:42:21.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7962" for this suite.
Nov  6 02:42:27.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:42:27.822: INFO: namespace kubectl-7962 deletion completed in 6.061592036s

• [SLOW TEST:6.292 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:42:27.822: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:42:38.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4864" for this suite.
Nov  6 02:42:44.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:42:44.999: INFO: namespace resourcequota-4864 deletion completed in 6.063909295s

• [SLOW TEST:17.176 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:42:44.999: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov  6 02:42:45.084: INFO: Waiting up to 5m0s for pod "pod-32f01ffd-4af4-4d07-acbe-35b53ce7e340" in namespace "emptydir-6989" to be "success or failure"
Nov  6 02:42:45.090: INFO: Pod "pod-32f01ffd-4af4-4d07-acbe-35b53ce7e340": Phase="Pending", Reason="", readiness=false. Elapsed: 6.373032ms
Nov  6 02:42:47.093: INFO: Pod "pod-32f01ffd-4af4-4d07-acbe-35b53ce7e340": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008940928s
Nov  6 02:42:49.095: INFO: Pod "pod-32f01ffd-4af4-4d07-acbe-35b53ce7e340": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011746123s
STEP: Saw pod success
Nov  6 02:42:49.096: INFO: Pod "pod-32f01ffd-4af4-4d07-acbe-35b53ce7e340" satisfied condition "success or failure"
Nov  6 02:42:49.097: INFO: Trying to get logs from node apps-114 pod pod-32f01ffd-4af4-4d07-acbe-35b53ce7e340 container test-container: <nil>
STEP: delete the pod
Nov  6 02:42:49.125: INFO: Waiting for pod pod-32f01ffd-4af4-4d07-acbe-35b53ce7e340 to disappear
Nov  6 02:42:49.156: INFO: Pod pod-32f01ffd-4af4-4d07-acbe-35b53ce7e340 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:42:49.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6989" for this suite.
Nov  6 02:42:55.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:42:55.266: INFO: namespace emptydir-6989 deletion completed in 6.107026449s

• [SLOW TEST:10.267 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:42:55.266: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-b69fe6ab-c635-4a4c-a10e-80a28ec8f6fb
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-b69fe6ab-c635-4a4c-a10e-80a28ec8f6fb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:44:21.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3916" for this suite.
Nov  6 02:44:49.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:44:49.741: INFO: namespace projected-3916 deletion completed in 28.066762618s

• [SLOW TEST:114.476 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:44:49.742: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Nov  6 02:44:49.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-6902 -- logs-generator --log-lines-total 100 --run-duration 20s'
Nov  6 02:44:49.874: INFO: stderr: ""
Nov  6 02:44:49.874: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Nov  6 02:44:49.874: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Nov  6 02:44:49.874: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-6902" to be "running and ready, or succeeded"
Nov  6 02:44:49.880: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 6.355244ms
Nov  6 02:44:51.883: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008649433s
Nov  6 02:44:53.885: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.011114869s
Nov  6 02:44:53.885: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Nov  6 02:44:53.885: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Nov  6 02:44:53.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 logs logs-generator logs-generator --namespace=kubectl-6902'
Nov  6 02:44:53.994: INFO: stderr: ""
Nov  6 02:44:53.994: INFO: stdout: "I1106 02:44:51.701585       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/c5j 233\nI1106 02:44:51.901746       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/8kj 257\nI1106 02:44:52.101752       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/9clm 380\nI1106 02:44:52.301729       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/6f6 497\nI1106 02:44:52.501665       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/xv8w 234\nI1106 02:44:52.701730       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/s6d 457\nI1106 02:44:52.901661       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/9sxr 272\nI1106 02:44:53.101768       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/xxc5 261\nI1106 02:44:53.301731       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/475 378\nI1106 02:44:53.501671       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/fj8 227\nI1106 02:44:53.701734       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/8cm 377\nI1106 02:44:53.901685       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/8xx 269\n"
STEP: limiting log lines
Nov  6 02:44:53.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 logs logs-generator logs-generator --namespace=kubectl-6902 --tail=1'
Nov  6 02:44:54.084: INFO: stderr: ""
Nov  6 02:44:54.084: INFO: stdout: "I1106 02:44:53.901685       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/8xx 269\n"
STEP: limiting log bytes
Nov  6 02:44:54.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 logs logs-generator logs-generator --namespace=kubectl-6902 --limit-bytes=1'
Nov  6 02:44:54.180: INFO: stderr: ""
Nov  6 02:44:54.180: INFO: stdout: "I"
STEP: exposing timestamps
Nov  6 02:44:54.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 logs logs-generator logs-generator --namespace=kubectl-6902 --tail=1 --timestamps'
Nov  6 02:44:54.277: INFO: stderr: ""
Nov  6 02:44:54.277: INFO: stdout: "2019-11-06T02:44:54.101894652Z I1106 02:44:54.101779       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/default/pods/qqd9 537\n"
STEP: restricting to a time range
Nov  6 02:44:56.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 logs logs-generator logs-generator --namespace=kubectl-6902 --since=1s'
Nov  6 02:44:56.873: INFO: stderr: ""
Nov  6 02:44:56.873: INFO: stdout: "I1106 02:44:55.901683       1 logs_generator.go:76] 21 GET /api/v1/namespaces/default/pods/x4nb 457\nI1106 02:44:56.101764       1 logs_generator.go:76] 22 GET /api/v1/namespaces/default/pods/hxt 260\nI1106 02:44:56.301676       1 logs_generator.go:76] 23 GET /api/v1/namespaces/kube-system/pods/xfrx 504\nI1106 02:44:56.501670       1 logs_generator.go:76] 24 GET /api/v1/namespaces/default/pods/cfp6 337\nI1106 02:44:56.701743       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/kube-system/pods/ntw2 546\n"
Nov  6 02:44:56.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 logs logs-generator logs-generator --namespace=kubectl-6902 --since=24h'
Nov  6 02:44:56.965: INFO: stderr: ""
Nov  6 02:44:56.965: INFO: stdout: "I1106 02:44:51.701585       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/c5j 233\nI1106 02:44:51.901746       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/8kj 257\nI1106 02:44:52.101752       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/9clm 380\nI1106 02:44:52.301729       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/6f6 497\nI1106 02:44:52.501665       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/xv8w 234\nI1106 02:44:52.701730       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/s6d 457\nI1106 02:44:52.901661       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/9sxr 272\nI1106 02:44:53.101768       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/xxc5 261\nI1106 02:44:53.301731       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/475 378\nI1106 02:44:53.501671       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/fj8 227\nI1106 02:44:53.701734       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/8cm 377\nI1106 02:44:53.901685       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/8xx 269\nI1106 02:44:54.101779       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/default/pods/qqd9 537\nI1106 02:44:54.301833       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/ns/pods/6pt 517\nI1106 02:44:54.501684       1 logs_generator.go:76] 14 GET /api/v1/namespaces/default/pods/wktl 240\nI1106 02:44:54.701737       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/kube-system/pods/d76 338\nI1106 02:44:54.901667       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/cn4 528\nI1106 02:44:55.101692       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/6jz 384\nI1106 02:44:55.301698       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/7f9p 387\nI1106 02:44:55.501697       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/5dz 269\nI1106 02:44:55.701789       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/vd2x 503\nI1106 02:44:55.901683       1 logs_generator.go:76] 21 GET /api/v1/namespaces/default/pods/x4nb 457\nI1106 02:44:56.101764       1 logs_generator.go:76] 22 GET /api/v1/namespaces/default/pods/hxt 260\nI1106 02:44:56.301676       1 logs_generator.go:76] 23 GET /api/v1/namespaces/kube-system/pods/xfrx 504\nI1106 02:44:56.501670       1 logs_generator.go:76] 24 GET /api/v1/namespaces/default/pods/cfp6 337\nI1106 02:44:56.701743       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/kube-system/pods/ntw2 546\nI1106 02:44:56.901723       1 logs_generator.go:76] 26 GET /api/v1/namespaces/ns/pods/tkcv 333\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Nov  6 02:44:56.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 delete pod logs-generator --namespace=kubectl-6902'
Nov  6 02:45:03.648: INFO: stderr: ""
Nov  6 02:45:03.648: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:45:03.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6902" for this suite.
Nov  6 02:45:09.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:45:09.712: INFO: namespace kubectl-6902 deletion completed in 6.056897452s

• [SLOW TEST:19.971 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:45:09.713: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  6 02:45:09.789: INFO: Waiting up to 5m0s for pod "downwardapi-volume-17a49595-0332-4e16-8516-acd103ac510c" in namespace "downward-api-4979" to be "success or failure"
Nov  6 02:45:09.800: INFO: Pod "downwardapi-volume-17a49595-0332-4e16-8516-acd103ac510c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.218752ms
Nov  6 02:45:11.803: INFO: Pod "downwardapi-volume-17a49595-0332-4e16-8516-acd103ac510c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014162755s
Nov  6 02:45:13.806: INFO: Pod "downwardapi-volume-17a49595-0332-4e16-8516-acd103ac510c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016305637s
STEP: Saw pod success
Nov  6 02:45:13.806: INFO: Pod "downwardapi-volume-17a49595-0332-4e16-8516-acd103ac510c" satisfied condition "success or failure"
Nov  6 02:45:13.807: INFO: Trying to get logs from node apps-114 pod downwardapi-volume-17a49595-0332-4e16-8516-acd103ac510c container client-container: <nil>
STEP: delete the pod
Nov  6 02:45:13.831: INFO: Waiting for pod downwardapi-volume-17a49595-0332-4e16-8516-acd103ac510c to disappear
Nov  6 02:45:13.837: INFO: Pod downwardapi-volume-17a49595-0332-4e16-8516-acd103ac510c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:45:13.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4979" for this suite.
Nov  6 02:45:19.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:45:19.940: INFO: namespace downward-api-4979 deletion completed in 6.089055101s

• [SLOW TEST:10.228 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:45:19.940: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Nov  6 02:45:19.989: INFO: Waiting up to 5m0s for pod "var-expansion-c5d9a15b-c29b-4495-a1b1-668dfb913b0b" in namespace "var-expansion-9771" to be "success or failure"
Nov  6 02:45:20.051: INFO: Pod "var-expansion-c5d9a15b-c29b-4495-a1b1-668dfb913b0b": Phase="Pending", Reason="", readiness=false. Elapsed: 62.098181ms
Nov  6 02:45:22.054: INFO: Pod "var-expansion-c5d9a15b-c29b-4495-a1b1-668dfb913b0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064493977s
Nov  6 02:45:24.056: INFO: Pod "var-expansion-c5d9a15b-c29b-4495-a1b1-668dfb913b0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067290909s
STEP: Saw pod success
Nov  6 02:45:24.056: INFO: Pod "var-expansion-c5d9a15b-c29b-4495-a1b1-668dfb913b0b" satisfied condition "success or failure"
Nov  6 02:45:24.058: INFO: Trying to get logs from node apps-114 pod var-expansion-c5d9a15b-c29b-4495-a1b1-668dfb913b0b container dapi-container: <nil>
STEP: delete the pod
Nov  6 02:45:24.085: INFO: Waiting for pod var-expansion-c5d9a15b-c29b-4495-a1b1-668dfb913b0b to disappear
Nov  6 02:45:24.096: INFO: Pod var-expansion-c5d9a15b-c29b-4495-a1b1-668dfb913b0b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:45:24.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9771" for this suite.
Nov  6 02:45:30.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:45:30.155: INFO: namespace var-expansion-9771 deletion completed in 6.05627131s

• [SLOW TEST:10.214 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:45:30.155: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-3788
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-3788
STEP: creating replication controller externalsvc in namespace services-3788
I1106 02:45:30.298827      26 runners.go:184] Created replication controller with name: externalsvc, namespace: services-3788, replica count: 2
I1106 02:45:33.349220      26 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Nov  6 02:45:33.426: INFO: Creating new exec pod
Nov  6 02:45:37.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=services-3788 execpodssfzx -- /bin/sh -x -c nslookup clusterip-service'
Nov  6 02:45:37.713: INFO: stderr: "+ nslookup clusterip-service\n"
Nov  6 02:45:37.713: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-3788.svc.cluster.local\tcanonical name = externalsvc.services-3788.svc.cluster.local.\nName:\texternalsvc.services-3788.svc.cluster.local\nAddress: 10.106.50.239\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-3788, will wait for the garbage collector to delete the pods
Nov  6 02:45:37.769: INFO: Deleting ReplicationController externalsvc took: 4.234329ms
Nov  6 02:45:38.170: INFO: Terminating ReplicationController externalsvc pods took: 400.219833ms
Nov  6 02:45:53.699: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:45:53.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3788" for this suite.
Nov  6 02:45:59.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:45:59.876: INFO: namespace services-3788 deletion completed in 6.090799466s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:29.721 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:45:59.876: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov  6 02:46:07.965: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  6 02:46:08.000: INFO: Pod pod-with-prestop-http-hook still exists
Nov  6 02:46:10.001: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  6 02:46:10.004: INFO: Pod pod-with-prestop-http-hook still exists
Nov  6 02:46:12.001: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  6 02:46:12.003: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:46:12.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7064" for this suite.
Nov  6 02:46:40.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:46:40.076: INFO: namespace container-lifecycle-hook-7064 deletion completed in 28.063938618s

• [SLOW TEST:40.199 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:46:40.076: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  6 02:46:40.793: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  6 02:46:42.799: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605200, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605200, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605200, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605200, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  6 02:46:45.827: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:46:45.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7908" for this suite.
Nov  6 02:46:57.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:46:58.015: INFO: namespace webhook-7908 deletion completed in 12.079656549s
STEP: Destroying namespace "webhook-7908-markers" for this suite.
Nov  6 02:47:04.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:47:04.106: INFO: namespace webhook-7908-markers deletion completed in 6.091060988s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.063 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:47:04.139: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3006.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-3006.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3006.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3006.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-3006.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3006.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  6 02:47:08.284: INFO: DNS probes using dns-3006/dns-test-efc4fffc-aad4-45b5-b034-c5cc12596d46 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:47:08.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3006" for this suite.
Nov  6 02:47:14.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:47:14.487: INFO: namespace dns-3006 deletion completed in 6.083620606s

• [SLOW TEST:10.348 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:47:14.487: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-6578
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  6 02:47:14.520: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  6 02:47:38.636: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.38.96.90:8080/dial?request=hostName&protocol=udp&host=10.38.96.88&port=8081&tries=1'] Namespace:pod-network-test-6578 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  6 02:47:38.636: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 02:47:38.804: INFO: Waiting for endpoints: map[]
Nov  6 02:47:38.807: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.38.96.90:8080/dial?request=hostName&protocol=udp&host=10.47.0.59&port=8081&tries=1'] Namespace:pod-network-test-6578 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  6 02:47:38.807: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 02:47:39.016: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:47:39.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6578" for this suite.
Nov  6 02:47:51.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:47:51.107: INFO: namespace pod-network-test-6578 deletion completed in 12.087170077s

• [SLOW TEST:36.620 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:47:51.107: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Nov  6 02:47:55.664: INFO: Successfully updated pod "adopt-release-dmsmt"
STEP: Checking that the Job readopts the Pod
Nov  6 02:47:55.664: INFO: Waiting up to 15m0s for pod "adopt-release-dmsmt" in namespace "job-5281" to be "adopted"
Nov  6 02:47:55.673: INFO: Pod "adopt-release-dmsmt": Phase="Running", Reason="", readiness=true. Elapsed: 9.034669ms
Nov  6 02:47:57.676: INFO: Pod "adopt-release-dmsmt": Phase="Running", Reason="", readiness=true. Elapsed: 2.011487767s
Nov  6 02:47:57.676: INFO: Pod "adopt-release-dmsmt" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Nov  6 02:47:58.182: INFO: Successfully updated pod "adopt-release-dmsmt"
STEP: Checking that the Job releases the Pod
Nov  6 02:47:58.182: INFO: Waiting up to 15m0s for pod "adopt-release-dmsmt" in namespace "job-5281" to be "released"
Nov  6 02:47:58.195: INFO: Pod "adopt-release-dmsmt": Phase="Running", Reason="", readiness=true. Elapsed: 12.921032ms
Nov  6 02:48:00.197: INFO: Pod "adopt-release-dmsmt": Phase="Running", Reason="", readiness=true. Elapsed: 2.015576972s
Nov  6 02:48:00.197: INFO: Pod "adopt-release-dmsmt" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:48:00.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5281" for this suite.
Nov  6 02:48:44.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:48:44.260: INFO: namespace job-5281 deletion completed in 44.060630018s

• [SLOW TEST:53.153 seconds]
[sig-apps] Job
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:48:44.261: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Nov  6 02:48:44.329: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6988 /api/v1/namespaces/watch-6988/configmaps/e2e-watch-test-label-changed 09b0860b-ca43-48a3-a618-d89ce462ee47 873824 0 2019-11-06 02:48:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  6 02:48:44.329: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6988 /api/v1/namespaces/watch-6988/configmaps/e2e-watch-test-label-changed 09b0860b-ca43-48a3-a618-d89ce462ee47 873825 0 2019-11-06 02:48:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov  6 02:48:44.329: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6988 /api/v1/namespaces/watch-6988/configmaps/e2e-watch-test-label-changed 09b0860b-ca43-48a3-a618-d89ce462ee47 873826 0 2019-11-06 02:48:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Nov  6 02:48:54.386: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6988 /api/v1/namespaces/watch-6988/configmaps/e2e-watch-test-label-changed 09b0860b-ca43-48a3-a618-d89ce462ee47 873842 0 2019-11-06 02:48:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  6 02:48:54.386: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6988 /api/v1/namespaces/watch-6988/configmaps/e2e-watch-test-label-changed 09b0860b-ca43-48a3-a618-d89ce462ee47 873843 0 2019-11-06 02:48:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Nov  6 02:48:54.386: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6988 /api/v1/namespaces/watch-6988/configmaps/e2e-watch-test-label-changed 09b0860b-ca43-48a3-a618-d89ce462ee47 873845 0 2019-11-06 02:48:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:48:54.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6988" for this suite.
Nov  6 02:49:00.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:49:00.458: INFO: namespace watch-6988 deletion completed in 6.063492496s

• [SLOW TEST:16.197 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:49:00.458: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Nov  6 02:49:00.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 create -f - --namespace=kubectl-8482'
Nov  6 02:49:00.857: INFO: stderr: ""
Nov  6 02:49:00.857: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  6 02:49:00.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8482'
Nov  6 02:49:00.975: INFO: stderr: ""
Nov  6 02:49:00.975: INFO: stdout: "update-demo-nautilus-wmzk9 update-demo-nautilus-zftj8 "
Nov  6 02:49:00.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-wmzk9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8482'
Nov  6 02:49:01.054: INFO: stderr: ""
Nov  6 02:49:01.054: INFO: stdout: ""
Nov  6 02:49:01.054: INFO: update-demo-nautilus-wmzk9 is created but not running
Nov  6 02:49:06.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8482'
Nov  6 02:49:06.139: INFO: stderr: ""
Nov  6 02:49:06.139: INFO: stdout: "update-demo-nautilus-wmzk9 update-demo-nautilus-zftj8 "
Nov  6 02:49:06.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-wmzk9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8482'
Nov  6 02:49:06.218: INFO: stderr: ""
Nov  6 02:49:06.218: INFO: stdout: "true"
Nov  6 02:49:06.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-wmzk9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8482'
Nov  6 02:49:06.299: INFO: stderr: ""
Nov  6 02:49:06.299: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  6 02:49:06.299: INFO: validating pod update-demo-nautilus-wmzk9
Nov  6 02:49:06.302: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  6 02:49:06.302: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  6 02:49:06.302: INFO: update-demo-nautilus-wmzk9 is verified up and running
Nov  6 02:49:06.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-zftj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8482'
Nov  6 02:49:06.386: INFO: stderr: ""
Nov  6 02:49:06.386: INFO: stdout: "true"
Nov  6 02:49:06.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods update-demo-nautilus-zftj8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8482'
Nov  6 02:49:06.489: INFO: stderr: ""
Nov  6 02:49:06.489: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  6 02:49:06.489: INFO: validating pod update-demo-nautilus-zftj8
Nov  6 02:49:06.492: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  6 02:49:06.492: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  6 02:49:06.492: INFO: update-demo-nautilus-zftj8 is verified up and running
STEP: using delete to clean up resources
Nov  6 02:49:06.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 delete --grace-period=0 --force -f - --namespace=kubectl-8482'
Nov  6 02:49:06.586: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  6 02:49:06.586: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  6 02:49:06.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8482'
Nov  6 02:49:06.674: INFO: stderr: "No resources found in kubectl-8482 namespace.\n"
Nov  6 02:49:06.674: INFO: stdout: ""
Nov  6 02:49:06.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -l name=update-demo --namespace=kubectl-8482 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  6 02:49:06.756: INFO: stderr: ""
Nov  6 02:49:06.756: INFO: stdout: "update-demo-nautilus-wmzk9\nupdate-demo-nautilus-zftj8\n"
Nov  6 02:49:07.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8482'
Nov  6 02:49:07.345: INFO: stderr: "No resources found in kubectl-8482 namespace.\n"
Nov  6 02:49:07.345: INFO: stdout: ""
Nov  6 02:49:07.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 get pods -l name=update-demo --namespace=kubectl-8482 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  6 02:49:07.431: INFO: stderr: ""
Nov  6 02:49:07.431: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:49:07.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8482" for this suite.
Nov  6 02:49:19.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:49:19.502: INFO: namespace kubectl-8482 deletion completed in 12.068516509s

• [SLOW TEST:19.044 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:49:19.502: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Nov  6 02:49:19.553: INFO: Waiting up to 5m0s for pod "client-containers-a185dd9c-948e-45df-9493-16ffa76b45e8" in namespace "containers-7532" to be "success or failure"
Nov  6 02:49:19.560: INFO: Pod "client-containers-a185dd9c-948e-45df-9493-16ffa76b45e8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.904315ms
Nov  6 02:49:21.563: INFO: Pod "client-containers-a185dd9c-948e-45df-9493-16ffa76b45e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009952849s
Nov  6 02:49:23.566: INFO: Pod "client-containers-a185dd9c-948e-45df-9493-16ffa76b45e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012511702s
STEP: Saw pod success
Nov  6 02:49:23.566: INFO: Pod "client-containers-a185dd9c-948e-45df-9493-16ffa76b45e8" satisfied condition "success or failure"
Nov  6 02:49:23.567: INFO: Trying to get logs from node apps-114 pod client-containers-a185dd9c-948e-45df-9493-16ffa76b45e8 container test-container: <nil>
STEP: delete the pod
Nov  6 02:49:23.594: INFO: Waiting for pod client-containers-a185dd9c-948e-45df-9493-16ffa76b45e8 to disappear
Nov  6 02:49:23.602: INFO: Pod client-containers-a185dd9c-948e-45df-9493-16ffa76b45e8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:49:23.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7532" for this suite.
Nov  6 02:49:29.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:49:29.701: INFO: namespace containers-7532 deletion completed in 6.096170458s

• [SLOW TEST:10.199 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:49:29.701: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Nov  6 02:49:29.753: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov  6 02:49:38.799: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:49:38.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5782" for this suite.
Nov  6 02:49:44.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:49:44.870: INFO: namespace pods-5782 deletion completed in 6.067478921s

• [SLOW TEST:15.170 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:49:44.870: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:50:02.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-277" for this suite.
Nov  6 02:50:08.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:50:08.094: INFO: namespace resourcequota-277 deletion completed in 6.065840146s

• [SLOW TEST:23.224 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:50:08.094: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Nov  6 02:50:12.695: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2477 pod-service-account-134dd59c-3a38-4101-bbba-444a955fe65e -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Nov  6 02:50:12.937: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2477 pod-service-account-134dd59c-3a38-4101-bbba-444a955fe65e -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Nov  6 02:50:13.172: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2477 pod-service-account-134dd59c-3a38-4101-bbba-444a955fe65e -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:50:13.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2477" for this suite.
Nov  6 02:50:19.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:50:19.485: INFO: namespace svcaccounts-2477 deletion completed in 6.062387316s

• [SLOW TEST:11.391 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:50:19.485: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Nov  6 02:50:29.660: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1106 02:50:29.660306      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:50:29.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1400" for this suite.
Nov  6 02:50:35.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:50:35.728: INFO: namespace gc-1400 deletion completed in 6.065690782s

• [SLOW TEST:16.243 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:50:35.728: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  6 02:50:36.594: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  6 02:50:38.600: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605436, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605436, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605436, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605436, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  6 02:50:41.627: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:50:41.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6153" for this suite.
Nov  6 02:50:47.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:50:47.747: INFO: namespace webhook-6153 deletion completed in 6.057791502s
STEP: Destroying namespace "webhook-6153-markers" for this suite.
Nov  6 02:50:53.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:50:53.814: INFO: namespace webhook-6153-markers deletion completed in 6.067334313s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.093 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:50:53.821: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  6 02:50:54.497: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  6 02:50:56.503: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605454, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605454, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605454, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605454, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  6 02:50:59.528: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:50:59.530: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:51:00.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8520" for this suite.
Nov  6 02:51:06.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:51:06.734: INFO: namespace webhook-8520 deletion completed in 6.063424618s
STEP: Destroying namespace "webhook-8520-markers" for this suite.
Nov  6 02:51:12.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:51:12.824: INFO: namespace webhook-8520-markers deletion completed in 6.089235829s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.010 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:51:12.831: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  6 02:51:12.887: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  6 02:51:12.896: INFO: Waiting for terminating namespaces to be deleted...
Nov  6 02:51:12.898: INFO: 
Logging pods the kubelet thinks is on node apps-113 before test
Nov  6 02:51:12.911: INFO: alertmanager-addon-5967cc89f8-8bdvd from cocktail-addon started at 2019-10-30 08:19:27 +0000 UTC (2 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container alertmanager-addon ready: true, restart count 0
Nov  6 02:51:12.911: INFO: 	Container configmap-reload ready: true, restart count 0
Nov  6 02:51:12.911: INFO: dashboard-proxy-cocktail-5cfd96484-9qjjr from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container dashboard-proxy-01 ready: true, restart count 0
Nov  6 02:51:12.911: INFO: cluster-health-checker-cocktail-58f4545c48-l9ncr from cocktail-system started at 2019-10-30 08:18:01 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container checker ready: true, restart count 0
Nov  6 02:51:12.911: INFO: cloud-metering-collector-cocktail-68bfd6cc67-q8tjh from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (3 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container cocktail-collector-aws ready: true, restart count 1
Nov  6 02:51:12.911: INFO: 	Container cocktail-collector-azure ready: true, restart count 0
Nov  6 02:51:12.911: INFO: 	Container cocktail-collector-google ready: true, restart count 1
Nov  6 02:51:12.911: INFO: monitoring-collector-cocktail-5647c8b855-54jph from cocktail-system started at 2019-10-30 08:18:01 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container statcollector ready: true, restart count 4
Nov  6 02:51:12.911: INFO: api-server-cocktail-88f64f646-x67ld from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container api-server-01 ready: true, restart count 0
Nov  6 02:51:12.911: INFO: metrics-server-5d9d98df9f-qsw2s from kube-system started at 2019-10-30 08:17:01 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container metrics-server ready: true, restart count 0
Nov  6 02:51:12.911: INFO: nginx-ingress-addon-controller-7dcb6fc5ff-t4rlv from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container nginx-ingress-addon-controller ready: true, restart count 0
Nov  6 02:51:12.911: INFO: monitoring-cocktail-59d5ffc9fd-szdwh from cocktail-system started at 2019-10-30 08:18:03 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container monitoring-01 ready: true, restart count 0
Nov  6 02:51:12.911: INFO: build-queue-cocktail-758498c967-slzk4 from cocktail-system started at 2019-10-30 08:19:23 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container nats-streaming ready: true, restart count 0
Nov  6 02:51:12.911: INFO: kube-controller-manager-apps-113 from kube-system started at 2019-10-30 08:16:38 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container kube-controller-manager ready: true, restart count 0
Nov  6 02:51:12.911: INFO: kube-scheduler-apps-113 from kube-system started at 2019-10-30 08:16:37 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container kube-scheduler ready: true, restart count 0
Nov  6 02:51:12.911: INFO: kube-apiserver-apps-113 from kube-system started at 2019-10-30 08:16:37 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container kube-apiserver ready: true, restart count 0
Nov  6 02:51:12.911: INFO: disk-usage-exporter-addon-t758w from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container disk-usage-exporter-addon ready: true, restart count 0
Nov  6 02:51:12.911: INFO: calico-kube-controllers-55754f75c-kxfjw from kube-system started at 2019-10-30 08:16:57 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov  6 02:51:12.911: INFO: node-exporter-addon-dqnzs from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container node-exporter-addon ready: true, restart count 0
Nov  6 02:51:12.911: INFO: kube-proxy-hdklg from kube-system started at 2019-10-30 08:16:08 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  6 02:51:12.911: INFO: coredns-7649fdbb4-fctcq from kube-system started at 2019-10-30 08:16:55 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container coredns ready: true, restart count 0
Nov  6 02:51:12.911: INFO: cloud-metering-cocktail-864ccb89c5-tsgj7 from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container cocktail-metering-api ready: true, restart count 0
Nov  6 02:51:12.911: INFO: prometheus-addon-5754fb587-t8m85 from cocktail-addon started at 2019-10-30 08:19:27 +0000 UTC (2 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container configmap-reload ready: true, restart count 0
Nov  6 02:51:12.911: INFO: 	Container prometheus-addon ready: true, restart count 0
Nov  6 02:51:12.911: INFO: monitoring-agent-njzizt-3-7657c68cd7-hwcqz from cocktail-addon started at 2019-10-30 09:24:28 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container statcollector ready: true, restart count 0
Nov  6 02:51:12.911: INFO: coredns-7649fdbb4-snqxg from kube-system started at 2019-10-30 08:16:56 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container coredns ready: true, restart count 0
Nov  6 02:51:12.911: INFO: dashboard-queue-cocktail-86b7c74d57-8wnfw from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container dashboard-queue ready: true, restart count 0
Nov  6 02:51:12.911: INFO: batch-server-cocktail-55d57dff79-4qm6j from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container batch ready: true, restart count 0
Nov  6 02:51:12.911: INFO: build-api-cocktail-6d6f8dfbbc-jhq8w from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container build-api ready: true, restart count 0
Nov  6 02:51:12.911: INFO: dashboard-session-cocktail-66658bd785-zl4lk from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container dashboard-session-01 ready: true, restart count 0
Nov  6 02:51:12.911: INFO: dashboard-cocktail-575c77f5bd-7xpz9 from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container cocktail-dashboard ready: true, restart count 0
Nov  6 02:51:12.911: INFO: api-cmdb-cocktail-7796b94f65-5x9kt from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container api-cmdb-01 ready: true, restart count 0
Nov  6 02:51:12.911: INFO: monitoring-db-cocktail-547dff6c7f-msc7q from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container db ready: true, restart count 0
Nov  6 02:51:12.911: INFO: calico-node-jv7rf from kube-system started at 2019-10-30 08:16:37 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container calico-node ready: true, restart count 0
Nov  6 02:51:12.911: INFO: addon-manager-7c8b9c74f6-9pllx from cocktail-addon started at 2019-10-30 08:17:39 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container addon-manager ready: true, restart count 0
Nov  6 02:51:12.911: INFO: sonobuoy-systemd-logs-daemon-set-a0ae98b6655c4fa6-tpjhf from sonobuoy started at 2019-11-06 01:13:06 +0000 UTC (2 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  6 02:51:12.911: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  6 02:51:12.911: INFO: nfs-client-provisioner-addon-566798455d-q7tw8 from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container nfs-client-provisioner-addon ready: true, restart count 0
Nov  6 02:51:12.911: INFO: kube-state-metrics-addon-7f48b7868b-jd4jx from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.911: INFO: 	Container kube-state-metrics-addon ready: true, restart count 0
Nov  6 02:51:12.911: INFO: 
Logging pods the kubelet thinks is on node apps-114 before test
Nov  6 02:51:12.928: INFO: calico-node-cbzfz from kube-system started at 2019-10-30 10:45:39 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.928: INFO: 	Container calico-node ready: true, restart count 0
Nov  6 02:51:12.928: INFO: sonobuoy from sonobuoy started at 2019-11-06 01:12:56 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.928: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  6 02:51:12.928: INFO: sonobuoy-systemd-logs-daemon-set-a0ae98b6655c4fa6-gcqdr from sonobuoy started at 2019-11-06 01:13:06 +0000 UTC (2 container statuses recorded)
Nov  6 02:51:12.928: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  6 02:51:12.928: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  6 02:51:12.928: INFO: node-exporter-addon-vzwg5 from cocktail-addon started at 2019-11-06 01:45:43 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.928: INFO: 	Container node-exporter-addon ready: true, restart count 0
Nov  6 02:51:12.928: INFO: sonobuoy-e2e-job-e818bd6c45834cee from sonobuoy started at 2019-11-06 01:13:06 +0000 UTC (2 container statuses recorded)
Nov  6 02:51:12.928: INFO: 	Container e2e ready: true, restart count 0
Nov  6 02:51:12.928: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  6 02:51:12.928: INFO: disk-usage-exporter-addon-zcv9w from cocktail-addon started at 2019-11-06 01:45:43 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.928: INFO: 	Container disk-usage-exporter-addon ready: true, restart count 0
Nov  6 02:51:12.928: INFO: kube-proxy-nnw7s from kube-system started at 2019-10-30 10:45:39 +0000 UTC (1 container statuses recorded)
Nov  6 02:51:12.928: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-5b8e5129-92e8-4598-80e0-3cd6ea1d2b4d 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-5b8e5129-92e8-4598-80e0-3cd6ea1d2b4d off the node apps-114
STEP: verifying the node doesn't have the label kubernetes.io/e2e-5b8e5129-92e8-4598-80e0-3cd6ea1d2b4d
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:51:29.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2257" for this suite.
Nov  6 02:51:47.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:51:47.253: INFO: namespace sched-pred-2257 deletion completed in 18.063339601s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:34.422 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:51:47.253: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov  6 02:51:47.310: INFO: Waiting up to 5m0s for pod "pod-ef0704bc-a1d5-40ca-9b6c-b39df14da12d" in namespace "emptydir-6171" to be "success or failure"
Nov  6 02:51:47.316: INFO: Pod "pod-ef0704bc-a1d5-40ca-9b6c-b39df14da12d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.043672ms
Nov  6 02:51:49.319: INFO: Pod "pod-ef0704bc-a1d5-40ca-9b6c-b39df14da12d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009129358s
Nov  6 02:51:51.322: INFO: Pod "pod-ef0704bc-a1d5-40ca-9b6c-b39df14da12d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011745256s
STEP: Saw pod success
Nov  6 02:51:51.322: INFO: Pod "pod-ef0704bc-a1d5-40ca-9b6c-b39df14da12d" satisfied condition "success or failure"
Nov  6 02:51:51.324: INFO: Trying to get logs from node apps-114 pod pod-ef0704bc-a1d5-40ca-9b6c-b39df14da12d container test-container: <nil>
STEP: delete the pod
Nov  6 02:51:51.342: INFO: Waiting for pod pod-ef0704bc-a1d5-40ca-9b6c-b39df14da12d to disappear
Nov  6 02:51:51.350: INFO: Pod pod-ef0704bc-a1d5-40ca-9b6c-b39df14da12d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:51:51.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6171" for this suite.
Nov  6 02:51:57.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:51:57.416: INFO: namespace emptydir-6171 deletion completed in 6.06395214s

• [SLOW TEST:10.163 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:51:57.416: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov  6 02:51:57.463: INFO: Waiting up to 5m0s for pod "pod-8038d0dc-3318-4774-b15b-fd59bfddf0a0" in namespace "emptydir-704" to be "success or failure"
Nov  6 02:51:57.475: INFO: Pod "pod-8038d0dc-3318-4774-b15b-fd59bfddf0a0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.463276ms
Nov  6 02:51:59.478: INFO: Pod "pod-8038d0dc-3318-4774-b15b-fd59bfddf0a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014494267s
Nov  6 02:52:01.480: INFO: Pod "pod-8038d0dc-3318-4774-b15b-fd59bfddf0a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016858688s
STEP: Saw pod success
Nov  6 02:52:01.480: INFO: Pod "pod-8038d0dc-3318-4774-b15b-fd59bfddf0a0" satisfied condition "success or failure"
Nov  6 02:52:01.482: INFO: Trying to get logs from node apps-114 pod pod-8038d0dc-3318-4774-b15b-fd59bfddf0a0 container test-container: <nil>
STEP: delete the pod
Nov  6 02:52:01.504: INFO: Waiting for pod pod-8038d0dc-3318-4774-b15b-fd59bfddf0a0 to disappear
Nov  6 02:52:01.516: INFO: Pod pod-8038d0dc-3318-4774-b15b-fd59bfddf0a0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:52:01.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-704" for this suite.
Nov  6 02:52:07.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:52:07.574: INFO: namespace emptydir-704 deletion completed in 6.05518223s

• [SLOW TEST:10.158 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:52:07.574: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Nov  6 02:52:07.638: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-720122187 proxy --unix-socket=/tmp/kubectl-proxy-unix448193434/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:52:07.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8473" for this suite.
Nov  6 02:52:13.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:52:13.757: INFO: namespace kubectl-8473 deletion completed in 6.054661441s

• [SLOW TEST:6.183 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:52:13.757: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1106 02:52:14.871532      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  6 02:52:14.871: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:52:14.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5557" for this suite.
Nov  6 02:52:20.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:52:20.998: INFO: namespace gc-5557 deletion completed in 6.124343754s

• [SLOW TEST:7.240 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:52:20.998: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:52:27.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3716" for this suite.
Nov  6 02:52:33.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:52:33.278: INFO: namespace namespaces-3716 deletion completed in 6.055963185s
STEP: Destroying namespace "nsdeletetest-904" for this suite.
Nov  6 02:52:33.279: INFO: Namespace nsdeletetest-904 was already deleted
STEP: Destroying namespace "nsdeletetest-3736" for this suite.
Nov  6 02:52:39.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:52:39.408: INFO: namespace nsdeletetest-3736 deletion completed in 6.128298411s

• [SLOW TEST:18.410 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:52:39.408: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 02:52:39.507: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Nov  6 02:52:39.511: INFO: Number of nodes with available pods: 0
Nov  6 02:52:39.511: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Nov  6 02:52:39.554: INFO: Number of nodes with available pods: 0
Nov  6 02:52:39.554: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:52:40.558: INFO: Number of nodes with available pods: 0
Nov  6 02:52:40.558: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:52:41.557: INFO: Number of nodes with available pods: 0
Nov  6 02:52:41.557: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:52:42.556: INFO: Number of nodes with available pods: 1
Nov  6 02:52:42.556: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Nov  6 02:52:42.582: INFO: Number of nodes with available pods: 1
Nov  6 02:52:42.582: INFO: Number of running nodes: 0, number of available pods: 1
Nov  6 02:52:43.585: INFO: Number of nodes with available pods: 0
Nov  6 02:52:43.585: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Nov  6 02:52:43.607: INFO: Number of nodes with available pods: 0
Nov  6 02:52:43.607: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:52:44.609: INFO: Number of nodes with available pods: 0
Nov  6 02:52:44.609: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:52:45.611: INFO: Number of nodes with available pods: 0
Nov  6 02:52:45.611: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:52:46.610: INFO: Number of nodes with available pods: 0
Nov  6 02:52:46.610: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:52:47.610: INFO: Number of nodes with available pods: 0
Nov  6 02:52:47.610: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:52:48.610: INFO: Number of nodes with available pods: 0
Nov  6 02:52:48.610: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:52:49.610: INFO: Number of nodes with available pods: 0
Nov  6 02:52:49.610: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:52:50.610: INFO: Number of nodes with available pods: 0
Nov  6 02:52:50.610: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:52:51.610: INFO: Number of nodes with available pods: 0
Nov  6 02:52:51.610: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:52:52.610: INFO: Number of nodes with available pods: 0
Nov  6 02:52:52.610: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:52:53.609: INFO: Number of nodes with available pods: 0
Nov  6 02:52:53.609: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:52:54.610: INFO: Number of nodes with available pods: 0
Nov  6 02:52:54.610: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:52:55.610: INFO: Number of nodes with available pods: 0
Nov  6 02:52:55.610: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:52:56.611: INFO: Number of nodes with available pods: 0
Nov  6 02:52:56.611: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:52:57.610: INFO: Number of nodes with available pods: 0
Nov  6 02:52:57.610: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:52:58.610: INFO: Number of nodes with available pods: 0
Nov  6 02:52:58.610: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:52:59.610: INFO: Number of nodes with available pods: 0
Nov  6 02:52:59.610: INFO: Node apps-113 is running more than one daemon pod
Nov  6 02:53:00.610: INFO: Number of nodes with available pods: 1
Nov  6 02:53:00.610: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8963, will wait for the garbage collector to delete the pods
Nov  6 02:53:00.669: INFO: Deleting DaemonSet.extensions daemon-set took: 3.658479ms
Nov  6 02:53:01.069: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.196345ms
Nov  6 02:53:07.479: INFO: Number of nodes with available pods: 0
Nov  6 02:53:07.479: INFO: Number of running nodes: 0, number of available pods: 0
Nov  6 02:53:07.480: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8963/daemonsets","resourceVersion":"875114"},"items":null}

Nov  6 02:53:07.482: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8963/pods","resourceVersion":"875114"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:53:07.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8963" for this suite.
Nov  6 02:53:13.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:53:13.578: INFO: namespace daemonsets-8963 deletion completed in 6.064346406s

• [SLOW TEST:34.170 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:53:13.578: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:53:24.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3344" for this suite.
Nov  6 02:53:30.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:53:30.799: INFO: namespace resourcequota-3344 deletion completed in 6.069426894s

• [SLOW TEST:17.221 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:53:30.799: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:54:30.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5719" for this suite.
Nov  6 02:54:58.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:54:58.954: INFO: namespace container-probe-5719 deletion completed in 28.092001568s

• [SLOW TEST:88.155 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:54:58.954: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  6 02:54:59.007: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b9c013c0-461c-492c-be18-7bccebab6e5d" in namespace "downward-api-8077" to be "success or failure"
Nov  6 02:54:59.011: INFO: Pod "downwardapi-volume-b9c013c0-461c-492c-be18-7bccebab6e5d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.597723ms
Nov  6 02:55:01.013: INFO: Pod "downwardapi-volume-b9c013c0-461c-492c-be18-7bccebab6e5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006792567s
Nov  6 02:55:03.016: INFO: Pod "downwardapi-volume-b9c013c0-461c-492c-be18-7bccebab6e5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009457825s
STEP: Saw pod success
Nov  6 02:55:03.016: INFO: Pod "downwardapi-volume-b9c013c0-461c-492c-be18-7bccebab6e5d" satisfied condition "success or failure"
Nov  6 02:55:03.018: INFO: Trying to get logs from node apps-114 pod downwardapi-volume-b9c013c0-461c-492c-be18-7bccebab6e5d container client-container: <nil>
STEP: delete the pod
Nov  6 02:55:03.068: INFO: Waiting for pod downwardapi-volume-b9c013c0-461c-492c-be18-7bccebab6e5d to disappear
Nov  6 02:55:03.078: INFO: Pod downwardapi-volume-b9c013c0-461c-492c-be18-7bccebab6e5d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:55:03.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8077" for this suite.
Nov  6 02:55:09.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:55:09.147: INFO: namespace downward-api-8077 deletion completed in 6.066393443s

• [SLOW TEST:10.193 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:55:09.147: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  6 02:55:09.612: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  6 02:55:11.618: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605709, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605709, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605709, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605709, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  6 02:55:14.692: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:55:15.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7525" for this suite.
Nov  6 02:55:21.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:55:21.154: INFO: namespace webhook-7525 deletion completed in 6.061700543s
STEP: Destroying namespace "webhook-7525-markers" for this suite.
Nov  6 02:55:27.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:55:27.264: INFO: namespace webhook-7525-markers deletion completed in 6.109453511s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.124 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:55:27.271: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Nov  6 02:55:37.336: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1106 02:55:37.336272      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  6 02:55:37.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-534" for this suite.
Nov  6 02:55:43.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:55:43.407: INFO: namespace gc-534 deletion completed in 6.06928821s

• [SLOW TEST:16.136 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:55:43.407: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-nnfn
STEP: Creating a pod to test atomic-volume-subpath
Nov  6 02:55:43.516: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-nnfn" in namespace "subpath-9728" to be "success or failure"
Nov  6 02:55:43.531: INFO: Pod "pod-subpath-test-downwardapi-nnfn": Phase="Pending", Reason="", readiness=false. Elapsed: 14.222954ms
Nov  6 02:55:45.533: INFO: Pod "pod-subpath-test-downwardapi-nnfn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016913872s
Nov  6 02:55:47.536: INFO: Pod "pod-subpath-test-downwardapi-nnfn": Phase="Running", Reason="", readiness=true. Elapsed: 4.019761179s
Nov  6 02:55:49.539: INFO: Pod "pod-subpath-test-downwardapi-nnfn": Phase="Running", Reason="", readiness=true. Elapsed: 6.022706242s
Nov  6 02:55:51.542: INFO: Pod "pod-subpath-test-downwardapi-nnfn": Phase="Running", Reason="", readiness=true. Elapsed: 8.025506985s
Nov  6 02:55:53.545: INFO: Pod "pod-subpath-test-downwardapi-nnfn": Phase="Running", Reason="", readiness=true. Elapsed: 10.028452269s
Nov  6 02:55:55.548: INFO: Pod "pod-subpath-test-downwardapi-nnfn": Phase="Running", Reason="", readiness=true. Elapsed: 12.031250902s
Nov  6 02:55:57.551: INFO: Pod "pod-subpath-test-downwardapi-nnfn": Phase="Running", Reason="", readiness=true. Elapsed: 14.034314943s
Nov  6 02:55:59.553: INFO: Pod "pod-subpath-test-downwardapi-nnfn": Phase="Running", Reason="", readiness=true. Elapsed: 16.037010523s
Nov  6 02:56:01.556: INFO: Pod "pod-subpath-test-downwardapi-nnfn": Phase="Running", Reason="", readiness=true. Elapsed: 18.039869277s
Nov  6 02:56:03.559: INFO: Pod "pod-subpath-test-downwardapi-nnfn": Phase="Running", Reason="", readiness=true. Elapsed: 20.042396612s
Nov  6 02:56:05.562: INFO: Pod "pod-subpath-test-downwardapi-nnfn": Phase="Running", Reason="", readiness=true. Elapsed: 22.04517477s
Nov  6 02:56:07.564: INFO: Pod "pod-subpath-test-downwardapi-nnfn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.047502205s
STEP: Saw pod success
Nov  6 02:56:07.564: INFO: Pod "pod-subpath-test-downwardapi-nnfn" satisfied condition "success or failure"
Nov  6 02:56:07.566: INFO: Trying to get logs from node apps-114 pod pod-subpath-test-downwardapi-nnfn container test-container-subpath-downwardapi-nnfn: <nil>
STEP: delete the pod
Nov  6 02:56:07.598: INFO: Waiting for pod pod-subpath-test-downwardapi-nnfn to disappear
Nov  6 02:56:07.606: INFO: Pod pod-subpath-test-downwardapi-nnfn no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-nnfn
Nov  6 02:56:07.606: INFO: Deleting pod "pod-subpath-test-downwardapi-nnfn" in namespace "subpath-9728"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:56:07.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9728" for this suite.
Nov  6 02:56:13.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:56:13.677: INFO: namespace subpath-9728 deletion completed in 6.067251734s

• [SLOW TEST:30.270 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:56:13.678: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  6 02:56:14.440: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  6 02:56:16.446: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605774, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605774, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605774, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708605774, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  6 02:56:19.482: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:56:31.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7686" for this suite.
Nov  6 02:56:37.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:56:37.749: INFO: namespace webhook-7686 deletion completed in 6.058042694s
STEP: Destroying namespace "webhook-7686-markers" for this suite.
Nov  6 02:56:43.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:56:43.816: INFO: namespace webhook-7686-markers deletion completed in 6.06713292s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.146 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:56:43.824: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-g949
STEP: Creating a pod to test atomic-volume-subpath
Nov  6 02:56:43.926: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-g949" in namespace "subpath-7576" to be "success or failure"
Nov  6 02:56:43.940: INFO: Pod "pod-subpath-test-projected-g949": Phase="Pending", Reason="", readiness=false. Elapsed: 13.898488ms
Nov  6 02:56:45.956: INFO: Pod "pod-subpath-test-projected-g949": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029923882s
Nov  6 02:56:47.958: INFO: Pod "pod-subpath-test-projected-g949": Phase="Running", Reason="", readiness=true. Elapsed: 4.032428446s
Nov  6 02:56:49.981: INFO: Pod "pod-subpath-test-projected-g949": Phase="Running", Reason="", readiness=true. Elapsed: 6.055105347s
Nov  6 02:56:51.983: INFO: Pod "pod-subpath-test-projected-g949": Phase="Running", Reason="", readiness=true. Elapsed: 8.057645762s
Nov  6 02:56:53.986: INFO: Pod "pod-subpath-test-projected-g949": Phase="Running", Reason="", readiness=true. Elapsed: 10.060305839s
Nov  6 02:56:55.989: INFO: Pod "pod-subpath-test-projected-g949": Phase="Running", Reason="", readiness=true. Elapsed: 12.062989359s
Nov  6 02:56:57.991: INFO: Pod "pod-subpath-test-projected-g949": Phase="Running", Reason="", readiness=true. Elapsed: 14.06537721s
Nov  6 02:56:59.994: INFO: Pod "pod-subpath-test-projected-g949": Phase="Running", Reason="", readiness=true. Elapsed: 16.068272477s
Nov  6 02:57:02.005: INFO: Pod "pod-subpath-test-projected-g949": Phase="Running", Reason="", readiness=true. Elapsed: 18.079560041s
Nov  6 02:57:04.025: INFO: Pod "pod-subpath-test-projected-g949": Phase="Running", Reason="", readiness=true. Elapsed: 20.099061282s
Nov  6 02:57:06.027: INFO: Pod "pod-subpath-test-projected-g949": Phase="Running", Reason="", readiness=true. Elapsed: 22.101428138s
Nov  6 02:57:08.047: INFO: Pod "pod-subpath-test-projected-g949": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.121056815s
STEP: Saw pod success
Nov  6 02:57:08.047: INFO: Pod "pod-subpath-test-projected-g949" satisfied condition "success or failure"
Nov  6 02:57:08.049: INFO: Trying to get logs from node apps-114 pod pod-subpath-test-projected-g949 container test-container-subpath-projected-g949: <nil>
STEP: delete the pod
Nov  6 02:57:08.083: INFO: Waiting for pod pod-subpath-test-projected-g949 to disappear
Nov  6 02:57:08.091: INFO: Pod pod-subpath-test-projected-g949 no longer exists
STEP: Deleting pod pod-subpath-test-projected-g949
Nov  6 02:57:08.091: INFO: Deleting pod "pod-subpath-test-projected-g949" in namespace "subpath-7576"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:57:08.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7576" for this suite.
Nov  6 02:57:14.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:57:14.154: INFO: namespace subpath-7576 deletion completed in 6.05967621s

• [SLOW TEST:30.331 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:57:14.155: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Nov  6 02:57:19.263: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:57:20.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1381" for this suite.
Nov  6 02:57:34.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:57:34.391: INFO: namespace replicaset-1381 deletion completed in 14.061367137s

• [SLOW TEST:20.236 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:57:34.392: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Nov  6 02:57:34.459: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 02:57:38.383: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:57:53.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4833" for this suite.
Nov  6 02:57:59.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:58:00.036: INFO: namespace crd-publish-openapi-4833 deletion completed in 6.089640914s

• [SLOW TEST:25.645 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:58:00.037: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Nov  6 02:58:00.076: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Nov  6 02:58:15.535: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 02:58:19.487: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:58:35.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8898" for this suite.
Nov  6 02:58:41.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:58:41.150: INFO: namespace crd-publish-openapi-8898 deletion completed in 6.060129117s

• [SLOW TEST:41.113 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:58:41.150: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-8f4f3cf0-b95e-4562-9528-67e790e11406
STEP: Creating a pod to test consume configMaps
Nov  6 02:58:41.239: INFO: Waiting up to 5m0s for pod "pod-configmaps-fd82fc6f-7d22-4500-9c14-b73bbab5bafa" in namespace "configmap-8524" to be "success or failure"
Nov  6 02:58:41.248: INFO: Pod "pod-configmaps-fd82fc6f-7d22-4500-9c14-b73bbab5bafa": Phase="Pending", Reason="", readiness=false. Elapsed: 9.117496ms
Nov  6 02:58:43.251: INFO: Pod "pod-configmaps-fd82fc6f-7d22-4500-9c14-b73bbab5bafa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01185555s
Nov  6 02:58:45.254: INFO: Pod "pod-configmaps-fd82fc6f-7d22-4500-9c14-b73bbab5bafa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014743303s
STEP: Saw pod success
Nov  6 02:58:45.254: INFO: Pod "pod-configmaps-fd82fc6f-7d22-4500-9c14-b73bbab5bafa" satisfied condition "success or failure"
Nov  6 02:58:45.256: INFO: Trying to get logs from node apps-114 pod pod-configmaps-fd82fc6f-7d22-4500-9c14-b73bbab5bafa container configmap-volume-test: <nil>
STEP: delete the pod
Nov  6 02:58:45.286: INFO: Waiting for pod pod-configmaps-fd82fc6f-7d22-4500-9c14-b73bbab5bafa to disappear
Nov  6 02:58:45.290: INFO: Pod pod-configmaps-fd82fc6f-7d22-4500-9c14-b73bbab5bafa no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:58:45.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8524" for this suite.
Nov  6 02:58:51.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:58:51.350: INFO: namespace configmap-8524 deletion completed in 6.05732375s

• [SLOW TEST:10.200 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:58:51.350: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  6 02:58:51.449: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f8c22d70-4d9b-47df-89aa-dd7887b04059" in namespace "projected-1464" to be "success or failure"
Nov  6 02:58:51.465: INFO: Pod "downwardapi-volume-f8c22d70-4d9b-47df-89aa-dd7887b04059": Phase="Pending", Reason="", readiness=false. Elapsed: 16.036707ms
Nov  6 02:58:53.468: INFO: Pod "downwardapi-volume-f8c22d70-4d9b-47df-89aa-dd7887b04059": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018525988s
Nov  6 02:58:55.470: INFO: Pod "downwardapi-volume-f8c22d70-4d9b-47df-89aa-dd7887b04059": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020979346s
STEP: Saw pod success
Nov  6 02:58:55.470: INFO: Pod "downwardapi-volume-f8c22d70-4d9b-47df-89aa-dd7887b04059" satisfied condition "success or failure"
Nov  6 02:58:55.472: INFO: Trying to get logs from node apps-114 pod downwardapi-volume-f8c22d70-4d9b-47df-89aa-dd7887b04059 container client-container: <nil>
STEP: delete the pod
Nov  6 02:58:55.502: INFO: Waiting for pod downwardapi-volume-f8c22d70-4d9b-47df-89aa-dd7887b04059 to disappear
Nov  6 02:58:55.506: INFO: Pod downwardapi-volume-f8c22d70-4d9b-47df-89aa-dd7887b04059 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:58:55.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1464" for this suite.
Nov  6 02:59:01.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:59:01.573: INFO: namespace projected-1464 deletion completed in 6.062445788s

• [SLOW TEST:10.223 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:59:01.574: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  6 02:59:01.625: INFO: Waiting up to 5m0s for pod "downward-api-085d22f4-8c79-49b9-b052-866537f5af63" in namespace "downward-api-9466" to be "success or failure"
Nov  6 02:59:01.632: INFO: Pod "downward-api-085d22f4-8c79-49b9-b052-866537f5af63": Phase="Pending", Reason="", readiness=false. Elapsed: 6.919067ms
Nov  6 02:59:03.634: INFO: Pod "downward-api-085d22f4-8c79-49b9-b052-866537f5af63": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009526395s
Nov  6 02:59:05.637: INFO: Pod "downward-api-085d22f4-8c79-49b9-b052-866537f5af63": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012008289s
STEP: Saw pod success
Nov  6 02:59:05.637: INFO: Pod "downward-api-085d22f4-8c79-49b9-b052-866537f5af63" satisfied condition "success or failure"
Nov  6 02:59:05.638: INFO: Trying to get logs from node apps-114 pod downward-api-085d22f4-8c79-49b9-b052-866537f5af63 container dapi-container: <nil>
STEP: delete the pod
Nov  6 02:59:05.669: INFO: Waiting for pod downward-api-085d22f4-8c79-49b9-b052-866537f5af63 to disappear
Nov  6 02:59:05.674: INFO: Pod downward-api-085d22f4-8c79-49b9-b052-866537f5af63 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:59:05.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9466" for this suite.
Nov  6 02:59:11.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:59:11.792: INFO: namespace downward-api-9466 deletion completed in 6.115565101s

• [SLOW TEST:10.219 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:59:11.793: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6977.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6977.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6977.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6977.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6977.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6977.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  6 02:59:15.872: INFO: DNS probes using dns-6977/dns-test-838047ec-d7ba-430d-81e5-4c2f16e99f51 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:59:15.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6977" for this suite.
Nov  6 02:59:21.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:59:22.026: INFO: namespace dns-6977 deletion completed in 6.073977756s

• [SLOW TEST:10.233 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:59:22.026: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:59:22.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4948" for this suite.
Nov  6 02:59:28.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:59:28.134: INFO: namespace services-4948 deletion completed in 6.057514201s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.108 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:59:28.134: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  6 02:59:28.184: INFO: Waiting up to 5m0s for pod "downward-api-38f7d619-a555-467d-8397-3b7148902ec8" in namespace "downward-api-2900" to be "success or failure"
Nov  6 02:59:28.191: INFO: Pod "downward-api-38f7d619-a555-467d-8397-3b7148902ec8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.894889ms
Nov  6 02:59:30.194: INFO: Pod "downward-api-38f7d619-a555-467d-8397-3b7148902ec8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009787285s
Nov  6 02:59:32.197: INFO: Pod "downward-api-38f7d619-a555-467d-8397-3b7148902ec8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012830307s
STEP: Saw pod success
Nov  6 02:59:32.197: INFO: Pod "downward-api-38f7d619-a555-467d-8397-3b7148902ec8" satisfied condition "success or failure"
Nov  6 02:59:32.201: INFO: Trying to get logs from node apps-114 pod downward-api-38f7d619-a555-467d-8397-3b7148902ec8 container dapi-container: <nil>
STEP: delete the pod
Nov  6 02:59:32.217: INFO: Waiting for pod downward-api-38f7d619-a555-467d-8397-3b7148902ec8 to disappear
Nov  6 02:59:32.224: INFO: Pod downward-api-38f7d619-a555-467d-8397-3b7148902ec8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:59:32.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2900" for this suite.
Nov  6 02:59:38.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:59:38.345: INFO: namespace downward-api-2900 deletion completed in 6.094230534s

• [SLOW TEST:10.211 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:59:38.346: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-90b2df9f-ee24-4539-91a5-c049bce41fda
STEP: Creating a pod to test consume configMaps
Nov  6 02:59:38.438: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e6a93ef4-c68a-4ac2-8cc7-5a0903a5a478" in namespace "projected-1131" to be "success or failure"
Nov  6 02:59:38.449: INFO: Pod "pod-projected-configmaps-e6a93ef4-c68a-4ac2-8cc7-5a0903a5a478": Phase="Pending", Reason="", readiness=false. Elapsed: 11.679684ms
Nov  6 02:59:40.452: INFO: Pod "pod-projected-configmaps-e6a93ef4-c68a-4ac2-8cc7-5a0903a5a478": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014479604s
Nov  6 02:59:42.454: INFO: Pod "pod-projected-configmaps-e6a93ef4-c68a-4ac2-8cc7-5a0903a5a478": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016782546s
STEP: Saw pod success
Nov  6 02:59:42.455: INFO: Pod "pod-projected-configmaps-e6a93ef4-c68a-4ac2-8cc7-5a0903a5a478" satisfied condition "success or failure"
Nov  6 02:59:42.456: INFO: Trying to get logs from node apps-114 pod pod-projected-configmaps-e6a93ef4-c68a-4ac2-8cc7-5a0903a5a478 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  6 02:59:42.501: INFO: Waiting for pod pod-projected-configmaps-e6a93ef4-c68a-4ac2-8cc7-5a0903a5a478 to disappear
Nov  6 02:59:42.508: INFO: Pod pod-projected-configmaps-e6a93ef4-c68a-4ac2-8cc7-5a0903a5a478 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:59:42.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1131" for this suite.
Nov  6 02:59:48.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:59:48.566: INFO: namespace projected-1131 deletion completed in 6.056174214s

• [SLOW TEST:10.221 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:59:48.567: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  6 02:59:51.634: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 02:59:51.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9301" for this suite.
Nov  6 02:59:57.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 02:59:57.716: INFO: namespace container-runtime-9301 deletion completed in 6.055697155s

• [SLOW TEST:9.149 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 02:59:57.716: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov  6 03:00:02.326: INFO: Successfully updated pod "labelsupdate6da13383-9e70-42b4-b68c-aa89c069e310"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:00:04.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5605" for this suite.
Nov  6 03:00:16.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:00:16.434: INFO: namespace downward-api-5605 deletion completed in 12.063854743s

• [SLOW TEST:18.717 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:00:16.434: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-6543
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  6 03:00:16.486: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  6 03:00:42.648: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.38.96.68:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6543 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  6 03:00:42.648: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 03:00:42.834: INFO: Found all expected endpoints: [netserver-0]
Nov  6 03:00:42.836: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.47.0.62:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6543 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  6 03:00:42.836: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
Nov  6 03:00:43.058: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:00:43.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6543" for this suite.
Nov  6 03:00:55.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:00:55.130: INFO: namespace pod-network-test-6543 deletion completed in 12.067503403s

• [SLOW TEST:38.695 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:00:55.130: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  6 03:00:56.168: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  6 03:00:58.175: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708606056, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708606056, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708606056, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708606056, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  6 03:01:01.206: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:01:01.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8917" for this suite.
Nov  6 03:01:07.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:01:07.669: INFO: namespace webhook-8917 deletion completed in 6.059316229s
STEP: Destroying namespace "webhook-8917-markers" for this suite.
Nov  6 03:01:13.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:01:13.736: INFO: namespace webhook-8917-markers deletion completed in 6.066664321s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.640 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:01:13.769: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1106 03:01:19.868609      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  6 03:01:19.868: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:01:19.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3769" for this suite.
Nov  6 03:01:25.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:01:25.937: INFO: namespace gc-3769 deletion completed in 6.06623604s

• [SLOW TEST:12.168 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:01:25.937: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-f1776365-4b2a-4ba1-94b8-0e352623ea6c
STEP: Creating a pod to test consume configMaps
Nov  6 03:01:26.042: INFO: Waiting up to 5m0s for pod "pod-configmaps-0e952036-0992-4a9b-aa86-ef4ffc511d0b" in namespace "configmap-281" to be "success or failure"
Nov  6 03:01:26.052: INFO: Pod "pod-configmaps-0e952036-0992-4a9b-aa86-ef4ffc511d0b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.647722ms
Nov  6 03:01:28.055: INFO: Pod "pod-configmaps-0e952036-0992-4a9b-aa86-ef4ffc511d0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013346875s
Nov  6 03:01:30.058: INFO: Pod "pod-configmaps-0e952036-0992-4a9b-aa86-ef4ffc511d0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015857069s
STEP: Saw pod success
Nov  6 03:01:30.058: INFO: Pod "pod-configmaps-0e952036-0992-4a9b-aa86-ef4ffc511d0b" satisfied condition "success or failure"
Nov  6 03:01:30.059: INFO: Trying to get logs from node apps-114 pod pod-configmaps-0e952036-0992-4a9b-aa86-ef4ffc511d0b container configmap-volume-test: <nil>
STEP: delete the pod
Nov  6 03:01:30.079: INFO: Waiting for pod pod-configmaps-0e952036-0992-4a9b-aa86-ef4ffc511d0b to disappear
Nov  6 03:01:30.086: INFO: Pod pod-configmaps-0e952036-0992-4a9b-aa86-ef4ffc511d0b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:01:30.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-281" for this suite.
Nov  6 03:01:36.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:01:36.168: INFO: namespace configmap-281 deletion completed in 6.079824975s

• [SLOW TEST:10.231 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:01:36.168: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 03:01:36.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 create -f - --namespace=kubectl-454'
Nov  6 03:01:38.305: INFO: stderr: ""
Nov  6 03:01:38.305: INFO: stdout: "replicationcontroller/redis-master created\n"
Nov  6 03:01:38.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 create -f - --namespace=kubectl-454'
Nov  6 03:01:38.602: INFO: stderr: ""
Nov  6 03:01:38.602: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  6 03:01:39.624: INFO: Selector matched 1 pods for map[app:redis]
Nov  6 03:01:39.624: INFO: Found 0 / 1
Nov  6 03:01:40.605: INFO: Selector matched 1 pods for map[app:redis]
Nov  6 03:01:40.605: INFO: Found 1 / 1
Nov  6 03:01:40.605: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  6 03:01:40.608: INFO: Selector matched 1 pods for map[app:redis]
Nov  6 03:01:40.608: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  6 03:01:40.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 describe pod redis-master-m6pwm --namespace=kubectl-454'
Nov  6 03:01:40.705: INFO: stderr: ""
Nov  6 03:01:40.705: INFO: stdout: "Name:         redis-master-m6pwm\nNamespace:    kubectl-454\nPriority:     0\nNode:         apps-114/192.168.1.114\nStart Time:   Wed, 06 Nov 2019 03:01:38 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 10.38.96.82/32\nStatus:       Running\nIP:           10.38.96.82\nIPs:\n  IP:           10.38.96.82\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://4081a13ca9ce7e1d2b71f65069572bacd96e5049dc8e95013b2452adaf4740ba\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 06 Nov 2019 03:01:40 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-5hsjq (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-5hsjq:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-5hsjq\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 30s\n                 node.kubernetes.io/unreachable:NoExecute for 30s\nEvents:\n  Type    Reason     Age        From               Message\n  ----    ------     ----       ----               -------\n  Normal  Scheduled  <unknown>  default-scheduler  Successfully assigned kubectl-454/redis-master-m6pwm to apps-114\n  Normal  Pulled     1s         kubelet, apps-114  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s         kubelet, apps-114  Created container redis-master\n  Normal  Started    0s         kubelet, apps-114  Started container redis-master\n"
Nov  6 03:01:40.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 describe rc redis-master --namespace=kubectl-454'
Nov  6 03:01:40.809: INFO: stderr: ""
Nov  6 03:01:40.809: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-454\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-m6pwm\n"
Nov  6 03:01:40.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 describe service redis-master --namespace=kubectl-454'
Nov  6 03:01:40.903: INFO: stderr: ""
Nov  6 03:01:40.903: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-454\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.103.216.112\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.38.96.82:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov  6 03:01:40.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 describe node apps-113'
Nov  6 03:01:41.028: INFO: stderr: ""
Nov  6 03:01:41.028: INFO: stdout: "Name:               apps-113\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    cube.acornsoft.io/clusterid=cncf-verifi\n                    cube.acornsoft.io/role=master\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=apps-113\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 192.168.1.113/24\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.47.0.0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 30 Oct 2019 08:15:47 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Wed, 30 Oct 2019 08:17:11 +0000   Wed, 30 Oct 2019 08:17:11 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Wed, 06 Nov 2019 03:00:42 +0000   Wed, 30 Oct 2019 08:16:37 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Wed, 06 Nov 2019 03:00:42 +0000   Wed, 30 Oct 2019 08:16:37 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Wed, 06 Nov 2019 03:00:42 +0000   Wed, 30 Oct 2019 08:16:37 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Wed, 06 Nov 2019 03:00:42 +0000   Wed, 30 Oct 2019 08:16:53 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.1.113\n  Hostname:    apps-113\nCapacity:\n cpu:                8\n ephemeral-storage:  958999032Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16202156Ki\n pods:               110\nAllocatable:\n cpu:                8\n ephemeral-storage:  883813506428\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16099756Ki\n pods:               110\nSystem Info:\n Machine ID:                 344566b4830a476b98ea8364c6fda3d5\n System UUID:                DEE8C213-D21D-B211-884C-000000821800\n Boot ID:                    6f8b0df8-bdc8-48ec-91f6-440c85b24b41\n Kernel Version:             3.10.0-957.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.2\n Kubelet Version:            v1.16.2\n Kube-Proxy Version:         v1.16.2\nPodCIDR:                     10.32.0.0/24\nPodCIDRs:                    10.32.0.0/24\nNon-terminated Pods:         (34 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  cocktail-addon             addon-manager-7c8b9c74f6-9pllx                             100m (1%)     100m (1%)   300Mi (1%)       300Mi (1%)     6d18h\n  cocktail-addon             alertmanager-addon-5967cc89f8-8bdvd                        60m (0%)      60m (0%)    62Mi (0%)        62Mi (0%)      6d18h\n  cocktail-addon             disk-usage-exporter-addon-t758w                            100m (1%)     100m (1%)   100Mi (0%)       100Mi (0%)     6d18h\n  cocktail-addon             kube-state-metrics-addon-7f48b7868b-jd4jx                  150m (1%)     150m (1%)   50Mi (0%)        50Mi (0%)      6d18h\n  cocktail-addon             monitoring-agent-njzizt-3-7657c68cd7-hwcqz                 300m (3%)     300m (3%)   256Mi (1%)       256Mi (1%)     6d17h\n  cocktail-addon             nfs-client-provisioner-addon-566798455d-q7tw8              20m (0%)      20m (0%)    30Mi (0%)        30Mi (0%)      6d18h\n  cocktail-addon             nginx-ingress-addon-controller-7dcb6fc5ff-t4rlv            0 (0%)        0 (0%)      0 (0%)           0 (0%)         6d18h\n  cocktail-addon             node-exporter-addon-dqnzs                                  200m (2%)     200m (2%)   50Mi (0%)        50Mi (0%)      6d18h\n  cocktail-addon             prometheus-addon-5754fb587-t8m85                           520m (6%)     520m (6%)   1044Mi (6%)      1044Mi (6%)    6d18h\n  cocktail-system            api-cmdb-cocktail-7796b94f65-5x9kt                         500m (6%)     1 (12%)     1Gi (6%)         2Gi (13%)      6d18h\n  cocktail-system            api-server-cocktail-88f64f646-x67ld                        1500m (18%)   2 (25%)     1536Mi (9%)      2Gi (13%)      6d18h\n  cocktail-system            batch-server-cocktail-55d57dff79-4qm6j                     100m (1%)     100m (1%)   100Mi (0%)       100Mi (0%)     6d18h\n  cocktail-system            build-api-cocktail-6d6f8dfbbc-jhq8w                        100m (1%)     200m (2%)   200Mi (1%)       400Mi (2%)     6d18h\n  cocktail-system            build-queue-cocktail-758498c967-slzk4                      250m (3%)     5 (62%)     100Mi (0%)       500Mi (3%)     6d18h\n  cocktail-system            cloud-metering-cocktail-864ccb89c5-tsgj7                   100m (1%)     200m (2%)   64Mi (0%)        256Mi (1%)     6d18h\n  cocktail-system            cloud-metering-collector-cocktail-68bfd6cc67-q8tjh         300m (3%)     600m (7%)   192Mi (1%)       768Mi (4%)     6d18h\n  cocktail-system            cluster-health-checker-cocktail-58f4545c48-l9ncr           50m (0%)      100m (1%)   50Mi (0%)        100Mi (0%)     6d18h\n  cocktail-system            dashboard-cocktail-575c77f5bd-7xpz9                        300m (3%)     300m (3%)   300Mi (1%)       300Mi (1%)     6d18h\n  cocktail-system            dashboard-proxy-cocktail-5cfd96484-9qjjr                   200m (2%)     200m (2%)   200Mi (1%)       200Mi (1%)     6d18h\n  cocktail-system            dashboard-queue-cocktail-86b7c74d57-8wnfw                  100m (1%)     200m (2%)   256Mi (1%)       512Mi (3%)     6d18h\n  cocktail-system            dashboard-session-cocktail-66658bd785-zl4lk                100m (1%)     200m (2%)   100Mi (0%)       300Mi (1%)     6d18h\n  cocktail-system            monitoring-cocktail-59d5ffc9fd-szdwh                       150m (1%)     200m (2%)   150Mi (0%)       200Mi (1%)     6d18h\n  cocktail-system            monitoring-collector-cocktail-5647c8b855-54jph             200m (2%)     200m (2%)   200Mi (1%)       200Mi (1%)     6d18h\n  cocktail-system            monitoring-db-cocktail-547dff6c7f-msc7q                    1 (12%)       1 (12%)     1Gi (6%)         2Gi (13%)      6d18h\n  kube-system                calico-kube-controllers-55754f75c-kxfjw                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         6d18h\n  kube-system                calico-node-jv7rf                                          250m (3%)     0 (0%)      0 (0%)           0 (0%)         6d18h\n  kube-system                coredns-7649fdbb4-fctcq                                    100m (1%)     0 (0%)      70Mi (0%)        170Mi (1%)     6d18h\n  kube-system                coredns-7649fdbb4-snqxg                                    100m (1%)     0 (0%)      70Mi (0%)        170Mi (1%)     6d18h\n  kube-system                kube-apiserver-apps-113                                    250m (3%)     0 (0%)      0 (0%)           0 (0%)         6d18h\n  kube-system                kube-controller-manager-apps-113                           200m (2%)     0 (0%)      0 (0%)           0 (0%)         6d18h\n  kube-system                kube-proxy-hdklg                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         6d18h\n  kube-system                kube-scheduler-apps-113                                    100m (1%)     0 (0%)      0 (0%)           0 (0%)         6d18h\n  kube-system                metrics-server-5d9d98df9f-qsw2s                            100m (1%)     200m (2%)   256Mi (1%)       256Mi (1%)     6d18h\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-a0ae98b6655c4fa6-tpjhf    0 (0%)        0 (0%)      0 (0%)           0 (0%)         108m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests      Limits\n  --------           --------      ------\n  cpu                7500m (93%)   13150m (164%)\n  memory             7784Mi (49%)  12468Mi (79%)\n  ephemeral-storage  0 (0%)        0 (0%)\nEvents:              <none>\n"
Nov  6 03:01:41.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 describe namespace kubectl-454'
Nov  6 03:01:41.125: INFO: stderr: ""
Nov  6 03:01:41.125: INFO: stdout: "Name:         kubectl-454\nLabels:       e2e-framework=kubectl\n              e2e-run=e7d50d4e-0c55-4e4e-bc94-cc2595a4b5df\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:01:41.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-454" for this suite.
Nov  6 03:02:09.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:02:09.219: INFO: namespace kubectl-454 deletion completed in 28.090780728s

• [SLOW TEST:33.051 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:02:09.219: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-d9a3544a-a703-48cf-870a-fca0da77df20 in namespace container-probe-6882
Nov  6 03:02:13.284: INFO: Started pod busybox-d9a3544a-a703-48cf-870a-fca0da77df20 in namespace container-probe-6882
STEP: checking the pod's current state and verifying that restartCount is present
Nov  6 03:02:13.286: INFO: Initial restart count of pod busybox-d9a3544a-a703-48cf-870a-fca0da77df20 is 0
Nov  6 03:03:07.361: INFO: Restart count of pod container-probe-6882/busybox-d9a3544a-a703-48cf-870a-fca0da77df20 is now 1 (54.075586918s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:03:07.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6882" for this suite.
Nov  6 03:03:13.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:03:13.490: INFO: namespace container-probe-6882 deletion completed in 6.062725294s

• [SLOW TEST:64.271 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:03:13.490: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 03:03:13.528: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov  6 03:03:17.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-6761 create -f -'
Nov  6 03:03:19.641: INFO: stderr: ""
Nov  6 03:03:19.641: INFO: stdout: "e2e-test-crd-publish-openapi-3393-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov  6 03:03:19.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-6761 delete e2e-test-crd-publish-openapi-3393-crds test-cr'
Nov  6 03:03:19.730: INFO: stderr: ""
Nov  6 03:03:19.730: INFO: stdout: "e2e-test-crd-publish-openapi-3393-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Nov  6 03:03:19.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-6761 apply -f -'
Nov  6 03:03:20.005: INFO: stderr: ""
Nov  6 03:03:20.005: INFO: stdout: "e2e-test-crd-publish-openapi-3393-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov  6 03:03:20.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=crd-publish-openapi-6761 delete e2e-test-crd-publish-openapi-3393-crds test-cr'
Nov  6 03:03:20.097: INFO: stderr: ""
Nov  6 03:03:20.097: INFO: stdout: "e2e-test-crd-publish-openapi-3393-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Nov  6 03:03:20.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 explain e2e-test-crd-publish-openapi-3393-crds'
Nov  6 03:03:20.394: INFO: stderr: ""
Nov  6 03:03:20.394: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3393-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:03:24.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6761" for this suite.
Nov  6 03:03:30.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:03:30.381: INFO: namespace crd-publish-openapi-6761 deletion completed in 6.06981053s

• [SLOW TEST:16.891 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:03:30.381: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  6 03:03:30.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-1000'
Nov  6 03:03:30.568: INFO: stderr: ""
Nov  6 03:03:30.568: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Nov  6 03:03:30.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 delete pods e2e-test-httpd-pod --namespace=kubectl-1000'
Nov  6 03:03:43.655: INFO: stderr: ""
Nov  6 03:03:43.655: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:03:43.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1000" for this suite.
Nov  6 03:03:49.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:03:49.722: INFO: namespace kubectl-1000 deletion completed in 6.058757873s

• [SLOW TEST:19.341 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:03:49.722: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Nov  6 03:03:49.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 cluster-info'
Nov  6 03:03:49.852: INFO: stderr: ""
Nov  6 03:03:49.852: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:03:49.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4668" for this suite.
Nov  6 03:03:55.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:03:55.924: INFO: namespace kubectl-4668 deletion completed in 6.068355133s

• [SLOW TEST:6.202 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:03:55.925: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Nov  6 03:03:55.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 --namespace=kubectl-3480 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Nov  6 03:03:58.603: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Nov  6 03:03:58.603: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:04:00.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3480" for this suite.
Nov  6 03:04:06.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:04:06.681: INFO: namespace kubectl-3480 deletion completed in 6.071142028s

• [SLOW TEST:10.756 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:04:06.682: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:04:06.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-8626" for this suite.
Nov  6 03:04:12.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:04:12.827: INFO: namespace tables-8626 deletion completed in 6.06720451s

• [SLOW TEST:6.145 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:04:12.827: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5639
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Nov  6 03:04:12.902: INFO: Found 0 stateful pods, waiting for 3
Nov  6 03:04:22.906: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  6 03:04:22.906: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  6 03:04:22.906: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Nov  6 03:04:22.926: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Nov  6 03:04:32.972: INFO: Updating stateful set ss2
Nov  6 03:04:32.995: INFO: Waiting for Pod statefulset-5639/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Nov  6 03:04:43.104: INFO: Found 2 stateful pods, waiting for 3
Nov  6 03:04:53.107: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  6 03:04:53.107: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  6 03:04:53.107: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Nov  6 03:04:53.125: INFO: Updating stateful set ss2
Nov  6 03:04:53.171: INFO: Waiting for Pod statefulset-5639/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  6 03:05:03.191: INFO: Updating stateful set ss2
Nov  6 03:05:03.255: INFO: Waiting for StatefulSet statefulset-5639/ss2 to complete update
Nov  6 03:05:03.255: INFO: Waiting for Pod statefulset-5639/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  6 03:05:13.260: INFO: Waiting for StatefulSet statefulset-5639/ss2 to complete update
Nov  6 03:05:13.260: INFO: Waiting for Pod statefulset-5639/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  6 03:05:23.260: INFO: Deleting all statefulset in ns statefulset-5639
Nov  6 03:05:23.262: INFO: Scaling statefulset ss2 to 0
Nov  6 03:05:43.289: INFO: Waiting for statefulset status.replicas updated to 0
Nov  6 03:05:43.291: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:05:43.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5639" for this suite.
Nov  6 03:05:49.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:05:49.363: INFO: namespace statefulset-5639 deletion completed in 6.05549449s

• [SLOW TEST:96.536 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:05:49.363: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  6 03:05:50.529: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  6 03:05:52.535: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708606350, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708606350, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708606350, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708606350, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  6 03:05:55.563: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:05:55.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1810" for this suite.
Nov  6 03:06:01.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:06:01.756: INFO: namespace webhook-1810 deletion completed in 6.084060718s
STEP: Destroying namespace "webhook-1810-markers" for this suite.
Nov  6 03:06:07.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:06:07.853: INFO: namespace webhook-1810-markers deletion completed in 6.097276087s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.497 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:06:07.861: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov  6 03:06:07.941: INFO: PodSpec: initContainers in spec.initContainers
Nov  6 03:06:59.780: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-d4912328-7f2f-4341-9fc3-f6c04e9f83c5", GenerateName:"", Namespace:"init-container-2484", SelfLink:"/api/v1/namespaces/init-container-2484/pods/pod-init-d4912328-7f2f-4341-9fc3-f6c04e9f83c5", UID:"fcd193ae-0bcb-4fe9-bbf9-1a9d43d9dca2", ResourceVersion:"878172", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63708606367, loc:(*time.Location)(0x84c02a0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"941563573"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.38.96.92/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-vrg7r", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc004a607c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-vrg7r", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-vrg7r", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-vrg7r", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0069b98e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"apps-114", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002f91200), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0069b9970)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0069b9990)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0069b9998), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0069b999c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708606368, loc:(*time.Location)(0x84c02a0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708606368, loc:(*time.Location)(0x84c02a0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708606368, loc:(*time.Location)(0x84c02a0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708606367, loc:(*time.Location)(0x84c02a0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.1.114", PodIP:"10.38.96.92", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.38.96.92"}}, StartTime:(*v1.Time)(0xc002a33180), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0008255e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0008256c0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://9c7722e6e47ef6f1e9fd474e787142fda5a37513bbcd0245fcb6bacfe67caad8", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002a331c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002a331a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0069b9a1f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:06:59.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2484" for this suite.
Nov  6 03:07:27.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:07:27.894: INFO: namespace init-container-2484 deletion completed in 28.104177113s

• [SLOW TEST:80.033 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:07:27.894: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  6 03:07:27.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-3502'
Nov  6 03:07:28.049: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  6 03:07:28.049: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Nov  6 03:07:28.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 delete jobs e2e-test-httpd-job --namespace=kubectl-3502'
Nov  6 03:07:28.156: INFO: stderr: ""
Nov  6 03:07:28.156: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:07:28.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3502" for this suite.
Nov  6 03:07:40.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:07:40.215: INFO: namespace kubectl-3502 deletion completed in 12.055807462s

• [SLOW TEST:12.320 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:07:40.215: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-ea2c291d-b1a8-4cf8-ba5e-a7ad4d74fbbe
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:07:40.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7301" for this suite.
Nov  6 03:07:46.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:07:46.357: INFO: namespace configmap-7301 deletion completed in 6.070172104s

• [SLOW TEST:6.142 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:07:46.357: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Nov  6 03:07:50.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec pod-sharedvolume-c5981853-d0ce-4e59-bec3-fd08a23f3c7f -c busybox-main-container --namespace=emptydir-2082 -- cat /usr/share/volumeshare/shareddata.txt'
Nov  6 03:07:50.699: INFO: stderr: ""
Nov  6 03:07:50.699: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:07:50.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2082" for this suite.
Nov  6 03:07:56.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:07:56.771: INFO: namespace emptydir-2082 deletion completed in 6.06836695s

• [SLOW TEST:10.414 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:07:56.772: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Nov  6 03:08:00.836: INFO: Pod pod-hostip-d8fb579f-6c26-4004-9fa6-ccc191e8f7d1 has hostIP: 192.168.1.114
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:08:00.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4195" for this suite.
Nov  6 03:08:12.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:08:12.931: INFO: namespace pods-4195 deletion completed in 12.093406239s

• [SLOW TEST:16.160 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:08:12.932: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov  6 03:08:17.502: INFO: Successfully updated pod "pod-update-06eeb863-e862-4770-9cdd-1efd2b1daf49"
STEP: verifying the updated pod is in kubernetes
Nov  6 03:08:17.516: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:08:17.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-289" for this suite.
Nov  6 03:08:45.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:08:45.580: INFO: namespace pods-289 deletion completed in 28.061803336s

• [SLOW TEST:32.648 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:08:45.580: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-8979
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-8979
I1106 03:08:45.715050      26 runners.go:184] Created replication controller with name: externalname-service, namespace: services-8979, replica count: 2
I1106 03:08:48.765389      26 runners.go:184] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  6 03:08:51.765: INFO: Creating new exec pod
I1106 03:08:51.765591      26 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  6 03:08:56.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=services-8979 execpod4lvzg -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Nov  6 03:08:57.055: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov  6 03:08:57.055: INFO: stdout: ""
Nov  6 03:08:57.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=services-8979 execpod4lvzg -- /bin/sh -x -c nc -zv -t -w 2 10.102.83.153 80'
Nov  6 03:08:57.313: INFO: stderr: "+ nc -zv -t -w 2 10.102.83.153 80\nConnection to 10.102.83.153 80 port [tcp/http] succeeded!\n"
Nov  6 03:08:57.313: INFO: stdout: ""
Nov  6 03:08:57.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=services-8979 execpod4lvzg -- /bin/sh -x -c nc -zv -t -w 2 192.168.1.113 30964'
Nov  6 03:08:57.586: INFO: stderr: "+ nc -zv -t -w 2 192.168.1.113 30964\nConnection to 192.168.1.113 30964 port [tcp/30964] succeeded!\n"
Nov  6 03:08:57.586: INFO: stdout: ""
Nov  6 03:08:57.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-720122187 exec --namespace=services-8979 execpod4lvzg -- /bin/sh -x -c nc -zv -t -w 2 192.168.1.114 30964'
Nov  6 03:08:57.828: INFO: stderr: "+ nc -zv -t -w 2 192.168.1.114 30964\nConnection to 192.168.1.114 30964 port [tcp/30964] succeeded!\n"
Nov  6 03:08:57.828: INFO: stdout: ""
Nov  6 03:08:57.828: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:08:57.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8979" for this suite.
Nov  6 03:09:03.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:09:04.057: INFO: namespace services-8979 deletion completed in 6.105460263s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:18.477 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:09:04.057: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-420b5157-6ba9-487a-ad04-e6ab9418ee44
STEP: Creating a pod to test consume secrets
Nov  6 03:09:04.108: INFO: Waiting up to 5m0s for pod "pod-secrets-b4b890cf-c390-42fa-871e-f19d2dffa300" in namespace "secrets-994" to be "success or failure"
Nov  6 03:09:04.115: INFO: Pod "pod-secrets-b4b890cf-c390-42fa-871e-f19d2dffa300": Phase="Pending", Reason="", readiness=false. Elapsed: 7.039587ms
Nov  6 03:09:06.118: INFO: Pod "pod-secrets-b4b890cf-c390-42fa-871e-f19d2dffa300": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009525244s
Nov  6 03:09:08.125: INFO: Pod "pod-secrets-b4b890cf-c390-42fa-871e-f19d2dffa300": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016707321s
STEP: Saw pod success
Nov  6 03:09:08.125: INFO: Pod "pod-secrets-b4b890cf-c390-42fa-871e-f19d2dffa300" satisfied condition "success or failure"
Nov  6 03:09:08.127: INFO: Trying to get logs from node apps-114 pod pod-secrets-b4b890cf-c390-42fa-871e-f19d2dffa300 container secret-volume-test: <nil>
STEP: delete the pod
Nov  6 03:09:08.150: INFO: Waiting for pod pod-secrets-b4b890cf-c390-42fa-871e-f19d2dffa300 to disappear
Nov  6 03:09:08.158: INFO: Pod pod-secrets-b4b890cf-c390-42fa-871e-f19d2dffa300 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:09:08.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-994" for this suite.
Nov  6 03:09:14.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:09:14.232: INFO: namespace secrets-994 deletion completed in 6.072209572s

• [SLOW TEST:10.175 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:09:14.233: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  6 03:09:15.174: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  6 03:09:17.180: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708606555, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708606555, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708606555, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708606555, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  6 03:09:20.217: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:09:20.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8795" for this suite.
Nov  6 03:09:26.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:09:26.343: INFO: namespace webhook-8795 deletion completed in 6.059591344s
STEP: Destroying namespace "webhook-8795-markers" for this suite.
Nov  6 03:09:32.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:09:32.409: INFO: namespace webhook-8795-markers deletion completed in 6.065617268s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.183 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:09:32.416: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-1e9cd09a-da51-4402-8a68-c7c5de1c53cc
STEP: Creating a pod to test consume secrets
Nov  6 03:09:32.478: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e828561b-19ab-403a-9871-3ee37d9ef99c" in namespace "projected-7558" to be "success or failure"
Nov  6 03:09:32.485: INFO: Pod "pod-projected-secrets-e828561b-19ab-403a-9871-3ee37d9ef99c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.874754ms
Nov  6 03:09:34.488: INFO: Pod "pod-projected-secrets-e828561b-19ab-403a-9871-3ee37d9ef99c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009462478s
Nov  6 03:09:36.490: INFO: Pod "pod-projected-secrets-e828561b-19ab-403a-9871-3ee37d9ef99c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012044133s
STEP: Saw pod success
Nov  6 03:09:36.490: INFO: Pod "pod-projected-secrets-e828561b-19ab-403a-9871-3ee37d9ef99c" satisfied condition "success or failure"
Nov  6 03:09:36.492: INFO: Trying to get logs from node apps-114 pod pod-projected-secrets-e828561b-19ab-403a-9871-3ee37d9ef99c container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  6 03:09:36.518: INFO: Waiting for pod pod-projected-secrets-e828561b-19ab-403a-9871-3ee37d9ef99c to disappear
Nov  6 03:09:36.527: INFO: Pod pod-projected-secrets-e828561b-19ab-403a-9871-3ee37d9ef99c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:09:36.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7558" for this suite.
Nov  6 03:09:42.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:09:42.585: INFO: namespace projected-7558 deletion completed in 6.055540646s

• [SLOW TEST:10.169 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:09:42.585: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-2597ffc4-d65f-44a9-a002-a292fcef18f9
STEP: Creating a pod to test consume secrets
Nov  6 03:09:42.687: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4de3babd-e20f-4da2-bc2c-e177f2ffd489" in namespace "projected-2733" to be "success or failure"
Nov  6 03:09:42.693: INFO: Pod "pod-projected-secrets-4de3babd-e20f-4da2-bc2c-e177f2ffd489": Phase="Pending", Reason="", readiness=false. Elapsed: 6.788451ms
Nov  6 03:09:44.696: INFO: Pod "pod-projected-secrets-4de3babd-e20f-4da2-bc2c-e177f2ffd489": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009566134s
Nov  6 03:09:46.699: INFO: Pod "pod-projected-secrets-4de3babd-e20f-4da2-bc2c-e177f2ffd489": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012838114s
STEP: Saw pod success
Nov  6 03:09:46.699: INFO: Pod "pod-projected-secrets-4de3babd-e20f-4da2-bc2c-e177f2ffd489" satisfied condition "success or failure"
Nov  6 03:09:46.701: INFO: Trying to get logs from node apps-114 pod pod-projected-secrets-4de3babd-e20f-4da2-bc2c-e177f2ffd489 container secret-volume-test: <nil>
STEP: delete the pod
Nov  6 03:09:46.750: INFO: Waiting for pod pod-projected-secrets-4de3babd-e20f-4da2-bc2c-e177f2ffd489 to disappear
Nov  6 03:09:46.760: INFO: Pod pod-projected-secrets-4de3babd-e20f-4da2-bc2c-e177f2ffd489 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:09:46.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2733" for this suite.
Nov  6 03:09:52.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:09:52.819: INFO: namespace projected-2733 deletion completed in 6.056492441s

• [SLOW TEST:10.234 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:09:52.819: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  6 03:09:52.870: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0363b643-1ef9-47a9-b6c4-3f66b2b784db" in namespace "downward-api-7728" to be "success or failure"
Nov  6 03:09:52.877: INFO: Pod "downwardapi-volume-0363b643-1ef9-47a9-b6c4-3f66b2b784db": Phase="Pending", Reason="", readiness=false. Elapsed: 6.508658ms
Nov  6 03:09:54.880: INFO: Pod "downwardapi-volume-0363b643-1ef9-47a9-b6c4-3f66b2b784db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009225004s
Nov  6 03:09:56.882: INFO: Pod "downwardapi-volume-0363b643-1ef9-47a9-b6c4-3f66b2b784db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011767988s
STEP: Saw pod success
Nov  6 03:09:56.882: INFO: Pod "downwardapi-volume-0363b643-1ef9-47a9-b6c4-3f66b2b784db" satisfied condition "success or failure"
Nov  6 03:09:56.884: INFO: Trying to get logs from node apps-114 pod downwardapi-volume-0363b643-1ef9-47a9-b6c4-3f66b2b784db container client-container: <nil>
STEP: delete the pod
Nov  6 03:09:56.941: INFO: Waiting for pod downwardapi-volume-0363b643-1ef9-47a9-b6c4-3f66b2b784db to disappear
Nov  6 03:09:56.952: INFO: Pod downwardapi-volume-0363b643-1ef9-47a9-b6c4-3f66b2b784db no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:09:56.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7728" for this suite.
Nov  6 03:10:02.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:10:03.011: INFO: namespace downward-api-7728 deletion completed in 6.056144999s

• [SLOW TEST:10.192 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:10:03.011: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:10:07.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4876" for this suite.
Nov  6 03:10:57.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:10:57.190: INFO: namespace kubelet-test-4876 deletion completed in 50.107724044s

• [SLOW TEST:54.178 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:10:57.190: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-4399a856-9386-4d00-954c-159accf8f933
STEP: Creating a pod to test consume secrets
Nov  6 03:10:57.273: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b549907b-29c2-49f0-b437-9c734a13f163" in namespace "projected-4662" to be "success or failure"
Nov  6 03:10:57.284: INFO: Pod "pod-projected-secrets-b549907b-29c2-49f0-b437-9c734a13f163": Phase="Pending", Reason="", readiness=false. Elapsed: 11.451588ms
Nov  6 03:10:59.287: INFO: Pod "pod-projected-secrets-b549907b-29c2-49f0-b437-9c734a13f163": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014111722s
Nov  6 03:11:01.289: INFO: Pod "pod-projected-secrets-b549907b-29c2-49f0-b437-9c734a13f163": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016606842s
STEP: Saw pod success
Nov  6 03:11:01.289: INFO: Pod "pod-projected-secrets-b549907b-29c2-49f0-b437-9c734a13f163" satisfied condition "success or failure"
Nov  6 03:11:01.291: INFO: Trying to get logs from node apps-114 pod pod-projected-secrets-b549907b-29c2-49f0-b437-9c734a13f163 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  6 03:11:01.347: INFO: Waiting for pod pod-projected-secrets-b549907b-29c2-49f0-b437-9c734a13f163 to disappear
Nov  6 03:11:01.359: INFO: Pod pod-projected-secrets-b549907b-29c2-49f0-b437-9c734a13f163 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:11:01.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4662" for this suite.
Nov  6 03:11:07.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:11:07.419: INFO: namespace projected-4662 deletion completed in 6.056944901s

• [SLOW TEST:10.229 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:11:07.419: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  6 03:11:07.469: INFO: Waiting up to 5m0s for pod "downwardapi-volume-359b9ea5-c652-41a7-ae96-1a1d2bc2d2e9" in namespace "downward-api-8403" to be "success or failure"
Nov  6 03:11:07.485: INFO: Pod "downwardapi-volume-359b9ea5-c652-41a7-ae96-1a1d2bc2d2e9": Phase="Pending", Reason="", readiness=false. Elapsed: 15.71784ms
Nov  6 03:11:09.488: INFO: Pod "downwardapi-volume-359b9ea5-c652-41a7-ae96-1a1d2bc2d2e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018814649s
Nov  6 03:11:11.490: INFO: Pod "downwardapi-volume-359b9ea5-c652-41a7-ae96-1a1d2bc2d2e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021334332s
STEP: Saw pod success
Nov  6 03:11:11.490: INFO: Pod "downwardapi-volume-359b9ea5-c652-41a7-ae96-1a1d2bc2d2e9" satisfied condition "success or failure"
Nov  6 03:11:11.492: INFO: Trying to get logs from node apps-114 pod downwardapi-volume-359b9ea5-c652-41a7-ae96-1a1d2bc2d2e9 container client-container: <nil>
STEP: delete the pod
Nov  6 03:11:11.519: INFO: Waiting for pod downwardapi-volume-359b9ea5-c652-41a7-ae96-1a1d2bc2d2e9 to disappear
Nov  6 03:11:11.526: INFO: Pod downwardapi-volume-359b9ea5-c652-41a7-ae96-1a1d2bc2d2e9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:11:11.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8403" for this suite.
Nov  6 03:11:17.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:11:17.585: INFO: namespace downward-api-8403 deletion completed in 6.056745692s

• [SLOW TEST:10.166 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:11:17.585: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:11:44.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8585" for this suite.
Nov  6 03:11:50.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:11:51.021: INFO: namespace container-runtime-8585 deletion completed in 6.062997878s

• [SLOW TEST:33.436 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:11:51.021: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov  6 03:11:51.077: INFO: Waiting up to 5m0s for pod "pod-2c872c83-c1e8-4a87-8a14-a0d12621a325" in namespace "emptydir-4799" to be "success or failure"
Nov  6 03:11:51.084: INFO: Pod "pod-2c872c83-c1e8-4a87-8a14-a0d12621a325": Phase="Pending", Reason="", readiness=false. Elapsed: 6.676655ms
Nov  6 03:11:53.087: INFO: Pod "pod-2c872c83-c1e8-4a87-8a14-a0d12621a325": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009268193s
Nov  6 03:11:55.090: INFO: Pod "pod-2c872c83-c1e8-4a87-8a14-a0d12621a325": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012277703s
STEP: Saw pod success
Nov  6 03:11:55.090: INFO: Pod "pod-2c872c83-c1e8-4a87-8a14-a0d12621a325" satisfied condition "success or failure"
Nov  6 03:11:55.092: INFO: Trying to get logs from node apps-114 pod pod-2c872c83-c1e8-4a87-8a14-a0d12621a325 container test-container: <nil>
STEP: delete the pod
Nov  6 03:11:55.111: INFO: Waiting for pod pod-2c872c83-c1e8-4a87-8a14-a0d12621a325 to disappear
Nov  6 03:11:55.136: INFO: Pod pod-2c872c83-c1e8-4a87-8a14-a0d12621a325 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:11:55.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4799" for this suite.
Nov  6 03:12:01.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:12:01.201: INFO: namespace emptydir-4799 deletion completed in 6.062360677s

• [SLOW TEST:10.180 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:12:01.201: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Nov  6 03:12:01.245: INFO: Waiting up to 1m0s for all nodes to be ready
Nov  6 03:13:01.263: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 03:13:01.265: INFO: Starting informer...
STEP: Starting pods...
Nov  6 03:13:01.474: INFO: Pod1 is running on apps-114. Tainting Node
Nov  6 03:13:05.688: INFO: Pod2 is running on apps-114. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Nov  6 03:13:23.618: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Nov  6 03:13:43.625: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:13:43.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-3176" for this suite.
Nov  6 03:13:49.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:13:49.790: INFO: namespace taint-multiple-pods-3176 deletion completed in 6.140559404s

• [SLOW TEST:108.589 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:13:49.791: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:13:49.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8776" for this suite.
Nov  6 03:13:55.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:13:55.981: INFO: namespace kubelet-test-8776 deletion completed in 6.063464045s

• [SLOW TEST:6.191 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:13:55.981: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-8e12010a-72be-4d20-a098-f3ff3b2e8118 in namespace container-probe-338
Nov  6 03:14:00.044: INFO: Started pod liveness-8e12010a-72be-4d20-a098-f3ff3b2e8118 in namespace container-probe-338
STEP: checking the pod's current state and verifying that restartCount is present
Nov  6 03:14:00.046: INFO: Initial restart count of pod liveness-8e12010a-72be-4d20-a098-f3ff3b2e8118 is 0
Nov  6 03:14:16.076: INFO: Restart count of pod container-probe-338/liveness-8e12010a-72be-4d20-a098-f3ff3b2e8118 is now 1 (16.029982104s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:14:16.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-338" for this suite.
Nov  6 03:14:22.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:14:22.176: INFO: namespace container-probe-338 deletion completed in 6.076111385s

• [SLOW TEST:26.195 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:14:22.176: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6455.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6455.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  6 03:14:26.255: INFO: DNS probes using dns-6455/dns-test-0e6d9241-fd3f-46a1-b04f-e3a8c38e7e70 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:14:26.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6455" for this suite.
Nov  6 03:14:32.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:14:32.400: INFO: namespace dns-6455 deletion completed in 6.108322574s

• [SLOW TEST:10.224 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:14:32.401: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:14:44.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4173" for this suite.
Nov  6 03:14:50.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:14:50.520: INFO: namespace job-4173 deletion completed in 6.056781778s

• [SLOW TEST:18.119 seconds]
[sig-apps] Job
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:14:50.520: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov  6 03:14:58.661: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  6 03:14:58.698: INFO: Pod pod-with-poststart-http-hook still exists
Nov  6 03:15:00.698: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  6 03:15:00.700: INFO: Pod pod-with-poststart-http-hook still exists
Nov  6 03:15:02.698: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  6 03:15:02.701: INFO: Pod pod-with-poststart-http-hook still exists
Nov  6 03:15:04.698: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  6 03:15:04.701: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:15:04.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6715" for this suite.
Nov  6 03:15:16.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:15:16.774: INFO: namespace container-lifecycle-hook-6715 deletion completed in 12.07080978s

• [SLOW TEST:26.254 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:15:16.774: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:15:27.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1688" for this suite.
Nov  6 03:15:33.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:15:33.951: INFO: namespace resourcequota-1688 deletion completed in 6.076241999s

• [SLOW TEST:17.177 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:15:33.951: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  6 03:15:34.027: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  6 03:15:34.040: INFO: Waiting for terminating namespaces to be deleted...
Nov  6 03:15:34.041: INFO: 
Logging pods the kubelet thinks is on node apps-113 before test
Nov  6 03:15:34.056: INFO: batch-server-cocktail-55d57dff79-4qm6j from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container batch ready: true, restart count 0
Nov  6 03:15:34.056: INFO: build-api-cocktail-6d6f8dfbbc-jhq8w from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container build-api ready: true, restart count 0
Nov  6 03:15:34.056: INFO: dashboard-session-cocktail-66658bd785-zl4lk from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container dashboard-session-01 ready: true, restart count 0
Nov  6 03:15:34.056: INFO: dashboard-cocktail-575c77f5bd-7xpz9 from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container cocktail-dashboard ready: true, restart count 0
Nov  6 03:15:34.056: INFO: api-cmdb-cocktail-7796b94f65-5x9kt from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container api-cmdb-01 ready: true, restart count 0
Nov  6 03:15:34.056: INFO: monitoring-db-cocktail-547dff6c7f-msc7q from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container db ready: true, restart count 0
Nov  6 03:15:34.056: INFO: calico-node-jv7rf from kube-system started at 2019-10-30 08:16:37 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container calico-node ready: true, restart count 0
Nov  6 03:15:34.056: INFO: addon-manager-7c8b9c74f6-9pllx from cocktail-addon started at 2019-10-30 08:17:39 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container addon-manager ready: true, restart count 0
Nov  6 03:15:34.056: INFO: sonobuoy-systemd-logs-daemon-set-a0ae98b6655c4fa6-tpjhf from sonobuoy started at 2019-11-06 01:13:06 +0000 UTC (2 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Nov  6 03:15:34.056: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  6 03:15:34.056: INFO: nfs-client-provisioner-addon-566798455d-q7tw8 from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container nfs-client-provisioner-addon ready: true, restart count 0
Nov  6 03:15:34.056: INFO: kube-state-metrics-addon-7f48b7868b-jd4jx from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container kube-state-metrics-addon ready: true, restart count 0
Nov  6 03:15:34.056: INFO: alertmanager-addon-5967cc89f8-8bdvd from cocktail-addon started at 2019-10-30 08:19:27 +0000 UTC (2 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container alertmanager-addon ready: true, restart count 0
Nov  6 03:15:34.056: INFO: 	Container configmap-reload ready: true, restart count 0
Nov  6 03:15:34.056: INFO: dashboard-proxy-cocktail-5cfd96484-9qjjr from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container dashboard-proxy-01 ready: true, restart count 0
Nov  6 03:15:34.056: INFO: cluster-health-checker-cocktail-58f4545c48-l9ncr from cocktail-system started at 2019-10-30 08:18:01 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container checker ready: true, restart count 0
Nov  6 03:15:34.056: INFO: cloud-metering-collector-cocktail-68bfd6cc67-q8tjh from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (3 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container cocktail-collector-aws ready: true, restart count 1
Nov  6 03:15:34.056: INFO: 	Container cocktail-collector-azure ready: true, restart count 0
Nov  6 03:15:34.056: INFO: 	Container cocktail-collector-google ready: true, restart count 1
Nov  6 03:15:34.056: INFO: monitoring-collector-cocktail-5647c8b855-54jph from cocktail-system started at 2019-10-30 08:18:01 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container statcollector ready: true, restart count 4
Nov  6 03:15:34.056: INFO: api-server-cocktail-88f64f646-x67ld from cocktail-system started at 2019-10-30 08:19:27 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container api-server-01 ready: true, restart count 0
Nov  6 03:15:34.056: INFO: metrics-server-5d9d98df9f-qsw2s from kube-system started at 2019-10-30 08:17:01 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container metrics-server ready: true, restart count 0
Nov  6 03:15:34.056: INFO: nginx-ingress-addon-controller-7dcb6fc5ff-t4rlv from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container nginx-ingress-addon-controller ready: true, restart count 0
Nov  6 03:15:34.056: INFO: monitoring-cocktail-59d5ffc9fd-szdwh from cocktail-system started at 2019-10-30 08:18:03 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container monitoring-01 ready: true, restart count 0
Nov  6 03:15:34.056: INFO: build-queue-cocktail-758498c967-slzk4 from cocktail-system started at 2019-10-30 08:19:23 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container nats-streaming ready: true, restart count 0
Nov  6 03:15:34.056: INFO: kube-controller-manager-apps-113 from kube-system started at 2019-10-30 08:16:38 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container kube-controller-manager ready: true, restart count 0
Nov  6 03:15:34.056: INFO: kube-scheduler-apps-113 from kube-system started at 2019-10-30 08:16:37 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container kube-scheduler ready: true, restart count 0
Nov  6 03:15:34.056: INFO: kube-apiserver-apps-113 from kube-system started at 2019-10-30 08:16:37 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container kube-apiserver ready: true, restart count 0
Nov  6 03:15:34.056: INFO: disk-usage-exporter-addon-t758w from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container disk-usage-exporter-addon ready: true, restart count 0
Nov  6 03:15:34.056: INFO: calico-kube-controllers-55754f75c-kxfjw from kube-system started at 2019-10-30 08:16:57 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov  6 03:15:34.056: INFO: node-exporter-addon-dqnzs from cocktail-addon started at 2019-10-30 08:17:58 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container node-exporter-addon ready: true, restart count 0
Nov  6 03:15:34.056: INFO: kube-proxy-hdklg from kube-system started at 2019-10-30 08:16:08 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  6 03:15:34.056: INFO: coredns-7649fdbb4-fctcq from kube-system started at 2019-10-30 08:16:55 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container coredns ready: true, restart count 0
Nov  6 03:15:34.056: INFO: cloud-metering-cocktail-864ccb89c5-tsgj7 from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container cocktail-metering-api ready: true, restart count 0
Nov  6 03:15:34.056: INFO: prometheus-addon-5754fb587-t8m85 from cocktail-addon started at 2019-10-30 08:19:27 +0000 UTC (2 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container configmap-reload ready: true, restart count 0
Nov  6 03:15:34.056: INFO: 	Container prometheus-addon ready: true, restart count 0
Nov  6 03:15:34.056: INFO: monitoring-agent-njzizt-3-7657c68cd7-hwcqz from cocktail-addon started at 2019-10-30 09:24:28 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container statcollector ready: true, restart count 0
Nov  6 03:15:34.056: INFO: coredns-7649fdbb4-snqxg from kube-system started at 2019-10-30 08:16:56 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container coredns ready: true, restart count 0
Nov  6 03:15:34.056: INFO: dashboard-queue-cocktail-86b7c74d57-8wnfw from cocktail-system started at 2019-10-30 08:18:00 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.056: INFO: 	Container dashboard-queue ready: true, restart count 0
Nov  6 03:15:34.056: INFO: 
Logging pods the kubelet thinks is on node apps-114 before test
Nov  6 03:15:34.062: INFO: sonobuoy-e2e-job-e818bd6c45834cee from sonobuoy started at 2019-11-06 01:13:06 +0000 UTC (2 container statuses recorded)
Nov  6 03:15:34.062: INFO: 	Container e2e ready: true, restart count 0
Nov  6 03:15:34.062: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  6 03:15:34.062: INFO: kube-proxy-nnw7s from kube-system started at 2019-10-30 10:45:39 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.062: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  6 03:15:34.062: INFO: disk-usage-exporter-addon-97rpq from cocktail-addon started at 2019-11-06 03:13:43 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.062: INFO: 	Container disk-usage-exporter-addon ready: true, restart count 0
Nov  6 03:15:34.062: INFO: calico-node-cbzfz from kube-system started at 2019-10-30 10:45:39 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.062: INFO: 	Container calico-node ready: true, restart count 0
Nov  6 03:15:34.062: INFO: sonobuoy from sonobuoy started at 2019-11-06 01:12:56 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.062: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  6 03:15:34.062: INFO: node-exporter-addon-mlfkx from cocktail-addon started at 2019-11-06 03:13:43 +0000 UTC (1 container statuses recorded)
Nov  6 03:15:34.062: INFO: 	Container node-exporter-addon ready: true, restart count 0
Nov  6 03:15:34.062: INFO: sonobuoy-systemd-logs-daemon-set-a0ae98b6655c4fa6-gcqdr from sonobuoy started at 2019-11-06 01:13:06 +0000 UTC (2 container statuses recorded)
Nov  6 03:15:34.062: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Nov  6 03:15:34.062: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-11286954-b057-461f-b758-402b14c7c726 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-11286954-b057-461f-b758-402b14c7c726 off the node apps-114
STEP: verifying the node doesn't have the label kubernetes.io/e2e-11286954-b057-461f-b758-402b14c7c726
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:15:42.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4805" for this suite.
Nov  6 03:15:54.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:15:54.251: INFO: namespace sched-pred-4805 deletion completed in 12.055773446s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:20.300 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:15:54.251: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  6 03:15:54.322: INFO: Waiting up to 5m0s for pod "downwardapi-volume-02b8b863-a99a-41b6-8a63-580739de7239" in namespace "projected-1033" to be "success or failure"
Nov  6 03:15:54.335: INFO: Pod "downwardapi-volume-02b8b863-a99a-41b6-8a63-580739de7239": Phase="Pending", Reason="", readiness=false. Elapsed: 12.436994ms
Nov  6 03:15:56.338: INFO: Pod "downwardapi-volume-02b8b863-a99a-41b6-8a63-580739de7239": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015306938s
Nov  6 03:15:58.362: INFO: Pod "downwardapi-volume-02b8b863-a99a-41b6-8a63-580739de7239": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040028212s
STEP: Saw pod success
Nov  6 03:15:58.362: INFO: Pod "downwardapi-volume-02b8b863-a99a-41b6-8a63-580739de7239" satisfied condition "success or failure"
Nov  6 03:15:58.365: INFO: Trying to get logs from node apps-114 pod downwardapi-volume-02b8b863-a99a-41b6-8a63-580739de7239 container client-container: <nil>
STEP: delete the pod
Nov  6 03:15:58.394: INFO: Waiting for pod downwardapi-volume-02b8b863-a99a-41b6-8a63-580739de7239 to disappear
Nov  6 03:15:58.401: INFO: Pod downwardapi-volume-02b8b863-a99a-41b6-8a63-580739de7239 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:15:58.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1033" for this suite.
Nov  6 03:16:04.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:16:04.462: INFO: namespace projected-1033 deletion completed in 6.058785569s

• [SLOW TEST:10.211 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:16:04.463: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  6 03:16:04.553: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eac8ae55-1ecb-45a3-bf62-61ffe5b8132e" in namespace "projected-3344" to be "success or failure"
Nov  6 03:16:04.559: INFO: Pod "downwardapi-volume-eac8ae55-1ecb-45a3-bf62-61ffe5b8132e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.782356ms
Nov  6 03:16:06.562: INFO: Pod "downwardapi-volume-eac8ae55-1ecb-45a3-bf62-61ffe5b8132e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009373739s
Nov  6 03:16:08.564: INFO: Pod "downwardapi-volume-eac8ae55-1ecb-45a3-bf62-61ffe5b8132e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011833972s
STEP: Saw pod success
Nov  6 03:16:08.564: INFO: Pod "downwardapi-volume-eac8ae55-1ecb-45a3-bf62-61ffe5b8132e" satisfied condition "success or failure"
Nov  6 03:16:08.566: INFO: Trying to get logs from node apps-114 pod downwardapi-volume-eac8ae55-1ecb-45a3-bf62-61ffe5b8132e container client-container: <nil>
STEP: delete the pod
Nov  6 03:16:08.593: INFO: Waiting for pod downwardapi-volume-eac8ae55-1ecb-45a3-bf62-61ffe5b8132e to disappear
Nov  6 03:16:08.601: INFO: Pod downwardapi-volume-eac8ae55-1ecb-45a3-bf62-61ffe5b8132e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:16:08.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3344" for this suite.
Nov  6 03:16:14.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:16:14.659: INFO: namespace projected-3344 deletion completed in 6.054910491s

• [SLOW TEST:10.196 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:16:14.659: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 03:16:14.711: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:16:18.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1176" for this suite.
Nov  6 03:17:02.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:17:02.994: INFO: namespace pods-1176 deletion completed in 44.069627712s

• [SLOW TEST:48.335 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:17:02.994: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:17:10.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3127" for this suite.
Nov  6 03:17:16.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:17:16.110: INFO: namespace resourcequota-3127 deletion completed in 6.065016257s

• [SLOW TEST:13.116 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:17:16.111: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-a9c313c0-5d6d-4a10-be41-667fe26581ee
STEP: Creating configMap with name cm-test-opt-upd-2c147dca-aa31-4cff-9280-3c96747dedf7
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a9c313c0-5d6d-4a10-be41-667fe26581ee
STEP: Updating configmap cm-test-opt-upd-2c147dca-aa31-4cff-9280-3c96747dedf7
STEP: Creating configMap with name cm-test-opt-create-30630080-e827-432b-bfcf-4a5e9afff289
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:17:24.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5255" for this suite.
Nov  6 03:17:36.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:17:36.417: INFO: namespace configmap-5255 deletion completed in 12.068770257s

• [SLOW TEST:20.306 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:17:36.417: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 03:17:36.493: INFO: Creating deployment "test-recreate-deployment"
Nov  6 03:17:36.500: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov  6 03:17:36.535: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Nov  6 03:17:38.540: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov  6 03:17:38.542: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708607056, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708607056, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708607056, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708607056, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  6 03:17:40.545: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov  6 03:17:40.549: INFO: Updating deployment test-recreate-deployment
Nov  6 03:17:40.549: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  6 03:17:40.736: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-3958 /apis/apps/v1/namespaces/deployment-3958/deployments/test-recreate-deployment 6d0449e5-b553-4205-a687-c779b238f6e1 880494 2 2019-11-06 03:17:36 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc007d6d538 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-11-06 03:17:40 +0000 UTC,LastTransitionTime:2019-11-06 03:17:40 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-11-06 03:17:40 +0000 UTC,LastTransitionTime:2019-11-06 03:17:36 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Nov  6 03:17:40.738: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-3958 /apis/apps/v1/namespaces/deployment-3958/replicasets/test-recreate-deployment-5f94c574ff 4e72054b-5599-43b0-8ab1-2a089f986f41 880493 1 2019-11-06 03:17:40 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 6d0449e5-b553-4205-a687-c779b238f6e1 0xc007d6d917 0xc007d6d918}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc007d6d978 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  6 03:17:40.738: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov  6 03:17:40.738: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-3958 /apis/apps/v1/namespaces/deployment-3958/replicasets/test-recreate-deployment-68fc85c7bb acf314ee-8843-4eff-a586-4ee2bc1608bb 880483 2 2019-11-06 03:17:36 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 6d0449e5-b553-4205-a687-c779b238f6e1 0xc007d6d9e7 0xc007d6d9e8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc007d6da48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  6 03:17:40.742: INFO: Pod "test-recreate-deployment-5f94c574ff-dcxjw" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-dcxjw test-recreate-deployment-5f94c574ff- deployment-3958 /api/v1/namespaces/deployment-3958/pods/test-recreate-deployment-5f94c574ff-dcxjw 463863d5-086c-4dd0-a014-a67cd6ceab0c 880495 0 2019-11-06 03:17:40 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 4e72054b-5599-43b0-8ab1-2a089f986f41 0xc007d6deb7 0xc007d6deb8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wnm8v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wnm8v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wnm8v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 03:17:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 03:17:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 03:17:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 03:17:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.114,PodIP:,StartTime:2019-11-06 03:17:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:17:40.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3958" for this suite.
Nov  6 03:17:46.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:17:46.801: INFO: namespace deployment-3958 deletion completed in 6.056173727s

• [SLOW TEST:10.384 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:17:46.801: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  6 03:17:46.843: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov  6 03:17:46.869: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov  6 03:17:51.871: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  6 03:17:51.871: INFO: Creating deployment "test-rolling-update-deployment"
Nov  6 03:17:51.874: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov  6 03:17:51.886: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov  6 03:17:53.890: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov  6 03:17:53.892: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708607071, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708607071, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708607071, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708607071, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  6 03:17:55.895: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  6 03:17:55.900: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-727 /apis/apps/v1/namespaces/deployment-727/deployments/test-rolling-update-deployment d223ae83-b261-466b-ab22-05c780b4a8f8 880606 1 2019-11-06 03:17:51 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0003828a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-11-06 03:17:51 +0000 UTC,LastTransitionTime:2019-11-06 03:17:51 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-11-06 03:17:54 +0000 UTC,LastTransitionTime:2019-11-06 03:17:51 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov  6 03:17:55.903: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-727 /apis/apps/v1/namespaces/deployment-727/replicasets/test-rolling-update-deployment-55d946486 5a23cf7a-0dbd-445c-abf7-ea36b057592f 880595 1 2019-11-06 03:17:51 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment d223ae83-b261-466b-ab22-05c780b4a8f8 0xc000383ed0 0xc000383ed1}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000383f38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  6 03:17:55.903: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov  6 03:17:55.903: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-727 /apis/apps/v1/namespaces/deployment-727/replicasets/test-rolling-update-controller 782ad5d2-9512-45de-86c6-fdd5035835d4 880605 2 2019-11-06 03:17:46 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment d223ae83-b261-466b-ab22-05c780b4a8f8 0xc000383807 0xc000383808}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc000383dd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  6 03:17:55.905: INFO: Pod "test-rolling-update-deployment-55d946486-fmcg4" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-fmcg4 test-rolling-update-deployment-55d946486- deployment-727 /api/v1/namespaces/deployment-727/pods/test-rolling-update-deployment-55d946486-fmcg4 00f30e54-c85c-4d11-bc66-a88d240ee375 880594 0 2019-11-06 03:17:51 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[cni.projectcalico.org/podIP:10.38.96.72/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 5a23cf7a-0dbd-445c-abf7-ea36b057592f 0xc002d0f5d0 0xc002d0f5d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jjv7l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jjv7l,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jjv7l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 03:17:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 03:17:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 03:17:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-06 03:17:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.114,PodIP:10.38.96.72,StartTime:2019-11-06 03:17:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-06 03:17:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://15ca5fb322d63bc8b03b3241bb41a40638844df78c69b9981b3e14809748d376,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.38.96.72,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:17:55.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-727" for this suite.
Nov  6 03:18:01.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:18:01.983: INFO: namespace deployment-727 deletion completed in 6.075159984s

• [SLOW TEST:15.181 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  6 03:18:01.983: INFO: >>> kubeConfig: /tmp/kubeconfig-720122187
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  6 03:18:18.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6393" for this suite.
Nov  6 03:18:24.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  6 03:18:24.327: INFO: namespace resourcequota-6393 deletion completed in 6.070034612s

• [SLOW TEST:22.344 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSNov  6 03:18:24.327: INFO: Running AfterSuite actions on all nodes
Nov  6 03:18:24.327: INFO: Running AfterSuite actions on node 1
Nov  6 03:18:24.327: INFO: Skipping dumping logs from cluster

Ran 276 of 4897 Specs in 7478.545 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4621 Skipped
PASS

Ginkgo ran 1 suite in 2h4m40.19931615s
Test Suite Passed
