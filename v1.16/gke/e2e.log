I0224 19:12:51.565101      17 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-651526472
I0224 19:12:51.565667      17 e2e.go:92] Starting e2e run "7595be1f-02c4-4a33-b28a-7add0be201db" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1582571569 - Will randomize all specs
Will run 276 of 4731 specs

Feb 24 19:12:51.596: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 19:12:51.600: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 24 19:12:51.765: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 24 19:12:52.107: INFO: 20 / 20 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 24 19:12:52.108: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
Feb 24 19:12:52.108: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 24 19:12:52.121: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'fluentd-gke' (0 seconds elapsed)
Feb 24 19:12:52.122: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'gke-metrics-agent' (0 seconds elapsed)
Feb 24 19:12:52.122: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'gke-metrics-agent-windows' (0 seconds elapsed)
Feb 24 19:12:52.122: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Feb 24 19:12:52.122: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'metadata-proxy-v0.1' (0 seconds elapsed)
Feb 24 19:12:52.122: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Feb 24 19:12:52.122: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'prometheus-to-sd' (0 seconds elapsed)
Feb 24 19:12:52.122: INFO: e2e test version: v1.16.4
Feb 24 19:12:52.124: INFO: kube-apiserver version: v1.16.4-gke.30
Feb 24 19:12:52.124: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 19:12:52.131: INFO: Cluster IP family: ipv4
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:12:52.133: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename subpath
Feb 24 19:12:52.272: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Feb 24 19:12:52.304: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1102
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-7qrw
STEP: Creating a pod to test atomic-volume-subpath
Feb 24 19:12:52.489: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-7qrw" in namespace "subpath-1102" to be "success or failure"
Feb 24 19:12:52.513: INFO: Pod "pod-subpath-test-configmap-7qrw": Phase="Pending", Reason="", readiness=false. Elapsed: 24.2831ms
Feb 24 19:12:54.517: INFO: Pod "pod-subpath-test-configmap-7qrw": Phase="Running", Reason="", readiness=true. Elapsed: 2.02799347s
Feb 24 19:12:56.520: INFO: Pod "pod-subpath-test-configmap-7qrw": Phase="Running", Reason="", readiness=true. Elapsed: 4.031370365s
Feb 24 19:12:58.644: INFO: Pod "pod-subpath-test-configmap-7qrw": Phase="Running", Reason="", readiness=true. Elapsed: 6.154504095s
Feb 24 19:13:00.647: INFO: Pod "pod-subpath-test-configmap-7qrw": Phase="Running", Reason="", readiness=true. Elapsed: 8.158080463s
Feb 24 19:13:02.651: INFO: Pod "pod-subpath-test-configmap-7qrw": Phase="Running", Reason="", readiness=true. Elapsed: 10.161529386s
Feb 24 19:13:04.654: INFO: Pod "pod-subpath-test-configmap-7qrw": Phase="Running", Reason="", readiness=true. Elapsed: 12.164872606s
Feb 24 19:13:06.700: INFO: Pod "pod-subpath-test-configmap-7qrw": Phase="Running", Reason="", readiness=true. Elapsed: 14.211061529s
Feb 24 19:13:08.705: INFO: Pod "pod-subpath-test-configmap-7qrw": Phase="Running", Reason="", readiness=true. Elapsed: 16.215629686s
Feb 24 19:13:10.708: INFO: Pod "pod-subpath-test-configmap-7qrw": Phase="Running", Reason="", readiness=true. Elapsed: 18.21885268s
Feb 24 19:13:12.711: INFO: Pod "pod-subpath-test-configmap-7qrw": Phase="Running", Reason="", readiness=true. Elapsed: 20.222289245s
Feb 24 19:13:14.715: INFO: Pod "pod-subpath-test-configmap-7qrw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.225852245s
STEP: Saw pod success
Feb 24 19:13:14.715: INFO: Pod "pod-subpath-test-configmap-7qrw" satisfied condition "success or failure"
Feb 24 19:13:14.718: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-subpath-test-configmap-7qrw container test-container-subpath-configmap-7qrw: <nil>
STEP: delete the pod
Feb 24 19:13:14.754: INFO: Waiting for pod pod-subpath-test-configmap-7qrw to disappear
Feb 24 19:13:14.763: INFO: Pod pod-subpath-test-configmap-7qrw no longer exists
STEP: Deleting pod pod-subpath-test-configmap-7qrw
Feb 24 19:13:14.763: INFO: Deleting pod "pod-subpath-test-configmap-7qrw" in namespace "subpath-1102"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:13:14.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1102" for this suite.
Feb 24 19:13:20.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:13:20.922: INFO: namespace subpath-1102 deletion completed in 6.151651801s

• [SLOW TEST:28.790 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:13:20.924: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1932
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-9cacac16-60a6-40eb-81d7-59b71e254afa
STEP: Creating a pod to test consume configMaps
Feb 24 19:13:21.114: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f0828790-2586-4409-9d3f-acdafc87c91f" in namespace "projected-1932" to be "success or failure"
Feb 24 19:13:21.119: INFO: Pod "pod-projected-configmaps-f0828790-2586-4409-9d3f-acdafc87c91f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.264061ms
Feb 24 19:13:23.122: INFO: Pod "pod-projected-configmaps-f0828790-2586-4409-9d3f-acdafc87c91f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008663312s
STEP: Saw pod success
Feb 24 19:13:23.123: INFO: Pod "pod-projected-configmaps-f0828790-2586-4409-9d3f-acdafc87c91f" satisfied condition "success or failure"
Feb 24 19:13:23.125: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-projected-configmaps-f0828790-2586-4409-9d3f-acdafc87c91f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 19:13:23.154: INFO: Waiting for pod pod-projected-configmaps-f0828790-2586-4409-9d3f-acdafc87c91f to disappear
Feb 24 19:13:23.159: INFO: Pod pod-projected-configmaps-f0828790-2586-4409-9d3f-acdafc87c91f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:13:23.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1932" for this suite.
Feb 24 19:13:29.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:13:29.317: INFO: namespace projected-1932 deletion completed in 6.153573498s

• [SLOW TEST:8.393 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:13:29.320: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1068
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 19:13:30.000: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 19:13:32.011: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718168409, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718168409, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718168410, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718168409, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 19:13:35.083: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
Feb 24 19:13:35.190: INFO: Waiting for webhook configuration to be ready...
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:13:35.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1068" for this suite.
Feb 24 19:13:41.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:13:41.515: INFO: namespace webhook-1068 deletion completed in 6.14203186s
STEP: Destroying namespace "webhook-1068-markers" for this suite.
Feb 24 19:13:47.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:13:47.682: INFO: namespace webhook-1068-markers deletion completed in 6.16637861s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.382 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:13:47.701: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-319
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 19:13:48.716: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 19:13:50.726: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718168428, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718168428, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718168428, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718168428, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 19:13:53.760: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 19:13:53.764: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-228-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:13:54.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-319" for this suite.
Feb 24 19:14:00.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:14:01.052: INFO: namespace webhook-319 deletion completed in 6.153274748s
STEP: Destroying namespace "webhook-319-markers" for this suite.
Feb 24 19:14:07.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:14:07.384: INFO: namespace webhook-319-markers deletion completed in 6.331776085s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.726 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:14:07.427: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4534
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-c909fe76-66c2-4a33-8fef-d4826357365e
STEP: Creating a pod to test consume secrets
Feb 24 19:14:07.728: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bcf2545c-9f2a-465b-848b-290a47d58cea" in namespace "projected-4534" to be "success or failure"
Feb 24 19:14:07.744: INFO: Pod "pod-projected-secrets-bcf2545c-9f2a-465b-848b-290a47d58cea": Phase="Pending", Reason="", readiness=false. Elapsed: 15.342615ms
Feb 24 19:14:09.747: INFO: Pod "pod-projected-secrets-bcf2545c-9f2a-465b-848b-290a47d58cea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018923312s
STEP: Saw pod success
Feb 24 19:14:09.747: INFO: Pod "pod-projected-secrets-bcf2545c-9f2a-465b-848b-290a47d58cea" satisfied condition "success or failure"
Feb 24 19:14:09.750: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-projected-secrets-bcf2545c-9f2a-465b-848b-290a47d58cea container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 24 19:14:09.774: INFO: Waiting for pod pod-projected-secrets-bcf2545c-9f2a-465b-848b-290a47d58cea to disappear
Feb 24 19:14:09.780: INFO: Pod pod-projected-secrets-bcf2545c-9f2a-465b-848b-290a47d58cea no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:14:09.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4534" for this suite.
Feb 24 19:14:15.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:14:15.957: INFO: namespace projected-4534 deletion completed in 6.172835663s

• [SLOW TEST:8.530 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:14:15.963: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-404
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-404
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-404 to expose endpoints map[]
Feb 24 19:14:16.239: INFO: successfully validated that service endpoint-test2 in namespace services-404 exposes endpoints map[] (26.244126ms elapsed)
STEP: Creating pod pod1 in namespace services-404
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-404 to expose endpoints map[pod1:[80]]
Feb 24 19:14:18.448: INFO: successfully validated that service endpoint-test2 in namespace services-404 exposes endpoints map[pod1:[80]] (2.185084406s elapsed)
STEP: Creating pod pod2 in namespace services-404
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-404 to expose endpoints map[pod1:[80] pod2:[80]]
Feb 24 19:14:20.599: INFO: successfully validated that service endpoint-test2 in namespace services-404 exposes endpoints map[pod1:[80] pod2:[80]] (2.033469848s elapsed)
STEP: Deleting pod pod1 in namespace services-404
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-404 to expose endpoints map[pod2:[80]]
Feb 24 19:14:20.633: INFO: successfully validated that service endpoint-test2 in namespace services-404 exposes endpoints map[pod2:[80]] (25.005575ms elapsed)
STEP: Deleting pod pod2 in namespace services-404
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-404 to expose endpoints map[]
Feb 24 19:14:21.748: INFO: successfully validated that service endpoint-test2 in namespace services-404 exposes endpoints map[] (1.10220686s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:14:21.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-404" for this suite.
Feb 24 19:14:34.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:14:34.180: INFO: namespace services-404 deletion completed in 12.204279019s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:18.218 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:14:34.188: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5190
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 24 19:14:34.408: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 24 19:14:34.420: INFO: Waiting for terminating namespaces to be deleted...
Feb 24 19:14:34.424: INFO: 
Logging pods the kubelet thinks is on node gke-c116p-default-pool-41de4435-50z7 before test
Feb 24 19:14:34.442: INFO: gke-metrics-agent-5hrbb from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:14:34.442: INFO: 	Container gke-metrics-agent ready: true, restart count 0
Feb 24 19:14:34.443: INFO: sonobuoy-systemd-logs-daemon-set-4d9132020e6e4914-5m24k from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 19:14:34.443: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 19:14:34.443: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 19:14:34.443: INFO: kube-dns-autoscaler-645f7d66cf-rmd2g from kube-system started at 2020-02-24 18:31:11 +0000 UTC (1 container statuses recorded)
Feb 24 19:14:34.443: INFO: 	Container autoscaler ready: true, restart count 0
Feb 24 19:14:34.444: INFO: fluentd-gke-scaler-84b9598957-hh4hk from kube-system started at 2020-02-24 18:31:11 +0000 UTC (1 container statuses recorded)
Feb 24 19:14:34.444: INFO: 	Container fluentd-gke-scaler ready: true, restart count 0
Feb 24 19:14:34.444: INFO: prometheus-to-sd-5gvqd from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:14:34.444: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:14:34.444: INFO: kube-proxy-xxnbn from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:14:34.444: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 19:14:34.445: INFO: fluentd-gke-bljn7 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (2 container statuses recorded)
Feb 24 19:14:34.445: INFO: 	Container fluentd-gke ready: true, restart count 0
Feb 24 19:14:34.445: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 19:14:34.445: INFO: kube-dns-68b499d58-t8vrp from kube-system started at 2020-02-24 18:31:11 +0000 UTC (4 container statuses recorded)
Feb 24 19:14:34.445: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 24 19:14:34.446: INFO: 	Container kubedns ready: true, restart count 0
Feb 24 19:14:34.446: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:14:34.446: INFO: 	Container sidecar ready: true, restart count 0
Feb 24 19:14:34.446: INFO: event-exporter-gke-5998887ffd-wf7jq from kube-system started at 2020-02-24 18:31:11 +0000 UTC (2 container statuses recorded)
Feb 24 19:14:34.446: INFO: 	Container event-exporter ready: true, restart count 0
Feb 24 19:14:34.446: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 19:14:34.446: INFO: l7-default-backend-678889f899-2hc4d from kube-system started at 2020-02-24 18:31:11 +0000 UTC (1 container statuses recorded)
Feb 24 19:14:34.447: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 24 19:14:34.447: INFO: 
Logging pods the kubelet thinks is on node gke-c116p-default-pool-41de4435-dz7p before test
Feb 24 19:14:34.464: INFO: prometheus-to-sd-lhjg7 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:14:34.464: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:14:34.464: INFO: gke-metrics-agent-ttjqh from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:14:34.464: INFO: 	Container gke-metrics-agent ready: true, restart count 0
Feb 24 19:14:34.464: INFO: metrics-server-v0.3.6-65d7cdc58b-rzf7x from kube-system started at 2020-02-24 18:31:26 +0000 UTC (2 container statuses recorded)
Feb 24 19:14:34.464: INFO: 	Container metrics-server ready: true, restart count 0
Feb 24 19:14:34.464: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Feb 24 19:14:34.464: INFO: sonobuoy from sonobuoy started at 2020-02-24 19:12:34 +0000 UTC (1 container statuses recorded)
Feb 24 19:14:34.464: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 24 19:14:34.465: INFO: sonobuoy-e2e-job-3461c811ccdb4a1e from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 19:14:34.465: INFO: 	Container e2e ready: true, restart count 0
Feb 24 19:14:34.465: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 19:14:34.465: INFO: sonobuoy-systemd-logs-daemon-set-4d9132020e6e4914-mxsbf from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 19:14:34.465: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 19:14:34.465: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 19:14:34.465: INFO: fluentd-gke-5zt82 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (2 container statuses recorded)
Feb 24 19:14:34.465: INFO: 	Container fluentd-gke ready: true, restart count 0
Feb 24 19:14:34.465: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 19:14:34.465: INFO: kube-proxy-zsrrm from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:14:34.465: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 19:14:34.465: INFO: stackdriver-metadata-agent-cluster-level-749b475b87-hcp6f from kube-system started at 2020-02-24 18:31:59 +0000 UTC (2 container statuses recorded)
Feb 24 19:14:34.465: INFO: 	Container metadata-agent ready: true, restart count 0
Feb 24 19:14:34.465: INFO: 	Container metadata-agent-nanny ready: true, restart count 0
Feb 24 19:14:34.465: INFO: 
Logging pods the kubelet thinks is on node gke-c116p-default-pool-41de4435-fss3 before test
Feb 24 19:14:34.475: INFO: kube-dns-68b499d58-7zjcx from kube-system started at 2020-02-24 18:31:22 +0000 UTC (4 container statuses recorded)
Feb 24 19:14:34.476: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 24 19:14:34.476: INFO: 	Container kubedns ready: true, restart count 0
Feb 24 19:14:34.476: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:14:34.476: INFO: 	Container sidecar ready: true, restart count 0
Feb 24 19:14:34.476: INFO: sonobuoy-systemd-logs-daemon-set-4d9132020e6e4914-n8lq6 from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 19:14:34.476: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 19:14:34.477: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 19:14:34.477: INFO: test-webserver-c1c23529-b996-4884-9e38-78f2ff6e3ec8 from container-probe-694 started at 2020-02-24 19:06:05 +0000 UTC (1 container statuses recorded)
Feb 24 19:14:34.477: INFO: 	Container test-webserver ready: true, restart count 0
Feb 24 19:14:34.477: INFO: gke-metrics-agent-256cx from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:14:34.477: INFO: 	Container gke-metrics-agent ready: true, restart count 0
Feb 24 19:14:34.477: INFO: prometheus-to-sd-xws82 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:14:34.478: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:14:34.478: INFO: fluentd-gke-l65zn from kube-system started at 2020-02-24 18:31:12 +0000 UTC (2 container statuses recorded)
Feb 24 19:14:34.478: INFO: 	Container fluentd-gke ready: true, restart count 0
Feb 24 19:14:34.478: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 19:14:34.478: INFO: kube-proxy-28x7v from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:14:34.479: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-437e25f0-98fb-42a3-befe-124c977afdbc 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-437e25f0-98fb-42a3-befe-124c977afdbc off the node gke-c116p-default-pool-41de4435-fss3
STEP: verifying the node doesn't have the label kubernetes.io/e2e-437e25f0-98fb-42a3-befe-124c977afdbc
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:14:38.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5190" for this suite.
Feb 24 19:14:54.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:14:54.772: INFO: namespace sched-pred-5190 deletion completed in 16.140940242s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:20.586 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:14:54.774: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2616
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 19:14:55.593: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 19:14:58.078: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718168495, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718168495, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718168495, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718168495, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 19:15:01.158: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:15:01.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2616" for this suite.
Feb 24 19:15:09.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:15:09.569: INFO: namespace webhook-2616 deletion completed in 8.155307258s
STEP: Destroying namespace "webhook-2616-markers" for this suite.
Feb 24 19:15:15.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:15:15.733: INFO: namespace webhook-2616-markers deletion completed in 6.162838127s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:20.977 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:15:15.755: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-769
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-769
I0224 19:15:15.928864      17 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-769, replica count: 1
I0224 19:15:16.979231      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0224 19:15:17.979677      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 24 19:15:18.358: INFO: Created: latency-svc-sfdqz
Feb 24 19:15:18.375: INFO: Got endpoints: latency-svc-sfdqz [295.88117ms]
Feb 24 19:15:18.403: INFO: Created: latency-svc-vwgxs
Feb 24 19:15:18.417: INFO: Created: latency-svc-lcqlw
Feb 24 19:15:18.432: INFO: Created: latency-svc-76plm
Feb 24 19:15:18.438: INFO: Got endpoints: latency-svc-vwgxs [62.025125ms]
Feb 24 19:15:18.446: INFO: Got endpoints: latency-svc-lcqlw [70.158578ms]
Feb 24 19:15:18.456: INFO: Created: latency-svc-fncqd
Feb 24 19:15:18.478: INFO: Created: latency-svc-pdpkg
Feb 24 19:15:18.480: INFO: Got endpoints: latency-svc-76plm [104.041276ms]
Feb 24 19:15:18.494: INFO: Got endpoints: latency-svc-fncqd [117.602633ms]
Feb 24 19:15:18.494: INFO: Created: latency-svc-dl8nq
Feb 24 19:15:18.499: INFO: Created: latency-svc-fdg2w
Feb 24 19:15:18.519: INFO: Got endpoints: latency-svc-pdpkg [139.326219ms]
Feb 24 19:15:18.537: INFO: Created: latency-svc-96qt8
Feb 24 19:15:18.546: INFO: Got endpoints: latency-svc-fdg2w [169.295805ms]
Feb 24 19:15:18.555: INFO: Created: latency-svc-wml4m
Feb 24 19:15:18.561: INFO: Got endpoints: latency-svc-dl8nq [184.64995ms]
Feb 24 19:15:18.585: INFO: Got endpoints: latency-svc-96qt8 [208.218692ms]
Feb 24 19:15:18.585: INFO: Created: latency-svc-5vblz
Feb 24 19:15:18.604: INFO: Got endpoints: latency-svc-wml4m [227.624372ms]
Feb 24 19:15:18.606: INFO: Created: latency-svc-b9s4t
Feb 24 19:15:18.607: INFO: Created: latency-svc-4ljzt
Feb 24 19:15:18.624: INFO: Got endpoints: latency-svc-5vblz [247.513624ms]
Feb 24 19:15:18.625: INFO: Created: latency-svc-hdbz8
Feb 24 19:15:18.625: INFO: Created: latency-svc-hcxd8
Feb 24 19:15:18.641: INFO: Got endpoints: latency-svc-b9s4t [262.558711ms]
Feb 24 19:15:18.642: INFO: Got endpoints: latency-svc-4ljzt [264.923137ms]
Feb 24 19:15:18.662: INFO: Created: latency-svc-vsr7r
Feb 24 19:15:18.672: INFO: Got endpoints: latency-svc-hdbz8 [293.248947ms]
Feb 24 19:15:18.688: INFO: Got endpoints: latency-svc-hcxd8 [309.14554ms]
Feb 24 19:15:18.689: INFO: Created: latency-svc-mjkpz
Feb 24 19:15:18.696: INFO: Got endpoints: latency-svc-vsr7r [317.129448ms]
Feb 24 19:15:18.707: INFO: Created: latency-svc-nw9j9
Feb 24 19:15:18.725: INFO: Created: latency-svc-9npc7
Feb 24 19:15:18.738: INFO: Got endpoints: latency-svc-nw9j9 [291.87487ms]
Feb 24 19:15:18.750: INFO: Created: latency-svc-t6xzn
Feb 24 19:15:18.750: INFO: Got endpoints: latency-svc-mjkpz [312.473979ms]
Feb 24 19:15:18.751: INFO: Got endpoints: latency-svc-9npc7 [270.577179ms]
Feb 24 19:15:18.775: INFO: Created: latency-svc-njbq7
Feb 24 19:15:18.795: INFO: Created: latency-svc-h84sf
Feb 24 19:15:18.799: INFO: Got endpoints: latency-svc-t6xzn [304.851045ms]
Feb 24 19:15:18.815: INFO: Got endpoints: latency-svc-njbq7 [295.835061ms]
Feb 24 19:15:18.830: INFO: Got endpoints: latency-svc-h84sf [283.511886ms]
Feb 24 19:15:18.830: INFO: Created: latency-svc-988q2
Feb 24 19:15:18.851: INFO: Created: latency-svc-cst6q
Feb 24 19:15:18.853: INFO: Created: latency-svc-bvpd4
Feb 24 19:15:18.871: INFO: Created: latency-svc-vlhj9
Feb 24 19:15:18.881: INFO: Got endpoints: latency-svc-988q2 [319.980972ms]
Feb 24 19:15:18.896: INFO: Got endpoints: latency-svc-cst6q [310.803262ms]
Feb 24 19:15:18.896: INFO: Got endpoints: latency-svc-bvpd4 [291.773873ms]
Feb 24 19:15:18.903: INFO: Created: latency-svc-ngts5
Feb 24 19:15:18.929: INFO: Created: latency-svc-7md5d
Feb 24 19:15:18.946: INFO: Created: latency-svc-8jlcf
Feb 24 19:15:18.949: INFO: Got endpoints: latency-svc-vlhj9 [324.90824ms]
Feb 24 19:15:18.950: INFO: Got endpoints: latency-svc-ngts5 [308.215367ms]
Feb 24 19:15:18.950: INFO: Got endpoints: latency-svc-7md5d [307.725903ms]
Feb 24 19:15:18.980: INFO: Created: latency-svc-7694t
Feb 24 19:15:18.984: INFO: Got endpoints: latency-svc-8jlcf [310.982216ms]
Feb 24 19:15:18.997: INFO: Created: latency-svc-ndprs
Feb 24 19:15:19.018: INFO: Created: latency-svc-mcjvw
Feb 24 19:15:19.022: INFO: Got endpoints: latency-svc-7694t [333.459177ms]
Feb 24 19:15:19.032: INFO: Got endpoints: latency-svc-ndprs [335.533607ms]
Feb 24 19:15:19.046: INFO: Created: latency-svc-vjp7b
Feb 24 19:15:19.070: INFO: Got endpoints: latency-svc-mcjvw [331.643374ms]
Feb 24 19:15:19.072: INFO: Created: latency-svc-z7wsj
Feb 24 19:15:19.095: INFO: Got endpoints: latency-svc-vjp7b [344.345433ms]
Feb 24 19:15:19.102: INFO: Created: latency-svc-xg5rz
Feb 24 19:15:19.118: INFO: Created: latency-svc-gml57
Feb 24 19:15:19.119: INFO: Created: latency-svc-f442b
Feb 24 19:15:19.121: INFO: Got endpoints: latency-svc-xg5rz [321.659949ms]
Feb 24 19:15:19.122: INFO: Got endpoints: latency-svc-z7wsj [370.975381ms]
Feb 24 19:15:19.149: INFO: Created: latency-svc-sqmlm
Feb 24 19:15:19.152: INFO: Got endpoints: latency-svc-gml57 [321.657045ms]
Feb 24 19:15:19.152: INFO: Got endpoints: latency-svc-f442b [337.135774ms]
Feb 24 19:15:19.180: INFO: Created: latency-svc-tls9l
Feb 24 19:15:19.206: INFO: Created: latency-svc-rvdzd
Feb 24 19:15:19.207: INFO: Got endpoints: latency-svc-sqmlm [325.536433ms]
Feb 24 19:15:19.225: INFO: Created: latency-svc-mk5r4
Feb 24 19:15:19.229: INFO: Got endpoints: latency-svc-tls9l [333.600979ms]
Feb 24 19:15:19.255: INFO: Created: latency-svc-q5jkk
Feb 24 19:15:19.256: INFO: Got endpoints: latency-svc-rvdzd [359.51797ms]
Feb 24 19:15:19.267: INFO: Got endpoints: latency-svc-mk5r4 [317.543707ms]
Feb 24 19:15:19.276: INFO: Created: latency-svc-qfbsc
Feb 24 19:15:19.297: INFO: Created: latency-svc-k4gb5
Feb 24 19:15:19.299: INFO: Got endpoints: latency-svc-q5jkk [348.409012ms]
Feb 24 19:15:19.323: INFO: Created: latency-svc-pnq4x
Feb 24 19:15:19.349: INFO: Created: latency-svc-zbz2h
Feb 24 19:15:19.358: INFO: Created: latency-svc-z58tp
Feb 24 19:15:19.362: INFO: Got endpoints: latency-svc-qfbsc [411.464929ms]
Feb 24 19:15:19.362: INFO: Got endpoints: latency-svc-k4gb5 [378.691672ms]
Feb 24 19:15:19.363: INFO: Got endpoints: latency-svc-pnq4x [340.960951ms]
Feb 24 19:15:19.419: INFO: Created: latency-svc-257p8
Feb 24 19:15:19.461: INFO: Got endpoints: latency-svc-zbz2h [390.98063ms]
Feb 24 19:15:19.464: INFO: Created: latency-svc-zbhcx
Feb 24 19:15:19.494: INFO: Created: latency-svc-9fcws
Feb 24 19:15:19.494: INFO: Got endpoints: latency-svc-z58tp [461.943129ms]
Feb 24 19:15:19.495: INFO: Got endpoints: latency-svc-257p8 [399.126677ms]
Feb 24 19:15:19.507: INFO: Created: latency-svc-8g48b
Feb 24 19:15:19.510: INFO: Got endpoints: latency-svc-zbhcx [388.310693ms]
Feb 24 19:15:19.521: INFO: Got endpoints: latency-svc-9fcws [399.185233ms]
Feb 24 19:15:19.540: INFO: Created: latency-svc-ggpnp
Feb 24 19:15:19.561: INFO: Created: latency-svc-ssktp
Feb 24 19:15:19.572: INFO: Got endpoints: latency-svc-8g48b [420.050989ms]
Feb 24 19:15:19.580: INFO: Got endpoints: latency-svc-ggpnp [427.58205ms]
Feb 24 19:15:19.589: INFO: Created: latency-svc-nccj6
Feb 24 19:15:19.607: INFO: Created: latency-svc-7pzcf
Feb 24 19:15:19.612: INFO: Got endpoints: latency-svc-ssktp [404.928621ms]
Feb 24 19:15:19.627: INFO: Created: latency-svc-bf96c
Feb 24 19:15:19.631: INFO: Got endpoints: latency-svc-nccj6 [401.350745ms]
Feb 24 19:15:19.649: INFO: Created: latency-svc-dnrfb
Feb 24 19:15:19.676: INFO: Created: latency-svc-x88p5
Feb 24 19:15:19.677: INFO: Got endpoints: latency-svc-7pzcf [420.355623ms]
Feb 24 19:15:19.698: INFO: Created: latency-svc-qhw7b
Feb 24 19:15:19.718: INFO: Got endpoints: latency-svc-bf96c [449.945129ms]
Feb 24 19:15:19.732: INFO: Created: latency-svc-ccpkv
Feb 24 19:15:19.779: INFO: Created: latency-svc-26bzf
Feb 24 19:15:19.824: INFO: Got endpoints: latency-svc-x88p5 [462.001242ms]
Feb 24 19:15:19.825: INFO: Got endpoints: latency-svc-dnrfb [525.298337ms]
Feb 24 19:15:19.840: INFO: Created: latency-svc-ncd7s
Feb 24 19:15:19.846: INFO: Created: latency-svc-j22w6
Feb 24 19:15:19.949: INFO: Created: latency-svc-jkgsg
Feb 24 19:15:20.003: INFO: Created: latency-svc-2ws4n
Feb 24 19:15:20.017: INFO: Got endpoints: latency-svc-qhw7b [653.424593ms]
Feb 24 19:15:20.017: INFO: Got endpoints: latency-svc-ccpkv [654.416384ms]
Feb 24 19:15:20.017: INFO: Got endpoints: latency-svc-26bzf [556.152507ms]
Feb 24 19:15:20.143: INFO: Created: latency-svc-h676r
Feb 24 19:15:20.143: INFO: Got endpoints: latency-svc-ncd7s [649.002249ms]
Feb 24 19:15:20.144: INFO: Got endpoints: latency-svc-j22w6 [649.185606ms]
Feb 24 19:15:20.173: INFO: Created: latency-svc-fz8h5
Feb 24 19:15:20.213: INFO: Got endpoints: latency-svc-jkgsg [702.550634ms]
Feb 24 19:15:20.213: INFO: Got endpoints: latency-svc-2ws4n [691.806735ms]
Feb 24 19:15:20.234: INFO: Created: latency-svc-x5j4q
Feb 24 19:15:20.279: INFO: Got endpoints: latency-svc-h676r [706.807175ms]
Feb 24 19:15:20.280: INFO: Created: latency-svc-f2jg4
Feb 24 19:15:20.328: INFO: Got endpoints: latency-svc-fz8h5 [747.552735ms]
Feb 24 19:15:20.334: INFO: Created: latency-svc-fswv8
Feb 24 19:15:20.346: INFO: Got endpoints: latency-svc-x5j4q [734.235589ms]
Feb 24 19:15:20.354: INFO: Created: latency-svc-cw6hk
Feb 24 19:15:20.374: INFO: Created: latency-svc-c26bd
Feb 24 19:15:20.379: INFO: Got endpoints: latency-svc-f2jg4 [747.967563ms]
Feb 24 19:15:20.398: INFO: Created: latency-svc-blght
Feb 24 19:15:20.398: INFO: Created: latency-svc-b44pl
Feb 24 19:15:20.478: INFO: Got endpoints: latency-svc-fswv8 [801.710724ms]
Feb 24 19:15:20.479: INFO: Created: latency-svc-72djw
Feb 24 19:15:20.479: INFO: Created: latency-svc-khkgw
Feb 24 19:15:20.565: INFO: Created: latency-svc-dvccp
Feb 24 19:15:20.573: INFO: Got endpoints: latency-svc-cw6hk [855.136358ms]
Feb 24 19:15:20.599: INFO: Got endpoints: latency-svc-c26bd [774.842176ms]
Feb 24 19:15:20.635: INFO: Created: latency-svc-rr4sh
Feb 24 19:15:20.680: INFO: Created: latency-svc-qqvbm
Feb 24 19:15:20.700: INFO: Got endpoints: latency-svc-b44pl [683.622254ms]
Feb 24 19:15:20.701: INFO: Got endpoints: latency-svc-blght [876.110306ms]
Feb 24 19:15:20.754: INFO: Got endpoints: latency-svc-khkgw [736.958675ms]
Feb 24 19:15:20.770: INFO: Created: latency-svc-nljr7
Feb 24 19:15:20.821: INFO: Created: latency-svc-6l5cm
Feb 24 19:15:20.840: INFO: Got endpoints: latency-svc-72djw [822.558056ms]
Feb 24 19:15:20.841: INFO: Got endpoints: latency-svc-dvccp [697.350086ms]
Feb 24 19:15:20.842: INFO: Got endpoints: latency-svc-rr4sh [697.35946ms]
Feb 24 19:15:20.893: INFO: Created: latency-svc-gldkz
Feb 24 19:15:20.933: INFO: Created: latency-svc-s8k97
Feb 24 19:15:20.940: INFO: Got endpoints: latency-svc-qqvbm [727.373384ms]
Feb 24 19:15:21.004: INFO: Got endpoints: latency-svc-nljr7 [790.951167ms]
Feb 24 19:15:21.010: INFO: Created: latency-svc-d695w
Feb 24 19:15:21.078: INFO: Got endpoints: latency-svc-6l5cm [798.484768ms]
Feb 24 19:15:21.093: INFO: Created: latency-svc-db5wq
Feb 24 19:15:21.141: INFO: Created: latency-svc-hfzq7
Feb 24 19:15:21.152: INFO: Got endpoints: latency-svc-gldkz [823.873215ms]
Feb 24 19:15:21.152: INFO: Got endpoints: latency-svc-s8k97 [806.027154ms]
Feb 24 19:15:21.200: INFO: Created: latency-svc-klvq2
Feb 24 19:15:21.205: INFO: Got endpoints: latency-svc-d695w [825.874909ms]
Feb 24 19:15:21.206: INFO: Created: latency-svc-wssxr
Feb 24 19:15:21.230: INFO: Got endpoints: latency-svc-db5wq [751.197856ms]
Feb 24 19:15:21.243: INFO: Created: latency-svc-rfsk8
Feb 24 19:15:21.258: INFO: Got endpoints: latency-svc-klvq2 [557.764842ms]
Feb 24 19:15:21.259: INFO: Got endpoints: latency-svc-hfzq7 [685.718882ms]
Feb 24 19:15:21.266: INFO: Created: latency-svc-2z6vm
Feb 24 19:15:21.285: INFO: Created: latency-svc-ndvll
Feb 24 19:15:21.313: INFO: Got endpoints: latency-svc-wssxr [713.632569ms]
Feb 24 19:15:21.329: INFO: Created: latency-svc-b52zp
Feb 24 19:15:21.355: INFO: Created: latency-svc-7mddv
Feb 24 19:15:21.365: INFO: Created: latency-svc-dtl6t
Feb 24 19:15:21.373: INFO: Created: latency-svc-9ppxb
Feb 24 19:15:21.374: INFO: Got endpoints: latency-svc-rfsk8 [672.832669ms]
Feb 24 19:15:21.388: INFO: Got endpoints: latency-svc-2z6vm [633.387894ms]
Feb 24 19:15:21.409: INFO: Created: latency-svc-mcq4v
Feb 24 19:15:21.423: INFO: Created: latency-svc-8j25x
Feb 24 19:15:21.430: INFO: Got endpoints: latency-svc-ndvll [589.769814ms]
Feb 24 19:15:21.469: INFO: Created: latency-svc-25dbn
Feb 24 19:15:21.482: INFO: Created: latency-svc-d7rwj
Feb 24 19:15:21.495: INFO: Created: latency-svc-vgh6q
Feb 24 19:15:21.503: INFO: Got endpoints: latency-svc-b52zp [661.434809ms]
Feb 24 19:15:21.519: INFO: Created: latency-svc-4thdv
Feb 24 19:15:21.540: INFO: Created: latency-svc-48ggm
Feb 24 19:15:21.549: INFO: Created: latency-svc-dcwrh
Feb 24 19:15:21.556: INFO: Got endpoints: latency-svc-7mddv [715.130552ms]
Feb 24 19:15:21.567: INFO: Created: latency-svc-7knmz
Feb 24 19:15:21.584: INFO: Created: latency-svc-2hzgk
Feb 24 19:15:21.592: INFO: Created: latency-svc-m6mbc
Feb 24 19:15:21.599: INFO: Got endpoints: latency-svc-dtl6t [658.595251ms]
Feb 24 19:15:21.603: INFO: Created: latency-svc-mfntp
Feb 24 19:15:21.614: INFO: Created: latency-svc-fw555
Feb 24 19:15:21.621: INFO: Got endpoints: latency-svc-9ppxb [615.908935ms]
Feb 24 19:15:21.638: INFO: Created: latency-svc-8mhsd
Feb 24 19:15:21.653: INFO: Created: latency-svc-8rwzk
Feb 24 19:15:21.731: INFO: Got endpoints: latency-svc-mcq4v [652.574509ms]
Feb 24 19:15:21.814: INFO: Got endpoints: latency-svc-8j25x [662.43675ms]
Feb 24 19:15:21.864: INFO: Got endpoints: latency-svc-25dbn [711.378728ms]
Feb 24 19:15:21.949: INFO: Got endpoints: latency-svc-d7rwj [743.640928ms]
Feb 24 19:15:22.127: INFO: Created: latency-svc-76zgh
Feb 24 19:15:22.282: INFO: Created: latency-svc-82rc6
Feb 24 19:15:22.291: INFO: Got endpoints: latency-svc-vgh6q [1.060827053s]
Feb 24 19:15:22.291: INFO: Got endpoints: latency-svc-dcwrh [977.990467ms]
Feb 24 19:15:22.292: INFO: Got endpoints: latency-svc-7knmz [917.180975ms]
Feb 24 19:15:22.301: INFO: Got endpoints: latency-svc-48ggm [1.04151913s]
Feb 24 19:15:22.302: INFO: Got endpoints: latency-svc-4thdv [1.04300449s]
Feb 24 19:15:22.534: INFO: Got endpoints: latency-svc-2hzgk [1.103421417s]
Feb 24 19:15:22.535: INFO: Got endpoints: latency-svc-mfntp [1.031183855s]
Feb 24 19:15:22.535: INFO: Got endpoints: latency-svc-fw555 [978.456716ms]
Feb 24 19:15:22.540: INFO: Got endpoints: latency-svc-m6mbc [1.15201439s]
Feb 24 19:15:22.541: INFO: Got endpoints: latency-svc-8mhsd [941.699737ms]
Feb 24 19:15:22.632: INFO: Created: latency-svc-jcwnp
Feb 24 19:15:22.834: INFO: Created: latency-svc-khvzf
Feb 24 19:15:22.909: INFO: Got endpoints: latency-svc-jcwnp [1.044340882s]
Feb 24 19:15:22.918: INFO: Created: latency-svc-4v54r
Feb 24 19:15:22.931: INFO: Got endpoints: latency-svc-82rc6 [1.116254766s]
Feb 24 19:15:22.931: INFO: Got endpoints: latency-svc-8rwzk [1.310361834s]
Feb 24 19:15:22.931: INFO: Got endpoints: latency-svc-76zgh [1.20036645s]
Feb 24 19:15:22.953: INFO: Created: latency-svc-srmbm
Feb 24 19:15:22.959: INFO: Got endpoints: latency-svc-khvzf [1.010056816s]
Feb 24 19:15:22.984: INFO: Created: latency-svc-gj2qx
Feb 24 19:15:22.985: INFO: Got endpoints: latency-svc-4v54r [694.26633ms]
Feb 24 19:15:23.034: INFO: Got endpoints: latency-svc-srmbm [732.596102ms]
Feb 24 19:15:23.045: INFO: Created: latency-svc-cfx8z
Feb 24 19:15:23.057: INFO: Created: latency-svc-6zmbs
Feb 24 19:15:23.089: INFO: Created: latency-svc-bcsfb
Feb 24 19:15:23.091: INFO: Got endpoints: latency-svc-gj2qx [799.440238ms]
Feb 24 19:15:23.092: INFO: Got endpoints: latency-svc-cfx8z [799.651927ms]
Feb 24 19:15:23.105: INFO: Created: latency-svc-ssmh9
Feb 24 19:15:23.108: INFO: Created: latency-svc-575cs
Feb 24 19:15:23.108: INFO: Got endpoints: latency-svc-6zmbs [807.236316ms]
Feb 24 19:15:23.126: INFO: Got endpoints: latency-svc-bcsfb [592.158574ms]
Feb 24 19:15:23.145: INFO: Created: latency-svc-f6694
Feb 24 19:15:23.151: INFO: Got endpoints: latency-svc-575cs [616.449532ms]
Feb 24 19:15:23.152: INFO: Got endpoints: latency-svc-ssmh9 [610.926315ms]
Feb 24 19:15:23.170: INFO: Created: latency-svc-tnm2c
Feb 24 19:15:23.180: INFO: Got endpoints: latency-svc-f6694 [645.165353ms]
Feb 24 19:15:23.191: INFO: Created: latency-svc-4sk2m
Feb 24 19:15:23.211: INFO: Got endpoints: latency-svc-tnm2c [670.603308ms]
Feb 24 19:15:23.216: INFO: Created: latency-svc-wsgm5
Feb 24 19:15:23.240: INFO: Created: latency-svc-gkr59
Feb 24 19:15:23.241: INFO: Got endpoints: latency-svc-4sk2m [332.209545ms]
Feb 24 19:15:23.261: INFO: Created: latency-svc-m4qcv
Feb 24 19:15:23.280: INFO: Created: latency-svc-jcvp8
Feb 24 19:15:23.280: INFO: Got endpoints: latency-svc-wsgm5 [349.322606ms]
Feb 24 19:15:23.281: INFO: Got endpoints: latency-svc-gkr59 [349.147061ms]
Feb 24 19:15:23.294: INFO: Created: latency-svc-627gc
Feb 24 19:15:23.309: INFO: Created: latency-svc-fv2kr
Feb 24 19:15:23.319: INFO: Got endpoints: latency-svc-m4qcv [387.587969ms]
Feb 24 19:15:23.327: INFO: Created: latency-svc-6dcxv
Feb 24 19:15:23.353: INFO: Created: latency-svc-pk559
Feb 24 19:15:23.384: INFO: Got endpoints: latency-svc-jcvp8 [424.109103ms]
Feb 24 19:15:23.389: INFO: Created: latency-svc-zkvrf
Feb 24 19:15:23.406: INFO: Created: latency-svc-t8c8h
Feb 24 19:15:23.428: INFO: Created: latency-svc-g6m7j
Feb 24 19:15:23.437: INFO: Got endpoints: latency-svc-627gc [451.514147ms]
Feb 24 19:15:23.452: INFO: Created: latency-svc-q2q4j
Feb 24 19:15:23.453: INFO: Got endpoints: latency-svc-fv2kr [417.862533ms]
Feb 24 19:15:23.474: INFO: Created: latency-svc-7lhtj
Feb 24 19:15:23.485: INFO: Created: latency-svc-r9rw2
Feb 24 19:15:23.540: INFO: Created: latency-svc-bdx5r
Feb 24 19:15:23.545: INFO: Got endpoints: latency-svc-6dcxv [453.987967ms]
Feb 24 19:15:23.556: INFO: Created: latency-svc-dc6fh
Feb 24 19:15:23.588: INFO: Got endpoints: latency-svc-pk559 [496.129973ms]
Feb 24 19:15:23.597: INFO: Created: latency-svc-rn522
Feb 24 19:15:23.597: INFO: Got endpoints: latency-svc-zkvrf [488.329884ms]
Feb 24 19:15:23.618: INFO: Created: latency-svc-sd4sl
Feb 24 19:15:23.645: INFO: Created: latency-svc-8lppr
Feb 24 19:15:23.671: INFO: Got endpoints: latency-svc-t8c8h [544.524774ms]
Feb 24 19:15:23.672: INFO: Created: latency-svc-fnkvj
Feb 24 19:15:23.688: INFO: Created: latency-svc-v8pbn
Feb 24 19:15:23.700: INFO: Created: latency-svc-psxl8
Feb 24 19:15:23.706: INFO: Got endpoints: latency-svc-g6m7j [554.177323ms]
Feb 24 19:15:23.730: INFO: Created: latency-svc-mb5fv
Feb 24 19:15:23.775: INFO: Created: latency-svc-pkkcg
Feb 24 19:15:23.813: INFO: Got endpoints: latency-svc-q2q4j [660.662985ms]
Feb 24 19:15:23.813: INFO: Created: latency-svc-phtkw
Feb 24 19:15:23.858: INFO: Created: latency-svc-krs5c
Feb 24 19:15:23.859: INFO: Got endpoints: latency-svc-r9rw2 [647.542796ms]
Feb 24 19:15:23.859: INFO: Got endpoints: latency-svc-7lhtj [678.127205ms]
Feb 24 19:15:23.913: INFO: Created: latency-svc-jhmm9
Feb 24 19:15:23.918: INFO: Got endpoints: latency-svc-dc6fh [676.885126ms]
Feb 24 19:15:23.942: INFO: Created: latency-svc-bwq9g
Feb 24 19:15:23.949: INFO: Got endpoints: latency-svc-bdx5r [668.236285ms]
Feb 24 19:15:23.973: INFO: Created: latency-svc-v4x95
Feb 24 19:15:23.978: INFO: Got endpoints: latency-svc-rn522 [697.523035ms]
Feb 24 19:15:23.987: INFO: Created: latency-svc-b8zk7
Feb 24 19:15:24.005: INFO: Created: latency-svc-dv4qz
Feb 24 19:15:24.016: INFO: Created: latency-svc-5n75d
Feb 24 19:15:24.024: INFO: Got endpoints: latency-svc-sd4sl [704.621566ms]
Feb 24 19:15:24.039: INFO: Created: latency-svc-l8ttb
Feb 24 19:15:24.082: INFO: Got endpoints: latency-svc-8lppr [698.424585ms]
Feb 24 19:15:24.117: INFO: Created: latency-svc-8f5gl
Feb 24 19:15:24.135: INFO: Got endpoints: latency-svc-fnkvj [698.113293ms]
Feb 24 19:15:24.154: INFO: Created: latency-svc-x6jbg
Feb 24 19:15:24.170: INFO: Got endpoints: latency-svc-v8pbn [716.715302ms]
Feb 24 19:15:24.193: INFO: Created: latency-svc-5p2zt
Feb 24 19:15:24.221: INFO: Got endpoints: latency-svc-psxl8 [675.980119ms]
Feb 24 19:15:24.242: INFO: Created: latency-svc-tnztd
Feb 24 19:15:24.269: INFO: Got endpoints: latency-svc-mb5fv [681.129123ms]
Feb 24 19:15:24.292: INFO: Created: latency-svc-7r74d
Feb 24 19:15:24.319: INFO: Got endpoints: latency-svc-pkkcg [721.722603ms]
Feb 24 19:15:24.354: INFO: Created: latency-svc-x6lxr
Feb 24 19:15:24.370: INFO: Got endpoints: latency-svc-phtkw [698.25574ms]
Feb 24 19:15:24.393: INFO: Created: latency-svc-mxq59
Feb 24 19:15:24.422: INFO: Got endpoints: latency-svc-krs5c [715.84676ms]
Feb 24 19:15:24.447: INFO: Created: latency-svc-7xm25
Feb 24 19:15:24.470: INFO: Got endpoints: latency-svc-jhmm9 [657.01942ms]
Feb 24 19:15:24.491: INFO: Created: latency-svc-6xg8w
Feb 24 19:15:24.519: INFO: Got endpoints: latency-svc-bwq9g [660.107322ms]
Feb 24 19:15:24.542: INFO: Created: latency-svc-pjtn5
Feb 24 19:15:24.569: INFO: Got endpoints: latency-svc-v4x95 [709.959756ms]
Feb 24 19:15:24.592: INFO: Created: latency-svc-5dfwg
Feb 24 19:15:24.621: INFO: Got endpoints: latency-svc-b8zk7 [702.301826ms]
Feb 24 19:15:24.638: INFO: Created: latency-svc-2nwz2
Feb 24 19:15:24.718: INFO: Got endpoints: latency-svc-dv4qz [768.750955ms]
Feb 24 19:15:24.797: INFO: Got endpoints: latency-svc-5n75d [818.438964ms]
Feb 24 19:15:24.798: INFO: Got endpoints: latency-svc-l8ttb [773.98455ms]
Feb 24 19:15:24.856: INFO: Created: latency-svc-xbmrw
Feb 24 19:15:24.902: INFO: Got endpoints: latency-svc-8f5gl [819.107879ms]
Feb 24 19:15:24.907: INFO: Created: latency-svc-gch4t
Feb 24 19:15:24.953: INFO: Created: latency-svc-v2mtc
Feb 24 19:15:24.961: INFO: Got endpoints: latency-svc-5p2zt [791.592279ms]
Feb 24 19:15:24.962: INFO: Got endpoints: latency-svc-x6jbg [826.536395ms]
Feb 24 19:15:24.983: INFO: Created: latency-svc-vfcwm
Feb 24 19:15:24.988: INFO: Got endpoints: latency-svc-tnztd [766.612675ms]
Feb 24 19:15:25.044: INFO: Created: latency-svc-qcmm7
Feb 24 19:15:25.060: INFO: Got endpoints: latency-svc-7r74d [791.268185ms]
Feb 24 19:15:25.063: INFO: Created: latency-svc-s7jt6
Feb 24 19:15:25.089: INFO: Got endpoints: latency-svc-x6lxr [770.356198ms]
Feb 24 19:15:25.098: INFO: Created: latency-svc-4c6p4
Feb 24 19:15:25.144: INFO: Created: latency-svc-dss9j
Feb 24 19:15:25.153: INFO: Got endpoints: latency-svc-mxq59 [783.080117ms]
Feb 24 19:15:25.158: INFO: Created: latency-svc-7wb87
Feb 24 19:15:25.171: INFO: Got endpoints: latency-svc-7xm25 [749.07492ms]
Feb 24 19:15:25.212: INFO: Created: latency-svc-kmq9q
Feb 24 19:15:25.249: INFO: Got endpoints: latency-svc-6xg8w [778.903283ms]
Feb 24 19:15:25.260: INFO: Created: latency-svc-wvbcz
Feb 24 19:15:25.280: INFO: Got endpoints: latency-svc-pjtn5 [760.823292ms]
Feb 24 19:15:25.316: INFO: Created: latency-svc-gxmc6
Feb 24 19:15:25.327: INFO: Got endpoints: latency-svc-5dfwg [756.98588ms]
Feb 24 19:15:25.361: INFO: Created: latency-svc-x2tfw
Feb 24 19:15:25.380: INFO: Got endpoints: latency-svc-2nwz2 [759.146903ms]
Feb 24 19:15:25.411: INFO: Created: latency-svc-9nlvk
Feb 24 19:15:25.430: INFO: Got endpoints: latency-svc-xbmrw [712.063024ms]
Feb 24 19:15:25.467: INFO: Created: latency-svc-5g66v
Feb 24 19:15:25.487: INFO: Got endpoints: latency-svc-gch4t [689.948199ms]
Feb 24 19:15:25.496: INFO: Created: latency-svc-l4c9g
Feb 24 19:15:25.536: INFO: Created: latency-svc-2nsnf
Feb 24 19:15:25.545: INFO: Got endpoints: latency-svc-v2mtc [746.567429ms]
Feb 24 19:15:25.570: INFO: Created: latency-svc-2x7mf
Feb 24 19:15:25.578: INFO: Got endpoints: latency-svc-vfcwm [676.115047ms]
Feb 24 19:15:25.625: INFO: Got endpoints: latency-svc-qcmm7 [663.644685ms]
Feb 24 19:15:25.631: INFO: Created: latency-svc-v49wg
Feb 24 19:15:25.661: INFO: Created: latency-svc-cxlxn
Feb 24 19:15:25.675: INFO: Got endpoints: latency-svc-s7jt6 [686.610988ms]
Feb 24 19:15:25.721: INFO: Created: latency-svc-2trvx
Feb 24 19:15:25.737: INFO: Got endpoints: latency-svc-4c6p4 [775.151526ms]
Feb 24 19:15:25.791: INFO: Created: latency-svc-5wc5f
Feb 24 19:15:25.799: INFO: Got endpoints: latency-svc-dss9j [738.344773ms]
Feb 24 19:15:25.816: INFO: Created: latency-svc-rp4td
Feb 24 19:15:25.834: INFO: Got endpoints: latency-svc-7wb87 [744.760584ms]
Feb 24 19:15:25.861: INFO: Created: latency-svc-kpjw8
Feb 24 19:15:25.870: INFO: Got endpoints: latency-svc-kmq9q [716.377806ms]
Feb 24 19:15:25.890: INFO: Created: latency-svc-vpd6r
Feb 24 19:15:25.920: INFO: Got endpoints: latency-svc-wvbcz [748.732559ms]
Feb 24 19:15:25.945: INFO: Created: latency-svc-c58j5
Feb 24 19:15:25.971: INFO: Got endpoints: latency-svc-gxmc6 [722.369011ms]
Feb 24 19:15:25.993: INFO: Created: latency-svc-fsnhs
Feb 24 19:15:26.020: INFO: Got endpoints: latency-svc-x2tfw [739.989536ms]
Feb 24 19:15:26.039: INFO: Created: latency-svc-r52p5
Feb 24 19:15:26.072: INFO: Got endpoints: latency-svc-9nlvk [744.626523ms]
Feb 24 19:15:26.094: INFO: Created: latency-svc-hxs7m
Feb 24 19:15:26.120: INFO: Got endpoints: latency-svc-5g66v [739.545706ms]
Feb 24 19:15:26.139: INFO: Created: latency-svc-fhl9v
Feb 24 19:15:26.174: INFO: Got endpoints: latency-svc-l4c9g [743.791538ms]
Feb 24 19:15:26.211: INFO: Created: latency-svc-z9dr2
Feb 24 19:15:26.232: INFO: Got endpoints: latency-svc-2nsnf [745.469487ms]
Feb 24 19:15:26.272: INFO: Got endpoints: latency-svc-2x7mf [727.263585ms]
Feb 24 19:15:26.318: INFO: Got endpoints: latency-svc-v49wg [739.797912ms]
Feb 24 19:15:26.371: INFO: Got endpoints: latency-svc-cxlxn [746.016801ms]
Feb 24 19:15:26.422: INFO: Got endpoints: latency-svc-2trvx [747.034116ms]
Feb 24 19:15:26.469: INFO: Got endpoints: latency-svc-5wc5f [731.319047ms]
Feb 24 19:15:26.521: INFO: Got endpoints: latency-svc-rp4td [722.209303ms]
Feb 24 19:15:26.571: INFO: Got endpoints: latency-svc-kpjw8 [736.619154ms]
Feb 24 19:15:26.621: INFO: Got endpoints: latency-svc-vpd6r [750.845959ms]
Feb 24 19:15:26.693: INFO: Got endpoints: latency-svc-c58j5 [772.388229ms]
Feb 24 19:15:26.721: INFO: Got endpoints: latency-svc-fsnhs [749.477782ms]
Feb 24 19:15:26.776: INFO: Got endpoints: latency-svc-r52p5 [756.355961ms]
Feb 24 19:15:26.826: INFO: Got endpoints: latency-svc-hxs7m [753.613649ms]
Feb 24 19:15:26.879: INFO: Got endpoints: latency-svc-fhl9v [758.676929ms]
Feb 24 19:15:26.928: INFO: Got endpoints: latency-svc-z9dr2 [753.253975ms]
Feb 24 19:15:26.928: INFO: Latencies: [62.025125ms 70.158578ms 104.041276ms 117.602633ms 139.326219ms 169.295805ms 184.64995ms 208.218692ms 227.624372ms 247.513624ms 262.558711ms 264.923137ms 270.577179ms 283.511886ms 291.773873ms 291.87487ms 293.248947ms 295.835061ms 304.851045ms 307.725903ms 308.215367ms 309.14554ms 310.803262ms 310.982216ms 312.473979ms 317.129448ms 317.543707ms 319.980972ms 321.657045ms 321.659949ms 324.90824ms 325.536433ms 331.643374ms 332.209545ms 333.459177ms 333.600979ms 335.533607ms 337.135774ms 340.960951ms 344.345433ms 348.409012ms 349.147061ms 349.322606ms 359.51797ms 370.975381ms 378.691672ms 387.587969ms 388.310693ms 390.98063ms 399.126677ms 399.185233ms 401.350745ms 404.928621ms 411.464929ms 417.862533ms 420.050989ms 420.355623ms 424.109103ms 427.58205ms 449.945129ms 451.514147ms 453.987967ms 461.943129ms 462.001242ms 488.329884ms 496.129973ms 525.298337ms 544.524774ms 554.177323ms 556.152507ms 557.764842ms 589.769814ms 592.158574ms 610.926315ms 615.908935ms 616.449532ms 633.387894ms 645.165353ms 647.542796ms 649.002249ms 649.185606ms 652.574509ms 653.424593ms 654.416384ms 657.01942ms 658.595251ms 660.107322ms 660.662985ms 661.434809ms 662.43675ms 663.644685ms 668.236285ms 670.603308ms 672.832669ms 675.980119ms 676.115047ms 676.885126ms 678.127205ms 681.129123ms 683.622254ms 685.718882ms 686.610988ms 689.948199ms 691.806735ms 694.26633ms 697.350086ms 697.35946ms 697.523035ms 698.113293ms 698.25574ms 698.424585ms 702.301826ms 702.550634ms 704.621566ms 706.807175ms 709.959756ms 711.378728ms 712.063024ms 713.632569ms 715.130552ms 715.84676ms 716.377806ms 716.715302ms 721.722603ms 722.209303ms 722.369011ms 727.263585ms 727.373384ms 731.319047ms 732.596102ms 734.235589ms 736.619154ms 736.958675ms 738.344773ms 739.545706ms 739.797912ms 739.989536ms 743.640928ms 743.791538ms 744.626523ms 744.760584ms 745.469487ms 746.016801ms 746.567429ms 747.034116ms 747.552735ms 747.967563ms 748.732559ms 749.07492ms 749.477782ms 750.845959ms 751.197856ms 753.253975ms 753.613649ms 756.355961ms 756.98588ms 758.676929ms 759.146903ms 760.823292ms 766.612675ms 768.750955ms 770.356198ms 772.388229ms 773.98455ms 774.842176ms 775.151526ms 778.903283ms 783.080117ms 790.951167ms 791.268185ms 791.592279ms 798.484768ms 799.440238ms 799.651927ms 801.710724ms 806.027154ms 807.236316ms 818.438964ms 819.107879ms 822.558056ms 823.873215ms 825.874909ms 826.536395ms 855.136358ms 876.110306ms 917.180975ms 941.699737ms 977.990467ms 978.456716ms 1.010056816s 1.031183855s 1.04151913s 1.04300449s 1.044340882s 1.060827053s 1.103421417s 1.116254766s 1.15201439s 1.20036645s 1.310361834s]
Feb 24 19:15:26.928: INFO: 50 %ile: 685.718882ms
Feb 24 19:15:26.928: INFO: 90 %ile: 823.873215ms
Feb 24 19:15:26.929: INFO: 99 %ile: 1.20036645s
Feb 24 19:15:26.929: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:15:26.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-769" for this suite.
Feb 24 19:15:42.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:15:43.134: INFO: namespace svc-latency-769 deletion completed in 16.192415299s

• [SLOW TEST:27.379 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:15:43.137: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1249
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-6bf14d1f-cc36-4d18-b3c0-ba8e176a9d1e
STEP: Creating a pod to test consume secrets
Feb 24 19:15:43.322: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-29dbe598-3e85-4451-b41e-821bf99c0b3e" in namespace "projected-1249" to be "success or failure"
Feb 24 19:15:43.346: INFO: Pod "pod-projected-secrets-29dbe598-3e85-4451-b41e-821bf99c0b3e": Phase="Pending", Reason="", readiness=false. Elapsed: 24.308395ms
Feb 24 19:15:45.350: INFO: Pod "pod-projected-secrets-29dbe598-3e85-4451-b41e-821bf99c0b3e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027821831s
STEP: Saw pod success
Feb 24 19:15:45.350: INFO: Pod "pod-projected-secrets-29dbe598-3e85-4451-b41e-821bf99c0b3e" satisfied condition "success or failure"
Feb 24 19:15:45.355: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-projected-secrets-29dbe598-3e85-4451-b41e-821bf99c0b3e container secret-volume-test: <nil>
STEP: delete the pod
Feb 24 19:15:45.381: INFO: Waiting for pod pod-projected-secrets-29dbe598-3e85-4451-b41e-821bf99c0b3e to disappear
Feb 24 19:15:45.386: INFO: Pod pod-projected-secrets-29dbe598-3e85-4451-b41e-821bf99c0b3e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:15:45.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1249" for this suite.
Feb 24 19:15:51.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:15:51.992: INFO: namespace projected-1249 deletion completed in 6.602122732s

• [SLOW TEST:8.856 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:15:52.001: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-9687
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Feb 24 19:15:52.334: INFO: Waiting up to 1m0s for all nodes to be ready
Feb 24 19:16:52.385: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 19:16:52.389: INFO: Starting informer...
STEP: Starting pod...
Feb 24 19:16:52.639: INFO: Pod is running on gke-c116p-default-pool-41de4435-fss3. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Feb 24 19:16:52.670: INFO: Pod wasn't evicted. Proceeding
Feb 24 19:16:52.670: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Feb 24 19:18:07.832: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:18:07.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-9687" for this suite.
Feb 24 19:18:19.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:18:20.094: INFO: namespace taint-single-pod-9687 deletion completed in 12.255953307s

• [SLOW TEST:148.093 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:18:20.095: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3322
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-3322
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-3322
STEP: creating replication controller externalsvc in namespace services-3322
I0224 19:18:20.359753      17 runners.go:184] Created replication controller with name: externalsvc, namespace: services-3322, replica count: 2
I0224 19:18:23.410549      17 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Feb 24 19:18:23.429: INFO: Creating new exec pod
Feb 24 19:18:25.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-3322 execpodgn8bd -- /bin/sh -x -c nslookup nodeport-service'
Feb 24 19:18:25.943: INFO: stderr: "+ nslookup nodeport-service\n"
Feb 24 19:18:25.943: INFO: stdout: "Server:\t\t10.77.0.10\nAddress:\t10.77.0.10#53\n\nnodeport-service.services-3322.svc.cluster.local\tcanonical name = externalsvc.services-3322.svc.cluster.local.\nName:\texternalsvc.services-3322.svc.cluster.local\nAddress: 10.77.14.192\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-3322, will wait for the garbage collector to delete the pods
Feb 24 19:18:26.006: INFO: Deleting ReplicationController externalsvc took: 8.812904ms
Feb 24 19:18:26.507: INFO: Terminating ReplicationController externalsvc pods took: 500.43067ms
Feb 24 19:18:40.852: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:18:40.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3322" for this suite.
Feb 24 19:18:46.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:18:47.057: INFO: namespace services-3322 deletion completed in 6.158738069s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:26.963 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:18:47.062: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9311
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0224 19:19:17.777105      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 24 19:19:17.777: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:19:17.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9311" for this suite.
Feb 24 19:19:23.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:19:23.938: INFO: namespace gc-9311 deletion completed in 6.157804593s

• [SLOW TEST:36.877 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:19:23.944: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2288
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 19:19:24.103: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb 24 19:19:27.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-2288 create -f -'
Feb 24 19:19:28.522: INFO: stderr: ""
Feb 24 19:19:28.522: INFO: stdout: "e2e-test-crd-publish-openapi-1-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Feb 24 19:19:28.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-2288 delete e2e-test-crd-publish-openapi-1-crds test-cr'
Feb 24 19:19:28.626: INFO: stderr: ""
Feb 24 19:19:28.626: INFO: stdout: "e2e-test-crd-publish-openapi-1-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Feb 24 19:19:28.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-2288 apply -f -'
Feb 24 19:19:28.842: INFO: stderr: ""
Feb 24 19:19:28.842: INFO: stdout: "e2e-test-crd-publish-openapi-1-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Feb 24 19:19:28.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-2288 delete e2e-test-crd-publish-openapi-1-crds test-cr'
Feb 24 19:19:28.950: INFO: stderr: ""
Feb 24 19:19:28.950: INFO: stdout: "e2e-test-crd-publish-openapi-1-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Feb 24 19:19:28.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 explain e2e-test-crd-publish-openapi-1-crds'
Feb 24 19:19:29.158: INFO: stderr: ""
Feb 24 19:19:29.158: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:19:32.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2288" for this suite.
Feb 24 19:19:38.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:19:39.366: INFO: namespace crd-publish-openapi-2288 deletion completed in 6.433268374s

• [SLOW TEST:15.423 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:19:39.369: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5812
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 19:19:39.543: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 24 19:19:44.547: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 24 19:19:44.547: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 24 19:19:44.580: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-5812 /apis/apps/v1/namespaces/deployment-5812/deployments/test-cleanup-deployment 9ae3f732-b256-46ec-879e-6e9baae6d1b0 17634 1 2020-02-24 19:19:44 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004dc2398 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Feb 24 19:19:44.592: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-5812 /apis/apps/v1/namespaces/deployment-5812/replicasets/test-cleanup-deployment-65db99849b d677a0e3-aa5d-41aa-8e3f-58118a106b00 17636 1 2020-02-24 19:19:44 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 9ae3f732-b256-46ec-879e-6e9baae6d1b0 0xc004dc2867 0xc004dc2868}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004dc28c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 24 19:19:44.592: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Feb 24 19:19:44.592: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-5812 /apis/apps/v1/namespaces/deployment-5812/replicasets/test-cleanup-controller 4a2571c6-2b5d-4092-baa7-49450c05963c 17635 1 2020-02-24 19:19:39 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 9ae3f732-b256-46ec-879e-6e9baae6d1b0 0xc004dc2787 0xc004dc2788}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004dc27e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 24 19:19:44.601: INFO: Pod "test-cleanup-controller-dz7hz" is available:
&Pod{ObjectMeta:{test-cleanup-controller-dz7hz test-cleanup-controller- deployment-5812 /api/v1/namespaces/deployment-5812/pods/test-cleanup-controller-dz7hz 413a2b12-b3bf-4a08-ab93-9d93375c0257 17620 0 2020-02-24 19:19:39 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 4a2571c6-2b5d-4092-baa7-49450c05963c 0xc004dc2d77 0xc004dc2d78}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-5qlwb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-5qlwb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-5qlwb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-fss3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 19:19:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 19:19:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 19:19:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 19:19:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.2,PodIP:10.12.0.65,StartTime:2020-02-24 19:19:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 19:19:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://033fa118e284ecfc4ee9318e72d3f13129b179f3e45071b5ff0cf3ff1cc2db05,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.12.0.65,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:19:44.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5812" for this suite.
Feb 24 19:19:50.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:19:50.757: INFO: namespace deployment-5812 deletion completed in 6.15063216s

• [SLOW TEST:11.388 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:19:50.758: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7515
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 19:19:50.992: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Feb 24 19:19:53.089: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:19:53.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7515" for this suite.
Feb 24 19:19:59.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:19:59.253: INFO: namespace replication-controller-7515 deletion completed in 6.150738216s

• [SLOW TEST:8.495 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:19:59.258: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7657
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-7657/configmap-test-9d2e0ffb-5534-4461-b1e9-9a6645aab1ee
STEP: Creating a pod to test consume configMaps
Feb 24 19:19:59.436: INFO: Waiting up to 5m0s for pod "pod-configmaps-63f3f4af-2a2c-49ea-85ec-c647788e49bc" in namespace "configmap-7657" to be "success or failure"
Feb 24 19:19:59.439: INFO: Pod "pod-configmaps-63f3f4af-2a2c-49ea-85ec-c647788e49bc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.254605ms
Feb 24 19:20:01.442: INFO: Pod "pod-configmaps-63f3f4af-2a2c-49ea-85ec-c647788e49bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006274965s
STEP: Saw pod success
Feb 24 19:20:01.443: INFO: Pod "pod-configmaps-63f3f4af-2a2c-49ea-85ec-c647788e49bc" satisfied condition "success or failure"
Feb 24 19:20:01.446: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-configmaps-63f3f4af-2a2c-49ea-85ec-c647788e49bc container env-test: <nil>
STEP: delete the pod
Feb 24 19:20:01.491: INFO: Waiting for pod pod-configmaps-63f3f4af-2a2c-49ea-85ec-c647788e49bc to disappear
Feb 24 19:20:01.496: INFO: Pod pod-configmaps-63f3f4af-2a2c-49ea-85ec-c647788e49bc no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:20:01.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7657" for this suite.
Feb 24 19:20:07.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:20:07.816: INFO: namespace configmap-7657 deletion completed in 6.312586256s

• [SLOW TEST:8.559 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:20:07.819: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-182
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Feb 24 19:20:12.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec pod-sharedvolume-6fbe1cf5-18bb-493e-a03d-65beca985a6e -c busybox-main-container --namespace=emptydir-182 -- cat /usr/share/volumeshare/shareddata.txt'
Feb 24 19:20:12.403: INFO: stderr: ""
Feb 24 19:20:12.403: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:20:12.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-182" for this suite.
Feb 24 19:20:18.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:20:19.395: INFO: namespace emptydir-182 deletion completed in 6.988009432s

• [SLOW TEST:11.577 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:20:19.398: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-61
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-61.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-61.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-61.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-61.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-61.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-61.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 24 19:20:33.738: INFO: DNS probes using dns-61/dns-test-80b0c700-48be-4bb0-850b-47261fdb345d succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:20:33.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-61" for this suite.
Feb 24 19:20:39.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:20:40.140: INFO: namespace dns-61 deletion completed in 6.187873518s

• [SLOW TEST:20.743 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:20:40.145: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-498
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 24 19:20:40.311: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-498 /api/v1/namespaces/watch-498/configmaps/e2e-watch-test-label-changed cbe69f3e-b2bc-4230-bff5-2872c494d4c3 18035 0 2020-02-24 19:20:40 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 24 19:20:40.311: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-498 /api/v1/namespaces/watch-498/configmaps/e2e-watch-test-label-changed cbe69f3e-b2bc-4230-bff5-2872c494d4c3 18036 0 2020-02-24 19:20:40 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 24 19:20:40.311: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-498 /api/v1/namespaces/watch-498/configmaps/e2e-watch-test-label-changed cbe69f3e-b2bc-4230-bff5-2872c494d4c3 18037 0 2020-02-24 19:20:40 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 24 19:20:50.341: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-498 /api/v1/namespaces/watch-498/configmaps/e2e-watch-test-label-changed cbe69f3e-b2bc-4230-bff5-2872c494d4c3 18080 0 2020-02-24 19:20:40 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 24 19:20:50.342: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-498 /api/v1/namespaces/watch-498/configmaps/e2e-watch-test-label-changed cbe69f3e-b2bc-4230-bff5-2872c494d4c3 18081 0 2020-02-24 19:20:40 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 24 19:20:50.342: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-498 /api/v1/namespaces/watch-498/configmaps/e2e-watch-test-label-changed cbe69f3e-b2bc-4230-bff5-2872c494d4c3 18082 0 2020-02-24 19:20:40 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:20:50.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-498" for this suite.
Feb 24 19:20:56.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:20:56.498: INFO: namespace watch-498 deletion completed in 6.149308169s

• [SLOW TEST:16.354 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:20:56.506: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4307
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 24 19:20:56.693: INFO: Number of nodes with available pods: 0
Feb 24 19:20:56.694: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:20:57.911: INFO: Number of nodes with available pods: 0
Feb 24 19:20:57.911: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:20:58.704: INFO: Number of nodes with available pods: 1
Feb 24 19:20:58.704: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:20:59.701: INFO: Number of nodes with available pods: 3
Feb 24 19:20:59.701: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 24 19:20:59.752: INFO: Number of nodes with available pods: 3
Feb 24 19:20:59.753: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4307, will wait for the garbage collector to delete the pods
Feb 24 19:21:00.865: INFO: Deleting DaemonSet.extensions daemon-set took: 10.15328ms
Feb 24 19:21:01.366: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.377536ms
Feb 24 19:21:10.369: INFO: Number of nodes with available pods: 0
Feb 24 19:21:10.370: INFO: Number of running nodes: 0, number of available pods: 0
Feb 24 19:21:10.373: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4307/daemonsets","resourceVersion":"18248"},"items":null}

Feb 24 19:21:10.377: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4307/pods","resourceVersion":"18248"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:21:10.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4307" for this suite.
Feb 24 19:21:16.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:21:16.541: INFO: namespace daemonsets-4307 deletion completed in 6.145931583s

• [SLOW TEST:20.035 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:21:16.547: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7043
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:21:18.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7043" for this suite.
Feb 24 19:21:32.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:21:32.983: INFO: namespace containers-7043 deletion completed in 14.188151998s

• [SLOW TEST:16.437 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:21:32.994: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7313
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-7deaf4dd-df3b-40e7-971d-747d6eb580d7
Feb 24 19:21:33.188: INFO: Pod name my-hostname-basic-7deaf4dd-df3b-40e7-971d-747d6eb580d7: Found 0 pods out of 1
Feb 24 19:21:38.193: INFO: Pod name my-hostname-basic-7deaf4dd-df3b-40e7-971d-747d6eb580d7: Found 1 pods out of 1
Feb 24 19:21:38.193: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-7deaf4dd-df3b-40e7-971d-747d6eb580d7" are running
Feb 24 19:21:38.195: INFO: Pod "my-hostname-basic-7deaf4dd-df3b-40e7-971d-747d6eb580d7-f4gjr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-24 19:21:33 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-24 19:21:34 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-24 19:21:34 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-24 19:21:33 +0000 UTC Reason: Message:}])
Feb 24 19:21:38.196: INFO: Trying to dial the pod
Feb 24 19:21:43.210: INFO: Controller my-hostname-basic-7deaf4dd-df3b-40e7-971d-747d6eb580d7: Got expected result from replica 1 [my-hostname-basic-7deaf4dd-df3b-40e7-971d-747d6eb580d7-f4gjr]: "my-hostname-basic-7deaf4dd-df3b-40e7-971d-747d6eb580d7-f4gjr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:21:43.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7313" for this suite.
Feb 24 19:21:51.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:21:51.368: INFO: namespace replication-controller-7313 deletion completed in 8.154173169s

• [SLOW TEST:18.374 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:21:51.374: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4022
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-4022
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-4022
I0224 19:21:51.711133      17 runners.go:184] Created replication controller with name: externalname-service, namespace: services-4022, replica count: 2
I0224 19:21:54.761900      17 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 24 19:21:54.762: INFO: Creating new exec pod
Feb 24 19:21:57.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-4022 execpod8v52j -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Feb 24 19:21:59.116: INFO: rc: 1
Feb 24 19:21:59.116: INFO: Service reachability failing with error: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-4022 execpod8v52j -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80] []  <nil>  + nc -zv -t -w 2 externalname-service 80
nc: connect to externalname-service port 80 (tcp) failed: Connection refused
command terminated with exit code 1
 [] <nil> 0xc002ae4090 exit status 1 <nil> <nil> true [0xc005603820 0xc005603838 0xc005603850] [0xc005603820 0xc005603838 0xc005603850] [0xc005603830 0xc005603848] [0x10efe30 0x10efe30] 0xc001bd13e0 <nil>}:
Command stdout:

stderr:
+ nc -zv -t -w 2 externalname-service 80
nc: connect to externalname-service port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Feb 24 19:22:00.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-4022 execpod8v52j -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Feb 24 19:22:01.421: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Feb 24 19:22:01.421: INFO: stdout: ""
Feb 24 19:22:01.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-4022 execpod8v52j -- /bin/sh -x -c nc -zv -t -w 2 10.77.3.4 80'
Feb 24 19:22:01.742: INFO: stderr: "+ nc -zv -t -w 2 10.77.3.4 80\nConnection to 10.77.3.4 80 port [tcp/http] succeeded!\n"
Feb 24 19:22:01.742: INFO: stdout: ""
Feb 24 19:22:01.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-4022 execpod8v52j -- /bin/sh -x -c nc -zv -t -w 2 10.77.32.3 31160'
Feb 24 19:22:02.005: INFO: stderr: "+ nc -zv -t -w 2 10.77.32.3 31160\nConnection to 10.77.32.3 31160 port [tcp/31160] succeeded!\n"
Feb 24 19:22:02.005: INFO: stdout: ""
Feb 24 19:22:02.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-4022 execpod8v52j -- /bin/sh -x -c nc -zv -t -w 2 10.77.32.4 31160'
Feb 24 19:22:02.282: INFO: stderr: "+ nc -zv -t -w 2 10.77.32.4 31160\nConnection to 10.77.32.4 31160 port [tcp/31160] succeeded!\n"
Feb 24 19:22:02.282: INFO: stdout: ""
Feb 24 19:22:02.282: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:22:02.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4022" for this suite.
Feb 24 19:22:08.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:22:08.462: INFO: namespace services-4022 deletion completed in 6.150887952s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:17.089 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:22:08.468: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1963
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 24 19:22:08.626: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1963 /api/v1/namespaces/watch-1963/configmaps/e2e-watch-test-configmap-a 8590618a-cac8-4f6a-ad7e-6176c3f282b1 18657 0 2020-02-24 19:22:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 24 19:22:08.626: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1963 /api/v1/namespaces/watch-1963/configmaps/e2e-watch-test-configmap-a 8590618a-cac8-4f6a-ad7e-6176c3f282b1 18657 0 2020-02-24 19:22:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 24 19:22:18.647: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1963 /api/v1/namespaces/watch-1963/configmaps/e2e-watch-test-configmap-a 8590618a-cac8-4f6a-ad7e-6176c3f282b1 18700 0 2020-02-24 19:22:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 24 19:22:18.647: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1963 /api/v1/namespaces/watch-1963/configmaps/e2e-watch-test-configmap-a 8590618a-cac8-4f6a-ad7e-6176c3f282b1 18700 0 2020-02-24 19:22:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 24 19:22:28.656: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1963 /api/v1/namespaces/watch-1963/configmaps/e2e-watch-test-configmap-a 8590618a-cac8-4f6a-ad7e-6176c3f282b1 18744 0 2020-02-24 19:22:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 24 19:22:28.657: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1963 /api/v1/namespaces/watch-1963/configmaps/e2e-watch-test-configmap-a 8590618a-cac8-4f6a-ad7e-6176c3f282b1 18744 0 2020-02-24 19:22:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 24 19:22:38.671: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1963 /api/v1/namespaces/watch-1963/configmaps/e2e-watch-test-configmap-a 8590618a-cac8-4f6a-ad7e-6176c3f282b1 18785 0 2020-02-24 19:22:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 24 19:22:38.671: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1963 /api/v1/namespaces/watch-1963/configmaps/e2e-watch-test-configmap-a 8590618a-cac8-4f6a-ad7e-6176c3f282b1 18785 0 2020-02-24 19:22:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 24 19:22:48.677: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1963 /api/v1/namespaces/watch-1963/configmaps/e2e-watch-test-configmap-b 423d5bc8-9add-428e-83df-634b63e7f407 18830 0 2020-02-24 19:22:48 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 24 19:22:48.677: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1963 /api/v1/namespaces/watch-1963/configmaps/e2e-watch-test-configmap-b 423d5bc8-9add-428e-83df-634b63e7f407 18830 0 2020-02-24 19:22:48 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 24 19:22:58.729: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1963 /api/v1/namespaces/watch-1963/configmaps/e2e-watch-test-configmap-b 423d5bc8-9add-428e-83df-634b63e7f407 18872 0 2020-02-24 19:22:48 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 24 19:22:58.729: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1963 /api/v1/namespaces/watch-1963/configmaps/e2e-watch-test-configmap-b 423d5bc8-9add-428e-83df-634b63e7f407 18872 0 2020-02-24 19:22:48 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:23:08.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1963" for this suite.
Feb 24 19:23:14.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:23:14.901: INFO: namespace watch-1963 deletion completed in 6.167200156s

• [SLOW TEST:66.433 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:23:14.907: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4214
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb 24 19:23:17.621: INFO: Successfully updated pod "labelsupdate15cab01c-8973-4ca6-a078-ff18b5817ddb"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:23:19.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4214" for this suite.
Feb 24 19:23:31.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:23:31.861: INFO: namespace projected-4214 deletion completed in 12.219487998s

• [SLOW TEST:16.955 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:23:31.867: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-3781
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 19:23:32.091: INFO: Creating ReplicaSet my-hostname-basic-f0d9d0dc-2287-4c85-b08c-a1e945899b3d
Feb 24 19:23:32.122: INFO: Pod name my-hostname-basic-f0d9d0dc-2287-4c85-b08c-a1e945899b3d: Found 0 pods out of 1
Feb 24 19:23:37.129: INFO: Pod name my-hostname-basic-f0d9d0dc-2287-4c85-b08c-a1e945899b3d: Found 1 pods out of 1
Feb 24 19:23:37.129: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-f0d9d0dc-2287-4c85-b08c-a1e945899b3d" is running
Feb 24 19:23:37.138: INFO: Pod "my-hostname-basic-f0d9d0dc-2287-4c85-b08c-a1e945899b3d-lds4r" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-24 19:23:32 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-24 19:23:34 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-24 19:23:34 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-24 19:23:32 +0000 UTC Reason: Message:}])
Feb 24 19:23:37.138: INFO: Trying to dial the pod
Feb 24 19:23:42.153: INFO: Controller my-hostname-basic-f0d9d0dc-2287-4c85-b08c-a1e945899b3d: Got expected result from replica 1 [my-hostname-basic-f0d9d0dc-2287-4c85-b08c-a1e945899b3d-lds4r]: "my-hostname-basic-f0d9d0dc-2287-4c85-b08c-a1e945899b3d-lds4r", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:23:42.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3781" for this suite.
Feb 24 19:23:48.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:23:48.557: INFO: namespace replicaset-3781 deletion completed in 6.400040695s

• [SLOW TEST:16.690 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:23:48.568: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2547
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Feb 24 19:23:48.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 create -f - --namespace=kubectl-2547'
Feb 24 19:23:49.294: INFO: stderr: ""
Feb 24 19:23:49.294: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 24 19:23:49.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2547'
Feb 24 19:23:49.464: INFO: stderr: ""
Feb 24 19:23:49.464: INFO: stdout: "update-demo-nautilus-f8cl5 update-demo-nautilus-zq4bh "
Feb 24 19:23:49.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-f8cl5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2547'
Feb 24 19:23:49.601: INFO: stderr: ""
Feb 24 19:23:49.601: INFO: stdout: ""
Feb 24 19:23:49.601: INFO: update-demo-nautilus-f8cl5 is created but not running
Feb 24 19:23:54.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2547'
Feb 24 19:23:54.719: INFO: stderr: ""
Feb 24 19:23:54.720: INFO: stdout: "update-demo-nautilus-f8cl5 update-demo-nautilus-zq4bh "
Feb 24 19:23:54.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-f8cl5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2547'
Feb 24 19:23:54.864: INFO: stderr: ""
Feb 24 19:23:54.864: INFO: stdout: "true"
Feb 24 19:23:54.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-f8cl5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2547'
Feb 24 19:23:54.960: INFO: stderr: ""
Feb 24 19:23:54.960: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 24 19:23:54.960: INFO: validating pod update-demo-nautilus-f8cl5
Feb 24 19:23:54.969: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 24 19:23:54.969: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 24 19:23:54.969: INFO: update-demo-nautilus-f8cl5 is verified up and running
Feb 24 19:23:54.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-zq4bh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2547'
Feb 24 19:23:55.061: INFO: stderr: ""
Feb 24 19:23:55.061: INFO: stdout: "true"
Feb 24 19:23:55.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-zq4bh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2547'
Feb 24 19:23:55.151: INFO: stderr: ""
Feb 24 19:23:55.151: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 24 19:23:55.151: INFO: validating pod update-demo-nautilus-zq4bh
Feb 24 19:23:55.158: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 24 19:23:55.158: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 24 19:23:55.158: INFO: update-demo-nautilus-zq4bh is verified up and running
STEP: using delete to clean up resources
Feb 24 19:23:55.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 delete --grace-period=0 --force -f - --namespace=kubectl-2547'
Feb 24 19:23:55.258: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 24 19:23:55.258: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 24 19:23:55.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2547'
Feb 24 19:23:55.400: INFO: stderr: "No resources found in kubectl-2547 namespace.\n"
Feb 24 19:23:55.400: INFO: stdout: ""
Feb 24 19:23:55.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods -l name=update-demo --namespace=kubectl-2547 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 24 19:23:55.499: INFO: stderr: ""
Feb 24 19:23:55.499: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:23:55.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2547" for this suite.
Feb 24 19:24:01.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:24:01.651: INFO: namespace kubectl-2547 deletion completed in 6.147139783s

• [SLOW TEST:13.083 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:24:01.656: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1172
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-aea5e8f9-b141-49dc-87be-861c0a4b914f
STEP: Creating a pod to test consume configMaps
Feb 24 19:24:01.832: INFO: Waiting up to 5m0s for pod "pod-configmaps-6486d2a1-cdd6-4204-8b64-777f4ad427ad" in namespace "configmap-1172" to be "success or failure"
Feb 24 19:24:01.853: INFO: Pod "pod-configmaps-6486d2a1-cdd6-4204-8b64-777f4ad427ad": Phase="Pending", Reason="", readiness=false. Elapsed: 20.554236ms
Feb 24 19:24:03.892: INFO: Pod "pod-configmaps-6486d2a1-cdd6-4204-8b64-777f4ad427ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059971298s
Feb 24 19:24:05.896: INFO: Pod "pod-configmaps-6486d2a1-cdd6-4204-8b64-777f4ad427ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063682528s
STEP: Saw pod success
Feb 24 19:24:05.896: INFO: Pod "pod-configmaps-6486d2a1-cdd6-4204-8b64-777f4ad427ad" satisfied condition "success or failure"
Feb 24 19:24:05.900: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-configmaps-6486d2a1-cdd6-4204-8b64-777f4ad427ad container configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 19:24:05.935: INFO: Waiting for pod pod-configmaps-6486d2a1-cdd6-4204-8b64-777f4ad427ad to disappear
Feb 24 19:24:05.942: INFO: Pod pod-configmaps-6486d2a1-cdd6-4204-8b64-777f4ad427ad no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:24:05.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1172" for this suite.
Feb 24 19:24:11.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:24:12.236: INFO: namespace configmap-1172 deletion completed in 6.287958709s

• [SLOW TEST:10.581 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:24:12.237: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6904
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-ada875ea-29f2-4da3-b8ea-0a994731467b
STEP: Creating configMap with name cm-test-opt-upd-d58422eb-cfa7-4b21-b5f3-cb1067599126
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ada875ea-29f2-4da3-b8ea-0a994731467b
STEP: Updating configmap cm-test-opt-upd-d58422eb-cfa7-4b21-b5f3-cb1067599126
STEP: Creating configMap with name cm-test-opt-create-a55c1d63-207a-4521-9608-26fc80b5c031
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:25:35.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6904" for this suite.
Feb 24 19:25:47.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:25:47.444: INFO: namespace configmap-6904 deletion completed in 12.150575387s

• [SLOW TEST:95.207 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:25:47.454: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3827
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 24 19:25:49.709: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:25:49.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3827" for this suite.
Feb 24 19:25:55.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:25:55.904: INFO: namespace container-runtime-3827 deletion completed in 6.164211707s

• [SLOW TEST:8.451 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:25:55.907: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-120
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-6dd2f731-bb63-4fdd-b9de-2b62cb585928
STEP: Creating a pod to test consume secrets
Feb 24 19:25:56.091: INFO: Waiting up to 5m0s for pod "pod-secrets-b5c87f55-5c7a-4f7a-96a9-40f612a04a21" in namespace "secrets-120" to be "success or failure"
Feb 24 19:25:56.101: INFO: Pod "pod-secrets-b5c87f55-5c7a-4f7a-96a9-40f612a04a21": Phase="Pending", Reason="", readiness=false. Elapsed: 9.585923ms
Feb 24 19:25:58.194: INFO: Pod "pod-secrets-b5c87f55-5c7a-4f7a-96a9-40f612a04a21": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.103332092s
STEP: Saw pod success
Feb 24 19:25:58.194: INFO: Pod "pod-secrets-b5c87f55-5c7a-4f7a-96a9-40f612a04a21" satisfied condition "success or failure"
Feb 24 19:25:58.297: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-secrets-b5c87f55-5c7a-4f7a-96a9-40f612a04a21 container secret-volume-test: <nil>
STEP: delete the pod
Feb 24 19:25:58.574: INFO: Waiting for pod pod-secrets-b5c87f55-5c7a-4f7a-96a9-40f612a04a21 to disappear
Feb 24 19:25:58.578: INFO: Pod pod-secrets-b5c87f55-5c7a-4f7a-96a9-40f612a04a21 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:25:58.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-120" for this suite.
Feb 24 19:26:04.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:26:04.773: INFO: namespace secrets-120 deletion completed in 6.187359381s

• [SLOW TEST:8.866 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:26:04.774: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4268
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:26:23.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4268" for this suite.
Feb 24 19:26:29.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:26:29.177: INFO: namespace resourcequota-4268 deletion completed in 6.149917845s

• [SLOW TEST:24.403 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:26:29.178: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-727
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-24e29aa7-e700-44ca-9877-86164254369b
STEP: Creating a pod to test consume secrets
Feb 24 19:26:29.400: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2f5e5078-9a29-4d06-80ac-951b97a37999" in namespace "projected-727" to be "success or failure"
Feb 24 19:26:29.406: INFO: Pod "pod-projected-secrets-2f5e5078-9a29-4d06-80ac-951b97a37999": Phase="Pending", Reason="", readiness=false. Elapsed: 5.762131ms
Feb 24 19:26:31.410: INFO: Pod "pod-projected-secrets-2f5e5078-9a29-4d06-80ac-951b97a37999": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009378381s
STEP: Saw pod success
Feb 24 19:26:31.410: INFO: Pod "pod-projected-secrets-2f5e5078-9a29-4d06-80ac-951b97a37999" satisfied condition "success or failure"
Feb 24 19:26:31.413: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-projected-secrets-2f5e5078-9a29-4d06-80ac-951b97a37999 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 24 19:26:31.439: INFO: Waiting for pod pod-projected-secrets-2f5e5078-9a29-4d06-80ac-951b97a37999 to disappear
Feb 24 19:26:31.442: INFO: Pod pod-projected-secrets-2f5e5078-9a29-4d06-80ac-951b97a37999 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:26:31.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-727" for this suite.
Feb 24 19:26:37.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:26:37.756: INFO: namespace projected-727 deletion completed in 6.309384762s

• [SLOW TEST:8.578 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:26:37.761: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7592
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 19:26:38.538: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 19:26:40.548: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718169198, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718169198, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718169198, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718169198, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 19:26:43.627: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
Feb 24 19:26:45.757: INFO: Waiting for webhook configuration to be ready...
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
Feb 24 19:26:50.904: INFO: Waiting for webhook configuration to be ready...
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:26:56.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7592" for this suite.
Feb 24 19:27:02.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:27:02.191: INFO: namespace webhook-7592 deletion completed in 6.156959289s
STEP: Destroying namespace "webhook-7592-markers" for this suite.
Feb 24 19:27:08.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:27:08.340: INFO: namespace webhook-7592-markers deletion completed in 6.14822816s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.601 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:27:08.367: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2723
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:27:24.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2723" for this suite.
Feb 24 19:27:30.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:27:30.987: INFO: namespace resourcequota-2723 deletion completed in 6.197411531s

• [SLOW TEST:22.621 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:27:30.992: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-29
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 24 19:27:31.216: INFO: Number of nodes with available pods: 0
Feb 24 19:27:31.216: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:27:32.234: INFO: Number of nodes with available pods: 0
Feb 24 19:27:32.234: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:27:33.229: INFO: Number of nodes with available pods: 2
Feb 24 19:27:33.229: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:27:34.237: INFO: Number of nodes with available pods: 3
Feb 24 19:27:34.237: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 24 19:27:34.300: INFO: Number of nodes with available pods: 2
Feb 24 19:27:34.301: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:27:35.310: INFO: Number of nodes with available pods: 2
Feb 24 19:27:35.310: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:27:36.309: INFO: Number of nodes with available pods: 2
Feb 24 19:27:36.309: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:27:37.323: INFO: Number of nodes with available pods: 2
Feb 24 19:27:37.323: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:27:38.310: INFO: Number of nodes with available pods: 2
Feb 24 19:27:38.310: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:27:39.310: INFO: Number of nodes with available pods: 2
Feb 24 19:27:39.310: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:27:40.310: INFO: Number of nodes with available pods: 2
Feb 24 19:27:40.310: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:27:41.311: INFO: Number of nodes with available pods: 2
Feb 24 19:27:41.312: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:27:42.308: INFO: Number of nodes with available pods: 3
Feb 24 19:27:42.308: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-29, will wait for the garbage collector to delete the pods
Feb 24 19:27:42.370: INFO: Deleting DaemonSet.extensions daemon-set took: 5.237485ms
Feb 24 19:27:42.970: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.171906ms
Feb 24 19:27:50.373: INFO: Number of nodes with available pods: 0
Feb 24 19:27:50.373: INFO: Number of running nodes: 0, number of available pods: 0
Feb 24 19:27:50.376: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-29/daemonsets","resourceVersion":"20541"},"items":null}

Feb 24 19:27:50.380: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-29/pods","resourceVersion":"20541"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:27:50.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-29" for this suite.
Feb 24 19:27:56.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:27:56.535: INFO: namespace daemonsets-29 deletion completed in 6.13794058s

• [SLOW TEST:25.545 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:27:56.540: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4075
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-710f1afe-f673-43a6-a564-591dbaf568dc
STEP: Creating a pod to test consume configMaps
Feb 24 19:27:56.731: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ad83c09f-dd4e-45e7-b4ff-096fbf613bd8" in namespace "projected-4075" to be "success or failure"
Feb 24 19:27:56.739: INFO: Pod "pod-projected-configmaps-ad83c09f-dd4e-45e7-b4ff-096fbf613bd8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.299047ms
Feb 24 19:27:58.743: INFO: Pod "pod-projected-configmaps-ad83c09f-dd4e-45e7-b4ff-096fbf613bd8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01173463s
STEP: Saw pod success
Feb 24 19:27:58.743: INFO: Pod "pod-projected-configmaps-ad83c09f-dd4e-45e7-b4ff-096fbf613bd8" satisfied condition "success or failure"
Feb 24 19:27:58.746: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-projected-configmaps-ad83c09f-dd4e-45e7-b4ff-096fbf613bd8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 19:27:58.771: INFO: Waiting for pod pod-projected-configmaps-ad83c09f-dd4e-45e7-b4ff-096fbf613bd8 to disappear
Feb 24 19:27:58.775: INFO: Pod pod-projected-configmaps-ad83c09f-dd4e-45e7-b4ff-096fbf613bd8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:27:58.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4075" for this suite.
Feb 24 19:28:06.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:28:07.464: INFO: namespace projected-4075 deletion completed in 8.683886512s

• [SLOW TEST:10.925 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:28:07.469: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5178
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Feb 24 19:28:07.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 create -f - --namespace=kubectl-5178'
Feb 24 19:28:07.930: INFO: stderr: ""
Feb 24 19:28:07.930: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 24 19:28:07.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5178'
Feb 24 19:28:08.037: INFO: stderr: ""
Feb 24 19:28:08.038: INFO: stdout: "update-demo-nautilus-t8s7c update-demo-nautilus-x4wrl "
Feb 24 19:28:08.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-t8s7c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5178'
Feb 24 19:28:08.126: INFO: stderr: ""
Feb 24 19:28:08.126: INFO: stdout: ""
Feb 24 19:28:08.126: INFO: update-demo-nautilus-t8s7c is created but not running
Feb 24 19:28:13.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5178'
Feb 24 19:28:13.217: INFO: stderr: ""
Feb 24 19:28:13.217: INFO: stdout: "update-demo-nautilus-t8s7c update-demo-nautilus-x4wrl "
Feb 24 19:28:13.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-t8s7c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5178'
Feb 24 19:28:13.303: INFO: stderr: ""
Feb 24 19:28:13.303: INFO: stdout: "true"
Feb 24 19:28:13.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-t8s7c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5178'
Feb 24 19:28:13.403: INFO: stderr: ""
Feb 24 19:28:13.403: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 24 19:28:13.403: INFO: validating pod update-demo-nautilus-t8s7c
Feb 24 19:28:13.410: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 24 19:28:13.410: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 24 19:28:13.410: INFO: update-demo-nautilus-t8s7c is verified up and running
Feb 24 19:28:13.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-x4wrl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5178'
Feb 24 19:28:13.503: INFO: stderr: ""
Feb 24 19:28:13.503: INFO: stdout: "true"
Feb 24 19:28:13.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-x4wrl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5178'
Feb 24 19:28:13.611: INFO: stderr: ""
Feb 24 19:28:13.611: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 24 19:28:13.611: INFO: validating pod update-demo-nautilus-x4wrl
Feb 24 19:28:13.619: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 24 19:28:13.619: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 24 19:28:13.619: INFO: update-demo-nautilus-x4wrl is verified up and running
STEP: rolling-update to new replication controller
Feb 24 19:28:13.623: INFO: scanned /root for discovery docs: <nil>
Feb 24 19:28:13.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-5178'
Feb 24 19:28:36.174: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 24 19:28:36.174: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 24 19:28:36.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5178'
Feb 24 19:28:36.276: INFO: stderr: ""
Feb 24 19:28:36.276: INFO: stdout: "update-demo-kitten-mxc2x update-demo-kitten-xx7kg "
Feb 24 19:28:36.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-kitten-mxc2x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5178'
Feb 24 19:28:36.363: INFO: stderr: ""
Feb 24 19:28:36.363: INFO: stdout: "true"
Feb 24 19:28:36.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-kitten-mxc2x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5178'
Feb 24 19:28:36.457: INFO: stderr: ""
Feb 24 19:28:36.457: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 24 19:28:36.457: INFO: validating pod update-demo-kitten-mxc2x
Feb 24 19:28:36.464: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 24 19:28:36.464: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 24 19:28:36.464: INFO: update-demo-kitten-mxc2x is verified up and running
Feb 24 19:28:36.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-kitten-xx7kg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5178'
Feb 24 19:28:36.558: INFO: stderr: ""
Feb 24 19:28:36.558: INFO: stdout: "true"
Feb 24 19:28:36.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-kitten-xx7kg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5178'
Feb 24 19:28:36.668: INFO: stderr: ""
Feb 24 19:28:36.668: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 24 19:28:36.668: INFO: validating pod update-demo-kitten-xx7kg
Feb 24 19:28:36.677: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 24 19:28:36.677: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 24 19:28:36.677: INFO: update-demo-kitten-xx7kg is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:28:36.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5178" for this suite.
Feb 24 19:29:04.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:29:04.836: INFO: namespace kubectl-5178 deletion completed in 28.155968119s

• [SLOW TEST:57.368 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:29:04.840: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3953
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 24 19:29:07.037: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:29:07.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3953" for this suite.
Feb 24 19:29:13.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:29:13.236: INFO: namespace container-runtime-3953 deletion completed in 6.142968592s

• [SLOW TEST:8.397 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:29:13.243: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4098
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 24 19:29:13.414: INFO: Waiting up to 5m0s for pod "pod-7d990f38-6649-43f6-ae8d-d495706bbc25" in namespace "emptydir-4098" to be "success or failure"
Feb 24 19:29:13.419: INFO: Pod "pod-7d990f38-6649-43f6-ae8d-d495706bbc25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.283323ms
Feb 24 19:29:15.422: INFO: Pod "pod-7d990f38-6649-43f6-ae8d-d495706bbc25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007848041s
Feb 24 19:29:17.425: INFO: Pod "pod-7d990f38-6649-43f6-ae8d-d495706bbc25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011030714s
STEP: Saw pod success
Feb 24 19:29:17.426: INFO: Pod "pod-7d990f38-6649-43f6-ae8d-d495706bbc25" satisfied condition "success or failure"
Feb 24 19:29:17.429: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-7d990f38-6649-43f6-ae8d-d495706bbc25 container test-container: <nil>
STEP: delete the pod
Feb 24 19:29:17.455: INFO: Waiting for pod pod-7d990f38-6649-43f6-ae8d-d495706bbc25 to disappear
Feb 24 19:29:17.459: INFO: Pod pod-7d990f38-6649-43f6-ae8d-d495706bbc25 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:29:17.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4098" for this suite.
Feb 24 19:29:23.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:29:23.624: INFO: namespace emptydir-4098 deletion completed in 6.159666237s

• [SLOW TEST:10.382 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:29:23.633: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7213
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:29:40.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7213" for this suite.
Feb 24 19:29:46.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:29:46.165: INFO: namespace resourcequota-7213 deletion completed in 6.148852582s

• [SLOW TEST:22.533 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:29:46.173: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4730
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 19:29:46.358: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 24 19:29:46.389: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 24 19:29:51.393: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 24 19:29:51.393: INFO: Creating deployment "test-rolling-update-deployment"
Feb 24 19:29:51.399: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 24 19:29:51.414: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 24 19:29:53.420: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 24 19:29:53.423: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718169391, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718169391, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718169391, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718169391, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 19:29:55.438: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718169391, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718169391, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718169395, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718169391, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 19:29:57.426: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 24 19:29:57.437: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-4730 /apis/apps/v1/namespaces/deployment-4730/deployments/test-rolling-update-deployment b8c63b8a-43cd-44f0-b089-851428c8d541 21318 1 2020-02-24 19:29:51 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000703f38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-02-24 19:29:51 +0000 UTC,LastTransitionTime:2020-02-24 19:29:51 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2020-02-24 19:29:55 +0000 UTC,LastTransitionTime:2020-02-24 19:29:51 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb 24 19:29:57.440: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-4730 /apis/apps/v1/namespaces/deployment-4730/replicasets/test-rolling-update-deployment-55d946486 56bbdbca-5c91-48fc-9e6d-4005b6749e09 21309 1 2020-02-24 19:29:51 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment b8c63b8a-43cd-44f0-b089-851428c8d541 0xc0004cbc30 0xc0004cbc31}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0004cbd28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 24 19:29:57.441: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 24 19:29:57.441: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-4730 /apis/apps/v1/namespaces/deployment-4730/replicasets/test-rolling-update-controller 381905ed-5785-4ded-a36b-660ba582cddc 21317 2 2020-02-24 19:29:46 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment b8c63b8a-43cd-44f0-b089-851428c8d541 0xc0004cb277 0xc0004cb278}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0004cbb38 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 24 19:29:57.444: INFO: Pod "test-rolling-update-deployment-55d946486-7rmkd" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-7rmkd test-rolling-update-deployment-55d946486- deployment-4730 /api/v1/namespaces/deployment-4730/pods/test-rolling-update-deployment-55d946486-7rmkd 34359fe9-72c6-4d18-b029-c04c4425f7af 21308 0 2020-02-24 19:29:51 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 56bbdbca-5c91-48fc-9e6d-4005b6749e09 0xc0004dc860 0xc0004dc861}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-m4jkq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-m4jkq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-m4jkq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-fss3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 19:29:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 19:29:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 19:29:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 19:29:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.2,PodIP:10.12.0.95,StartTime:2020-02-24 19:29:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 19:29:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:a606eaca41c3c69c7d2c8a142ec445e71156bae8526ae7970f62b6399e57761c,ContainerID:docker://d2a4c67f0d479c160a891b8db4f52233e9e1b22a7206789ab863a9b215d07820,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.12.0.95,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:29:57.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4730" for this suite.
Feb 24 19:30:05.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:30:05.607: INFO: namespace deployment-4730 deletion completed in 8.159454189s

• [SLOW TEST:19.434 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:30:05.610: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8936
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 19:30:05.790: INFO: Waiting up to 5m0s for pod "downwardapi-volume-18d5dcca-47de-4ecf-8b25-3c22f4e43575" in namespace "downward-api-8936" to be "success or failure"
Feb 24 19:30:05.796: INFO: Pod "downwardapi-volume-18d5dcca-47de-4ecf-8b25-3c22f4e43575": Phase="Pending", Reason="", readiness=false. Elapsed: 6.106687ms
Feb 24 19:30:07.801: INFO: Pod "downwardapi-volume-18d5dcca-47de-4ecf-8b25-3c22f4e43575": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010498961s
STEP: Saw pod success
Feb 24 19:30:07.801: INFO: Pod "downwardapi-volume-18d5dcca-47de-4ecf-8b25-3c22f4e43575" satisfied condition "success or failure"
Feb 24 19:30:07.806: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downwardapi-volume-18d5dcca-47de-4ecf-8b25-3c22f4e43575 container client-container: <nil>
STEP: delete the pod
Feb 24 19:30:07.857: INFO: Waiting for pod downwardapi-volume-18d5dcca-47de-4ecf-8b25-3c22f4e43575 to disappear
Feb 24 19:30:07.860: INFO: Pod downwardapi-volume-18d5dcca-47de-4ecf-8b25-3c22f4e43575 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:30:07.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8936" for this suite.
Feb 24 19:30:13.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:30:14.007: INFO: namespace downward-api-8936 deletion completed in 6.139640715s

• [SLOW TEST:8.398 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:30:14.011: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5959
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 19:30:14.181: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 24 19:30:14.199: INFO: Number of nodes with available pods: 0
Feb 24 19:30:14.199: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:30:15.213: INFO: Number of nodes with available pods: 0
Feb 24 19:30:15.213: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:30:16.207: INFO: Number of nodes with available pods: 1
Feb 24 19:30:16.207: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:30:17.207: INFO: Number of nodes with available pods: 3
Feb 24 19:30:17.207: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 24 19:30:17.244: INFO: Wrong image for pod: daemon-set-4n5br. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:17.244: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:17.244: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:18.343: INFO: Wrong image for pod: daemon-set-4n5br. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:18.343: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:18.343: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:19.266: INFO: Wrong image for pod: daemon-set-4n5br. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:19.266: INFO: Pod daemon-set-4n5br is not available
Feb 24 19:30:19.266: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:19.266: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:20.266: INFO: Wrong image for pod: daemon-set-4n5br. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:20.266: INFO: Pod daemon-set-4n5br is not available
Feb 24 19:30:20.266: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:20.266: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:21.268: INFO: Wrong image for pod: daemon-set-4n5br. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:21.268: INFO: Pod daemon-set-4n5br is not available
Feb 24 19:30:21.268: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:21.268: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:22.266: INFO: Wrong image for pod: daemon-set-4n5br. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:22.266: INFO: Pod daemon-set-4n5br is not available
Feb 24 19:30:22.266: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:22.266: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:23.265: INFO: Wrong image for pod: daemon-set-4n5br. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:23.265: INFO: Pod daemon-set-4n5br is not available
Feb 24 19:30:23.265: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:23.265: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:24.267: INFO: Wrong image for pod: daemon-set-4n5br. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:24.267: INFO: Pod daemon-set-4n5br is not available
Feb 24 19:30:24.267: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:24.267: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:25.266: INFO: Wrong image for pod: daemon-set-4n5br. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:25.266: INFO: Pod daemon-set-4n5br is not available
Feb 24 19:30:25.266: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:25.266: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:26.265: INFO: Wrong image for pod: daemon-set-4n5br. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:26.265: INFO: Pod daemon-set-4n5br is not available
Feb 24 19:30:26.265: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:26.265: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:27.265: INFO: Wrong image for pod: daemon-set-4n5br. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:27.265: INFO: Pod daemon-set-4n5br is not available
Feb 24 19:30:27.265: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:27.265: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:28.265: INFO: Wrong image for pod: daemon-set-4n5br. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:28.265: INFO: Pod daemon-set-4n5br is not available
Feb 24 19:30:28.265: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:28.265: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:29.265: INFO: Wrong image for pod: daemon-set-4n5br. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:29.265: INFO: Pod daemon-set-4n5br is not available
Feb 24 19:30:29.265: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:29.265: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:30.267: INFO: Wrong image for pod: daemon-set-4n5br. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:30.267: INFO: Pod daemon-set-4n5br is not available
Feb 24 19:30:30.267: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:30.267: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:31.266: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:31.266: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:31.266: INFO: Pod daemon-set-lcckz is not available
Feb 24 19:30:32.265: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:32.265: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:32.265: INFO: Pod daemon-set-lcckz is not available
Feb 24 19:30:33.279: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:33.279: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:33.279: INFO: Pod daemon-set-lcckz is not available
Feb 24 19:30:34.265: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:34.266: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:35.347: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:35.347: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:36.265: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:36.265: INFO: Wrong image for pod: daemon-set-h5bgf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:36.265: INFO: Pod daemon-set-h5bgf is not available
Feb 24 19:30:37.299: INFO: Pod daemon-set-5k9lk is not available
Feb 24 19:30:37.299: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:38.266: INFO: Pod daemon-set-5k9lk is not available
Feb 24 19:30:38.266: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:39.266: INFO: Pod daemon-set-5k9lk is not available
Feb 24 19:30:39.266: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:40.266: INFO: Pod daemon-set-5k9lk is not available
Feb 24 19:30:40.266: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:41.266: INFO: Pod daemon-set-5k9lk is not available
Feb 24 19:30:41.266: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:42.266: INFO: Wrong image for pod: daemon-set-bx8rr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 19:30:42.266: INFO: Pod daemon-set-bx8rr is not available
Feb 24 19:30:43.272: INFO: Pod daemon-set-h57mk is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 24 19:30:43.286: INFO: Number of nodes with available pods: 2
Feb 24 19:30:43.286: INFO: Node gke-c116p-default-pool-41de4435-fss3 is running more than one daemon pod
Feb 24 19:30:44.293: INFO: Number of nodes with available pods: 2
Feb 24 19:30:44.294: INFO: Node gke-c116p-default-pool-41de4435-fss3 is running more than one daemon pod
Feb 24 19:30:45.293: INFO: Number of nodes with available pods: 3
Feb 24 19:30:45.293: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5959, will wait for the garbage collector to delete the pods
Feb 24 19:30:45.366: INFO: Deleting DaemonSet.extensions daemon-set took: 6.667566ms
Feb 24 19:30:45.967: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.198163ms
Feb 24 19:30:50.871: INFO: Number of nodes with available pods: 0
Feb 24 19:30:50.872: INFO: Number of running nodes: 0, number of available pods: 0
Feb 24 19:30:50.875: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5959/daemonsets","resourceVersion":"21678"},"items":null}

Feb 24 19:30:50.878: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5959/pods","resourceVersion":"21678"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:30:50.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5959" for this suite.
Feb 24 19:30:56.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:30:57.046: INFO: namespace daemonsets-5959 deletion completed in 6.152460269s

• [SLOW TEST:43.037 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:30:57.049: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-2846
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-2846
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-2846
STEP: Deleting pre-stop pod
Feb 24 19:31:06.313: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:31:06.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-2846" for this suite.
Feb 24 19:31:50.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:31:50.505: INFO: namespace prestop-2846 deletion completed in 44.172314668s

• [SLOW TEST:53.457 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:31:50.508: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3412
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 24 19:31:50.670: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 24 19:31:50.693: INFO: Waiting for terminating namespaces to be deleted...
Feb 24 19:31:50.697: INFO: 
Logging pods the kubelet thinks is on node gke-c116p-default-pool-41de4435-50z7 before test
Feb 24 19:31:50.721: INFO: kube-dns-68b499d58-t8vrp from kube-system started at 2020-02-24 18:31:11 +0000 UTC (4 container statuses recorded)
Feb 24 19:31:50.722: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 24 19:31:50.722: INFO: 	Container kubedns ready: true, restart count 0
Feb 24 19:31:50.722: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:31:50.722: INFO: 	Container sidecar ready: true, restart count 0
Feb 24 19:31:50.722: INFO: event-exporter-gke-5998887ffd-wf7jq from kube-system started at 2020-02-24 18:31:11 +0000 UTC (2 container statuses recorded)
Feb 24 19:31:50.723: INFO: 	Container event-exporter ready: true, restart count 0
Feb 24 19:31:50.723: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 19:31:50.723: INFO: l7-default-backend-678889f899-2hc4d from kube-system started at 2020-02-24 18:31:11 +0000 UTC (1 container statuses recorded)
Feb 24 19:31:50.723: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 24 19:31:50.723: INFO: gke-metrics-agent-5hrbb from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:31:50.723: INFO: 	Container gke-metrics-agent ready: true, restart count 0
Feb 24 19:31:50.723: INFO: sonobuoy-systemd-logs-daemon-set-4d9132020e6e4914-5m24k from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 19:31:50.724: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 19:31:50.724: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 19:31:50.724: INFO: kube-dns-autoscaler-645f7d66cf-rmd2g from kube-system started at 2020-02-24 18:31:11 +0000 UTC (1 container statuses recorded)
Feb 24 19:31:50.724: INFO: 	Container autoscaler ready: true, restart count 0
Feb 24 19:31:50.724: INFO: fluentd-gke-scaler-84b9598957-hh4hk from kube-system started at 2020-02-24 18:31:11 +0000 UTC (1 container statuses recorded)
Feb 24 19:31:50.724: INFO: 	Container fluentd-gke-scaler ready: true, restart count 0
Feb 24 19:31:50.725: INFO: prometheus-to-sd-5gvqd from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:31:50.725: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:31:50.725: INFO: kube-proxy-xxnbn from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:31:50.725: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 19:31:50.725: INFO: fluentd-gke-bljn7 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (2 container statuses recorded)
Feb 24 19:31:50.725: INFO: 	Container fluentd-gke ready: true, restart count 0
Feb 24 19:31:50.725: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 19:31:50.726: INFO: 
Logging pods the kubelet thinks is on node gke-c116p-default-pool-41de4435-dz7p before test
Feb 24 19:31:50.751: INFO: prometheus-to-sd-lhjg7 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:31:50.751: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:31:50.751: INFO: gke-metrics-agent-ttjqh from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:31:50.751: INFO: 	Container gke-metrics-agent ready: true, restart count 0
Feb 24 19:31:50.751: INFO: metrics-server-v0.3.6-65d7cdc58b-rzf7x from kube-system started at 2020-02-24 18:31:26 +0000 UTC (2 container statuses recorded)
Feb 24 19:31:50.751: INFO: 	Container metrics-server ready: true, restart count 0
Feb 24 19:31:50.751: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Feb 24 19:31:50.751: INFO: sonobuoy from sonobuoy started at 2020-02-24 19:12:34 +0000 UTC (1 container statuses recorded)
Feb 24 19:31:50.751: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 24 19:31:50.751: INFO: sonobuoy-e2e-job-3461c811ccdb4a1e from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 19:31:50.751: INFO: 	Container e2e ready: true, restart count 0
Feb 24 19:31:50.751: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 19:31:50.751: INFO: sonobuoy-systemd-logs-daemon-set-4d9132020e6e4914-mxsbf from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 19:31:50.751: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 19:31:50.751: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 19:31:50.751: INFO: fluentd-gke-5zt82 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (2 container statuses recorded)
Feb 24 19:31:50.751: INFO: 	Container fluentd-gke ready: true, restart count 0
Feb 24 19:31:50.751: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 19:31:50.751: INFO: kube-proxy-zsrrm from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:31:50.751: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 19:31:50.751: INFO: stackdriver-metadata-agent-cluster-level-749b475b87-hcp6f from kube-system started at 2020-02-24 18:31:59 +0000 UTC (2 container statuses recorded)
Feb 24 19:31:50.751: INFO: 	Container metadata-agent ready: true, restart count 0
Feb 24 19:31:50.752: INFO: 	Container metadata-agent-nanny ready: true, restart count 0
Feb 24 19:31:50.752: INFO: 
Logging pods the kubelet thinks is on node gke-c116p-default-pool-41de4435-fss3 before test
Feb 24 19:31:50.766: INFO: gke-metrics-agent-256cx from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:31:50.767: INFO: 	Container gke-metrics-agent ready: true, restart count 0
Feb 24 19:31:50.767: INFO: prometheus-to-sd-xws82 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:31:50.767: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:31:50.767: INFO: sonobuoy-systemd-logs-daemon-set-4d9132020e6e4914-n8lq6 from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 19:31:50.767: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 19:31:50.767: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 19:31:50.767: INFO: fluentd-gke-l65zn from kube-system started at 2020-02-24 18:31:12 +0000 UTC (2 container statuses recorded)
Feb 24 19:31:50.767: INFO: 	Container fluentd-gke ready: true, restart count 0
Feb 24 19:31:50.767: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 19:31:50.767: INFO: kube-proxy-28x7v from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:31:50.768: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 19:31:50.768: INFO: kube-dns-68b499d58-hmrqf from kube-system started at 2020-02-24 19:16:52 +0000 UTC (4 container statuses recorded)
Feb 24 19:31:50.768: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 24 19:31:50.768: INFO: 	Container kubedns ready: true, restart count 0
Feb 24 19:31:50.768: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:31:50.768: INFO: 	Container sidecar ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-9a30222b-f9df-4452-ae56-386a6ee3b41b 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-9a30222b-f9df-4452-ae56-386a6ee3b41b off the node gke-c116p-default-pool-41de4435-fss3
STEP: verifying the node doesn't have the label kubernetes.io/e2e-9a30222b-f9df-4452-ae56-386a6ee3b41b
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:32:05.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3412" for this suite.
Feb 24 19:32:25.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:32:25.209: INFO: namespace sched-pred-3412 deletion completed in 20.158368111s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:34.702 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:32:25.214: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6416
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-d1b991b7-6ab1-4a0b-876b-dff3716e1624
STEP: Creating secret with name s-test-opt-upd-a76bcbfb-c7ee-4c20-bc3b-1ce305fedcff
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-d1b991b7-6ab1-4a0b-876b-dff3716e1624
STEP: Updating secret s-test-opt-upd-a76bcbfb-c7ee-4c20-bc3b-1ce305fedcff
STEP: Creating secret with name s-test-opt-create-29fe92b4-2b1a-40db-9266-14b8cb0790f7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:33:52.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6416" for this suite.
Feb 24 19:34:12.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:34:12.569: INFO: namespace projected-6416 deletion completed in 20.149371834s

• [SLOW TEST:107.356 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:34:12.572: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6800
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6800
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-6800
Feb 24 19:34:12.771: INFO: Found 0 stateful pods, waiting for 1
Feb 24 19:34:22.776: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 24 19:34:22.800: INFO: Deleting all statefulset in ns statefulset-6800
Feb 24 19:34:22.803: INFO: Scaling statefulset ss to 0
Feb 24 19:34:32.880: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 19:34:32.894: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:34:32.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6800" for this suite.
Feb 24 19:34:38.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:34:39.064: INFO: namespace statefulset-6800 deletion completed in 6.150685797s

• [SLOW TEST:26.492 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:34:39.068: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-785
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-e4182860-25d2-4074-b9c3-1ab1d95689d4 in namespace container-probe-785
Feb 24 19:34:43.339: INFO: Started pod busybox-e4182860-25d2-4074-b9c3-1ab1d95689d4 in namespace container-probe-785
STEP: checking the pod's current state and verifying that restartCount is present
Feb 24 19:34:43.341: INFO: Initial restart count of pod busybox-e4182860-25d2-4074-b9c3-1ab1d95689d4 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:38:44.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-785" for this suite.
Feb 24 19:38:50.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:38:50.607: INFO: namespace container-probe-785 deletion completed in 6.142538913s

• [SLOW TEST:251.540 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:38:50.610: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2982
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 24 19:38:50.812: INFO: Waiting up to 5m0s for pod "pod-74b19680-84ae-471b-8913-83f03b5fcfda" in namespace "emptydir-2982" to be "success or failure"
Feb 24 19:38:50.818: INFO: Pod "pod-74b19680-84ae-471b-8913-83f03b5fcfda": Phase="Pending", Reason="", readiness=false. Elapsed: 5.667308ms
Feb 24 19:38:52.822: INFO: Pod "pod-74b19680-84ae-471b-8913-83f03b5fcfda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009069747s
STEP: Saw pod success
Feb 24 19:38:52.822: INFO: Pod "pod-74b19680-84ae-471b-8913-83f03b5fcfda" satisfied condition "success or failure"
Feb 24 19:38:52.824: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-74b19680-84ae-471b-8913-83f03b5fcfda container test-container: <nil>
STEP: delete the pod
Feb 24 19:38:52.859: INFO: Waiting for pod pod-74b19680-84ae-471b-8913-83f03b5fcfda to disappear
Feb 24 19:38:52.865: INFO: Pod pod-74b19680-84ae-471b-8913-83f03b5fcfda no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:38:52.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2982" for this suite.
Feb 24 19:38:58.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:38:59.008: INFO: namespace emptydir-2982 deletion completed in 6.138771064s

• [SLOW TEST:8.398 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:38:59.011: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5417
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 19:38:59.188: INFO: Waiting up to 5m0s for pod "downwardapi-volume-07f61fb8-9bc8-43fd-b953-7fad0ddfa07d" in namespace "projected-5417" to be "success or failure"
Feb 24 19:38:59.191: INFO: Pod "downwardapi-volume-07f61fb8-9bc8-43fd-b953-7fad0ddfa07d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.549618ms
Feb 24 19:39:01.194: INFO: Pod "downwardapi-volume-07f61fb8-9bc8-43fd-b953-7fad0ddfa07d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006311621s
Feb 24 19:39:03.281: INFO: Pod "downwardapi-volume-07f61fb8-9bc8-43fd-b953-7fad0ddfa07d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.093060625s
STEP: Saw pod success
Feb 24 19:39:03.281: INFO: Pod "downwardapi-volume-07f61fb8-9bc8-43fd-b953-7fad0ddfa07d" satisfied condition "success or failure"
Feb 24 19:39:03.370: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downwardapi-volume-07f61fb8-9bc8-43fd-b953-7fad0ddfa07d container client-container: <nil>
STEP: delete the pod
Feb 24 19:39:03.419: INFO: Waiting for pod downwardapi-volume-07f61fb8-9bc8-43fd-b953-7fad0ddfa07d to disappear
Feb 24 19:39:03.425: INFO: Pod downwardapi-volume-07f61fb8-9bc8-43fd-b953-7fad0ddfa07d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:39:03.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5417" for this suite.
Feb 24 19:39:09.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:39:09.588: INFO: namespace projected-5417 deletion completed in 6.159025168s

• [SLOW TEST:10.578 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:39:09.593: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-277
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0224 19:39:19.897985      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 24 19:39:19.898: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:39:19.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-277" for this suite.
Feb 24 19:39:25.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:39:26.068: INFO: namespace gc-277 deletion completed in 6.163740825s

• [SLOW TEST:16.475 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:39:26.069: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5090
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 24 19:39:26.228: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 24 19:39:26.252: INFO: Waiting for terminating namespaces to be deleted...
Feb 24 19:39:26.255: INFO: 
Logging pods the kubelet thinks is on node gke-c116p-default-pool-41de4435-50z7 before test
Feb 24 19:39:26.279: INFO: kube-dns-autoscaler-645f7d66cf-rmd2g from kube-system started at 2020-02-24 18:31:11 +0000 UTC (1 container statuses recorded)
Feb 24 19:39:26.279: INFO: 	Container autoscaler ready: true, restart count 0
Feb 24 19:39:26.279: INFO: fluentd-gke-scaler-84b9598957-hh4hk from kube-system started at 2020-02-24 18:31:11 +0000 UTC (1 container statuses recorded)
Feb 24 19:39:26.280: INFO: 	Container fluentd-gke-scaler ready: true, restart count 0
Feb 24 19:39:26.280: INFO: prometheus-to-sd-5gvqd from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:39:26.280: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:39:26.280: INFO: kube-proxy-xxnbn from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:39:26.280: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 19:39:26.280: INFO: fluentd-gke-bljn7 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (2 container statuses recorded)
Feb 24 19:39:26.281: INFO: 	Container fluentd-gke ready: true, restart count 0
Feb 24 19:39:26.281: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 19:39:26.281: INFO: kube-dns-68b499d58-t8vrp from kube-system started at 2020-02-24 18:31:11 +0000 UTC (4 container statuses recorded)
Feb 24 19:39:26.281: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 24 19:39:26.281: INFO: 	Container kubedns ready: true, restart count 0
Feb 24 19:39:26.282: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:39:26.282: INFO: 	Container sidecar ready: true, restart count 0
Feb 24 19:39:26.282: INFO: event-exporter-gke-5998887ffd-wf7jq from kube-system started at 2020-02-24 18:31:11 +0000 UTC (2 container statuses recorded)
Feb 24 19:39:26.282: INFO: 	Container event-exporter ready: true, restart count 0
Feb 24 19:39:26.282: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 19:39:26.282: INFO: l7-default-backend-678889f899-2hc4d from kube-system started at 2020-02-24 18:31:11 +0000 UTC (1 container statuses recorded)
Feb 24 19:39:26.282: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 24 19:39:26.283: INFO: gke-metrics-agent-5hrbb from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:39:26.283: INFO: 	Container gke-metrics-agent ready: true, restart count 0
Feb 24 19:39:26.283: INFO: sonobuoy-systemd-logs-daemon-set-4d9132020e6e4914-5m24k from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 19:39:26.283: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 19:39:26.283: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 19:39:26.284: INFO: 
Logging pods the kubelet thinks is on node gke-c116p-default-pool-41de4435-dz7p before test
Feb 24 19:39:26.329: INFO: sonobuoy-e2e-job-3461c811ccdb4a1e from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 19:39:26.330: INFO: 	Container e2e ready: true, restart count 0
Feb 24 19:39:26.330: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 19:39:26.330: INFO: sonobuoy-systemd-logs-daemon-set-4d9132020e6e4914-mxsbf from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 19:39:26.330: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 19:39:26.330: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 19:39:26.331: INFO: metrics-server-v0.3.6-65d7cdc58b-rzf7x from kube-system started at 2020-02-24 18:31:26 +0000 UTC (2 container statuses recorded)
Feb 24 19:39:26.331: INFO: 	Container metrics-server ready: true, restart count 0
Feb 24 19:39:26.331: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Feb 24 19:39:26.331: INFO: sonobuoy from sonobuoy started at 2020-02-24 19:12:34 +0000 UTC (1 container statuses recorded)
Feb 24 19:39:26.331: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 24 19:39:26.332: INFO: fluentd-gke-5zt82 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (2 container statuses recorded)
Feb 24 19:39:26.332: INFO: 	Container fluentd-gke ready: true, restart count 0
Feb 24 19:39:26.332: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 19:39:26.332: INFO: kube-proxy-zsrrm from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:39:26.332: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 19:39:26.333: INFO: stackdriver-metadata-agent-cluster-level-749b475b87-hcp6f from kube-system started at 2020-02-24 18:31:59 +0000 UTC (2 container statuses recorded)
Feb 24 19:39:26.333: INFO: 	Container metadata-agent ready: true, restart count 0
Feb 24 19:39:26.333: INFO: 	Container metadata-agent-nanny ready: true, restart count 0
Feb 24 19:39:26.333: INFO: prometheus-to-sd-lhjg7 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:39:26.333: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:39:26.333: INFO: gke-metrics-agent-ttjqh from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:39:26.334: INFO: 	Container gke-metrics-agent ready: true, restart count 0
Feb 24 19:39:26.334: INFO: 
Logging pods the kubelet thinks is on node gke-c116p-default-pool-41de4435-fss3 before test
Feb 24 19:39:26.348: INFO: gke-metrics-agent-256cx from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:39:26.348: INFO: 	Container gke-metrics-agent ready: true, restart count 0
Feb 24 19:39:26.349: INFO: prometheus-to-sd-xws82 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:39:26.349: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:39:26.349: INFO: sonobuoy-systemd-logs-daemon-set-4d9132020e6e4914-n8lq6 from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 19:39:26.349: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 19:39:26.349: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 19:39:26.349: INFO: fluentd-gke-l65zn from kube-system started at 2020-02-24 18:31:12 +0000 UTC (2 container statuses recorded)
Feb 24 19:39:26.350: INFO: 	Container fluentd-gke ready: true, restart count 0
Feb 24 19:39:26.350: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 19:39:26.350: INFO: kube-proxy-28x7v from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:39:26.350: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 19:39:26.350: INFO: kube-dns-68b499d58-hmrqf from kube-system started at 2020-02-24 19:16:52 +0000 UTC (4 container statuses recorded)
Feb 24 19:39:26.351: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 24 19:39:26.351: INFO: 	Container kubedns ready: true, restart count 0
Feb 24 19:39:26.351: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:39:26.351: INFO: 	Container sidecar ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-9a7ae47e-c0b5-4640-934f-36d42bd5bedf 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-9a7ae47e-c0b5-4640-934f-36d42bd5bedf off the node gke-c116p-default-pool-41de4435-fss3
STEP: verifying the node doesn't have the label kubernetes.io/e2e-9a7ae47e-c0b5-4640-934f-36d42bd5bedf
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:44:32.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5090" for this suite.
Feb 24 19:44:54.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:44:54.802: INFO: namespace sched-pred-5090 deletion completed in 22.21547898s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:328.733 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:44:54.812: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4589
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-4589
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-4589
I0224 19:44:55.116755      17 runners.go:184] Created replication controller with name: externalname-service, namespace: services-4589, replica count: 2
I0224 19:44:58.167605      17 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 24 19:44:58.168: INFO: Creating new exec pod
Feb 24 19:45:01.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-4589 execpodzctdq -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Feb 24 19:45:02.726: INFO: rc: 1
Feb 24 19:45:02.726: INFO: Service reachability failing with error: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-4589 execpodzctdq -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80] []  <nil>  + nc -zv -t -w 2 externalname-service 80
nc: connect to externalname-service port 80 (tcp) failed: Connection refused
command terminated with exit code 1
 [] <nil> 0xc004b9d110 exit status 1 <nil> <nil> true [0xc005603808 0xc005603820 0xc005603838] [0xc005603808 0xc005603820 0xc005603838] [0xc005603818 0xc005603830] [0x10efe30 0x10efe30] 0xc008620ae0 <nil>}:
Command stdout:

stderr:
+ nc -zv -t -w 2 externalname-service 80
nc: connect to externalname-service port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Feb 24 19:45:03.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-4589 execpodzctdq -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Feb 24 19:45:05.092: INFO: rc: 1
Feb 24 19:45:05.092: INFO: Service reachability failing with error: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-4589 execpodzctdq -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80] []  <nil>  + nc -zv -t -w 2 externalname-service 80
nc: connect to externalname-service port 80 (tcp) failed: Connection refused
command terminated with exit code 1
 [] <nil> 0xc004b9d4d0 exit status 1 <nil> <nil> true [0xc005603840 0xc005603858 0xc005603870] [0xc005603840 0xc005603858 0xc005603870] [0xc005603850 0xc005603868] [0x10efe30 0x10efe30] 0xc008621020 <nil>}:
Command stdout:

stderr:
+ nc -zv -t -w 2 externalname-service 80
nc: connect to externalname-service port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Feb 24 19:45:05.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-4589 execpodzctdq -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Feb 24 19:45:06.009: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Feb 24 19:45:06.009: INFO: stdout: ""
Feb 24 19:45:06.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-4589 execpodzctdq -- /bin/sh -x -c nc -zv -t -w 2 10.77.13.49 80'
Feb 24 19:45:06.262: INFO: stderr: "+ nc -zv -t -w 2 10.77.13.49 80\nConnection to 10.77.13.49 80 port [tcp/http] succeeded!\n"
Feb 24 19:45:06.262: INFO: stdout: ""
Feb 24 19:45:06.262: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:45:06.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4589" for this suite.
Feb 24 19:45:12.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:45:12.441: INFO: namespace services-4589 deletion completed in 6.146665949s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:17.630 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:45:12.447: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-7338
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:45:12.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-7338" for this suite.
Feb 24 19:45:18.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:45:19.109: INFO: namespace tables-7338 deletion completed in 6.451024501s

• [SLOW TEST:6.662 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:45:19.110: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6441
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Feb 24 19:45:21.315: INFO: Pod pod-hostip-032d0f2c-f74d-4a83-bded-3b0dd08d8d9e has hostIP: 10.77.32.2
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:45:21.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6441" for this suite.
Feb 24 19:45:33.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:45:33.656: INFO: namespace pods-6441 deletion completed in 12.330912841s

• [SLOW TEST:14.546 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:45:33.660: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1902
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 19:45:34.447: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 19:45:37.623: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
Feb 24 19:45:37.683: INFO: Waiting for webhook configuration to be ready...
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:45:37.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1902" for this suite.
Feb 24 19:45:45.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:45:46.065: INFO: namespace webhook-1902 deletion completed in 8.203104111s
STEP: Destroying namespace "webhook-1902-markers" for this suite.
Feb 24 19:45:52.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:45:52.900: INFO: namespace webhook-1902-markers deletion completed in 6.834166184s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.268 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:45:52.928: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-2170
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Feb 24 19:45:53.712: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 19:45:56.747: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 19:45:56.752: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:45:59.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2170" for this suite.
Feb 24 19:46:05.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:46:05.949: INFO: namespace crd-webhook-2170 deletion completed in 6.168653136s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:13.041 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:46:05.970: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6780
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:46:34.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6780" for this suite.
Feb 24 19:46:40.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:46:40.905: INFO: namespace container-runtime-6780 deletion completed in 6.201553237s

• [SLOW TEST:34.935 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:46:40.915: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7075
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 24 19:46:41.093: INFO: Waiting up to 5m0s for pod "pod-0c2f2f06-9367-4d64-98c2-1196ac05fbf7" in namespace "emptydir-7075" to be "success or failure"
Feb 24 19:46:41.106: INFO: Pod "pod-0c2f2f06-9367-4d64-98c2-1196ac05fbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.777827ms
Feb 24 19:46:43.110: INFO: Pod "pod-0c2f2f06-9367-4d64-98c2-1196ac05fbf7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016880382s
STEP: Saw pod success
Feb 24 19:46:43.110: INFO: Pod "pod-0c2f2f06-9367-4d64-98c2-1196ac05fbf7" satisfied condition "success or failure"
Feb 24 19:46:43.114: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-0c2f2f06-9367-4d64-98c2-1196ac05fbf7 container test-container: <nil>
STEP: delete the pod
Feb 24 19:46:43.153: INFO: Waiting for pod pod-0c2f2f06-9367-4d64-98c2-1196ac05fbf7 to disappear
Feb 24 19:46:43.157: INFO: Pod pod-0c2f2f06-9367-4d64-98c2-1196ac05fbf7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:46:43.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7075" for this suite.
Feb 24 19:46:51.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:46:51.345: INFO: namespace emptydir-7075 deletion completed in 8.183269198s

• [SLOW TEST:10.431 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:46:51.348: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-770
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-770.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-770.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-770.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-770.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-770.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-770.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-770.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-770.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-770.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-770.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-770.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-770.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-770.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 54.7.77.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.77.7.54_udp@PTR;check="$$(dig +tcp +noall +answer +search 54.7.77.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.77.7.54_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-770.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-770.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-770.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-770.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-770.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-770.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-770.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-770.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-770.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-770.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-770.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-770.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-770.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 54.7.77.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.77.7.54_udp@PTR;check="$$(dig +tcp +noall +answer +search 54.7.77.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.77.7.54_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 24 19:47:06.294: INFO: Unable to read wheezy_udp@dns-test-service.dns-770.svc.cluster.local from pod dns-770/dns-test-793f2a84-0f37-480f-9876-a73b481b92a9: the server could not find the requested resource (get pods dns-test-793f2a84-0f37-480f-9876-a73b481b92a9)
Feb 24 19:47:06.298: INFO: Unable to read wheezy_tcp@dns-test-service.dns-770.svc.cluster.local from pod dns-770/dns-test-793f2a84-0f37-480f-9876-a73b481b92a9: the server could not find the requested resource (get pods dns-test-793f2a84-0f37-480f-9876-a73b481b92a9)
Feb 24 19:47:06.303: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-770.svc.cluster.local from pod dns-770/dns-test-793f2a84-0f37-480f-9876-a73b481b92a9: the server could not find the requested resource (get pods dns-test-793f2a84-0f37-480f-9876-a73b481b92a9)
Feb 24 19:47:06.308: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-770.svc.cluster.local from pod dns-770/dns-test-793f2a84-0f37-480f-9876-a73b481b92a9: the server could not find the requested resource (get pods dns-test-793f2a84-0f37-480f-9876-a73b481b92a9)
Feb 24 19:47:06.418: INFO: Lookups using dns-770/dns-test-793f2a84-0f37-480f-9876-a73b481b92a9 failed for: [wheezy_udp@dns-test-service.dns-770.svc.cluster.local wheezy_tcp@dns-test-service.dns-770.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-770.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-770.svc.cluster.local]

Feb 24 19:47:11.538: INFO: DNS probes using dns-770/dns-test-793f2a84-0f37-480f-9876-a73b481b92a9 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:47:11.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-770" for this suite.
Feb 24 19:47:17.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:47:17.851: INFO: namespace dns-770 deletion completed in 6.162099197s

• [SLOW TEST:26.504 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:47:17.859: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3108
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Feb 24 19:47:18.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=kubectl-3108 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 24 19:47:21.251: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 24 19:47:21.251: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:47:23.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3108" for this suite.
Feb 24 19:47:29.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:47:29.427: INFO: namespace kubectl-3108 deletion completed in 6.166342573s

• [SLOW TEST:11.569 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:47:29.432: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7705
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 19:47:29.683: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 24 19:47:29.701: INFO: Number of nodes with available pods: 0
Feb 24 19:47:29.702: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 24 19:47:29.732: INFO: Number of nodes with available pods: 0
Feb 24 19:47:29.732: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:47:30.738: INFO: Number of nodes with available pods: 0
Feb 24 19:47:30.738: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:47:31.737: INFO: Number of nodes with available pods: 1
Feb 24 19:47:31.738: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 24 19:47:31.768: INFO: Number of nodes with available pods: 1
Feb 24 19:47:31.769: INFO: Number of running nodes: 0, number of available pods: 1
Feb 24 19:47:32.773: INFO: Number of nodes with available pods: 0
Feb 24 19:47:32.773: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 24 19:47:32.790: INFO: Number of nodes with available pods: 0
Feb 24 19:47:32.790: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:47:33.798: INFO: Number of nodes with available pods: 0
Feb 24 19:47:33.799: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:47:34.794: INFO: Number of nodes with available pods: 0
Feb 24 19:47:34.794: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:47:35.876: INFO: Number of nodes with available pods: 0
Feb 24 19:47:35.876: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:47:36.796: INFO: Number of nodes with available pods: 0
Feb 24 19:47:36.796: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 19:47:37.798: INFO: Number of nodes with available pods: 1
Feb 24 19:47:37.798: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7705, will wait for the garbage collector to delete the pods
Feb 24 19:47:37.893: INFO: Deleting DaemonSet.extensions daemon-set took: 26.871044ms
Feb 24 19:47:38.393: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.187546ms
Feb 24 19:47:50.398: INFO: Number of nodes with available pods: 0
Feb 24 19:47:50.398: INFO: Number of running nodes: 0, number of available pods: 0
Feb 24 19:47:50.402: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7705/daemonsets","resourceVersion":"26885"},"items":null}

Feb 24 19:47:50.405: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7705/pods","resourceVersion":"26885"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:47:50.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7705" for this suite.
Feb 24 19:47:56.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:47:56.595: INFO: namespace daemonsets-7705 deletion completed in 6.158492783s

• [SLOW TEST:27.164 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:47:56.602: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3538
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 19:47:56.778: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d4afa6e3-0054-4e61-ad1b-15b1eaf92680" in namespace "projected-3538" to be "success or failure"
Feb 24 19:47:56.787: INFO: Pod "downwardapi-volume-d4afa6e3-0054-4e61-ad1b-15b1eaf92680": Phase="Pending", Reason="", readiness=false. Elapsed: 8.867286ms
Feb 24 19:47:58.790: INFO: Pod "downwardapi-volume-d4afa6e3-0054-4e61-ad1b-15b1eaf92680": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011564066s
STEP: Saw pod success
Feb 24 19:47:58.790: INFO: Pod "downwardapi-volume-d4afa6e3-0054-4e61-ad1b-15b1eaf92680" satisfied condition "success or failure"
Feb 24 19:47:58.793: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downwardapi-volume-d4afa6e3-0054-4e61-ad1b-15b1eaf92680 container client-container: <nil>
STEP: delete the pod
Feb 24 19:47:58.815: INFO: Waiting for pod downwardapi-volume-d4afa6e3-0054-4e61-ad1b-15b1eaf92680 to disappear
Feb 24 19:47:58.824: INFO: Pod downwardapi-volume-d4afa6e3-0054-4e61-ad1b-15b1eaf92680 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:47:58.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3538" for this suite.
Feb 24 19:48:04.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:48:04.968: INFO: namespace projected-3538 deletion completed in 6.140622226s

• [SLOW TEST:8.367 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:48:04.975: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4578
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-4ca3a45c-e98f-40a9-9acf-a92a4029c941
STEP: Creating a pod to test consume configMaps
Feb 24 19:48:05.156: INFO: Waiting up to 5m0s for pod "pod-configmaps-d1f36149-705e-40a9-8ec0-c3b1607f55e1" in namespace "configmap-4578" to be "success or failure"
Feb 24 19:48:05.159: INFO: Pod "pod-configmaps-d1f36149-705e-40a9-8ec0-c3b1607f55e1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.904793ms
Feb 24 19:48:07.166: INFO: Pod "pod-configmaps-d1f36149-705e-40a9-8ec0-c3b1607f55e1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009955815s
STEP: Saw pod success
Feb 24 19:48:07.167: INFO: Pod "pod-configmaps-d1f36149-705e-40a9-8ec0-c3b1607f55e1" satisfied condition "success or failure"
Feb 24 19:48:07.175: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-configmaps-d1f36149-705e-40a9-8ec0-c3b1607f55e1 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 19:48:07.228: INFO: Waiting for pod pod-configmaps-d1f36149-705e-40a9-8ec0-c3b1607f55e1 to disappear
Feb 24 19:48:07.246: INFO: Pod pod-configmaps-d1f36149-705e-40a9-8ec0-c3b1607f55e1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:48:07.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4578" for this suite.
Feb 24 19:48:13.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:48:13.445: INFO: namespace configmap-4578 deletion completed in 6.184587392s

• [SLOW TEST:8.471 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:48:13.450: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6904
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:48:26.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6904" for this suite.
Feb 24 19:48:32.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:48:32.258: INFO: namespace resourcequota-6904 deletion completed in 6.152259371s

• [SLOW TEST:18.809 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:48:32.262: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-7285
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 19:48:32.460: INFO: (0) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 34.159656ms)
Feb 24 19:48:32.472: INFO: (1) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 11.482916ms)
Feb 24 19:48:32.478: INFO: (2) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 5.901027ms)
Feb 24 19:48:32.484: INFO: (3) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 5.901687ms)
Feb 24 19:48:32.490: INFO: (4) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 5.699543ms)
Feb 24 19:48:32.494: INFO: (5) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 4.640174ms)
Feb 24 19:48:32.503: INFO: (6) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 8.113884ms)
Feb 24 19:48:32.508: INFO: (7) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 5.203778ms)
Feb 24 19:48:32.513: INFO: (8) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 4.447822ms)
Feb 24 19:48:32.519: INFO: (9) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 6.264897ms)
Feb 24 19:48:32.526: INFO: (10) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 6.449141ms)
Feb 24 19:48:32.530: INFO: (11) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 4.198486ms)
Feb 24 19:48:32.535: INFO: (12) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 4.050032ms)
Feb 24 19:48:32.540: INFO: (13) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 5.554481ms)
Feb 24 19:48:32.545: INFO: (14) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 4.15729ms)
Feb 24 19:48:32.549: INFO: (15) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 4.149352ms)
Feb 24 19:48:32.555: INFO: (16) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 5.226254ms)
Feb 24 19:48:32.561: INFO: (17) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 5.730023ms)
Feb 24 19:48:32.566: INFO: (18) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 4.668832ms)
Feb 24 19:48:32.572: INFO: (19) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 6.098055ms)
[AfterEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:48:32.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7285" for this suite.
Feb 24 19:48:38.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:48:38.732: INFO: namespace proxy-7285 deletion completed in 6.152575408s

• [SLOW TEST:6.470 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:48:38.738: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9136
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-3e688536-5bee-4b1d-9a7a-e9172444a36f
STEP: Creating a pod to test consume configMaps
Feb 24 19:48:38.941: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-632bf59c-acab-4733-8884-a0dfe302d328" in namespace "projected-9136" to be "success or failure"
Feb 24 19:48:38.945: INFO: Pod "pod-projected-configmaps-632bf59c-acab-4733-8884-a0dfe302d328": Phase="Pending", Reason="", readiness=false. Elapsed: 4.086897ms
Feb 24 19:48:40.951: INFO: Pod "pod-projected-configmaps-632bf59c-acab-4733-8884-a0dfe302d328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010589465s
STEP: Saw pod success
Feb 24 19:48:40.952: INFO: Pod "pod-projected-configmaps-632bf59c-acab-4733-8884-a0dfe302d328" satisfied condition "success or failure"
Feb 24 19:48:40.958: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-projected-configmaps-632bf59c-acab-4733-8884-a0dfe302d328 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 19:48:41.012: INFO: Waiting for pod pod-projected-configmaps-632bf59c-acab-4733-8884-a0dfe302d328 to disappear
Feb 24 19:48:41.024: INFO: Pod pod-projected-configmaps-632bf59c-acab-4733-8884-a0dfe302d328 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:48:41.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9136" for this suite.
Feb 24 19:48:47.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:48:47.199: INFO: namespace projected-9136 deletion completed in 6.165827528s

• [SLOW TEST:8.462 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:48:47.202: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5809
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Feb 24 19:48:47.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 cluster-info'
Feb 24 19:48:47.472: INFO: stderr: ""
Feb 24 19:48:47.472: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.77.0.1:443\x1b[0m\n\x1b[0;32mGLBCDefaultBackend\x1b[0m is running at \x1b[0;33mhttps://10.77.0.1:443/api/v1/namespaces/kube-system/services/default-http-backend:http/proxy\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.77.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://10.77.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:48:47.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5809" for this suite.
Feb 24 19:48:53.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:48:53.625: INFO: namespace kubectl-5809 deletion completed in 6.149208551s

• [SLOW TEST:6.424 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:48:53.631: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5800
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Feb 24 19:48:53.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 create -f - --namespace=kubectl-5800'
Feb 24 19:48:54.119: INFO: stderr: ""
Feb 24 19:48:54.119: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 24 19:48:55.123: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 19:48:55.123: INFO: Found 0 / 1
Feb 24 19:48:56.122: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 19:48:56.122: INFO: Found 1 / 1
Feb 24 19:48:56.122: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 24 19:48:56.125: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 19:48:56.125: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 24 19:48:56.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 patch pod redis-master-4qtm4 --namespace=kubectl-5800 -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 24 19:48:56.242: INFO: stderr: ""
Feb 24 19:48:56.243: INFO: stdout: "pod/redis-master-4qtm4 patched\n"
STEP: checking annotations
Feb 24 19:48:56.246: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 19:48:56.246: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:48:56.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5800" for this suite.
Feb 24 19:49:10.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:49:10.405: INFO: namespace kubectl-5800 deletion completed in 14.156242594s

• [SLOW TEST:16.775 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:49:10.410: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6290
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-6290/secret-test-946100b5-4be8-4073-be60-a76cdc9d7ddb
STEP: Creating a pod to test consume secrets
Feb 24 19:49:10.589: INFO: Waiting up to 5m0s for pod "pod-configmaps-c522e4c7-1b87-4e30-85d2-766462a28f81" in namespace "secrets-6290" to be "success or failure"
Feb 24 19:49:10.595: INFO: Pod "pod-configmaps-c522e4c7-1b87-4e30-85d2-766462a28f81": Phase="Pending", Reason="", readiness=false. Elapsed: 6.155548ms
Feb 24 19:49:12.599: INFO: Pod "pod-configmaps-c522e4c7-1b87-4e30-85d2-766462a28f81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009751531s
STEP: Saw pod success
Feb 24 19:49:12.599: INFO: Pod "pod-configmaps-c522e4c7-1b87-4e30-85d2-766462a28f81" satisfied condition "success or failure"
Feb 24 19:49:12.603: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-configmaps-c522e4c7-1b87-4e30-85d2-766462a28f81 container env-test: <nil>
STEP: delete the pod
Feb 24 19:49:12.629: INFO: Waiting for pod pod-configmaps-c522e4c7-1b87-4e30-85d2-766462a28f81 to disappear
Feb 24 19:49:12.634: INFO: Pod pod-configmaps-c522e4c7-1b87-4e30-85d2-766462a28f81 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:49:12.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6290" for this suite.
Feb 24 19:49:18.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:49:19.197: INFO: namespace secrets-6290 deletion completed in 6.555950492s

• [SLOW TEST:8.788 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:49:19.203: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6029
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-8448fafe-1948-4b70-9ba4-9e8b90ebbb3e
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-8448fafe-1948-4b70-9ba4-9e8b90ebbb3e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:50:48.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6029" for this suite.
Feb 24 19:51:02.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:51:02.626: INFO: namespace projected-6029 deletion completed in 14.15415883s

• [SLOW TEST:103.423 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:51:02.632: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8522
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-8522
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 24 19:51:02.797: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 24 19:51:25.142: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.12.2.40:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8522 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 19:51:25.142: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 19:51:25.326: INFO: Found all expected endpoints: [netserver-0]
Feb 24 19:51:25.333: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.12.1.39:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8522 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 19:51:25.333: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 19:51:25.548: INFO: Found all expected endpoints: [netserver-1]
Feb 24 19:51:25.552: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.12.0.137:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8522 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 19:51:25.552: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 19:51:25.767: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:51:25.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8522" for this suite.
Feb 24 19:51:37.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:51:38.132: INFO: namespace pod-network-test-8522 deletion completed in 12.355407487s

• [SLOW TEST:35.500 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:51:38.135: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9347
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 19:51:38.499: INFO: Waiting up to 5m0s for pod "downwardapi-volume-13cf61d3-5598-4f2f-aa4e-b0a20177a12b" in namespace "downward-api-9347" to be "success or failure"
Feb 24 19:51:38.512: INFO: Pod "downwardapi-volume-13cf61d3-5598-4f2f-aa4e-b0a20177a12b": Phase="Pending", Reason="", readiness=false. Elapsed: 13.060967ms
Feb 24 19:51:40.601: INFO: Pod "downwardapi-volume-13cf61d3-5598-4f2f-aa4e-b0a20177a12b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.102580003s
STEP: Saw pod success
Feb 24 19:51:40.602: INFO: Pod "downwardapi-volume-13cf61d3-5598-4f2f-aa4e-b0a20177a12b" satisfied condition "success or failure"
Feb 24 19:51:40.631: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downwardapi-volume-13cf61d3-5598-4f2f-aa4e-b0a20177a12b container client-container: <nil>
STEP: delete the pod
Feb 24 19:51:40.658: INFO: Waiting for pod downwardapi-volume-13cf61d3-5598-4f2f-aa4e-b0a20177a12b to disappear
Feb 24 19:51:40.664: INFO: Pod downwardapi-volume-13cf61d3-5598-4f2f-aa4e-b0a20177a12b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:51:40.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9347" for this suite.
Feb 24 19:51:46.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:51:46.834: INFO: namespace downward-api-9347 deletion completed in 6.166147486s

• [SLOW TEST:8.700 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:51:46.840: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-908
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Feb 24 19:51:46.999: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Feb 24 19:51:47.474: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Feb 24 19:51:49.678: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 19:51:51.763: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 19:51:53.682: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 19:51:55.683: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 19:51:57.683: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 19:51:59.682: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170707, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 19:52:03.971: INFO: Waited 2.280494349s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:52:06.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-908" for this suite.
Feb 24 19:52:12.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:52:12.888: INFO: namespace aggregator-908 deletion completed in 6.151248283s

• [SLOW TEST:26.049 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:52:12.893: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8880
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 24 19:52:13.125: INFO: Waiting up to 5m0s for pod "pod-e4fc9f52-d361-4ccf-b298-0d0adfa1a718" in namespace "emptydir-8880" to be "success or failure"
Feb 24 19:52:13.128: INFO: Pod "pod-e4fc9f52-d361-4ccf-b298-0d0adfa1a718": Phase="Pending", Reason="", readiness=false. Elapsed: 3.047001ms
Feb 24 19:52:15.132: INFO: Pod "pod-e4fc9f52-d361-4ccf-b298-0d0adfa1a718": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006466339s
Feb 24 19:52:17.135: INFO: Pod "pod-e4fc9f52-d361-4ccf-b298-0d0adfa1a718": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010063658s
STEP: Saw pod success
Feb 24 19:52:17.135: INFO: Pod "pod-e4fc9f52-d361-4ccf-b298-0d0adfa1a718" satisfied condition "success or failure"
Feb 24 19:52:17.139: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-e4fc9f52-d361-4ccf-b298-0d0adfa1a718 container test-container: <nil>
STEP: delete the pod
Feb 24 19:52:17.171: INFO: Waiting for pod pod-e4fc9f52-d361-4ccf-b298-0d0adfa1a718 to disappear
Feb 24 19:52:17.175: INFO: Pod pod-e4fc9f52-d361-4ccf-b298-0d0adfa1a718 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:52:17.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8880" for this suite.
Feb 24 19:52:23.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:52:23.350: INFO: namespace emptydir-8880 deletion completed in 6.1700045s

• [SLOW TEST:10.457 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:52:23.358: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2802
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 24 19:52:23.581: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 24 19:52:23.595: INFO: Waiting for terminating namespaces to be deleted...
Feb 24 19:52:23.598: INFO: 
Logging pods the kubelet thinks is on node gke-c116p-default-pool-41de4435-50z7 before test
Feb 24 19:52:23.616: INFO: gke-metrics-agent-5hrbb from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:52:23.616: INFO: 	Container gke-metrics-agent ready: true, restart count 0
Feb 24 19:52:23.617: INFO: sonobuoy-systemd-logs-daemon-set-4d9132020e6e4914-5m24k from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 19:52:23.617: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 19:52:23.617: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 19:52:23.617: INFO: kube-dns-autoscaler-645f7d66cf-rmd2g from kube-system started at 2020-02-24 18:31:11 +0000 UTC (1 container statuses recorded)
Feb 24 19:52:23.618: INFO: 	Container autoscaler ready: true, restart count 0
Feb 24 19:52:23.618: INFO: fluentd-gke-scaler-84b9598957-hh4hk from kube-system started at 2020-02-24 18:31:11 +0000 UTC (1 container statuses recorded)
Feb 24 19:52:23.618: INFO: 	Container fluentd-gke-scaler ready: true, restart count 0
Feb 24 19:52:23.618: INFO: prometheus-to-sd-5gvqd from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:52:23.618: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:52:23.618: INFO: kube-proxy-xxnbn from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:52:23.619: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 19:52:23.619: INFO: fluentd-gke-bljn7 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (2 container statuses recorded)
Feb 24 19:52:23.619: INFO: 	Container fluentd-gke ready: true, restart count 0
Feb 24 19:52:23.619: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 19:52:23.619: INFO: kube-dns-68b499d58-t8vrp from kube-system started at 2020-02-24 18:31:11 +0000 UTC (4 container statuses recorded)
Feb 24 19:52:23.620: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 24 19:52:23.620: INFO: 	Container kubedns ready: true, restart count 0
Feb 24 19:52:23.620: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:52:23.620: INFO: 	Container sidecar ready: true, restart count 0
Feb 24 19:52:23.620: INFO: event-exporter-gke-5998887ffd-wf7jq from kube-system started at 2020-02-24 18:31:11 +0000 UTC (2 container statuses recorded)
Feb 24 19:52:23.620: INFO: 	Container event-exporter ready: true, restart count 0
Feb 24 19:52:23.621: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 19:52:23.621: INFO: l7-default-backend-678889f899-2hc4d from kube-system started at 2020-02-24 18:31:11 +0000 UTC (1 container statuses recorded)
Feb 24 19:52:23.621: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 24 19:52:23.621: INFO: 
Logging pods the kubelet thinks is on node gke-c116p-default-pool-41de4435-dz7p before test
Feb 24 19:52:23.638: INFO: fluentd-gke-5zt82 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (2 container statuses recorded)
Feb 24 19:52:23.638: INFO: 	Container fluentd-gke ready: true, restart count 0
Feb 24 19:52:23.638: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 19:52:23.638: INFO: kube-proxy-zsrrm from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:52:23.638: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 19:52:23.639: INFO: stackdriver-metadata-agent-cluster-level-749b475b87-hcp6f from kube-system started at 2020-02-24 18:31:59 +0000 UTC (2 container statuses recorded)
Feb 24 19:52:23.639: INFO: 	Container metadata-agent ready: true, restart count 0
Feb 24 19:52:23.639: INFO: 	Container metadata-agent-nanny ready: true, restart count 0
Feb 24 19:52:23.639: INFO: prometheus-to-sd-lhjg7 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:52:23.639: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:52:23.639: INFO: gke-metrics-agent-ttjqh from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:52:23.639: INFO: 	Container gke-metrics-agent ready: true, restart count 0
Feb 24 19:52:23.639: INFO: sonobuoy-systemd-logs-daemon-set-4d9132020e6e4914-mxsbf from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 19:52:23.639: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 19:52:23.640: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 19:52:23.640: INFO: metrics-server-v0.3.6-65d7cdc58b-rzf7x from kube-system started at 2020-02-24 18:31:26 +0000 UTC (2 container statuses recorded)
Feb 24 19:52:23.640: INFO: 	Container metrics-server ready: true, restart count 0
Feb 24 19:52:23.640: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Feb 24 19:52:23.640: INFO: sonobuoy from sonobuoy started at 2020-02-24 19:12:34 +0000 UTC (1 container statuses recorded)
Feb 24 19:52:23.640: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 24 19:52:23.640: INFO: sonobuoy-e2e-job-3461c811ccdb4a1e from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 19:52:23.640: INFO: 	Container e2e ready: true, restart count 0
Feb 24 19:52:23.640: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 19:52:23.641: INFO: 
Logging pods the kubelet thinks is on node gke-c116p-default-pool-41de4435-fss3 before test
Feb 24 19:52:23.651: INFO: fluentd-gke-l65zn from kube-system started at 2020-02-24 18:31:12 +0000 UTC (2 container statuses recorded)
Feb 24 19:52:23.652: INFO: 	Container fluentd-gke ready: true, restart count 0
Feb 24 19:52:23.654: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 19:52:23.655: INFO: kube-proxy-28x7v from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:52:23.655: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 19:52:23.655: INFO: kube-dns-68b499d58-hmrqf from kube-system started at 2020-02-24 19:16:52 +0000 UTC (4 container statuses recorded)
Feb 24 19:52:23.655: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 24 19:52:23.656: INFO: 	Container kubedns ready: true, restart count 0
Feb 24 19:52:23.656: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:52:23.656: INFO: 	Container sidecar ready: true, restart count 0
Feb 24 19:52:23.656: INFO: gke-metrics-agent-256cx from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:52:23.656: INFO: 	Container gke-metrics-agent ready: true, restart count 0
Feb 24 19:52:23.656: INFO: prometheus-to-sd-xws82 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 19:52:23.657: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 19:52:23.657: INFO: sonobuoy-systemd-logs-daemon-set-4d9132020e6e4914-n8lq6 from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 19:52:23.657: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 19:52:23.657: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15f66e9defcd3a93], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:52:24.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2802" for this suite.
Feb 24 19:52:30.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:52:30.868: INFO: namespace sched-pred-2802 deletion completed in 6.164236761s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.511 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:52:30.871: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1049
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Feb 24 19:52:31.084: INFO: namespace kubectl-1049
Feb 24 19:52:31.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 create -f - --namespace=kubectl-1049'
Feb 24 19:52:31.405: INFO: stderr: ""
Feb 24 19:52:31.405: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 24 19:52:32.411: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 19:52:32.411: INFO: Found 0 / 1
Feb 24 19:52:33.409: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 19:52:33.409: INFO: Found 1 / 1
Feb 24 19:52:33.409: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 24 19:52:33.412: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 19:52:33.412: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 24 19:52:33.412: INFO: wait on redis-master startup in kubectl-1049 
Feb 24 19:52:33.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 logs redis-master-qf9dr redis-master --namespace=kubectl-1049'
Feb 24 19:52:33.546: INFO: stderr: ""
Feb 24 19:52:33.546: INFO: stdout: "1:C 24 Feb 2020 19:52:32.336 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 24 Feb 2020 19:52:32.336 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 24 Feb 2020 19:52:32.336 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 24 Feb 2020 19:52:32.339 * Running mode=standalone, port=6379.\n1:M 24 Feb 2020 19:52:32.340 # Server initialized\n1:M 24 Feb 2020 19:52:32.340 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 24 Feb 2020 19:52:32.340 * Ready to accept connections\n"
STEP: exposing RC
Feb 24 19:52:33.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-1049'
Feb 24 19:52:33.785: INFO: stderr: ""
Feb 24 19:52:33.785: INFO: stdout: "service/rm2 exposed\n"
Feb 24 19:52:33.793: INFO: Service rm2 in namespace kubectl-1049 found.
STEP: exposing service
Feb 24 19:52:35.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-1049'
Feb 24 19:52:36.188: INFO: stderr: ""
Feb 24 19:52:36.188: INFO: stdout: "service/rm3 exposed\n"
Feb 24 19:52:36.200: INFO: Service rm3 in namespace kubectl-1049 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:52:38.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1049" for this suite.
Feb 24 19:52:50.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:52:50.392: INFO: namespace kubectl-1049 deletion completed in 12.168263568s

• [SLOW TEST:19.521 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:52:50.398: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1755
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-a899b831-2b9a-4f1e-a5ad-62f4ce9b6bb5
STEP: Creating a pod to test consume configMaps
Feb 24 19:52:50.724: INFO: Waiting up to 5m0s for pod "pod-configmaps-7dadb722-2364-482e-ab21-c105f7d0f062" in namespace "configmap-1755" to be "success or failure"
Feb 24 19:52:50.736: INFO: Pod "pod-configmaps-7dadb722-2364-482e-ab21-c105f7d0f062": Phase="Pending", Reason="", readiness=false. Elapsed: 11.857065ms
Feb 24 19:52:52.741: INFO: Pod "pod-configmaps-7dadb722-2364-482e-ab21-c105f7d0f062": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017347909s
STEP: Saw pod success
Feb 24 19:52:52.742: INFO: Pod "pod-configmaps-7dadb722-2364-482e-ab21-c105f7d0f062" satisfied condition "success or failure"
Feb 24 19:52:52.745: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-configmaps-7dadb722-2364-482e-ab21-c105f7d0f062 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 19:52:52.773: INFO: Waiting for pod pod-configmaps-7dadb722-2364-482e-ab21-c105f7d0f062 to disappear
Feb 24 19:52:52.779: INFO: Pod pod-configmaps-7dadb722-2364-482e-ab21-c105f7d0f062 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:52:52.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1755" for this suite.
Feb 24 19:53:00.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:53:00.941: INFO: namespace configmap-1755 deletion completed in 8.158593123s

• [SLOW TEST:10.544 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:53:00.945: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7987
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 19:53:25.275: INFO: Container started at 2020-02-24 19:53:03 +0000 UTC, pod became ready at 2020-02-24 19:53:23 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:53:25.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7987" for this suite.
Feb 24 19:53:53.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:53:53.586: INFO: namespace container-probe-7987 deletion completed in 28.306337437s

• [SLOW TEST:52.641 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:53:53.592: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3228
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 24 19:53:53.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-3228'
Feb 24 19:53:53.868: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 24 19:53:53.868: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Feb 24 19:53:53.900: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Feb 24 19:53:53.915: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb 24 19:53:53.932: INFO: scanned /root for discovery docs: <nil>
Feb 24 19:53:53.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-3228'
Feb 24 19:54:09.876: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 24 19:54:09.876: INFO: stdout: "Created e2e-test-httpd-rc-e130229cfd80b3eb6cab97c2763b7d0a\nScaling up e2e-test-httpd-rc-e130229cfd80b3eb6cab97c2763b7d0a from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-e130229cfd80b3eb6cab97c2763b7d0a up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-e130229cfd80b3eb6cab97c2763b7d0a to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Feb 24 19:54:09.876: INFO: stdout: "Created e2e-test-httpd-rc-e130229cfd80b3eb6cab97c2763b7d0a\nScaling up e2e-test-httpd-rc-e130229cfd80b3eb6cab97c2763b7d0a from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-e130229cfd80b3eb6cab97c2763b7d0a up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-e130229cfd80b3eb6cab97c2763b7d0a to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Feb 24 19:54:09.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-3228'
Feb 24 19:54:09.971: INFO: stderr: ""
Feb 24 19:54:09.971: INFO: stdout: "e2e-test-httpd-rc-e130229cfd80b3eb6cab97c2763b7d0a-vbjg4 "
Feb 24 19:54:09.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods e2e-test-httpd-rc-e130229cfd80b3eb6cab97c2763b7d0a-vbjg4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3228'
Feb 24 19:54:10.056: INFO: stderr: ""
Feb 24 19:54:10.056: INFO: stdout: "true"
Feb 24 19:54:10.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods e2e-test-httpd-rc-e130229cfd80b3eb6cab97c2763b7d0a-vbjg4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3228'
Feb 24 19:54:10.144: INFO: stderr: ""
Feb 24 19:54:10.145: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Feb 24 19:54:10.145: INFO: e2e-test-httpd-rc-e130229cfd80b3eb6cab97c2763b7d0a-vbjg4 is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Feb 24 19:54:10.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 delete rc e2e-test-httpd-rc --namespace=kubectl-3228'
Feb 24 19:54:10.243: INFO: stderr: ""
Feb 24 19:54:10.243: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:54:10.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3228" for this suite.
Feb 24 19:54:22.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:54:22.609: INFO: namespace kubectl-3228 deletion completed in 12.361748675s

• [SLOW TEST:29.018 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:54:22.618: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6757
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Feb 24 19:54:22.901: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-651526472 proxy --unix-socket=/tmp/kubectl-proxy-unix260041283/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:54:22.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6757" for this suite.
Feb 24 19:54:29.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:54:29.192: INFO: namespace kubectl-6757 deletion completed in 6.207458392s

• [SLOW TEST:6.575 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:54:29.196: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5403
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 24 19:54:29.434: INFO: Waiting up to 5m0s for pod "pod-073efbb8-60bc-4077-8de3-10c1740125fc" in namespace "emptydir-5403" to be "success or failure"
Feb 24 19:54:29.443: INFO: Pod "pod-073efbb8-60bc-4077-8de3-10c1740125fc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.475835ms
Feb 24 19:54:31.447: INFO: Pod "pod-073efbb8-60bc-4077-8de3-10c1740125fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012910965s
STEP: Saw pod success
Feb 24 19:54:31.447: INFO: Pod "pod-073efbb8-60bc-4077-8de3-10c1740125fc" satisfied condition "success or failure"
Feb 24 19:54:31.451: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-073efbb8-60bc-4077-8de3-10c1740125fc container test-container: <nil>
STEP: delete the pod
Feb 24 19:54:31.491: INFO: Waiting for pod pod-073efbb8-60bc-4077-8de3-10c1740125fc to disappear
Feb 24 19:54:31.499: INFO: Pod pod-073efbb8-60bc-4077-8de3-10c1740125fc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:54:31.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5403" for this suite.
Feb 24 19:54:37.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:54:37.917: INFO: namespace emptydir-5403 deletion completed in 6.409940038s

• [SLOW TEST:8.721 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:54:37.931: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-378
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-c6gp9 in namespace proxy-378
I0224 19:54:38.325960      17 runners.go:184] Created replication controller with name: proxy-service-c6gp9, namespace: proxy-378, replica count: 1
I0224 19:54:39.377483      17 runners.go:184] proxy-service-c6gp9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0224 19:54:40.377871      17 runners.go:184] proxy-service-c6gp9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0224 19:54:41.378190      17 runners.go:184] proxy-service-c6gp9 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 24 19:54:41.386: INFO: setup took 3.206297499s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 24 19:54:41.414: INFO: (0) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 26.617208ms)
Feb 24 19:54:41.414: INFO: (0) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 27.672012ms)
Feb 24 19:54:41.414: INFO: (0) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 26.706225ms)
Feb 24 19:54:41.415: INFO: (0) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 26.93311ms)
Feb 24 19:54:41.419: INFO: (0) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 31.350234ms)
Feb 24 19:54:41.419: INFO: (0) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 32.713543ms)
Feb 24 19:54:41.420: INFO: (0) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 32.219294ms)
Feb 24 19:54:41.423: INFO: (0) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 36.25178ms)
Feb 24 19:54:41.426: INFO: (0) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 38.421506ms)
Feb 24 19:54:41.427: INFO: (0) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 39.168576ms)
Feb 24 19:54:41.432: INFO: (0) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 43.855058ms)
Feb 24 19:54:41.432: INFO: (0) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 44.959762ms)
Feb 24 19:54:41.432: INFO: (0) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 44.087657ms)
Feb 24 19:54:41.434: INFO: (0) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 47.147565ms)
Feb 24 19:54:41.434: INFO: (0) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 46.559228ms)
Feb 24 19:54:41.435: INFO: (0) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 47.081188ms)
Feb 24 19:54:41.444: INFO: (1) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 9.236359ms)
Feb 24 19:54:41.451: INFO: (1) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 14.983813ms)
Feb 24 19:54:41.456: INFO: (1) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 19.67877ms)
Feb 24 19:54:41.458: INFO: (1) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 23.009077ms)
Feb 24 19:54:41.458: INFO: (1) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 21.967461ms)
Feb 24 19:54:41.458: INFO: (1) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 22.648251ms)
Feb 24 19:54:41.458: INFO: (1) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 22.568321ms)
Feb 24 19:54:41.458: INFO: (1) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 23.067627ms)
Feb 24 19:54:41.460: INFO: (1) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 24.482477ms)
Feb 24 19:54:41.461: INFO: (1) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 25.919056ms)
Feb 24 19:54:41.464: INFO: (1) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 28.383679ms)
Feb 24 19:54:41.464: INFO: (1) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 29.096352ms)
Feb 24 19:54:41.464: INFO: (1) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 29.205604ms)
Feb 24 19:54:41.465: INFO: (1) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 27.96894ms)
Feb 24 19:54:41.465: INFO: (1) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 29.309599ms)
Feb 24 19:54:41.465: INFO: (1) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 28.570745ms)
Feb 24 19:54:41.479: INFO: (2) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 13.445192ms)
Feb 24 19:54:41.483: INFO: (2) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 17.007418ms)
Feb 24 19:54:41.483: INFO: (2) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 16.684243ms)
Feb 24 19:54:41.483: INFO: (2) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 17.321827ms)
Feb 24 19:54:41.483: INFO: (2) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 17.903478ms)
Feb 24 19:54:41.484: INFO: (2) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 17.609257ms)
Feb 24 19:54:41.489: INFO: (2) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 22.821923ms)
Feb 24 19:54:41.490: INFO: (2) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 23.215627ms)
Feb 24 19:54:41.490: INFO: (2) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 24.075267ms)
Feb 24 19:54:41.490: INFO: (2) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 24.033813ms)
Feb 24 19:54:41.490: INFO: (2) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 23.990085ms)
Feb 24 19:54:41.490: INFO: (2) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 23.925107ms)
Feb 24 19:54:41.492: INFO: (2) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 26.443357ms)
Feb 24 19:54:41.492: INFO: (2) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 26.338886ms)
Feb 24 19:54:41.492: INFO: (2) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 26.029964ms)
Feb 24 19:54:41.493: INFO: (2) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 25.984267ms)
Feb 24 19:54:41.514: INFO: (3) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 19.826017ms)
Feb 24 19:54:41.515: INFO: (3) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 20.256042ms)
Feb 24 19:54:41.520: INFO: (3) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 26.535834ms)
Feb 24 19:54:41.520: INFO: (3) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 26.766017ms)
Feb 24 19:54:41.521: INFO: (3) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 26.985391ms)
Feb 24 19:54:41.521: INFO: (3) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 27.458754ms)
Feb 24 19:54:41.521: INFO: (3) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 28.254219ms)
Feb 24 19:54:41.521: INFO: (3) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 28.179091ms)
Feb 24 19:54:41.522: INFO: (3) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 28.580575ms)
Feb 24 19:54:41.522: INFO: (3) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 28.739662ms)
Feb 24 19:54:41.523: INFO: (3) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 29.571111ms)
Feb 24 19:54:41.523: INFO: (3) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 29.298073ms)
Feb 24 19:54:41.525: INFO: (3) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 31.199831ms)
Feb 24 19:54:41.526: INFO: (3) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 31.271931ms)
Feb 24 19:54:41.526: INFO: (3) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 32.050391ms)
Feb 24 19:54:41.526: INFO: (3) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 32.242127ms)
Feb 24 19:54:41.541: INFO: (4) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 14.191898ms)
Feb 24 19:54:41.545: INFO: (4) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 18.142835ms)
Feb 24 19:54:41.546: INFO: (4) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 19.229278ms)
Feb 24 19:54:41.546: INFO: (4) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 19.542639ms)
Feb 24 19:54:41.547: INFO: (4) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 20.613089ms)
Feb 24 19:54:41.547: INFO: (4) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 19.822922ms)
Feb 24 19:54:41.547: INFO: (4) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 20.799664ms)
Feb 24 19:54:41.547: INFO: (4) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 21.094883ms)
Feb 24 19:54:41.553: INFO: (4) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 25.288962ms)
Feb 24 19:54:41.553: INFO: (4) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 25.708934ms)
Feb 24 19:54:41.553: INFO: (4) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 26.022995ms)
Feb 24 19:54:41.554: INFO: (4) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 26.454475ms)
Feb 24 19:54:41.554: INFO: (4) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 26.102353ms)
Feb 24 19:54:41.554: INFO: (4) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 26.213512ms)
Feb 24 19:54:41.555: INFO: (4) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 27.808841ms)
Feb 24 19:54:41.557: INFO: (4) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 28.935536ms)
Feb 24 19:54:41.574: INFO: (5) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 16.451135ms)
Feb 24 19:54:41.574: INFO: (5) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 16.711912ms)
Feb 24 19:54:41.578: INFO: (5) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 20.866068ms)
Feb 24 19:54:41.578: INFO: (5) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 20.537454ms)
Feb 24 19:54:41.580: INFO: (5) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 22.475064ms)
Feb 24 19:54:41.582: INFO: (5) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 24.19584ms)
Feb 24 19:54:41.584: INFO: (5) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 26.773657ms)
Feb 24 19:54:41.584: INFO: (5) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 27.080462ms)
Feb 24 19:54:41.585: INFO: (5) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 26.397228ms)
Feb 24 19:54:41.585: INFO: (5) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 26.920459ms)
Feb 24 19:54:41.585: INFO: (5) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 27.099115ms)
Feb 24 19:54:41.585: INFO: (5) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 27.098535ms)
Feb 24 19:54:41.585: INFO: (5) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 27.539401ms)
Feb 24 19:54:41.587: INFO: (5) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 29.031602ms)
Feb 24 19:54:41.591: INFO: (5) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 33.217092ms)
Feb 24 19:54:41.591: INFO: (5) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 33.004479ms)
Feb 24 19:54:41.609: INFO: (6) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 17.464555ms)
Feb 24 19:54:41.609: INFO: (6) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 17.904434ms)
Feb 24 19:54:41.613: INFO: (6) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 21.074815ms)
Feb 24 19:54:41.613: INFO: (6) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 21.300588ms)
Feb 24 19:54:41.613: INFO: (6) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 21.005941ms)
Feb 24 19:54:41.614: INFO: (6) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 21.385867ms)
Feb 24 19:54:41.614: INFO: (6) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 21.805784ms)
Feb 24 19:54:41.615: INFO: (6) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 23.032894ms)
Feb 24 19:54:41.620: INFO: (6) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 28.26488ms)
Feb 24 19:54:41.620: INFO: (6) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 27.749973ms)
Feb 24 19:54:41.622: INFO: (6) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 29.722849ms)
Feb 24 19:54:41.622: INFO: (6) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 30.179694ms)
Feb 24 19:54:41.622: INFO: (6) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 29.615931ms)
Feb 24 19:54:41.622: INFO: (6) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 29.929377ms)
Feb 24 19:54:41.622: INFO: (6) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 29.867649ms)
Feb 24 19:54:41.624: INFO: (6) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 31.339747ms)
Feb 24 19:54:41.640: INFO: (7) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 15.883498ms)
Feb 24 19:54:41.640: INFO: (7) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 16.284793ms)
Feb 24 19:54:41.645: INFO: (7) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 20.858873ms)
Feb 24 19:54:41.645: INFO: (7) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 20.754557ms)
Feb 24 19:54:41.645: INFO: (7) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 20.355767ms)
Feb 24 19:54:41.646: INFO: (7) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 21.225647ms)
Feb 24 19:54:41.646: INFO: (7) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 22.250451ms)
Feb 24 19:54:41.647: INFO: (7) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 22.478023ms)
Feb 24 19:54:41.648: INFO: (7) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 22.434477ms)
Feb 24 19:54:41.652: INFO: (7) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 27.282397ms)
Feb 24 19:54:41.653: INFO: (7) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 27.579405ms)
Feb 24 19:54:41.653: INFO: (7) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 27.729262ms)
Feb 24 19:54:41.653: INFO: (7) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 28.227917ms)
Feb 24 19:54:41.654: INFO: (7) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 29.429053ms)
Feb 24 19:54:41.655: INFO: (7) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 30.152974ms)
Feb 24 19:54:41.655: INFO: (7) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 30.387596ms)
Feb 24 19:54:41.676: INFO: (8) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 20.501073ms)
Feb 24 19:54:41.678: INFO: (8) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 21.073746ms)
Feb 24 19:54:41.679: INFO: (8) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 23.324693ms)
Feb 24 19:54:41.679: INFO: (8) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 23.756053ms)
Feb 24 19:54:41.679: INFO: (8) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 23.202788ms)
Feb 24 19:54:41.686: INFO: (8) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 29.861562ms)
Feb 24 19:54:41.686: INFO: (8) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 29.444281ms)
Feb 24 19:54:41.688: INFO: (8) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 31.452172ms)
Feb 24 19:54:41.688: INFO: (8) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 31.557907ms)
Feb 24 19:54:41.688: INFO: (8) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 31.390233ms)
Feb 24 19:54:41.689: INFO: (8) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 32.568719ms)
Feb 24 19:54:41.689: INFO: (8) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 32.796367ms)
Feb 24 19:54:41.689: INFO: (8) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 33.75556ms)
Feb 24 19:54:41.690: INFO: (8) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 33.100227ms)
Feb 24 19:54:41.690: INFO: (8) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 34.363434ms)
Feb 24 19:54:41.690: INFO: (8) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 34.012209ms)
Feb 24 19:54:41.709: INFO: (9) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 17.906674ms)
Feb 24 19:54:41.714: INFO: (9) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 23.242194ms)
Feb 24 19:54:41.714: INFO: (9) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 23.172615ms)
Feb 24 19:54:41.714: INFO: (9) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 23.487271ms)
Feb 24 19:54:41.717: INFO: (9) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 26.356174ms)
Feb 24 19:54:41.718: INFO: (9) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 26.362788ms)
Feb 24 19:54:41.721: INFO: (9) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 29.625637ms)
Feb 24 19:54:41.721: INFO: (9) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 30.336392ms)
Feb 24 19:54:41.722: INFO: (9) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 29.546353ms)
Feb 24 19:54:41.722: INFO: (9) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 30.277071ms)
Feb 24 19:54:41.722: INFO: (9) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 30.896147ms)
Feb 24 19:54:41.726: INFO: (9) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 34.476497ms)
Feb 24 19:54:41.727: INFO: (9) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 34.739718ms)
Feb 24 19:54:41.727: INFO: (9) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 35.550353ms)
Feb 24 19:54:41.727: INFO: (9) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 35.167083ms)
Feb 24 19:54:41.727: INFO: (9) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 35.738598ms)
Feb 24 19:54:41.798: INFO: (10) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 70.733158ms)
Feb 24 19:54:41.804: INFO: (10) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 75.50318ms)
Feb 24 19:54:41.804: INFO: (10) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 75.721876ms)
Feb 24 19:54:41.804: INFO: (10) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 76.108331ms)
Feb 24 19:54:41.805: INFO: (10) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 76.771347ms)
Feb 24 19:54:41.805: INFO: (10) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 77.057391ms)
Feb 24 19:54:41.810: INFO: (10) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 81.609596ms)
Feb 24 19:54:41.810: INFO: (10) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 82.393497ms)
Feb 24 19:54:41.810: INFO: (10) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 81.576056ms)
Feb 24 19:54:41.810: INFO: (10) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 81.703345ms)
Feb 24 19:54:41.810: INFO: (10) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 82.741897ms)
Feb 24 19:54:41.810: INFO: (10) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 82.272186ms)
Feb 24 19:54:41.811: INFO: (10) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 82.466955ms)
Feb 24 19:54:41.811: INFO: (10) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 82.378916ms)
Feb 24 19:54:41.813: INFO: (10) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 84.049948ms)
Feb 24 19:54:41.814: INFO: (10) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 85.605663ms)
Feb 24 19:54:41.847: INFO: (11) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 32.050715ms)
Feb 24 19:54:41.847: INFO: (11) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 32.374464ms)
Feb 24 19:54:41.852: INFO: (11) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 36.358731ms)
Feb 24 19:54:41.852: INFO: (11) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 37.740782ms)
Feb 24 19:54:41.852: INFO: (11) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 37.65855ms)
Feb 24 19:54:41.852: INFO: (11) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 37.805284ms)
Feb 24 19:54:41.853: INFO: (11) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 38.124826ms)
Feb 24 19:54:41.853: INFO: (11) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 38.276424ms)
Feb 24 19:54:41.853: INFO: (11) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 38.569389ms)
Feb 24 19:54:41.853: INFO: (11) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 38.193876ms)
Feb 24 19:54:41.853: INFO: (11) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 38.076102ms)
Feb 24 19:54:41.856: INFO: (11) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 40.957934ms)
Feb 24 19:54:41.857: INFO: (11) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 41.560582ms)
Feb 24 19:54:41.859: INFO: (11) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 44.443426ms)
Feb 24 19:54:41.859: INFO: (11) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 44.397132ms)
Feb 24 19:54:41.859: INFO: (11) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 44.568549ms)
Feb 24 19:54:41.882: INFO: (12) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 22.682068ms)
Feb 24 19:54:41.884: INFO: (12) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 23.748768ms)
Feb 24 19:54:41.884: INFO: (12) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 24.319262ms)
Feb 24 19:54:41.886: INFO: (12) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 25.088086ms)
Feb 24 19:54:41.886: INFO: (12) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 26.201136ms)
Feb 24 19:54:41.886: INFO: (12) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 25.471191ms)
Feb 24 19:54:41.886: INFO: (12) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 25.462668ms)
Feb 24 19:54:41.886: INFO: (12) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 26.27181ms)
Feb 24 19:54:41.886: INFO: (12) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 25.343821ms)
Feb 24 19:54:41.887: INFO: (12) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 26.757302ms)
Feb 24 19:54:41.893: INFO: (12) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 33.006323ms)
Feb 24 19:54:41.894: INFO: (12) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 33.516935ms)
Feb 24 19:54:41.895: INFO: (12) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 35.059144ms)
Feb 24 19:54:41.895: INFO: (12) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 34.593024ms)
Feb 24 19:54:41.897: INFO: (12) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 36.518784ms)
Feb 24 19:54:41.897: INFO: (12) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 36.367342ms)
Feb 24 19:54:41.924: INFO: (13) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 25.250306ms)
Feb 24 19:54:41.924: INFO: (13) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 26.022181ms)
Feb 24 19:54:41.924: INFO: (13) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 25.637126ms)
Feb 24 19:54:41.924: INFO: (13) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 26.553583ms)
Feb 24 19:54:41.924: INFO: (13) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 25.418388ms)
Feb 24 19:54:41.924: INFO: (13) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 25.648668ms)
Feb 24 19:54:41.924: INFO: (13) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 26.866943ms)
Feb 24 19:54:41.932: INFO: (13) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 34.523699ms)
Feb 24 19:54:41.932: INFO: (13) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 34.631816ms)
Feb 24 19:54:41.932: INFO: (13) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 34.782122ms)
Feb 24 19:54:41.948: INFO: (13) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 49.784683ms)
Feb 24 19:54:41.948: INFO: (13) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 50.179742ms)
Feb 24 19:54:41.948: INFO: (13) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 50.332405ms)
Feb 24 19:54:41.948: INFO: (13) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 50.492213ms)
Feb 24 19:54:41.948: INFO: (13) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 50.658056ms)
Feb 24 19:54:41.948: INFO: (13) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 50.257544ms)
Feb 24 19:54:41.974: INFO: (14) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 25.173664ms)
Feb 24 19:54:41.974: INFO: (14) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 25.637039ms)
Feb 24 19:54:41.976: INFO: (14) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 27.265965ms)
Feb 24 19:54:41.979: INFO: (14) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 27.916643ms)
Feb 24 19:54:41.979: INFO: (14) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 29.991149ms)
Feb 24 19:54:41.979: INFO: (14) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 28.324881ms)
Feb 24 19:54:41.979: INFO: (14) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 28.338136ms)
Feb 24 19:54:41.979: INFO: (14) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 30.784216ms)
Feb 24 19:54:41.980: INFO: (14) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 28.215287ms)
Feb 24 19:54:41.980: INFO: (14) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 30.725281ms)
Feb 24 19:54:41.981: INFO: (14) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 31.971178ms)
Feb 24 19:54:41.983: INFO: (14) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 32.16354ms)
Feb 24 19:54:41.983: INFO: (14) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 34.372143ms)
Feb 24 19:54:41.983: INFO: (14) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 34.349382ms)
Feb 24 19:54:41.986: INFO: (14) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 34.337165ms)
Feb 24 19:54:41.988: INFO: (14) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 36.975761ms)
Feb 24 19:54:42.007: INFO: (15) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 18.624124ms)
Feb 24 19:54:42.008: INFO: (15) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 19.161612ms)
Feb 24 19:54:42.008: INFO: (15) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 19.245664ms)
Feb 24 19:54:42.022: INFO: (15) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 32.670621ms)
Feb 24 19:54:42.022: INFO: (15) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 32.585261ms)
Feb 24 19:54:42.022: INFO: (15) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 32.709044ms)
Feb 24 19:54:42.022: INFO: (15) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 33.241042ms)
Feb 24 19:54:42.023: INFO: (15) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 32.804797ms)
Feb 24 19:54:42.023: INFO: (15) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 32.88167ms)
Feb 24 19:54:42.023: INFO: (15) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 32.97092ms)
Feb 24 19:54:42.023: INFO: (15) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 33.927651ms)
Feb 24 19:54:42.023: INFO: (15) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 34.346752ms)
Feb 24 19:54:42.023: INFO: (15) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 33.871409ms)
Feb 24 19:54:42.023: INFO: (15) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 33.544654ms)
Feb 24 19:54:42.023: INFO: (15) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 34.306501ms)
Feb 24 19:54:42.027: INFO: (15) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 36.981741ms)
Feb 24 19:54:42.040: INFO: (16) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 13.091304ms)
Feb 24 19:54:42.051: INFO: (16) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 23.420678ms)
Feb 24 19:54:42.051: INFO: (16) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 23.759718ms)
Feb 24 19:54:42.052: INFO: (16) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 24.589545ms)
Feb 24 19:54:42.052: INFO: (16) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 25.0488ms)
Feb 24 19:54:42.052: INFO: (16) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 25.182388ms)
Feb 24 19:54:42.052: INFO: (16) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 25.524678ms)
Feb 24 19:54:42.052: INFO: (16) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 25.448358ms)
Feb 24 19:54:42.053: INFO: (16) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 25.614387ms)
Feb 24 19:54:42.055: INFO: (16) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 27.947404ms)
Feb 24 19:54:42.055: INFO: (16) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 27.679707ms)
Feb 24 19:54:42.055: INFO: (16) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 28.120822ms)
Feb 24 19:54:42.057: INFO: (16) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 30.156867ms)
Feb 24 19:54:42.058: INFO: (16) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 30.467012ms)
Feb 24 19:54:42.058: INFO: (16) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 30.798557ms)
Feb 24 19:54:42.058: INFO: (16) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 30.651255ms)
Feb 24 19:54:42.072: INFO: (17) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 13.376067ms)
Feb 24 19:54:42.072: INFO: (17) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 13.490029ms)
Feb 24 19:54:42.074: INFO: (17) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 14.77315ms)
Feb 24 19:54:42.077: INFO: (17) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 17.83568ms)
Feb 24 19:54:42.078: INFO: (17) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 18.835952ms)
Feb 24 19:54:42.078: INFO: (17) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 18.8342ms)
Feb 24 19:54:42.079: INFO: (17) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 19.676698ms)
Feb 24 19:54:42.079: INFO: (17) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 19.586446ms)
Feb 24 19:54:42.079: INFO: (17) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 19.158203ms)
Feb 24 19:54:42.083: INFO: (17) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 24.163756ms)
Feb 24 19:54:42.083: INFO: (17) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 24.315783ms)
Feb 24 19:54:42.083: INFO: (17) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 23.750199ms)
Feb 24 19:54:42.083: INFO: (17) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 24.103259ms)
Feb 24 19:54:42.083: INFO: (17) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 24.039547ms)
Feb 24 19:54:42.084: INFO: (17) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 24.745356ms)
Feb 24 19:54:42.084: INFO: (17) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 24.652846ms)
Feb 24 19:54:42.105: INFO: (18) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 20.996538ms)
Feb 24 19:54:42.106: INFO: (18) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 22.223425ms)
Feb 24 19:54:42.113: INFO: (18) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 27.686264ms)
Feb 24 19:54:42.113: INFO: (18) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 28.257454ms)
Feb 24 19:54:42.113: INFO: (18) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 28.206144ms)
Feb 24 19:54:42.114: INFO: (18) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 28.256967ms)
Feb 24 19:54:42.114: INFO: (18) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 28.579854ms)
Feb 24 19:54:42.115: INFO: (18) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 29.927905ms)
Feb 24 19:54:42.115: INFO: (18) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 29.402412ms)
Feb 24 19:54:42.115: INFO: (18) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 30.495807ms)
Feb 24 19:54:42.116: INFO: (18) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 31.906995ms)
Feb 24 19:54:42.116: INFO: (18) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 31.963025ms)
Feb 24 19:54:42.118: INFO: (18) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 32.751648ms)
Feb 24 19:54:42.118: INFO: (18) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 33.77756ms)
Feb 24 19:54:42.119: INFO: (18) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 34.224901ms)
Feb 24 19:54:42.119: INFO: (18) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 33.780169ms)
Feb 24 19:54:42.140: INFO: (19) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:443/proxy/tlsrewriteme... (200; 20.992183ms)
Feb 24 19:54:42.140: INFO: (19) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:462/proxy/: tls qux (200; 20.242146ms)
Feb 24 19:54:42.140: INFO: (19) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname2/proxy/: bar (200; 21.041181ms)
Feb 24 19:54:42.141: INFO: (19) /api/v1/namespaces/proxy-378/pods/https:proxy-service-c6gp9-6k9fn:460/proxy/: tls baz (200; 20.58878ms)
Feb 24 19:54:42.141: INFO: (19) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname1/proxy/: tls baz (200; 21.279643ms)
Feb 24 19:54:42.141: INFO: (19) /api/v1/namespaces/proxy-378/services/https:proxy-service-c6gp9:tlsportname2/proxy/: tls qux (200; 21.65328ms)
Feb 24 19:54:42.141: INFO: (19) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 21.383302ms)
Feb 24 19:54:42.145: INFO: (19) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn/proxy/rewriteme">test</a> (200; 25.384577ms)
Feb 24 19:54:42.145: INFO: (19) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">test</... (200; 25.22975ms)
Feb 24 19:54:42.145: INFO: (19) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:1080/proxy/rewriteme">t... (200; 25.420264ms)
Feb 24 19:54:42.145: INFO: (19) /api/v1/namespaces/proxy-378/pods/http:proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 25.734982ms)
Feb 24 19:54:42.145: INFO: (19) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:160/proxy/: foo (200; 25.655078ms)
Feb 24 19:54:42.151: INFO: (19) /api/v1/namespaces/proxy-378/pods/proxy-service-c6gp9-6k9fn:162/proxy/: bar (200; 30.92048ms)
Feb 24 19:54:42.151: INFO: (19) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname2/proxy/: bar (200; 30.762905ms)
Feb 24 19:54:42.151: INFO: (19) /api/v1/namespaces/proxy-378/services/http:proxy-service-c6gp9:portname1/proxy/: foo (200; 30.925674ms)
Feb 24 19:54:42.151: INFO: (19) /api/v1/namespaces/proxy-378/services/proxy-service-c6gp9:portname1/proxy/: foo (200; 31.039287ms)
STEP: deleting ReplicationController proxy-service-c6gp9 in namespace proxy-378, will wait for the garbage collector to delete the pods
Feb 24 19:54:42.211: INFO: Deleting ReplicationController proxy-service-c6gp9 took: 7.283712ms
Feb 24 19:54:42.713: INFO: Terminating ReplicationController proxy-service-c6gp9 pods took: 501.582322ms
[AfterEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:54:50.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-378" for this suite.
Feb 24 19:54:56.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:54:56.695: INFO: namespace proxy-378 deletion completed in 6.153168545s

• [SLOW TEST:18.765 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:54:56.703: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3419
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 19:54:57.342: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 19:54:59.360: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170897, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170897, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170897, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718170897, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 19:55:02.390: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
Feb 24 19:55:02.413: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Feb 24 19:55:06.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 attach --namespace=webhook-3419 to-be-attached-pod -i -c=container1'
Feb 24 19:55:07.263: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:55:07.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3419" for this suite.
Feb 24 19:55:19.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:55:20.273: INFO: namespace webhook-3419 deletion completed in 12.682920551s
STEP: Destroying namespace "webhook-3419-markers" for this suite.
Feb 24 19:55:26.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:55:26.477: INFO: namespace webhook-3419-markers deletion completed in 6.203443225s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:29.794 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:55:26.499: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-625
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 19:55:26.678: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d438fe72-569a-4f9e-9e19-8013388a1acd" in namespace "projected-625" to be "success or failure"
Feb 24 19:55:26.684: INFO: Pod "downwardapi-volume-d438fe72-569a-4f9e-9e19-8013388a1acd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.167583ms
Feb 24 19:55:28.689: INFO: Pod "downwardapi-volume-d438fe72-569a-4f9e-9e19-8013388a1acd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010455945s
STEP: Saw pod success
Feb 24 19:55:28.689: INFO: Pod "downwardapi-volume-d438fe72-569a-4f9e-9e19-8013388a1acd" satisfied condition "success or failure"
Feb 24 19:55:28.692: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downwardapi-volume-d438fe72-569a-4f9e-9e19-8013388a1acd container client-container: <nil>
STEP: delete the pod
Feb 24 19:55:28.723: INFO: Waiting for pod downwardapi-volume-d438fe72-569a-4f9e-9e19-8013388a1acd to disappear
Feb 24 19:55:28.730: INFO: Pod downwardapi-volume-d438fe72-569a-4f9e-9e19-8013388a1acd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:55:28.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-625" for this suite.
Feb 24 19:55:34.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:55:34.933: INFO: namespace projected-625 deletion completed in 6.195103915s

• [SLOW TEST:8.434 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:55:34.937: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3749
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-5e3f7469-c51d-4d09-aac2-b36af1bd6d30
STEP: Creating a pod to test consume secrets
Feb 24 19:55:35.124: INFO: Waiting up to 5m0s for pod "pod-secrets-201f16e4-9929-435e-8460-2fc2b28810d4" in namespace "secrets-3749" to be "success or failure"
Feb 24 19:55:35.128: INFO: Pod "pod-secrets-201f16e4-9929-435e-8460-2fc2b28810d4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.204124ms
Feb 24 19:55:37.206: INFO: Pod "pod-secrets-201f16e4-9929-435e-8460-2fc2b28810d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08217125s
Feb 24 19:55:39.209: INFO: Pod "pod-secrets-201f16e4-9929-435e-8460-2fc2b28810d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.085658395s
STEP: Saw pod success
Feb 24 19:55:39.209: INFO: Pod "pod-secrets-201f16e4-9929-435e-8460-2fc2b28810d4" satisfied condition "success or failure"
Feb 24 19:55:39.212: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-secrets-201f16e4-9929-435e-8460-2fc2b28810d4 container secret-volume-test: <nil>
STEP: delete the pod
Feb 24 19:55:39.241: INFO: Waiting for pod pod-secrets-201f16e4-9929-435e-8460-2fc2b28810d4 to disappear
Feb 24 19:55:39.248: INFO: Pod pod-secrets-201f16e4-9929-435e-8460-2fc2b28810d4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:55:39.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3749" for this suite.
Feb 24 19:55:45.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:55:45.396: INFO: namespace secrets-3749 deletion completed in 6.143305019s

• [SLOW TEST:10.460 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:55:45.405: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2459
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:55:47.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2459" for this suite.
Feb 24 19:56:31.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:56:31.841: INFO: namespace kubelet-test-2459 deletion completed in 44.177043099s

• [SLOW TEST:46.437 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:56:31.845: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2647
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-857d0f72-1ad9-4545-92a4-4869b49d76be
STEP: Creating a pod to test consume configMaps
Feb 24 19:56:32.027: INFO: Waiting up to 5m0s for pod "pod-configmaps-40e39bc3-be5b-4ba9-a28d-a0995987acfa" in namespace "configmap-2647" to be "success or failure"
Feb 24 19:56:32.032: INFO: Pod "pod-configmaps-40e39bc3-be5b-4ba9-a28d-a0995987acfa": Phase="Pending", Reason="", readiness=false. Elapsed: 5.06277ms
Feb 24 19:56:34.041: INFO: Pod "pod-configmaps-40e39bc3-be5b-4ba9-a28d-a0995987acfa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013612182s
STEP: Saw pod success
Feb 24 19:56:34.041: INFO: Pod "pod-configmaps-40e39bc3-be5b-4ba9-a28d-a0995987acfa" satisfied condition "success or failure"
Feb 24 19:56:34.052: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-configmaps-40e39bc3-be5b-4ba9-a28d-a0995987acfa container configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 19:56:34.113: INFO: Waiting for pod pod-configmaps-40e39bc3-be5b-4ba9-a28d-a0995987acfa to disappear
Feb 24 19:56:34.118: INFO: Pod pod-configmaps-40e39bc3-be5b-4ba9-a28d-a0995987acfa no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:56:34.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2647" for this suite.
Feb 24 19:56:42.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:56:42.297: INFO: namespace configmap-2647 deletion completed in 8.173484281s

• [SLOW TEST:10.452 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:56:42.302: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2642
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-2642
STEP: creating replication controller nodeport-test in namespace services-2642
I0224 19:56:42.556911      17 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-2642, replica count: 2
I0224 19:56:45.607802      17 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 24 19:56:45.608: INFO: Creating new exec pod
Feb 24 19:56:48.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-2642 execpodbqq89 -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Feb 24 19:56:49.985: INFO: rc: 1
Feb 24 19:56:49.985: INFO: Service reachability failing with error: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-2642 execpodbqq89 -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80] []  <nil>  + nc -zv -t -w 2 nodeport-test 80
nc: connect to nodeport-test port 80 (tcp) failed: Connection refused
command terminated with exit code 1
 [] <nil> 0xc00200aab0 exit status 1 <nil> <nil> true [0xc001ff6708 0xc001ff6720 0xc001ff6738] [0xc001ff6708 0xc001ff6720 0xc001ff6738] [0xc001ff6718 0xc001ff6730] [0x10efe30 0x10efe30] 0xc008620f60 <nil>}:
Command stdout:

stderr:
+ nc -zv -t -w 2 nodeport-test 80
nc: connect to nodeport-test port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Feb 24 19:56:50.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-2642 execpodbqq89 -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Feb 24 19:56:52.230: INFO: rc: 1
Feb 24 19:56:52.230: INFO: Service reachability failing with error: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-2642 execpodbqq89 -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80] []  <nil>  + nc -zv -t -w 2 nodeport-test 80
nc: connect to nodeport-test port 80 (tcp) failed: Connection refused
command terminated with exit code 1
 [] <nil> 0xc00200b050 exit status 1 <nil> <nil> true [0xc001ff6740 0xc001ff6758 0xc001ff6770] [0xc001ff6740 0xc001ff6758 0xc001ff6770] [0xc001ff6750 0xc001ff6768] [0x10efe30 0x10efe30] 0xc0086214a0 <nil>}:
Command stdout:

stderr:
+ nc -zv -t -w 2 nodeport-test 80
nc: connect to nodeport-test port 80 (tcp) failed: Connection refused
command terminated with exit code 1

error:
exit status 1
Retrying...
Feb 24 19:56:52.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-2642 execpodbqq89 -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Feb 24 19:56:53.265: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Feb 24 19:56:53.265: INFO: stdout: ""
Feb 24 19:56:53.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-2642 execpodbqq89 -- /bin/sh -x -c nc -zv -t -w 2 10.77.6.89 80'
Feb 24 19:56:53.524: INFO: stderr: "+ nc -zv -t -w 2 10.77.6.89 80\nConnection to 10.77.6.89 80 port [tcp/http] succeeded!\n"
Feb 24 19:56:53.524: INFO: stdout: ""
Feb 24 19:56:53.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-2642 execpodbqq89 -- /bin/sh -x -c nc -zv -t -w 2 10.77.32.3 30180'
Feb 24 19:56:53.799: INFO: stderr: "+ nc -zv -t -w 2 10.77.32.3 30180\nConnection to 10.77.32.3 30180 port [tcp/30180] succeeded!\n"
Feb 24 19:56:53.799: INFO: stdout: ""
Feb 24 19:56:53.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-2642 execpodbqq89 -- /bin/sh -x -c nc -zv -t -w 2 10.77.32.4 30180'
Feb 24 19:56:54.078: INFO: stderr: "+ nc -zv -t -w 2 10.77.32.4 30180\nConnection to 10.77.32.4 30180 port [tcp/30180] succeeded!\n"
Feb 24 19:56:54.078: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:56:54.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2642" for this suite.
Feb 24 19:57:00.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:57:00.267: INFO: namespace services-2642 deletion completed in 6.183451651s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:17.965 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:57:00.271: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-8226
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Feb 24 19:57:00.969: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Feb 24 19:57:02.979: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718171020, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718171020, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718171021, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718171020, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 19:57:06.000: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 19:57:06.004: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:57:09.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-8226" for this suite.
Feb 24 19:57:16.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:57:16.166: INFO: namespace crd-webhook-8226 deletion completed in 6.16756264s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:15.927 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:57:16.205: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-4859
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 19:57:16.416: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-9b113b98-0ea0-4de7-9415-2f8c6055adc6" in namespace "security-context-test-4859" to be "success or failure"
Feb 24 19:57:16.421: INFO: Pod "busybox-privileged-false-9b113b98-0ea0-4de7-9415-2f8c6055adc6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.47102ms
Feb 24 19:57:18.539: INFO: Pod "busybox-privileged-false-9b113b98-0ea0-4de7-9415-2f8c6055adc6": Phase="Running", Reason="", readiness=true. Elapsed: 2.123388255s
Feb 24 19:57:20.543: INFO: Pod "busybox-privileged-false-9b113b98-0ea0-4de7-9415-2f8c6055adc6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.127840197s
Feb 24 19:57:20.544: INFO: Pod "busybox-privileged-false-9b113b98-0ea0-4de7-9415-2f8c6055adc6" satisfied condition "success or failure"
Feb 24 19:57:20.557: INFO: Got logs for pod "busybox-privileged-false-9b113b98-0ea0-4de7-9415-2f8c6055adc6": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:57:20.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4859" for this suite.
Feb 24 19:57:26.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:57:26.876: INFO: namespace security-context-test-4859 deletion completed in 6.315265488s

• [SLOW TEST:10.672 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:57:26.880: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1100
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 24 19:57:27.108: INFO: Waiting up to 5m0s for pod "pod-f3b110bb-fb65-4fb2-83ed-d1da2be6dc5c" in namespace "emptydir-1100" to be "success or failure"
Feb 24 19:57:27.112: INFO: Pod "pod-f3b110bb-fb65-4fb2-83ed-d1da2be6dc5c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044486ms
Feb 24 19:57:29.115: INFO: Pod "pod-f3b110bb-fb65-4fb2-83ed-d1da2be6dc5c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007198418s
STEP: Saw pod success
Feb 24 19:57:29.115: INFO: Pod "pod-f3b110bb-fb65-4fb2-83ed-d1da2be6dc5c" satisfied condition "success or failure"
Feb 24 19:57:29.118: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-f3b110bb-fb65-4fb2-83ed-d1da2be6dc5c container test-container: <nil>
STEP: delete the pod
Feb 24 19:57:29.144: INFO: Waiting for pod pod-f3b110bb-fb65-4fb2-83ed-d1da2be6dc5c to disappear
Feb 24 19:57:29.150: INFO: Pod pod-f3b110bb-fb65-4fb2-83ed-d1da2be6dc5c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:57:29.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1100" for this suite.
Feb 24 19:57:35.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:57:35.307: INFO: namespace emptydir-1100 deletion completed in 6.152514437s

• [SLOW TEST:8.428 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:57:35.310: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2334
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:57:39.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2334" for this suite.
Feb 24 19:57:45.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:57:45.707: INFO: namespace kubelet-test-2334 deletion completed in 6.152041147s

• [SLOW TEST:10.397 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:57:45.713: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2156
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-f9cffa22-3a0b-4c36-989a-a13c8aaac0b4
STEP: Creating secret with name secret-projected-all-test-volume-b3bca038-72b4-4be0-befd-45145b3ecbc7
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 24 19:57:45.999: INFO: Waiting up to 5m0s for pod "projected-volume-bc8393df-e669-4c9b-a7b9-e1d2ee67131e" in namespace "projected-2156" to be "success or failure"
Feb 24 19:57:46.006: INFO: Pod "projected-volume-bc8393df-e669-4c9b-a7b9-e1d2ee67131e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.706801ms
Feb 24 19:57:48.011: INFO: Pod "projected-volume-bc8393df-e669-4c9b-a7b9-e1d2ee67131e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01265767s
STEP: Saw pod success
Feb 24 19:57:48.012: INFO: Pod "projected-volume-bc8393df-e669-4c9b-a7b9-e1d2ee67131e" satisfied condition "success or failure"
Feb 24 19:57:48.016: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod projected-volume-bc8393df-e669-4c9b-a7b9-e1d2ee67131e container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 24 19:57:48.370: INFO: Waiting for pod projected-volume-bc8393df-e669-4c9b-a7b9-e1d2ee67131e to disappear
Feb 24 19:57:48.465: INFO: Pod projected-volume-bc8393df-e669-4c9b-a7b9-e1d2ee67131e no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:57:48.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2156" for this suite.
Feb 24 19:57:54.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:57:54.742: INFO: namespace projected-2156 deletion completed in 6.198054333s

• [SLOW TEST:9.029 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:57:54.743: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3599
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-fea84cc7-d1e0-47ae-85c8-17a5bec76e17
STEP: Creating a pod to test consume secrets
Feb 24 19:57:54.932: INFO: Waiting up to 5m0s for pod "pod-secrets-3b4141e9-eea1-4b9b-a127-cb4efe7d28f7" in namespace "secrets-3599" to be "success or failure"
Feb 24 19:57:54.957: INFO: Pod "pod-secrets-3b4141e9-eea1-4b9b-a127-cb4efe7d28f7": Phase="Pending", Reason="", readiness=false. Elapsed: 24.324319ms
Feb 24 19:57:56.960: INFO: Pod "pod-secrets-3b4141e9-eea1-4b9b-a127-cb4efe7d28f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027391008s
STEP: Saw pod success
Feb 24 19:57:56.960: INFO: Pod "pod-secrets-3b4141e9-eea1-4b9b-a127-cb4efe7d28f7" satisfied condition "success or failure"
Feb 24 19:57:56.964: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-secrets-3b4141e9-eea1-4b9b-a127-cb4efe7d28f7 container secret-volume-test: <nil>
STEP: delete the pod
Feb 24 19:57:56.994: INFO: Waiting for pod pod-secrets-3b4141e9-eea1-4b9b-a127-cb4efe7d28f7 to disappear
Feb 24 19:57:56.996: INFO: Pod pod-secrets-3b4141e9-eea1-4b9b-a127-cb4efe7d28f7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:57:56.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3599" for this suite.
Feb 24 19:58:03.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:58:03.201: INFO: namespace secrets-3599 deletion completed in 6.201028821s

• [SLOW TEST:8.459 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:58:03.208: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6925
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:58:20.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6925" for this suite.
Feb 24 19:58:26.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:58:26.806: INFO: namespace resourcequota-6925 deletion completed in 6.196571622s

• [SLOW TEST:23.599 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:58:26.809: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4689
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 24 19:58:27.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-4689'
Feb 24 19:58:27.130: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 24 19:58:27.131: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Feb 24 19:58:29.165: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-mwlhw]
Feb 24 19:58:29.165: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-mwlhw" in namespace "kubectl-4689" to be "running and ready"
Feb 24 19:58:29.169: INFO: Pod "e2e-test-httpd-rc-mwlhw": Phase="Running", Reason="", readiness=true. Elapsed: 3.56687ms
Feb 24 19:58:29.169: INFO: Pod "e2e-test-httpd-rc-mwlhw" satisfied condition "running and ready"
Feb 24 19:58:29.169: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-mwlhw]
Feb 24 19:58:29.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 logs rc/e2e-test-httpd-rc --namespace=kubectl-4689'
Feb 24 19:58:29.284: INFO: stderr: ""
Feb 24 19:58:29.284: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.12.0.163. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.12.0.163. Set the 'ServerName' directive globally to suppress this message\n[Mon Feb 24 19:58:28.254607 2020] [mpm_event:notice] [pid 1:tid 139761682013032] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Mon Feb 24 19:58:28.254790 2020] [core:notice] [pid 1:tid 139761682013032] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Feb 24 19:58:29.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 delete rc e2e-test-httpd-rc --namespace=kubectl-4689'
Feb 24 19:58:29.390: INFO: stderr: ""
Feb 24 19:58:29.390: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:58:29.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4689" for this suite.
Feb 24 19:58:35.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:58:35.561: INFO: namespace kubectl-4689 deletion completed in 6.157176109s

• [SLOW TEST:8.752 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:58:35.565: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3363
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 24 19:58:35.744: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3363 /api/v1/namespaces/watch-3363/configmaps/e2e-watch-test-watch-closed 3999e344-a3dd-4c74-8520-b841937a7e1d 30762 0 2020-02-24 19:58:35 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 24 19:58:35.745: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3363 /api/v1/namespaces/watch-3363/configmaps/e2e-watch-test-watch-closed 3999e344-a3dd-4c74-8520-b841937a7e1d 30763 0 2020-02-24 19:58:35 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 24 19:58:35.763: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3363 /api/v1/namespaces/watch-3363/configmaps/e2e-watch-test-watch-closed 3999e344-a3dd-4c74-8520-b841937a7e1d 30764 0 2020-02-24 19:58:35 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 24 19:58:35.763: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3363 /api/v1/namespaces/watch-3363/configmaps/e2e-watch-test-watch-closed 3999e344-a3dd-4c74-8520-b841937a7e1d 30765 0 2020-02-24 19:58:35 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:58:35.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3363" for this suite.
Feb 24 19:58:41.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:58:41.938: INFO: namespace watch-3363 deletion completed in 6.170185823s

• [SLOW TEST:6.373 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:58:41.947: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-7335
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-7335, will wait for the garbage collector to delete the pods
Feb 24 19:58:46.207: INFO: Deleting Job.batch foo took: 11.32546ms
Feb 24 19:58:46.307: INFO: Terminating Job.batch foo pods took: 100.27701ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 19:59:19.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7335" for this suite.
Feb 24 19:59:25.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 19:59:25.197: INFO: namespace job-7335 deletion completed in 6.167029396s

• [SLOW TEST:43.251 seconds]
[sig-apps] Job
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 19:59:25.201: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1836
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1836
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Feb 24 19:59:25.405: INFO: Found 0 stateful pods, waiting for 3
Feb 24 19:59:35.412: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 19:59:35.412: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 19:59:35.412: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 19:59:35.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=statefulset-1836 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 19:59:35.717: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 19:59:35.717: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 19:59:35.717: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Feb 24 19:59:45.791: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 24 19:59:55.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=statefulset-1836 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 19:59:56.145: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 24 19:59:56.145: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 24 19:59:56.145: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision
Feb 24 20:00:16.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=statefulset-1836 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 20:00:16.521: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 20:00:16.521: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 20:00:16.521: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 24 20:00:26.592: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 24 20:00:36.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=statefulset-1836 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 20:00:36.910: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 24 20:00:36.910: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 24 20:00:36.910: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 24 20:00:56.953: INFO: Waiting for StatefulSet statefulset-1836/ss2 to complete update
Feb 24 20:00:56.953: INFO: Waiting for Pod statefulset-1836/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 24 20:01:07.236: INFO: Deleting all statefulset in ns statefulset-1836
Feb 24 20:01:07.516: INFO: Scaling statefulset ss2 to 0
Feb 24 20:01:27.802: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 20:01:27.806: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:01:27.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1836" for this suite.
Feb 24 20:01:33.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:01:34.226: INFO: namespace statefulset-1836 deletion completed in 6.369711995s

• [SLOW TEST:129.025 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:01:34.229: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4964
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-kltq
STEP: Creating a pod to test atomic-volume-subpath
Feb 24 20:01:34.782: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-kltq" in namespace "subpath-4964" to be "success or failure"
Feb 24 20:01:34.797: INFO: Pod "pod-subpath-test-projected-kltq": Phase="Pending", Reason="", readiness=false. Elapsed: 15.242843ms
Feb 24 20:01:36.802: INFO: Pod "pod-subpath-test-projected-kltq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020026391s
Feb 24 20:01:38.807: INFO: Pod "pod-subpath-test-projected-kltq": Phase="Running", Reason="", readiness=true. Elapsed: 4.025574479s
Feb 24 20:01:40.812: INFO: Pod "pod-subpath-test-projected-kltq": Phase="Running", Reason="", readiness=true. Elapsed: 6.030558973s
Feb 24 20:01:42.816: INFO: Pod "pod-subpath-test-projected-kltq": Phase="Running", Reason="", readiness=true. Elapsed: 8.034256518s
Feb 24 20:01:44.819: INFO: Pod "pod-subpath-test-projected-kltq": Phase="Running", Reason="", readiness=true. Elapsed: 10.03725456s
Feb 24 20:01:46.832: INFO: Pod "pod-subpath-test-projected-kltq": Phase="Running", Reason="", readiness=true. Elapsed: 12.050541135s
Feb 24 20:01:48.838: INFO: Pod "pod-subpath-test-projected-kltq": Phase="Running", Reason="", readiness=true. Elapsed: 14.056623508s
Feb 24 20:01:50.843: INFO: Pod "pod-subpath-test-projected-kltq": Phase="Running", Reason="", readiness=true. Elapsed: 16.061273559s
Feb 24 20:01:52.848: INFO: Pod "pod-subpath-test-projected-kltq": Phase="Running", Reason="", readiness=true. Elapsed: 18.066438253s
Feb 24 20:01:54.852: INFO: Pod "pod-subpath-test-projected-kltq": Phase="Running", Reason="", readiness=true. Elapsed: 20.070219342s
Feb 24 20:01:56.855: INFO: Pod "pod-subpath-test-projected-kltq": Phase="Running", Reason="", readiness=true. Elapsed: 22.073319673s
Feb 24 20:01:58.880: INFO: Pod "pod-subpath-test-projected-kltq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.098518458s
STEP: Saw pod success
Feb 24 20:01:58.880: INFO: Pod "pod-subpath-test-projected-kltq" satisfied condition "success or failure"
Feb 24 20:01:58.914: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-subpath-test-projected-kltq container test-container-subpath-projected-kltq: <nil>
STEP: delete the pod
Feb 24 20:01:58.966: INFO: Waiting for pod pod-subpath-test-projected-kltq to disappear
Feb 24 20:01:58.990: INFO: Pod pod-subpath-test-projected-kltq no longer exists
STEP: Deleting pod pod-subpath-test-projected-kltq
Feb 24 20:01:58.990: INFO: Deleting pod "pod-subpath-test-projected-kltq" in namespace "subpath-4964"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:01:58.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4964" for this suite.
Feb 24 20:02:05.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:02:05.148: INFO: namespace subpath-4964 deletion completed in 6.150477815s

• [SLOW TEST:30.920 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:02:05.155: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3819
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3819.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-3819.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3819.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3819.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3819.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-3819.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3819.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-3819.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3819.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3819.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-3819.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3819.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-3819.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3819.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-3819.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3819.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-3819.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3819.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 24 20:02:09.456: INFO: DNS probes using dns-3819/dns-test-2a290ae9-45a8-4977-b13f-71497ea27625 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:02:09.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3819" for this suite.
Feb 24 20:02:15.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:02:15.685: INFO: namespace dns-3819 deletion completed in 6.160818115s

• [SLOW TEST:10.530 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:02:15.689: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-4829
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5168
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9091
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:02:22.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4829" for this suite.
Feb 24 20:02:28.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:02:29.135: INFO: namespace namespaces-4829 deletion completed in 6.166017779s
STEP: Destroying namespace "nsdeletetest-5168" for this suite.
Feb 24 20:02:29.139: INFO: Namespace nsdeletetest-5168 was already deleted
STEP: Destroying namespace "nsdeletetest-9091" for this suite.
Feb 24 20:02:35.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:02:35.324: INFO: namespace nsdeletetest-9091 deletion completed in 6.184603521s

• [SLOW TEST:19.635 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:02:35.328: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5585
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-20b8629d-e6d4-4f23-a4ad-a59eb7d64f16
STEP: Creating a pod to test consume secrets
Feb 24 20:02:35.528: INFO: Waiting up to 5m0s for pod "pod-secrets-8d8e4512-834f-4e68-94dd-2dbbd83c7166" in namespace "secrets-5585" to be "success or failure"
Feb 24 20:02:35.552: INFO: Pod "pod-secrets-8d8e4512-834f-4e68-94dd-2dbbd83c7166": Phase="Pending", Reason="", readiness=false. Elapsed: 23.881079ms
Feb 24 20:02:37.558: INFO: Pod "pod-secrets-8d8e4512-834f-4e68-94dd-2dbbd83c7166": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030182584s
Feb 24 20:02:39.562: INFO: Pod "pod-secrets-8d8e4512-834f-4e68-94dd-2dbbd83c7166": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03375549s
STEP: Saw pod success
Feb 24 20:02:39.562: INFO: Pod "pod-secrets-8d8e4512-834f-4e68-94dd-2dbbd83c7166" satisfied condition "success or failure"
Feb 24 20:02:39.566: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-secrets-8d8e4512-834f-4e68-94dd-2dbbd83c7166 container secret-volume-test: <nil>
STEP: delete the pod
Feb 24 20:02:39.597: INFO: Waiting for pod pod-secrets-8d8e4512-834f-4e68-94dd-2dbbd83c7166 to disappear
Feb 24 20:02:39.600: INFO: Pod pod-secrets-8d8e4512-834f-4e68-94dd-2dbbd83c7166 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:02:39.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5585" for this suite.
Feb 24 20:02:45.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:02:45.760: INFO: namespace secrets-5585 deletion completed in 6.151765079s

• [SLOW TEST:10.433 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:02:45.769: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8064
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Feb 24 20:02:45.923: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 24 20:02:45.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 create -f - --namespace=kubectl-8064'
Feb 24 20:02:46.323: INFO: stderr: ""
Feb 24 20:02:46.323: INFO: stdout: "service/redis-slave created\n"
Feb 24 20:02:46.323: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 24 20:02:46.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 create -f - --namespace=kubectl-8064'
Feb 24 20:02:46.593: INFO: stderr: ""
Feb 24 20:02:46.593: INFO: stdout: "service/redis-master created\n"
Feb 24 20:02:46.593: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 24 20:02:46.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 create -f - --namespace=kubectl-8064'
Feb 24 20:02:46.887: INFO: stderr: ""
Feb 24 20:02:46.887: INFO: stdout: "service/frontend created\n"
Feb 24 20:02:46.887: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 24 20:02:46.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 create -f - --namespace=kubectl-8064'
Feb 24 20:02:47.087: INFO: stderr: ""
Feb 24 20:02:47.088: INFO: stdout: "deployment.apps/frontend created\n"
Feb 24 20:02:47.088: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 24 20:02:47.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 create -f - --namespace=kubectl-8064'
Feb 24 20:02:47.374: INFO: stderr: ""
Feb 24 20:02:47.374: INFO: stdout: "deployment.apps/redis-master created\n"
Feb 24 20:02:47.374: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 24 20:02:47.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 create -f - --namespace=kubectl-8064'
Feb 24 20:02:48.001: INFO: stderr: ""
Feb 24 20:02:48.001: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Feb 24 20:02:48.001: INFO: Waiting for all frontend pods to be Running.
Feb 24 20:03:08.052: INFO: Waiting for frontend to serve content.
Feb 24 20:03:08.070: INFO: Trying to add a new entry to the guestbook.
Feb 24 20:03:08.083: INFO: Verifying that added entry can be retrieved.
Feb 24 20:03:08.097: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 24 20:03:13.112: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 24 20:03:18.307: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 24 20:03:23.327: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 24 20:03:28.356: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 24 20:03:33.379: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 24 20:03:38.396: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 24 20:03:43.412: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 24 20:03:48.643: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 24 20:03:53.657: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Feb 24 20:03:58.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 delete --grace-period=0 --force -f - --namespace=kubectl-8064'
Feb 24 20:03:59.152: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 24 20:03:59.152: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 24 20:03:59.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 delete --grace-period=0 --force -f - --namespace=kubectl-8064'
Feb 24 20:03:59.271: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 24 20:03:59.271: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 24 20:03:59.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 delete --grace-period=0 --force -f - --namespace=kubectl-8064'
Feb 24 20:03:59.448: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 24 20:03:59.448: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 24 20:03:59.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 delete --grace-period=0 --force -f - --namespace=kubectl-8064'
Feb 24 20:03:59.552: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 24 20:03:59.552: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 24 20:03:59.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 delete --grace-period=0 --force -f - --namespace=kubectl-8064'
Feb 24 20:03:59.668: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 24 20:03:59.668: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 24 20:03:59.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 delete --grace-period=0 --force -f - --namespace=kubectl-8064'
Feb 24 20:03:59.765: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 24 20:03:59.765: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:03:59.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8064" for this suite.
Feb 24 20:04:27.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:04:27.954: INFO: namespace kubectl-8064 deletion completed in 28.184096211s

• [SLOW TEST:102.185 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:04:27.963: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1322
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Feb 24 20:04:28.117: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Feb 24 20:04:42.816: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:04:46.616: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:05:02.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1322" for this suite.
Feb 24 20:05:10.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:05:10.618: INFO: namespace crd-publish-openapi-1322 deletion completed in 8.173749624s

• [SLOW TEST:42.656 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:05:10.622: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7128
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-7128
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-7128
STEP: creating replication controller externalsvc in namespace services-7128
I0224 20:05:10.864340      17 runners.go:184] Created replication controller with name: externalsvc, namespace: services-7128, replica count: 2
I0224 20:05:13.915084      17 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Feb 24 20:05:13.937: INFO: Creating new exec pod
Feb 24 20:05:17.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=services-7128 execpodpp7vw -- /bin/sh -x -c nslookup clusterip-service'
Feb 24 20:05:19.347: INFO: stderr: "+ nslookup clusterip-service\n"
Feb 24 20:05:19.347: INFO: stdout: "Server:\t\t10.77.0.10\nAddress:\t10.77.0.10#53\n\nclusterip-service.services-7128.svc.cluster.local\tcanonical name = externalsvc.services-7128.svc.cluster.local.\nName:\texternalsvc.services-7128.svc.cluster.local\nAddress: 10.77.7.41\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-7128, will wait for the garbage collector to delete the pods
Feb 24 20:05:19.408: INFO: Deleting ReplicationController externalsvc took: 7.217376ms
Feb 24 20:05:20.008: INFO: Terminating ReplicationController externalsvc pods took: 600.540806ms
Feb 24 20:05:30.844: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:05:30.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7128" for this suite.
Feb 24 20:05:36.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:05:37.053: INFO: namespace services-7128 deletion completed in 6.172882609s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:26.432 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:05:37.059: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2552
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2552.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2552.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2552.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2552.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 24 20:05:41.343: INFO: DNS probes using dns-test-a37ace9b-12ce-4433-8fcc-720e4b41d962 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2552.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2552.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2552.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2552.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 24 20:05:43.473: INFO: DNS probes using dns-test-8f678fe3-64db-48c6-ba38-7355faa4f082 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2552.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-2552.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2552.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-2552.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 24 20:05:45.608: INFO: DNS probes using dns-test-5b22fc1f-f142-4112-bc38-8169bfb06fc4 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:05:45.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2552" for this suite.
Feb 24 20:05:51.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:05:52.848: INFO: namespace dns-2552 deletion completed in 7.191622888s

• [SLOW TEST:15.790 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:05:52.849: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-2270
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb 24 20:05:58.234: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:05:58.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2270" for this suite.
Feb 24 20:06:10.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:06:11.036: INFO: namespace replicaset-2270 deletion completed in 12.407893709s

• [SLOW TEST:18.187 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:06:11.046: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-303
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-303
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 24 20:06:11.207: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 24 20:06:29.501: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.12.1.48 8081 | grep -v '^\s*$'] Namespace:pod-network-test-303 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 20:06:29.502: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:06:30.672: INFO: Found all expected endpoints: [netserver-0]
Feb 24 20:06:30.676: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.12.2.46 8081 | grep -v '^\s*$'] Namespace:pod-network-test-303 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 20:06:30.676: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:06:31.882: INFO: Found all expected endpoints: [netserver-1]
Feb 24 20:06:31.887: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.12.0.179 8081 | grep -v '^\s*$'] Namespace:pod-network-test-303 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 20:06:31.887: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:06:33.084: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:06:33.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-303" for this suite.
Feb 24 20:06:45.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:06:45.227: INFO: namespace pod-network-test-303 deletion completed in 12.137595219s

• [SLOW TEST:34.182 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:06:45.232: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8128
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:06:45.441: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb 24 20:06:49.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-8128 create -f -'
Feb 24 20:06:50.040: INFO: stderr: ""
Feb 24 20:06:50.040: INFO: stdout: "e2e-test-crd-publish-openapi-3836-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Feb 24 20:06:50.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-8128 delete e2e-test-crd-publish-openapi-3836-crds test-cr'
Feb 24 20:06:50.130: INFO: stderr: ""
Feb 24 20:06:50.130: INFO: stdout: "e2e-test-crd-publish-openapi-3836-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Feb 24 20:06:50.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-8128 apply -f -'
Feb 24 20:06:50.435: INFO: stderr: ""
Feb 24 20:06:50.435: INFO: stdout: "e2e-test-crd-publish-openapi-3836-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Feb 24 20:06:50.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-8128 delete e2e-test-crd-publish-openapi-3836-crds test-cr'
Feb 24 20:06:50.527: INFO: stderr: ""
Feb 24 20:06:50.527: INFO: stdout: "e2e-test-crd-publish-openapi-3836-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Feb 24 20:06:50.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 explain e2e-test-crd-publish-openapi-3836-crds'
Feb 24 20:06:50.773: INFO: stderr: ""
Feb 24 20:06:50.773: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3836-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:06:55.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8128" for this suite.
Feb 24 20:07:01.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:07:01.701: INFO: namespace crd-publish-openapi-8128 deletion completed in 6.160983534s

• [SLOW TEST:16.470 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:07:01.706: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7748
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 20:07:02.267: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Feb 24 20:07:04.317: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718171622, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718171622, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718171622, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718171622, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 20:07:07.417: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:07:07.422: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2913-crds.webhook.example.com via the AdmissionRegistration API
Feb 24 20:07:08.052: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:07:10.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7748" for this suite.
Feb 24 20:07:16.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:07:16.460: INFO: namespace webhook-7748 deletion completed in 6.23540459s
STEP: Destroying namespace "webhook-7748-markers" for this suite.
Feb 24 20:07:22.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:07:22.847: INFO: namespace webhook-7748-markers deletion completed in 6.386008786s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.202 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:07:22.908: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5720
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-bece6437-e1bf-40b9-8fbb-583fb51a55d4
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-bece6437-e1bf-40b9-8fbb-583fb51a55d4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:08:56.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5720" for this suite.
Feb 24 20:09:24.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:09:24.952: INFO: namespace configmap-5720 deletion completed in 28.225898488s

• [SLOW TEST:122.044 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:09:24.953: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3623
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-3623
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 24 20:09:25.217: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 24 20:09:47.632: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.12.0.184:8080/dial?request=hostName&protocol=udp&host=10.12.0.183&port=8081&tries=1'] Namespace:pod-network-test-3623 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 20:09:47.632: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:09:47.944: INFO: Waiting for endpoints: map[]
Feb 24 20:09:47.949: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.12.0.184:8080/dial?request=hostName&protocol=udp&host=10.12.1.49&port=8081&tries=1'] Namespace:pod-network-test-3623 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 20:09:47.949: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:09:48.172: INFO: Waiting for endpoints: map[]
Feb 24 20:09:48.272: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.12.0.184:8080/dial?request=hostName&protocol=udp&host=10.12.2.47&port=8081&tries=1'] Namespace:pod-network-test-3623 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 20:09:48.273: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:09:48.676: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:09:48.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3623" for this suite.
Feb 24 20:10:00.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:10:00.881: INFO: namespace pod-network-test-3623 deletion completed in 12.187717791s

• [SLOW TEST:35.928 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:10:00.886: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-9940
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Feb 24 20:10:01.077: INFO: Waiting up to 5m0s for pod "var-expansion-4a057593-4ba8-45bf-929c-9da46a76849d" in namespace "var-expansion-9940" to be "success or failure"
Feb 24 20:10:01.094: INFO: Pod "var-expansion-4a057593-4ba8-45bf-929c-9da46a76849d": Phase="Pending", Reason="", readiness=false. Elapsed: 17.078159ms
Feb 24 20:10:03.154: INFO: Pod "var-expansion-4a057593-4ba8-45bf-929c-9da46a76849d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.077577949s
STEP: Saw pod success
Feb 24 20:10:03.155: INFO: Pod "var-expansion-4a057593-4ba8-45bf-929c-9da46a76849d" satisfied condition "success or failure"
Feb 24 20:10:03.259: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod var-expansion-4a057593-4ba8-45bf-929c-9da46a76849d container dapi-container: <nil>
STEP: delete the pod
Feb 24 20:10:03.725: INFO: Waiting for pod var-expansion-4a057593-4ba8-45bf-929c-9da46a76849d to disappear
Feb 24 20:10:03.819: INFO: Pod var-expansion-4a057593-4ba8-45bf-929c-9da46a76849d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:10:03.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9940" for this suite.
Feb 24 20:10:09.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:10:10.090: INFO: namespace var-expansion-9940 deletion completed in 6.179648647s

• [SLOW TEST:9.206 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:10:10.092: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5037
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:10:22.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5037" for this suite.
Feb 24 20:10:28.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:10:28.962: INFO: namespace resourcequota-5037 deletion completed in 6.215654148s

• [SLOW TEST:18.870 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:10:28.971: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9435
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:10:29.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 version'
Feb 24 20:10:29.224: INFO: stderr: ""
Feb 24 20:10:29.224: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.4\", GitCommit:\"224be7bdce5a9dd0c2fd0d46b83865648e2fe0ba\", GitTreeState:\"clean\", BuildDate:\"2019-12-11T12:47:40Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16+\", GitVersion:\"v1.16.4-gke.30\", GitCommit:\"3ad237299eb4e2752046c512eacc8187bad0a041\", GitTreeState:\"clean\", BuildDate:\"2020-01-31T11:17:48Z\", GoVersion:\"go1.12.12b4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:10:29.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9435" for this suite.
Feb 24 20:10:35.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:10:35.395: INFO: namespace kubectl-9435 deletion completed in 6.165969187s

• [SLOW TEST:6.424 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:10:35.398: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9135
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Feb 24 20:10:35.588: INFO: Waiting up to 5m0s for pod "client-containers-949849de-96ae-4159-95a5-d3b4ae767a41" in namespace "containers-9135" to be "success or failure"
Feb 24 20:10:35.591: INFO: Pod "client-containers-949849de-96ae-4159-95a5-d3b4ae767a41": Phase="Pending", Reason="", readiness=false. Elapsed: 3.329566ms
Feb 24 20:10:37.599: INFO: Pod "client-containers-949849de-96ae-4159-95a5-d3b4ae767a41": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010963035s
Feb 24 20:10:39.603: INFO: Pod "client-containers-949849de-96ae-4159-95a5-d3b4ae767a41": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014935409s
STEP: Saw pod success
Feb 24 20:10:39.603: INFO: Pod "client-containers-949849de-96ae-4159-95a5-d3b4ae767a41" satisfied condition "success or failure"
Feb 24 20:10:39.607: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod client-containers-949849de-96ae-4159-95a5-d3b4ae767a41 container test-container: <nil>
STEP: delete the pod
Feb 24 20:10:39.633: INFO: Waiting for pod client-containers-949849de-96ae-4159-95a5-d3b4ae767a41 to disappear
Feb 24 20:10:39.639: INFO: Pod client-containers-949849de-96ae-4159-95a5-d3b4ae767a41 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:10:39.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9135" for this suite.
Feb 24 20:10:45.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:10:45.812: INFO: namespace containers-9135 deletion completed in 6.16879796s

• [SLOW TEST:10.415 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:10:45.820: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9324
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:10:46.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9324" for this suite.
Feb 24 20:10:52.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:10:53.024: INFO: namespace resourcequota-9324 deletion completed in 6.985091777s

• [SLOW TEST:7.204 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:10:53.027: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-608
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-608
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-608 to expose endpoints map[]
Feb 24 20:10:53.293: INFO: Get endpoints failed (26.069988ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb 24 20:10:54.297: INFO: successfully validated that service multi-endpoint-test in namespace services-608 exposes endpoints map[] (1.02989715s elapsed)
STEP: Creating pod pod1 in namespace services-608
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-608 to expose endpoints map[pod1:[100]]
Feb 24 20:10:56.359: INFO: successfully validated that service multi-endpoint-test in namespace services-608 exposes endpoints map[pod1:[100]] (2.039538242s elapsed)
STEP: Creating pod pod2 in namespace services-608
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-608 to expose endpoints map[pod1:[100] pod2:[101]]
Feb 24 20:10:58.714: INFO: successfully validated that service multi-endpoint-test in namespace services-608 exposes endpoints map[pod1:[100] pod2:[101]] (2.338536465s elapsed)
STEP: Deleting pod pod1 in namespace services-608
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-608 to expose endpoints map[pod2:[101]]
Feb 24 20:10:59.777: INFO: successfully validated that service multi-endpoint-test in namespace services-608 exposes endpoints map[pod2:[101]] (1.02345042s elapsed)
STEP: Deleting pod pod2 in namespace services-608
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-608 to expose endpoints map[]
Feb 24 20:11:00.823: INFO: successfully validated that service multi-endpoint-test in namespace services-608 exposes endpoints map[] (1.035894546s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:11:00.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-608" for this suite.
Feb 24 20:11:12.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:11:13.041: INFO: namespace services-608 deletion completed in 12.153042313s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:20.014 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:11:13.042: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9923
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 24 20:11:13.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-9923'
Feb 24 20:11:13.374: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 24 20:11:13.374: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Feb 24 20:11:15.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 delete deployment e2e-test-httpd-deployment --namespace=kubectl-9923'
Feb 24 20:11:15.494: INFO: stderr: ""
Feb 24 20:11:15.494: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:11:15.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9923" for this suite.
Feb 24 20:11:21.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:11:22.051: INFO: namespace kubectl-9923 deletion completed in 6.550118606s

• [SLOW TEST:9.009 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:11:22.054: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-108
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 20:11:23.450: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 20:11:26.542: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:11:26.545: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7738-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:11:28.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-108" for this suite.
Feb 24 20:11:35.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:11:35.147: INFO: namespace webhook-108 deletion completed in 6.233245486s
STEP: Destroying namespace "webhook-108-markers" for this suite.
Feb 24 20:11:41.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:11:41.332: INFO: namespace webhook-108-markers deletion completed in 6.184368749s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.456 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:11:41.515: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4264
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Feb 24 20:11:41.994: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:12:05.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4264" for this suite.
Feb 24 20:12:11.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:12:11.360: INFO: namespace crd-publish-openapi-4264 deletion completed in 6.149583112s

• [SLOW TEST:29.846 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:12:11.362: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1375
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-0f409374-1b49-4d8e-9efd-c270bfa335ab
STEP: Creating a pod to test consume configMaps
Feb 24 20:12:11.563: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2c8a56d7-bbd4-4e6e-a619-2e63b5030c24" in namespace "projected-1375" to be "success or failure"
Feb 24 20:12:11.571: INFO: Pod "pod-projected-configmaps-2c8a56d7-bbd4-4e6e-a619-2e63b5030c24": Phase="Pending", Reason="", readiness=false. Elapsed: 7.786588ms
Feb 24 20:12:13.575: INFO: Pod "pod-projected-configmaps-2c8a56d7-bbd4-4e6e-a619-2e63b5030c24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012084916s
STEP: Saw pod success
Feb 24 20:12:13.575: INFO: Pod "pod-projected-configmaps-2c8a56d7-bbd4-4e6e-a619-2e63b5030c24" satisfied condition "success or failure"
Feb 24 20:12:13.579: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-projected-configmaps-2c8a56d7-bbd4-4e6e-a619-2e63b5030c24 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 20:12:13.631: INFO: Waiting for pod pod-projected-configmaps-2c8a56d7-bbd4-4e6e-a619-2e63b5030c24 to disappear
Feb 24 20:12:13.636: INFO: Pod pod-projected-configmaps-2c8a56d7-bbd4-4e6e-a619-2e63b5030c24 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:12:13.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1375" for this suite.
Feb 24 20:12:21.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:12:22.263: INFO: namespace projected-1375 deletion completed in 8.622614632s

• [SLOW TEST:10.902 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:12:22.270: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5896
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 24 20:12:27.088: INFO: Successfully updated pod "pod-update-activedeadlineseconds-b934e788-770e-4196-bebe-38935afa1d55"
Feb 24 20:12:27.088: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-b934e788-770e-4196-bebe-38935afa1d55" in namespace "pods-5896" to be "terminated due to deadline exceeded"
Feb 24 20:12:27.091: INFO: Pod "pod-update-activedeadlineseconds-b934e788-770e-4196-bebe-38935afa1d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.094554ms
Feb 24 20:12:29.094: INFO: Pod "pod-update-activedeadlineseconds-b934e788-770e-4196-bebe-38935afa1d55": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.005164182s
Feb 24 20:12:29.094: INFO: Pod "pod-update-activedeadlineseconds-b934e788-770e-4196-bebe-38935afa1d55" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:12:29.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5896" for this suite.
Feb 24 20:12:35.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:12:35.236: INFO: namespace pods-5896 deletion completed in 6.137670907s

• [SLOW TEST:12.967 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:12:35.239: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7082
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 20:12:35.937: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 20:12:38.988: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:12:39.079: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:12:40.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7082" for this suite.
Feb 24 20:12:47.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:12:47.411: INFO: namespace webhook-7082 deletion completed in 6.422916412s
STEP: Destroying namespace "webhook-7082-markers" for this suite.
Feb 24 20:12:55.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:12:55.566: INFO: namespace webhook-7082-markers deletion completed in 8.15397729s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:20.345 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:12:55.592: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-7410
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:12:55.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7410" for this suite.
Feb 24 20:13:01.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:13:01.964: INFO: namespace custom-resource-definition-7410 deletion completed in 6.202842606s

• [SLOW TEST:6.373 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:13:01.966: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-733
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 20:13:02.151: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c6c97239-f03a-47e1-b781-6e6cfd66de93" in namespace "downward-api-733" to be "success or failure"
Feb 24 20:13:02.159: INFO: Pod "downwardapi-volume-c6c97239-f03a-47e1-b781-6e6cfd66de93": Phase="Pending", Reason="", readiness=false. Elapsed: 6.818174ms
Feb 24 20:13:04.162: INFO: Pod "downwardapi-volume-c6c97239-f03a-47e1-b781-6e6cfd66de93": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010222864s
Feb 24 20:13:06.166: INFO: Pod "downwardapi-volume-c6c97239-f03a-47e1-b781-6e6cfd66de93": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013546585s
STEP: Saw pod success
Feb 24 20:13:06.166: INFO: Pod "downwardapi-volume-c6c97239-f03a-47e1-b781-6e6cfd66de93" satisfied condition "success or failure"
Feb 24 20:13:06.169: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downwardapi-volume-c6c97239-f03a-47e1-b781-6e6cfd66de93 container client-container: <nil>
STEP: delete the pod
Feb 24 20:13:06.200: INFO: Waiting for pod downwardapi-volume-c6c97239-f03a-47e1-b781-6e6cfd66de93 to disappear
Feb 24 20:13:06.204: INFO: Pod downwardapi-volume-c6c97239-f03a-47e1-b781-6e6cfd66de93 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:13:06.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-733" for this suite.
Feb 24 20:13:12.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:13:12.393: INFO: namespace downward-api-733 deletion completed in 6.178278188s

• [SLOW TEST:10.428 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:13:12.400: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5516
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 24 20:13:12.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-5516'
Feb 24 20:13:12.705: INFO: stderr: ""
Feb 24 20:13:12.705: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Feb 24 20:13:12.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 delete pods e2e-test-httpd-pod --namespace=kubectl-5516'
Feb 24 20:13:20.507: INFO: stderr: ""
Feb 24 20:13:20.507: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:13:20.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5516" for this suite.
Feb 24 20:13:26.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:13:26.741: INFO: namespace kubectl-5516 deletion completed in 6.222650059s

• [SLOW TEST:14.342 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:13:26.744: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1973
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb 24 20:13:26.911: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:13:30.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1973" for this suite.
Feb 24 20:13:42.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:13:42.910: INFO: namespace init-container-1973 deletion completed in 12.159947024s

• [SLOW TEST:16.167 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:13:42.914: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1251
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-7dfb16d7-9c6d-4533-8099-ff60062281e6
STEP: Creating a pod to test consume secrets
Feb 24 20:13:43.105: INFO: Waiting up to 5m0s for pod "pod-secrets-91f8d528-8a61-45e5-bd56-b71741eab3cd" in namespace "secrets-1251" to be "success or failure"
Feb 24 20:13:43.124: INFO: Pod "pod-secrets-91f8d528-8a61-45e5-bd56-b71741eab3cd": Phase="Pending", Reason="", readiness=false. Elapsed: 18.773986ms
Feb 24 20:13:45.128: INFO: Pod "pod-secrets-91f8d528-8a61-45e5-bd56-b71741eab3cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022548055s
STEP: Saw pod success
Feb 24 20:13:45.128: INFO: Pod "pod-secrets-91f8d528-8a61-45e5-bd56-b71741eab3cd" satisfied condition "success or failure"
Feb 24 20:13:45.131: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-secrets-91f8d528-8a61-45e5-bd56-b71741eab3cd container secret-env-test: <nil>
STEP: delete the pod
Feb 24 20:13:45.159: INFO: Waiting for pod pod-secrets-91f8d528-8a61-45e5-bd56-b71741eab3cd to disappear
Feb 24 20:13:45.166: INFO: Pod pod-secrets-91f8d528-8a61-45e5-bd56-b71741eab3cd no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:13:45.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1251" for this suite.
Feb 24 20:13:51.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:13:51.351: INFO: namespace secrets-1251 deletion completed in 6.180941078s

• [SLOW TEST:8.438 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:13:51.354: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1646
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 24 20:13:54.089: INFO: Successfully updated pod "pod-update-b5d42dbf-629b-494e-b135-3ab45c834246"
STEP: verifying the updated pod is in kubernetes
Feb 24 20:13:54.110: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:13:54.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1646" for this suite.
Feb 24 20:14:22.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:14:23.306: INFO: namespace pods-1646 deletion completed in 29.186861135s

• [SLOW TEST:31.953 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:14:23.310: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4662
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:14:25.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4662" for this suite.
Feb 24 20:15:09.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:15:09.790: INFO: namespace kubelet-test-4662 deletion completed in 44.174621663s

• [SLOW TEST:46.481 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:15:09.795: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5955
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Feb 24 20:15:09.963: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:15:13.759: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:15:29.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5955" for this suite.
Feb 24 20:15:35.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:15:36.001: INFO: namespace crd-publish-openapi-5955 deletion completed in 6.201483779s

• [SLOW TEST:26.207 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:15:36.004: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8990
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-9780
STEP: Creating secret with name secret-test-2506029e-564a-4094-b90d-f6431b463a7e
STEP: Creating a pod to test consume secrets
Feb 24 20:15:36.420: INFO: Waiting up to 5m0s for pod "pod-secrets-84af8dae-0faf-4d31-ab98-67e0f9737a64" in namespace "secrets-8990" to be "success or failure"
Feb 24 20:15:36.423: INFO: Pod "pod-secrets-84af8dae-0faf-4d31-ab98-67e0f9737a64": Phase="Pending", Reason="", readiness=false. Elapsed: 2.321525ms
Feb 24 20:15:38.545: INFO: Pod "pod-secrets-84af8dae-0faf-4d31-ab98-67e0f9737a64": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.124265084s
STEP: Saw pod success
Feb 24 20:15:38.545: INFO: Pod "pod-secrets-84af8dae-0faf-4d31-ab98-67e0f9737a64" satisfied condition "success or failure"
Feb 24 20:15:38.636: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-secrets-84af8dae-0faf-4d31-ab98-67e0f9737a64 container secret-volume-test: <nil>
STEP: delete the pod
Feb 24 20:15:38.916: INFO: Waiting for pod pod-secrets-84af8dae-0faf-4d31-ab98-67e0f9737a64 to disappear
Feb 24 20:15:38.923: INFO: Pod pod-secrets-84af8dae-0faf-4d31-ab98-67e0f9737a64 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:15:38.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8990" for this suite.
Feb 24 20:15:44.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:15:45.072: INFO: namespace secrets-8990 deletion completed in 6.145483266s
STEP: Destroying namespace "secret-namespace-9780" for this suite.
Feb 24 20:15:51.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:15:51.240: INFO: namespace secret-namespace-9780 deletion completed in 6.166894855s

• [SLOW TEST:15.236 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:15:51.243: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4987
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 24 20:15:51.423: INFO: Waiting up to 5m0s for pod "pod-86028af3-5816-4ecf-8eab-6a053e31d044" in namespace "emptydir-4987" to be "success or failure"
Feb 24 20:15:51.439: INFO: Pod "pod-86028af3-5816-4ecf-8eab-6a053e31d044": Phase="Pending", Reason="", readiness=false. Elapsed: 15.91797ms
Feb 24 20:15:53.450: INFO: Pod "pod-86028af3-5816-4ecf-8eab-6a053e31d044": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027051303s
STEP: Saw pod success
Feb 24 20:15:53.450: INFO: Pod "pod-86028af3-5816-4ecf-8eab-6a053e31d044" satisfied condition "success or failure"
Feb 24 20:15:53.459: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-86028af3-5816-4ecf-8eab-6a053e31d044 container test-container: <nil>
STEP: delete the pod
Feb 24 20:15:53.498: INFO: Waiting for pod pod-86028af3-5816-4ecf-8eab-6a053e31d044 to disappear
Feb 24 20:15:53.508: INFO: Pod pod-86028af3-5816-4ecf-8eab-6a053e31d044 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:15:53.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4987" for this suite.
Feb 24 20:16:01.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:16:01.681: INFO: namespace emptydir-4987 deletion completed in 8.167328512s

• [SLOW TEST:10.439 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:16:01.685: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4713
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0224 20:16:42.256841      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 24 20:16:42.257: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:16:42.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4713" for this suite.
Feb 24 20:16:48.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:16:49.712: INFO: namespace gc-4713 deletion completed in 7.449264644s

• [SLOW TEST:48.027 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:16:49.715: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1129
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:16:49.941: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb 24 20:16:55.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-1129 create -f -'
Feb 24 20:16:55.951: INFO: stderr: ""
Feb 24 20:16:55.951: INFO: stdout: "e2e-test-crd-publish-openapi-7057-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Feb 24 20:16:55.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-1129 delete e2e-test-crd-publish-openapi-7057-crds test-cr'
Feb 24 20:16:56.048: INFO: stderr: ""
Feb 24 20:16:56.048: INFO: stdout: "e2e-test-crd-publish-openapi-7057-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Feb 24 20:16:56.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-1129 apply -f -'
Feb 24 20:16:56.288: INFO: stderr: ""
Feb 24 20:16:56.288: INFO: stdout: "e2e-test-crd-publish-openapi-7057-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Feb 24 20:16:56.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-1129 delete e2e-test-crd-publish-openapi-7057-crds test-cr'
Feb 24 20:16:56.392: INFO: stderr: ""
Feb 24 20:16:56.392: INFO: stdout: "e2e-test-crd-publish-openapi-7057-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Feb 24 20:16:56.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 explain e2e-test-crd-publish-openapi-7057-crds'
Feb 24 20:16:56.655: INFO: stderr: ""
Feb 24 20:16:56.655: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7057-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:17:01.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1129" for this suite.
Feb 24 20:17:07.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:17:07.838: INFO: namespace crd-publish-openapi-1129 deletion completed in 6.800788028s

• [SLOW TEST:18.124 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:17:07.841: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4036
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 20:17:08.540: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 20:17:10.550: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718172228, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718172228, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718172228, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718172228, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 20:17:13.652: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:17:13.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4036" for this suite.
Feb 24 20:17:25.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:17:25.915: INFO: namespace webhook-4036 deletion completed in 12.189174441s
STEP: Destroying namespace "webhook-4036-markers" for this suite.
Feb 24 20:17:31.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:17:32.065: INFO: namespace webhook-4036-markers deletion completed in 6.1486175s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.242 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:17:32.089: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-6585
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 24 20:17:36.477: INFO: &Pod{ObjectMeta:{send-events-9d0b8d6c-d4a5-49b5-8976-e9be3da873ae  events-6585 /api/v1/namespaces/events-6585/pods/send-events-9d0b8d6c-d4a5-49b5-8976-e9be3da873ae 2a58efd8-9f7a-4206-8735-b157d8e19c7d 37517 0 2020-02-24 20:17:32 +0000 UTC <nil> <nil> map[name:foo time:308637715] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-psrnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-psrnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-psrnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-fss3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 20:17:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 20:17:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 20:17:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 20:17:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.2,PodIP:10.12.0.206,StartTime:2020-02-24 20:17:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 20:17:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://d29bfb9cedad2032ab78f982a9e6e12d8756b979b875d530d34ee15134827765,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.12.0.206,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Feb 24 20:17:38.481: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 24 20:17:40.485: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:17:40.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6585" for this suite.
Feb 24 20:18:26.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:18:26.671: INFO: namespace events-6585 deletion completed in 46.170409973s

• [SLOW TEST:54.583 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:18:26.677: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8619
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:18:26.881: INFO: Create a RollingUpdate DaemonSet
Feb 24 20:18:26.888: INFO: Check that daemon pods launch on every node of the cluster
Feb 24 20:18:26.913: INFO: Number of nodes with available pods: 0
Feb 24 20:18:26.913: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 20:18:27.921: INFO: Number of nodes with available pods: 0
Feb 24 20:18:27.921: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 20:18:28.927: INFO: Number of nodes with available pods: 1
Feb 24 20:18:28.927: INFO: Node gke-c116p-default-pool-41de4435-50z7 is running more than one daemon pod
Feb 24 20:18:29.927: INFO: Number of nodes with available pods: 3
Feb 24 20:18:29.927: INFO: Number of running nodes: 3, number of available pods: 3
Feb 24 20:18:29.927: INFO: Update the DaemonSet to trigger a rollout
Feb 24 20:18:29.943: INFO: Updating DaemonSet daemon-set
Feb 24 20:18:40.964: INFO: Roll back the DaemonSet before rollout is complete
Feb 24 20:18:40.974: INFO: Updating DaemonSet daemon-set
Feb 24 20:18:40.975: INFO: Make sure DaemonSet rollback is complete
Feb 24 20:18:40.980: INFO: Wrong image for pod: daemon-set-nbww2. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb 24 20:18:40.980: INFO: Pod daemon-set-nbww2 is not available
Feb 24 20:18:41.991: INFO: Wrong image for pod: daemon-set-nbww2. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb 24 20:18:41.991: INFO: Pod daemon-set-nbww2 is not available
Feb 24 20:18:42.991: INFO: Wrong image for pod: daemon-set-nbww2. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb 24 20:18:42.991: INFO: Pod daemon-set-nbww2 is not available
Feb 24 20:18:43.991: INFO: Wrong image for pod: daemon-set-nbww2. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb 24 20:18:43.991: INFO: Pod daemon-set-nbww2 is not available
Feb 24 20:18:44.991: INFO: Wrong image for pod: daemon-set-nbww2. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb 24 20:18:44.992: INFO: Pod daemon-set-nbww2 is not available
Feb 24 20:18:46.993: INFO: Pod daemon-set-68c99 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8619, will wait for the garbage collector to delete the pods
Feb 24 20:18:47.091: INFO: Deleting DaemonSet.extensions daemon-set took: 18.234283ms
Feb 24 20:18:47.692: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.243243ms
Feb 24 20:19:00.596: INFO: Number of nodes with available pods: 0
Feb 24 20:19:00.596: INFO: Number of running nodes: 0, number of available pods: 0
Feb 24 20:19:00.600: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8619/daemonsets","resourceVersion":"37953"},"items":null}

Feb 24 20:19:00.605: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8619/pods","resourceVersion":"37953"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:19:00.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8619" for this suite.
Feb 24 20:19:06.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:19:07.413: INFO: namespace daemonsets-8619 deletion completed in 6.78588296s

• [SLOW TEST:40.737 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:19:07.420: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8485
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:19:07.711: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:19:11.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8485" for this suite.
Feb 24 20:19:55.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:19:56.012: INFO: namespace pods-8485 deletion completed in 44.165385036s

• [SLOW TEST:48.592 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:19:56.015: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9129
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb 24 20:19:56.184: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:19:59.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9129" for this suite.
Feb 24 20:20:05.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:20:06.006: INFO: namespace init-container-9129 deletion completed in 6.25934341s

• [SLOW TEST:9.992 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:20:06.011: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5434
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Feb 24 20:20:06.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 create -f - --namespace=kubectl-5434'
Feb 24 20:20:06.527: INFO: stderr: ""
Feb 24 20:20:06.527: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 24 20:20:06.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5434'
Feb 24 20:20:06.778: INFO: stderr: ""
Feb 24 20:20:06.778: INFO: stdout: "update-demo-nautilus-2twwl update-demo-nautilus-5c8z7 "
Feb 24 20:20:06.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-2twwl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5434'
Feb 24 20:20:07.028: INFO: stderr: ""
Feb 24 20:20:07.028: INFO: stdout: ""
Feb 24 20:20:07.028: INFO: update-demo-nautilus-2twwl is created but not running
Feb 24 20:20:12.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5434'
Feb 24 20:20:12.130: INFO: stderr: ""
Feb 24 20:20:12.130: INFO: stdout: "update-demo-nautilus-2twwl update-demo-nautilus-5c8z7 "
Feb 24 20:20:12.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-2twwl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5434'
Feb 24 20:20:12.287: INFO: stderr: ""
Feb 24 20:20:12.287: INFO: stdout: "true"
Feb 24 20:20:12.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-2twwl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5434'
Feb 24 20:20:12.373: INFO: stderr: ""
Feb 24 20:20:12.373: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 24 20:20:12.373: INFO: validating pod update-demo-nautilus-2twwl
Feb 24 20:20:12.383: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 24 20:20:12.383: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 24 20:20:12.383: INFO: update-demo-nautilus-2twwl is verified up and running
Feb 24 20:20:12.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-5c8z7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5434'
Feb 24 20:20:12.474: INFO: stderr: ""
Feb 24 20:20:12.474: INFO: stdout: "true"
Feb 24 20:20:12.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-5c8z7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5434'
Feb 24 20:20:12.556: INFO: stderr: ""
Feb 24 20:20:12.556: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 24 20:20:12.556: INFO: validating pod update-demo-nautilus-5c8z7
Feb 24 20:20:12.564: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 24 20:20:12.564: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 24 20:20:12.564: INFO: update-demo-nautilus-5c8z7 is verified up and running
STEP: scaling down the replication controller
Feb 24 20:20:12.566: INFO: scanned /root for discovery docs: <nil>
Feb 24 20:20:12.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-5434'
Feb 24 20:20:13.722: INFO: stderr: ""
Feb 24 20:20:13.722: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 24 20:20:13.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5434'
Feb 24 20:20:13.858: INFO: stderr: ""
Feb 24 20:20:13.858: INFO: stdout: "update-demo-nautilus-2twwl update-demo-nautilus-5c8z7 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 24 20:20:18.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5434'
Feb 24 20:20:18.962: INFO: stderr: ""
Feb 24 20:20:18.962: INFO: stdout: "update-demo-nautilus-2twwl "
Feb 24 20:20:18.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-2twwl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5434'
Feb 24 20:20:19.047: INFO: stderr: ""
Feb 24 20:20:19.047: INFO: stdout: "true"
Feb 24 20:20:19.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-2twwl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5434'
Feb 24 20:20:19.137: INFO: stderr: ""
Feb 24 20:20:19.137: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 24 20:20:19.137: INFO: validating pod update-demo-nautilus-2twwl
Feb 24 20:20:19.146: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 24 20:20:19.146: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 24 20:20:19.146: INFO: update-demo-nautilus-2twwl is verified up and running
STEP: scaling up the replication controller
Feb 24 20:20:19.149: INFO: scanned /root for discovery docs: <nil>
Feb 24 20:20:19.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-5434'
Feb 24 20:20:20.277: INFO: stderr: ""
Feb 24 20:20:20.277: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 24 20:20:20.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5434'
Feb 24 20:20:20.375: INFO: stderr: ""
Feb 24 20:20:20.375: INFO: stdout: "update-demo-nautilus-2twwl update-demo-nautilus-8mfkt "
Feb 24 20:20:20.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-2twwl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5434'
Feb 24 20:20:20.470: INFO: stderr: ""
Feb 24 20:20:20.470: INFO: stdout: "true"
Feb 24 20:20:20.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-2twwl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5434'
Feb 24 20:20:20.565: INFO: stderr: ""
Feb 24 20:20:20.565: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 24 20:20:20.565: INFO: validating pod update-demo-nautilus-2twwl
Feb 24 20:20:20.572: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 24 20:20:20.572: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 24 20:20:20.572: INFO: update-demo-nautilus-2twwl is verified up and running
Feb 24 20:20:20.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-8mfkt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5434'
Feb 24 20:20:20.708: INFO: stderr: ""
Feb 24 20:20:20.708: INFO: stdout: "true"
Feb 24 20:20:20.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods update-demo-nautilus-8mfkt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5434'
Feb 24 20:20:20.842: INFO: stderr: ""
Feb 24 20:20:20.842: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 24 20:20:20.843: INFO: validating pod update-demo-nautilus-8mfkt
Feb 24 20:20:20.851: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 24 20:20:20.851: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 24 20:20:20.851: INFO: update-demo-nautilus-8mfkt is verified up and running
STEP: using delete to clean up resources
Feb 24 20:20:20.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 delete --grace-period=0 --force -f - --namespace=kubectl-5434'
Feb 24 20:20:20.962: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 24 20:20:20.962: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 24 20:20:20.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5434'
Feb 24 20:20:21.069: INFO: stderr: "No resources found in kubectl-5434 namespace.\n"
Feb 24 20:20:21.069: INFO: stdout: ""
Feb 24 20:20:21.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods -l name=update-demo --namespace=kubectl-5434 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 24 20:20:21.178: INFO: stderr: ""
Feb 24 20:20:21.178: INFO: stdout: "update-demo-nautilus-2twwl\nupdate-demo-nautilus-8mfkt\n"
Feb 24 20:20:21.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5434'
Feb 24 20:20:22.124: INFO: stderr: "No resources found in kubectl-5434 namespace.\n"
Feb 24 20:20:22.124: INFO: stdout: ""
Feb 24 20:20:22.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods -l name=update-demo --namespace=kubectl-5434 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 24 20:20:22.384: INFO: stderr: ""
Feb 24 20:20:22.384: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:20:22.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5434" for this suite.
Feb 24 20:20:28.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:20:28.907: INFO: namespace kubectl-5434 deletion completed in 6.407133773s

• [SLOW TEST:22.897 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:20:28.912: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-1891
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Feb 24 20:20:29.111: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-1891" to be "success or failure"
Feb 24 20:20:29.116: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.630184ms
Feb 24 20:20:31.120: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008254604s
Feb 24 20:20:33.124: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01238486s
STEP: Saw pod success
Feb 24 20:20:33.124: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 24 20:20:33.127: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 24 20:20:33.155: INFO: Waiting for pod pod-host-path-test to disappear
Feb 24 20:20:33.159: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:20:33.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-1891" for this suite.
Feb 24 20:20:39.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:20:39.319: INFO: namespace hostpath-1891 deletion completed in 6.150727264s

• [SLOW TEST:10.408 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:20:39.323: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9923
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:20:39.498: INFO: Creating deployment "test-recreate-deployment"
Feb 24 20:20:39.507: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 24 20:20:39.535: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Feb 24 20:20:41.685: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 24 20:20:41.746: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 24 20:20:41.903: INFO: Updating deployment test-recreate-deployment
Feb 24 20:20:41.903: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 24 20:20:42.115: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-9923 /apis/apps/v1/namespaces/deployment-9923/deployments/test-recreate-deployment f4c518bc-2b5e-4491-ae53-15d69a955bfc 38554 2 2020-02-24 20:20:39 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0004dc9f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-02-24 20:20:41 +0000 UTC,LastTransitionTime:2020-02-24 20:20:41 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2020-02-24 20:20:42 +0000 UTC,LastTransitionTime:2020-02-24 20:20:39 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Feb 24 20:20:42.123: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-9923 /apis/apps/v1/namespaces/deployment-9923/replicasets/test-recreate-deployment-5f94c574ff 7ce8b2f4-014c-488f-82dd-4c2af21d0911 38552 1 2020-02-24 20:20:41 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment f4c518bc-2b5e-4491-ae53-15d69a955bfc 0xc0004dd727 0xc0004dd728}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0004dd9d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 24 20:20:42.123: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 24 20:20:42.124: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-9923 /apis/apps/v1/namespaces/deployment-9923/replicasets/test-recreate-deployment-68fc85c7bb 71d15f8f-8a3c-4219-bcfa-5c79f6c045a6 38544 2 2020-02-24 20:20:39 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment f4c518bc-2b5e-4491-ae53-15d69a955bfc 0xc0004ddb17 0xc0004ddb18}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001108768 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 24 20:20:42.128: INFO: Pod "test-recreate-deployment-5f94c574ff-mhl77" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-mhl77 test-recreate-deployment-5f94c574ff- deployment-9923 /api/v1/namespaces/deployment-9923/pods/test-recreate-deployment-5f94c574ff-mhl77 742dff97-ecdd-4137-82ac-8bb4b8349fbb 38553 0 2020-02-24 20:20:42 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 7ce8b2f4-014c-488f-82dd-4c2af21d0911 0xc001109167 0xc001109168}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-st526,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-st526,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-st526,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-fss3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 20:20:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 20:20:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 20:20:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 20:20:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.2,PodIP:,StartTime:2020-02-24 20:20:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:20:42.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9923" for this suite.
Feb 24 20:20:48.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:20:48.876: INFO: namespace deployment-9923 deletion completed in 6.743296947s

• [SLOW TEST:9.554 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:20:48.881: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3078
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:20:53.350: INFO: Waiting up to 5m0s for pod "client-envvars-466fc927-3789-42a1-a906-865eed8fa6da" in namespace "pods-3078" to be "success or failure"
Feb 24 20:20:53.361: INFO: Pod "client-envvars-466fc927-3789-42a1-a906-865eed8fa6da": Phase="Pending", Reason="", readiness=false. Elapsed: 10.379518ms
Feb 24 20:20:55.364: INFO: Pod "client-envvars-466fc927-3789-42a1-a906-865eed8fa6da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014297636s
STEP: Saw pod success
Feb 24 20:20:55.365: INFO: Pod "client-envvars-466fc927-3789-42a1-a906-865eed8fa6da" satisfied condition "success or failure"
Feb 24 20:20:55.367: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod client-envvars-466fc927-3789-42a1-a906-865eed8fa6da container env3cont: <nil>
STEP: delete the pod
Feb 24 20:20:55.391: INFO: Waiting for pod client-envvars-466fc927-3789-42a1-a906-865eed8fa6da to disappear
Feb 24 20:20:55.397: INFO: Pod client-envvars-466fc927-3789-42a1-a906-865eed8fa6da no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:20:55.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3078" for this suite.
Feb 24 20:21:25.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:21:25.581: INFO: namespace pods-3078 deletion completed in 30.179257862s

• [SLOW TEST:36.701 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:21:25.583: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-4419
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Feb 24 20:21:25.770: INFO: Waiting up to 5m0s for pod "client-containers-2ab223c9-7bb9-4a2f-a905-a8466fc1f9ad" in namespace "containers-4419" to be "success or failure"
Feb 24 20:21:25.782: INFO: Pod "client-containers-2ab223c9-7bb9-4a2f-a905-a8466fc1f9ad": Phase="Pending", Reason="", readiness=false. Elapsed: 12.037002ms
Feb 24 20:21:27.786: INFO: Pod "client-containers-2ab223c9-7bb9-4a2f-a905-a8466fc1f9ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015466725s
STEP: Saw pod success
Feb 24 20:21:27.786: INFO: Pod "client-containers-2ab223c9-7bb9-4a2f-a905-a8466fc1f9ad" satisfied condition "success or failure"
Feb 24 20:21:27.790: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod client-containers-2ab223c9-7bb9-4a2f-a905-a8466fc1f9ad container test-container: <nil>
STEP: delete the pod
Feb 24 20:21:27.833: INFO: Waiting for pod client-containers-2ab223c9-7bb9-4a2f-a905-a8466fc1f9ad to disappear
Feb 24 20:21:27.841: INFO: Pod client-containers-2ab223c9-7bb9-4a2f-a905-a8466fc1f9ad no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:21:27.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4419" for this suite.
Feb 24 20:21:33.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:21:34.190: INFO: namespace containers-4419 deletion completed in 6.339639155s

• [SLOW TEST:8.608 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:21:34.200: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2415
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-3e3d9f64-6be0-4993-b85c-7036ed968220
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:21:34.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2415" for this suite.
Feb 24 20:21:40.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:21:40.720: INFO: namespace configmap-2415 deletion completed in 6.175190403s

• [SLOW TEST:6.521 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:21:40.725: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-697
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 20:21:40.910: INFO: Waiting up to 5m0s for pod "downwardapi-volume-81a4cf27-2d0c-4b97-aa38-c56f8c83b8f2" in namespace "downward-api-697" to be "success or failure"
Feb 24 20:21:40.916: INFO: Pod "downwardapi-volume-81a4cf27-2d0c-4b97-aa38-c56f8c83b8f2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.89513ms
Feb 24 20:21:42.919: INFO: Pod "downwardapi-volume-81a4cf27-2d0c-4b97-aa38-c56f8c83b8f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009594702s
Feb 24 20:21:44.925: INFO: Pod "downwardapi-volume-81a4cf27-2d0c-4b97-aa38-c56f8c83b8f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015074135s
STEP: Saw pod success
Feb 24 20:21:44.925: INFO: Pod "downwardapi-volume-81a4cf27-2d0c-4b97-aa38-c56f8c83b8f2" satisfied condition "success or failure"
Feb 24 20:21:44.930: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downwardapi-volume-81a4cf27-2d0c-4b97-aa38-c56f8c83b8f2 container client-container: <nil>
STEP: delete the pod
Feb 24 20:21:44.972: INFO: Waiting for pod downwardapi-volume-81a4cf27-2d0c-4b97-aa38-c56f8c83b8f2 to disappear
Feb 24 20:21:44.978: INFO: Pod downwardapi-volume-81a4cf27-2d0c-4b97-aa38-c56f8c83b8f2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:21:44.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-697" for this suite.
Feb 24 20:21:50.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:21:51.173: INFO: namespace downward-api-697 deletion completed in 6.189865753s

• [SLOW TEST:10.449 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:21:51.178: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6341
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-91332ae9-7027-4c53-a264-002bf5e426a5
STEP: Creating a pod to test consume secrets
Feb 24 20:21:51.436: INFO: Waiting up to 5m0s for pod "pod-secrets-2d8390b8-a0b2-4f95-b92a-0ecff71a7217" in namespace "secrets-6341" to be "success or failure"
Feb 24 20:21:51.453: INFO: Pod "pod-secrets-2d8390b8-a0b2-4f95-b92a-0ecff71a7217": Phase="Pending", Reason="", readiness=false. Elapsed: 16.487362ms
Feb 24 20:21:53.459: INFO: Pod "pod-secrets-2d8390b8-a0b2-4f95-b92a-0ecff71a7217": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021950045s
STEP: Saw pod success
Feb 24 20:21:53.459: INFO: Pod "pod-secrets-2d8390b8-a0b2-4f95-b92a-0ecff71a7217" satisfied condition "success or failure"
Feb 24 20:21:53.463: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-secrets-2d8390b8-a0b2-4f95-b92a-0ecff71a7217 container secret-volume-test: <nil>
STEP: delete the pod
Feb 24 20:21:53.489: INFO: Waiting for pod pod-secrets-2d8390b8-a0b2-4f95-b92a-0ecff71a7217 to disappear
Feb 24 20:21:53.504: INFO: Pod pod-secrets-2d8390b8-a0b2-4f95-b92a-0ecff71a7217 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:21:53.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6341" for this suite.
Feb 24 20:22:01.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:22:01.681: INFO: namespace secrets-6341 deletion completed in 8.166835464s

• [SLOW TEST:10.503 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:22:01.685: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-503
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:22:01.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 create -f - --namespace=kubectl-503'
Feb 24 20:22:02.064: INFO: stderr: ""
Feb 24 20:22:02.064: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 24 20:22:02.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 create -f - --namespace=kubectl-503'
Feb 24 20:22:02.348: INFO: stderr: ""
Feb 24 20:22:02.348: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 24 20:22:03.454: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 20:22:03.454: INFO: Found 1 / 1
Feb 24 20:22:03.454: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 24 20:22:03.528: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 20:22:03.528: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 24 20:22:03.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 describe pod redis-master-hjn4v --namespace=kubectl-503'
Feb 24 20:22:03.787: INFO: stderr: ""
Feb 24 20:22:03.787: INFO: stdout: "Name:         redis-master-hjn4v\nNamespace:    kubectl-503\nPriority:     0\nNode:         gke-c116p-default-pool-41de4435-fss3/10.77.32.2\nStart Time:   Mon, 24 Feb 2020 20:22:02 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           10.12.0.220\nIPs:\n  IP:           10.12.0.220\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://0f337b352e4514d965aef69d1099a7e1707c2e5e2031c753a8331d75539df665\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:a606eaca41c3c69c7d2c8a142ec445e71156bae8526ae7970f62b6399e57761c\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 24 Feb 2020 20:22:03 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9mwq9 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-9mwq9:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-9mwq9\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                           Message\n  ----    ------     ----  ----                                           -------\n  Normal  Scheduled  1s    default-scheduler                              Successfully assigned kubectl-503/redis-master-hjn4v to gke-c116p-default-pool-41de4435-fss3\n  Normal  Pulled     1s    kubelet, gke-c116p-default-pool-41de4435-fss3  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s    kubelet, gke-c116p-default-pool-41de4435-fss3  Created container redis-master\n  Normal  Started    0s    kubelet, gke-c116p-default-pool-41de4435-fss3  Started container redis-master\n"
Feb 24 20:22:03.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 describe rc redis-master --namespace=kubectl-503'
Feb 24 20:22:03.939: INFO: stderr: ""
Feb 24 20:22:03.939: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-503\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: redis-master-hjn4v\n"
Feb 24 20:22:03.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 describe service redis-master --namespace=kubectl-503'
Feb 24 20:22:04.056: INFO: stderr: ""
Feb 24 20:22:04.056: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-503\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.77.8.97\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.12.0.220:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 24 20:22:04.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 describe node gke-c116p-default-pool-41de4435-50z7'
Feb 24 20:22:04.195: INFO: stderr: ""
Feb 24 20:22:04.195: INFO: stdout: "Name:               gke-c116p-default-pool-41de4435-50z7\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=n1-standard-1\n                    beta.kubernetes.io/os=linux\n                    cloud.google.com/gke-nodepool=default-pool\n                    cloud.google.com/gke-os-distribution=cos\n                    failure-domain.beta.kubernetes.io/region=us-east4\n                    failure-domain.beta.kubernetes.io/zone=us-east4-a\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=gke-c116p-default-pool-41de4435-50z7\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/kube-proxy-ds-ready=true\nAnnotations:        container.googleapis.com/instance_id: 7384162872734624600\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 24 Feb 2020 18:31:10 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                          Status  LastHeartbeatTime                 LastTransitionTime                Reason                          Message\n  ----                          ------  -----------------                 ------------------                ------                          -------\n  ReadonlyFilesystem            False   Mon, 24 Feb 2020 20:21:25 +0000   Mon, 24 Feb 2020 18:31:11 +0000   FilesystemIsNotReadOnly         Filesystem is not read-only\n  CorruptDockerOverlay2         False   Mon, 24 Feb 2020 20:21:25 +0000   Mon, 24 Feb 2020 18:31:11 +0000   NoCorruptDockerOverlay2         docker overlay2 is functioning properly\n  FrequentUnregisterNetDevice   False   Mon, 24 Feb 2020 20:21:25 +0000   Mon, 24 Feb 2020 18:31:11 +0000   NoFrequentUnregisterNetDevice   node is functioning properly\n  FrequentKubeletRestart        False   Mon, 24 Feb 2020 20:21:25 +0000   Mon, 24 Feb 2020 18:31:11 +0000   NoFrequentKubeletRestart        kubelet is functioning properly\n  FrequentDockerRestart         False   Mon, 24 Feb 2020 20:21:25 +0000   Mon, 24 Feb 2020 18:31:11 +0000   NoFrequentDockerRestart         docker is functioning properly\n  FrequentContainerdRestart     False   Mon, 24 Feb 2020 20:21:25 +0000   Mon, 24 Feb 2020 18:31:11 +0000   NoFrequentContainerdRestart     containerd is functioning properly\n  KernelDeadlock                False   Mon, 24 Feb 2020 20:21:25 +0000   Mon, 24 Feb 2020 18:31:11 +0000   KernelHasNoDeadlock             kernel has no deadlock\n  NetworkUnavailable            False   Mon, 24 Feb 2020 18:31:12 +0000   Mon, 24 Feb 2020 18:31:12 +0000   RouteCreated                    NodeController create implicit route\n  MemoryPressure                False   Mon, 24 Feb 2020 20:21:23 +0000   Mon, 24 Feb 2020 18:31:10 +0000   KubeletHasSufficientMemory      kubelet has sufficient memory available\n  DiskPressure                  False   Mon, 24 Feb 2020 20:21:23 +0000   Mon, 24 Feb 2020 18:31:10 +0000   KubeletHasNoDiskPressure        kubelet has no disk pressure\n  PIDPressure                   False   Mon, 24 Feb 2020 20:21:23 +0000   Mon, 24 Feb 2020 18:31:10 +0000   KubeletHasSufficientPID         kubelet has sufficient PID available\n  Ready                         True    Mon, 24 Feb 2020 20:21:23 +0000   Mon, 24 Feb 2020 18:31:11 +0000   KubeletReady                    kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   10.77.32.3\n  ExternalIP:   \n  InternalDNS:  gke-c116p-default-pool-41de4435-50z7.c.pkm-scratch.internal\n  Hostname:     gke-c116p-default-pool-41de4435-50z7.c.pkm-scratch.internal\nCapacity:\n attachable-volumes-gce-pd:  127\n cpu:                        1\n ephemeral-storage:          98868448Ki\n hugepages-2Mi:              0\n memory:                     3785940Ki\n pods:                       110\nAllocatable:\n attachable-volumes-gce-pd:  127\n cpu:                        940m\n ephemeral-storage:          47093746742\n hugepages-2Mi:              0\n memory:                     2700500Ki\n pods:                       110\nSystem Info:\n Machine ID:                 c1dcbd43c4d54389180c8f7176fab05a\n System UUID:                c1dcbd43-c4d5-4389-180c-8f7176fab05a\n Boot ID:                    913e21f8-5d0d-424a-9b4b-8f25375ab4d5\n Kernel Version:             4.19.76+\n OS Image:                   Container-Optimized OS from Google\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://19.3.1\n Kubelet Version:            v1.16.4-gke.30\n Kube-Proxy Version:         v1.16.4-gke.30\nPodCIDR:                     10.12.1.0/24\nPodCIDRs:                    10.12.1.0/24\nProviderID:                  gce://pkm-scratch/us-east4-a/gke-c116p-default-pool-41de4435-50z7\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                event-exporter-gke-5998887ffd-wf7jq                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         111m\n  kube-system                fluentd-gke-bljn7                                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         110m\n  kube-system                fluentd-gke-scaler-84b9598957-hh4hk                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         111m\n  kube-system                gke-metrics-agent-5hrbb                                    2m (0%)       0 (0%)      20Mi (0%)        50Mi (1%)      110m\n  kube-system                kube-dns-68b499d58-t8vrp                                   260m (27%)    0 (0%)      110Mi (4%)       170Mi (6%)     111m\n  kube-system                kube-dns-autoscaler-645f7d66cf-rmd2g                       20m (2%)      0 (0%)      10Mi (0%)        0 (0%)         111m\n  kube-system                kube-proxy-xxnbn                                           100m (10%)    0 (0%)      0 (0%)           0 (0%)         110m\n  kube-system                l7-default-backend-678889f899-2hc4d                        10m (1%)      10m (1%)    20Mi (0%)        20Mi (0%)      111m\n  kube-system                prometheus-to-sd-5gvqd                                     0 (0%)        0 (0%)      0 (0%)           0 (0%)         110m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-4d9132020e6e4914-5m24k    0 (0%)        0 (0%)      0 (0%)           0 (0%)         69m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                   Requests    Limits\n  --------                   --------    ------\n  cpu                        392m (41%)  10m (1%)\n  memory                     160Mi (6%)  240Mi (9%)\n  ephemeral-storage          0 (0%)      0 (0%)\n  attachable-volumes-gce-pd  0           0\nEvents:                      <none>\n"
Feb 24 20:22:04.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 describe namespace kubectl-503'
Feb 24 20:22:04.319: INFO: stderr: ""
Feb 24 20:22:04.319: INFO: stdout: "Name:         kubectl-503\nLabels:       e2e-framework=kubectl\n              e2e-run=7595be1f-02c4-4a33-b28a-7add0be201db\nAnnotations:  <none>\nStatus:       Active\n\nResource Quotas\n Name:                       gke-resource-quotas\n Resource                    Used  Hard\n --------                    ---   ---\n count/ingresses.extensions  0     100\n count/jobs.batch            0     5k\n pods                        1     1500\n services                    1     500\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:22:04.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-503" for this suite.
Feb 24 20:22:16.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:22:16.538: INFO: namespace kubectl-503 deletion completed in 12.207690504s

• [SLOW TEST:14.853 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:22:16.544: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1012
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 20:22:17.032: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 20:22:20.175: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:22:20.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1012" for this suite.
Feb 24 20:22:26.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:22:26.537: INFO: namespace webhook-1012 deletion completed in 6.150706423s
STEP: Destroying namespace "webhook-1012-markers" for this suite.
Feb 24 20:22:32.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:22:32.731: INFO: namespace webhook-1012-markers deletion completed in 6.193642231s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.209 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:22:32.753: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4343
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:22:34.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4343" for this suite.
Feb 24 20:23:20.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:23:21.124: INFO: namespace kubelet-test-4343 deletion completed in 46.169434406s

• [SLOW TEST:48.371 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:23:21.127: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6985
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-mp2t
STEP: Creating a pod to test atomic-volume-subpath
Feb 24 20:23:21.328: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-mp2t" in namespace "subpath-6985" to be "success or failure"
Feb 24 20:23:21.355: INFO: Pod "pod-subpath-test-secret-mp2t": Phase="Pending", Reason="", readiness=false. Elapsed: 26.618821ms
Feb 24 20:23:23.360: INFO: Pod "pod-subpath-test-secret-mp2t": Phase="Running", Reason="", readiness=true. Elapsed: 2.031790155s
Feb 24 20:23:25.368: INFO: Pod "pod-subpath-test-secret-mp2t": Phase="Running", Reason="", readiness=true. Elapsed: 4.03934336s
Feb 24 20:23:27.374: INFO: Pod "pod-subpath-test-secret-mp2t": Phase="Running", Reason="", readiness=true. Elapsed: 6.04523729s
Feb 24 20:23:29.378: INFO: Pod "pod-subpath-test-secret-mp2t": Phase="Running", Reason="", readiness=true. Elapsed: 8.049278298s
Feb 24 20:23:31.384: INFO: Pod "pod-subpath-test-secret-mp2t": Phase="Running", Reason="", readiness=true. Elapsed: 10.055332028s
Feb 24 20:23:33.397: INFO: Pod "pod-subpath-test-secret-mp2t": Phase="Running", Reason="", readiness=true. Elapsed: 12.068145925s
Feb 24 20:23:35.400: INFO: Pod "pod-subpath-test-secret-mp2t": Phase="Running", Reason="", readiness=true. Elapsed: 14.071497716s
Feb 24 20:23:37.407: INFO: Pod "pod-subpath-test-secret-mp2t": Phase="Running", Reason="", readiness=true. Elapsed: 16.078218391s
Feb 24 20:23:39.411: INFO: Pod "pod-subpath-test-secret-mp2t": Phase="Running", Reason="", readiness=true. Elapsed: 18.082376872s
Feb 24 20:23:41.418: INFO: Pod "pod-subpath-test-secret-mp2t": Phase="Running", Reason="", readiness=true. Elapsed: 20.089197152s
Feb 24 20:23:43.421: INFO: Pod "pod-subpath-test-secret-mp2t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.092444481s
STEP: Saw pod success
Feb 24 20:23:43.421: INFO: Pod "pod-subpath-test-secret-mp2t" satisfied condition "success or failure"
Feb 24 20:23:43.424: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-subpath-test-secret-mp2t container test-container-subpath-secret-mp2t: <nil>
STEP: delete the pod
Feb 24 20:23:43.451: INFO: Waiting for pod pod-subpath-test-secret-mp2t to disappear
Feb 24 20:23:43.454: INFO: Pod pod-subpath-test-secret-mp2t no longer exists
STEP: Deleting pod pod-subpath-test-secret-mp2t
Feb 24 20:23:43.455: INFO: Deleting pod "pod-subpath-test-secret-mp2t" in namespace "subpath-6985"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:23:43.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6985" for this suite.
Feb 24 20:23:49.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:23:49.803: INFO: namespace subpath-6985 deletion completed in 6.339703009s

• [SLOW TEST:28.677 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:23:49.807: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7980
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 24 20:23:49.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-7980'
Feb 24 20:23:50.112: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 24 20:23:50.112: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Feb 24 20:23:50.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 delete jobs e2e-test-httpd-job --namespace=kubectl-7980'
Feb 24 20:23:50.233: INFO: stderr: ""
Feb 24 20:23:50.233: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:23:50.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7980" for this suite.
Feb 24 20:23:56.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:23:56.400: INFO: namespace kubectl-7980 deletion completed in 6.158902277s

• [SLOW TEST:6.594 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:23:56.405: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4884
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 24 20:23:56.643: INFO: Waiting up to 5m0s for pod "downward-api-4c97227e-3340-4c17-b4a4-bd31d4739eec" in namespace "downward-api-4884" to be "success or failure"
Feb 24 20:23:56.647: INFO: Pod "downward-api-4c97227e-3340-4c17-b4a4-bd31d4739eec": Phase="Pending", Reason="", readiness=false. Elapsed: 3.340881ms
Feb 24 20:23:58.730: INFO: Pod "downward-api-4c97227e-3340-4c17-b4a4-bd31d4739eec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086622658s
Feb 24 20:24:00.734: INFO: Pod "downward-api-4c97227e-3340-4c17-b4a4-bd31d4739eec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.090974144s
STEP: Saw pod success
Feb 24 20:24:00.735: INFO: Pod "downward-api-4c97227e-3340-4c17-b4a4-bd31d4739eec" satisfied condition "success or failure"
Feb 24 20:24:00.738: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downward-api-4c97227e-3340-4c17-b4a4-bd31d4739eec container dapi-container: <nil>
STEP: delete the pod
Feb 24 20:24:00.773: INFO: Waiting for pod downward-api-4c97227e-3340-4c17-b4a4-bd31d4739eec to disappear
Feb 24 20:24:00.777: INFO: Pod downward-api-4c97227e-3340-4c17-b4a4-bd31d4739eec no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:24:00.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4884" for this suite.
Feb 24 20:24:06.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:24:07.531: INFO: namespace downward-api-4884 deletion completed in 6.745517109s

• [SLOW TEST:11.126 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:24:07.535: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9838
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 20:24:07.733: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f4c24102-7882-4515-b098-4e66eae45a56" in namespace "projected-9838" to be "success or failure"
Feb 24 20:24:07.741: INFO: Pod "downwardapi-volume-f4c24102-7882-4515-b098-4e66eae45a56": Phase="Pending", Reason="", readiness=false. Elapsed: 7.902643ms
Feb 24 20:24:09.745: INFO: Pod "downwardapi-volume-f4c24102-7882-4515-b098-4e66eae45a56": Phase="Running", Reason="", readiness=true. Elapsed: 2.011788792s
Feb 24 20:24:11.749: INFO: Pod "downwardapi-volume-f4c24102-7882-4515-b098-4e66eae45a56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015663218s
STEP: Saw pod success
Feb 24 20:24:11.749: INFO: Pod "downwardapi-volume-f4c24102-7882-4515-b098-4e66eae45a56" satisfied condition "success or failure"
Feb 24 20:24:11.752: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downwardapi-volume-f4c24102-7882-4515-b098-4e66eae45a56 container client-container: <nil>
STEP: delete the pod
Feb 24 20:24:11.776: INFO: Waiting for pod downwardapi-volume-f4c24102-7882-4515-b098-4e66eae45a56 to disappear
Feb 24 20:24:11.783: INFO: Pod downwardapi-volume-f4c24102-7882-4515-b098-4e66eae45a56 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:24:11.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9838" for this suite.
Feb 24 20:24:17.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:24:17.948: INFO: namespace projected-9838 deletion completed in 6.160275827s

• [SLOW TEST:10.413 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:24:17.952: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5526
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-8632a459-b8ed-49d6-9842-accc214ec488
STEP: Creating a pod to test consume configMaps
Feb 24 20:24:18.569: INFO: Waiting up to 5m0s for pod "pod-configmaps-6f18ad5f-9c50-4edb-9cac-544ce8cde899" in namespace "configmap-5526" to be "success or failure"
Feb 24 20:24:18.710: INFO: Pod "pod-configmaps-6f18ad5f-9c50-4edb-9cac-544ce8cde899": Phase="Pending", Reason="", readiness=false. Elapsed: 140.784111ms
Feb 24 20:24:20.714: INFO: Pod "pod-configmaps-6f18ad5f-9c50-4edb-9cac-544ce8cde899": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.144592893s
STEP: Saw pod success
Feb 24 20:24:20.714: INFO: Pod "pod-configmaps-6f18ad5f-9c50-4edb-9cac-544ce8cde899" satisfied condition "success or failure"
Feb 24 20:24:20.717: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-configmaps-6f18ad5f-9c50-4edb-9cac-544ce8cde899 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 20:24:20.775: INFO: Waiting for pod pod-configmaps-6f18ad5f-9c50-4edb-9cac-544ce8cde899 to disappear
Feb 24 20:24:20.781: INFO: Pod pod-configmaps-6f18ad5f-9c50-4edb-9cac-544ce8cde899 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:24:20.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5526" for this suite.
Feb 24 20:24:26.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:24:26.980: INFO: namespace configmap-5526 deletion completed in 6.189774292s

• [SLOW TEST:9.029 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:24:26.984: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8096
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Feb 24 20:24:27.158: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb 24 20:24:34.241: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:24:34.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8096" for this suite.
Feb 24 20:24:40.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:24:40.450: INFO: namespace pods-8096 deletion completed in 6.192112524s

• [SLOW TEST:13.467 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:24:40.454: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5386
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 20:24:40.691: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2eb9d79f-3a0d-439f-b76b-7058ce16073d" in namespace "projected-5386" to be "success or failure"
Feb 24 20:24:40.697: INFO: Pod "downwardapi-volume-2eb9d79f-3a0d-439f-b76b-7058ce16073d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.511902ms
Feb 24 20:24:42.700: INFO: Pod "downwardapi-volume-2eb9d79f-3a0d-439f-b76b-7058ce16073d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009251688s
STEP: Saw pod success
Feb 24 20:24:42.701: INFO: Pod "downwardapi-volume-2eb9d79f-3a0d-439f-b76b-7058ce16073d" satisfied condition "success or failure"
Feb 24 20:24:42.704: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downwardapi-volume-2eb9d79f-3a0d-439f-b76b-7058ce16073d container client-container: <nil>
STEP: delete the pod
Feb 24 20:24:42.739: INFO: Waiting for pod downwardapi-volume-2eb9d79f-3a0d-439f-b76b-7058ce16073d to disappear
Feb 24 20:24:42.746: INFO: Pod downwardapi-volume-2eb9d79f-3a0d-439f-b76b-7058ce16073d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:24:42.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5386" for this suite.
Feb 24 20:24:50.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:24:50.914: INFO: namespace projected-5386 deletion completed in 8.164479045s

• [SLOW TEST:10.461 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:24:50.918: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3855
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-vb69
STEP: Creating a pod to test atomic-volume-subpath
Feb 24 20:24:51.170: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-vb69" in namespace "subpath-3855" to be "success or failure"
Feb 24 20:24:51.176: INFO: Pod "pod-subpath-test-downwardapi-vb69": Phase="Pending", Reason="", readiness=false. Elapsed: 5.055199ms
Feb 24 20:24:53.179: INFO: Pod "pod-subpath-test-downwardapi-vb69": Phase="Running", Reason="", readiness=true. Elapsed: 2.008710297s
Feb 24 20:24:55.183: INFO: Pod "pod-subpath-test-downwardapi-vb69": Phase="Running", Reason="", readiness=true. Elapsed: 4.012113084s
Feb 24 20:24:57.186: INFO: Pod "pod-subpath-test-downwardapi-vb69": Phase="Running", Reason="", readiness=true. Elapsed: 6.015495628s
Feb 24 20:24:59.274: INFO: Pod "pod-subpath-test-downwardapi-vb69": Phase="Running", Reason="", readiness=true. Elapsed: 8.103429293s
Feb 24 20:25:01.277: INFO: Pod "pod-subpath-test-downwardapi-vb69": Phase="Running", Reason="", readiness=true. Elapsed: 10.106741363s
Feb 24 20:25:03.363: INFO: Pod "pod-subpath-test-downwardapi-vb69": Phase="Running", Reason="", readiness=true. Elapsed: 12.192229126s
Feb 24 20:25:05.369: INFO: Pod "pod-subpath-test-downwardapi-vb69": Phase="Running", Reason="", readiness=true. Elapsed: 14.198483407s
Feb 24 20:25:07.452: INFO: Pod "pod-subpath-test-downwardapi-vb69": Phase="Running", Reason="", readiness=true. Elapsed: 16.281725666s
Feb 24 20:25:09.456: INFO: Pod "pod-subpath-test-downwardapi-vb69": Phase="Running", Reason="", readiness=true. Elapsed: 18.285175607s
Feb 24 20:25:11.459: INFO: Pod "pod-subpath-test-downwardapi-vb69": Phase="Running", Reason="", readiness=true. Elapsed: 20.288712219s
Feb 24 20:25:13.462: INFO: Pod "pod-subpath-test-downwardapi-vb69": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.291775552s
STEP: Saw pod success
Feb 24 20:25:13.462: INFO: Pod "pod-subpath-test-downwardapi-vb69" satisfied condition "success or failure"
Feb 24 20:25:13.465: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-subpath-test-downwardapi-vb69 container test-container-subpath-downwardapi-vb69: <nil>
STEP: delete the pod
Feb 24 20:25:13.487: INFO: Waiting for pod pod-subpath-test-downwardapi-vb69 to disappear
Feb 24 20:25:13.493: INFO: Pod pod-subpath-test-downwardapi-vb69 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-vb69
Feb 24 20:25:13.493: INFO: Deleting pod "pod-subpath-test-downwardapi-vb69" in namespace "subpath-3855"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:25:13.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3855" for this suite.
Feb 24 20:25:21.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:25:21.655: INFO: namespace subpath-3855 deletion completed in 8.154308057s

• [SLOW TEST:30.737 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:25:21.658: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5614
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb 24 20:25:27.066: INFO: Successfully updated pod "annotationupdatece957135-b1b4-435b-a226-3a535ef5dd01"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:25:29.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5614" for this suite.
Feb 24 20:25:43.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:25:43.585: INFO: namespace projected-5614 deletion completed in 14.48991831s

• [SLOW TEST:21.928 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:25:43.588: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-8605
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-496
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3184
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:25:57.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8605" for this suite.
Feb 24 20:26:03.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:26:04.368: INFO: namespace namespaces-8605 deletion completed in 6.965856889s
STEP: Destroying namespace "nsdeletetest-496" for this suite.
Feb 24 20:26:04.380: INFO: Namespace nsdeletetest-496 was already deleted
STEP: Destroying namespace "nsdeletetest-3184" for this suite.
Feb 24 20:26:10.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:26:10.701: INFO: namespace nsdeletetest-3184 deletion completed in 6.320475266s

• [SLOW TEST:27.113 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:26:10.713: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-506
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:26:10.918: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:26:11.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-506" for this suite.
Feb 24 20:26:18.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:26:18.193: INFO: namespace custom-resource-definition-506 deletion completed in 6.397042965s

• [SLOW TEST:7.481 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:26:18.207: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4927
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-4927
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-4927
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4927
Feb 24 20:26:18.414: INFO: Found 0 stateful pods, waiting for 1
Feb 24 20:26:28.420: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 24 20:26:28.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=statefulset-4927 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 20:26:28.709: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 20:26:28.709: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 20:26:28.709: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 24 20:26:28.713: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 24 20:26:38.719: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 24 20:26:38.719: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 20:26:38.740: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Feb 24 20:26:38.740: INFO: ss-0  gke-c116p-default-pool-41de4435-fss3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:18 +0000 UTC  }]
Feb 24 20:26:38.740: INFO: 
Feb 24 20:26:38.740: INFO: StatefulSet ss has not reached scale 3, at 1
Feb 24 20:26:39.753: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992407803s
Feb 24 20:26:40.761: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.981963559s
Feb 24 20:26:41.765: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.974403614s
Feb 24 20:26:42.769: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.969997414s
Feb 24 20:26:43.773: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.966154404s
Feb 24 20:26:44.777: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.962149243s
Feb 24 20:26:45.781: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.957884098s
Feb 24 20:26:46.786: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.953577653s
Feb 24 20:26:47.791: INFO: Verifying statefulset ss doesn't scale past 3 for another 949.112014ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4927
Feb 24 20:26:48.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=statefulset-4927 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 20:26:49.601: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 24 20:26:49.601: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 24 20:26:49.601: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 24 20:26:49.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=statefulset-4927 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 20:26:49.931: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 24 20:26:49.931: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 24 20:26:49.931: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 24 20:26:49.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=statefulset-4927 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 20:26:50.299: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 24 20:26:50.299: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 24 20:26:50.299: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 24 20:26:50.302: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 20:26:50.302: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 20:26:50.302: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 24 20:26:50.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=statefulset-4927 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 20:26:50.573: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 20:26:50.573: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 20:26:50.573: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 24 20:26:50.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=statefulset-4927 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 20:26:50.870: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 20:26:50.870: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 20:26:50.870: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 24 20:26:50.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=statefulset-4927 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 20:26:51.218: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 20:26:51.218: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 20:26:51.218: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 24 20:26:51.218: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 20:26:51.221: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 24 20:27:01.229: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 24 20:27:01.229: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 24 20:27:01.229: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 24 20:27:01.247: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Feb 24 20:27:01.248: INFO: ss-0  gke-c116p-default-pool-41de4435-fss3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:18 +0000 UTC  }]
Feb 24 20:27:01.248: INFO: ss-1  gke-c116p-default-pool-41de4435-dz7p  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  }]
Feb 24 20:27:01.248: INFO: ss-2  gke-c116p-default-pool-41de4435-50z7  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  }]
Feb 24 20:27:01.248: INFO: 
Feb 24 20:27:01.249: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 24 20:27:02.253: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Feb 24 20:27:02.253: INFO: ss-0  gke-c116p-default-pool-41de4435-fss3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:18 +0000 UTC  }]
Feb 24 20:27:02.253: INFO: ss-1  gke-c116p-default-pool-41de4435-dz7p  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  }]
Feb 24 20:27:02.253: INFO: ss-2  gke-c116p-default-pool-41de4435-50z7  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  }]
Feb 24 20:27:02.253: INFO: 
Feb 24 20:27:02.253: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 24 20:27:03.348: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Feb 24 20:27:03.349: INFO: ss-1  gke-c116p-default-pool-41de4435-dz7p  Running  0s     [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  }]
Feb 24 20:27:03.349: INFO: ss-2  gke-c116p-default-pool-41de4435-50z7  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  }]
Feb 24 20:27:03.349: INFO: 
Feb 24 20:27:03.350: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 24 20:27:04.357: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Feb 24 20:27:04.358: INFO: ss-2  gke-c116p-default-pool-41de4435-50z7  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  }]
Feb 24 20:27:04.358: INFO: 
Feb 24 20:27:04.358: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 24 20:27:05.364: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Feb 24 20:27:05.364: INFO: ss-2  gke-c116p-default-pool-41de4435-50z7  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  }]
Feb 24 20:27:05.364: INFO: 
Feb 24 20:27:05.364: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 24 20:27:06.368: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Feb 24 20:27:06.368: INFO: ss-2  gke-c116p-default-pool-41de4435-50z7  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  }]
Feb 24 20:27:06.368: INFO: 
Feb 24 20:27:06.368: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 24 20:27:07.379: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Feb 24 20:27:07.379: INFO: ss-2  gke-c116p-default-pool-41de4435-50z7  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  }]
Feb 24 20:27:07.379: INFO: 
Feb 24 20:27:07.379: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 24 20:27:08.383: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Feb 24 20:27:08.383: INFO: ss-2  gke-c116p-default-pool-41de4435-50z7  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  }]
Feb 24 20:27:08.383: INFO: 
Feb 24 20:27:08.383: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 24 20:27:09.387: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Feb 24 20:27:09.387: INFO: ss-2  gke-c116p-default-pool-41de4435-50z7  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 20:26:38 +0000 UTC  }]
Feb 24 20:27:09.387: INFO: 
Feb 24 20:27:09.387: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 24 20:27:10.391: INFO: Verifying statefulset ss doesn't scale past 0 for another 852.019467ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4927
Feb 24 20:27:11.394: INFO: Scaling statefulset ss to 0
Feb 24 20:27:11.405: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 24 20:27:11.409: INFO: Deleting all statefulset in ns statefulset-4927
Feb 24 20:27:11.418: INFO: Scaling statefulset ss to 0
Feb 24 20:27:11.443: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 20:27:11.447: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:27:11.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4927" for this suite.
Feb 24 20:27:17.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:27:17.645: INFO: namespace statefulset-4927 deletion completed in 6.168216094s

• [SLOW TEST:59.438 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:27:17.651: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8518
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 20:27:17.945: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d878c7e7-e47c-40d4-8d2b-5e7c398d5616" in namespace "downward-api-8518" to be "success or failure"
Feb 24 20:27:17.960: INFO: Pod "downwardapi-volume-d878c7e7-e47c-40d4-8d2b-5e7c398d5616": Phase="Pending", Reason="", readiness=false. Elapsed: 14.137509ms
Feb 24 20:27:19.964: INFO: Pod "downwardapi-volume-d878c7e7-e47c-40d4-8d2b-5e7c398d5616": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018595587s
STEP: Saw pod success
Feb 24 20:27:19.964: INFO: Pod "downwardapi-volume-d878c7e7-e47c-40d4-8d2b-5e7c398d5616" satisfied condition "success or failure"
Feb 24 20:27:19.967: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downwardapi-volume-d878c7e7-e47c-40d4-8d2b-5e7c398d5616 container client-container: <nil>
STEP: delete the pod
Feb 24 20:27:20.001: INFO: Waiting for pod downwardapi-volume-d878c7e7-e47c-40d4-8d2b-5e7c398d5616 to disappear
Feb 24 20:27:20.011: INFO: Pod downwardapi-volume-d878c7e7-e47c-40d4-8d2b-5e7c398d5616 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:27:20.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8518" for this suite.
Feb 24 20:27:26.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:27:26.206: INFO: namespace downward-api-8518 deletion completed in 6.190482949s

• [SLOW TEST:8.556 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:27:26.211: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5845
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 20:27:27.263: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 20:27:29.274: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718172847, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718172847, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718172847, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718172847, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 20:27:32.364: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:27:32.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5845" for this suite.
Feb 24 20:27:38.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:27:38.579: INFO: namespace webhook-5845 deletion completed in 6.163618054s
STEP: Destroying namespace "webhook-5845-markers" for this suite.
Feb 24 20:27:44.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:27:44.724: INFO: namespace webhook-5845-markers deletion completed in 6.144087719s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.527 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:27:44.738: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2938
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-a37e4401-4a13-4bf4-8ac3-fcd85a33ac6a in namespace container-probe-2938
Feb 24 20:27:46.947: INFO: Started pod liveness-a37e4401-4a13-4bf4-8ac3-fcd85a33ac6a in namespace container-probe-2938
STEP: checking the pod's current state and verifying that restartCount is present
Feb 24 20:27:46.952: INFO: Initial restart count of pod liveness-a37e4401-4a13-4bf4-8ac3-fcd85a33ac6a is 0
Feb 24 20:28:05.382: INFO: Restart count of pod container-probe-2938/liveness-a37e4401-4a13-4bf4-8ac3-fcd85a33ac6a is now 1 (18.429529779s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:28:05.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2938" for this suite.
Feb 24 20:28:11.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:28:11.589: INFO: namespace container-probe-2938 deletion completed in 6.170852318s

• [SLOW TEST:26.851 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:28:11.592: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9459
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0224 20:28:17.831110      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 24 20:28:17.831: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:28:17.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9459" for this suite.
Feb 24 20:28:25.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:28:25.991: INFO: namespace gc-9459 deletion completed in 8.153582666s

• [SLOW TEST:14.400 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:28:25.997: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7663
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Feb 24 20:28:26.688: INFO: created pod pod-service-account-defaultsa
Feb 24 20:28:26.688: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 24 20:28:26.718: INFO: created pod pod-service-account-mountsa
Feb 24 20:28:26.718: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 24 20:28:26.778: INFO: created pod pod-service-account-nomountsa
Feb 24 20:28:26.778: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 24 20:28:26.818: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 24 20:28:26.818: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 24 20:28:26.856: INFO: created pod pod-service-account-mountsa-mountspec
Feb 24 20:28:26.856: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 24 20:28:26.913: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 24 20:28:26.913: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 24 20:28:26.946: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 24 20:28:26.946: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 24 20:28:26.988: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 24 20:28:26.988: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 24 20:28:27.022: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 24 20:28:27.022: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:28:27.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7663" for this suite.
Feb 24 20:28:41.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:28:41.243: INFO: namespace svcaccounts-7663 deletion completed in 14.2042124s

• [SLOW TEST:15.246 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:28:41.244: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-8585
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 24 20:28:47.560: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8585 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 20:28:47.560: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:28:47.742: INFO: Exec stderr: ""
Feb 24 20:28:47.742: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8585 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 20:28:47.742: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:28:47.950: INFO: Exec stderr: ""
Feb 24 20:28:47.950: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8585 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 20:28:47.950: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:28:48.163: INFO: Exec stderr: ""
Feb 24 20:28:48.163: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8585 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 20:28:48.163: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:28:48.673: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 24 20:28:48.674: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8585 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 20:28:48.674: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:28:49.129: INFO: Exec stderr: ""
Feb 24 20:28:49.129: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8585 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 20:28:49.129: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:28:49.425: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 24 20:28:49.426: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8585 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 20:28:49.426: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:28:49.614: INFO: Exec stderr: ""
Feb 24 20:28:49.614: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8585 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 20:28:49.614: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:28:49.817: INFO: Exec stderr: ""
Feb 24 20:28:49.818: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8585 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 20:28:49.818: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:28:50.050: INFO: Exec stderr: ""
Feb 24 20:28:50.050: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8585 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 20:28:50.050: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:28:50.237: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:28:50.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-8585" for this suite.
Feb 24 20:29:34.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:29:34.408: INFO: namespace e2e-kubelet-etc-hosts-8585 deletion completed in 44.164244462s

• [SLOW TEST:53.165 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:29:34.415: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-213
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Feb 24 20:29:34.576: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-651526472 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:29:34.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-213" for this suite.
Feb 24 20:29:40.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:29:40.858: INFO: namespace kubectl-213 deletion completed in 6.164542641s

• [SLOW TEST:6.443 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:29:40.867: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-713
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:29:41.065: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-84169a45-819e-4c44-87c4-3de9430f5b26" in namespace "security-context-test-713" to be "success or failure"
Feb 24 20:29:41.072: INFO: Pod "busybox-readonly-false-84169a45-819e-4c44-87c4-3de9430f5b26": Phase="Pending", Reason="", readiness=false. Elapsed: 6.64716ms
Feb 24 20:29:43.075: INFO: Pod "busybox-readonly-false-84169a45-819e-4c44-87c4-3de9430f5b26": Phase="Running", Reason="", readiness=true. Elapsed: 2.00995125s
Feb 24 20:29:45.082: INFO: Pod "busybox-readonly-false-84169a45-819e-4c44-87c4-3de9430f5b26": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016617023s
Feb 24 20:29:45.082: INFO: Pod "busybox-readonly-false-84169a45-819e-4c44-87c4-3de9430f5b26" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:29:45.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-713" for this suite.
Feb 24 20:29:51.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:29:51.286: INFO: namespace security-context-test-713 deletion completed in 6.197211325s

• [SLOW TEST:10.420 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:29:51.292: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-840
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 24 20:29:51.534: INFO: Waiting up to 5m0s for pod "pod-dd586a6d-357e-4ad8-ac1e-f68c58caf1e7" in namespace "emptydir-840" to be "success or failure"
Feb 24 20:29:51.546: INFO: Pod "pod-dd586a6d-357e-4ad8-ac1e-f68c58caf1e7": Phase="Pending", Reason="", readiness=false. Elapsed: 11.176466ms
Feb 24 20:29:53.549: INFO: Pod "pod-dd586a6d-357e-4ad8-ac1e-f68c58caf1e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014535252s
STEP: Saw pod success
Feb 24 20:29:53.549: INFO: Pod "pod-dd586a6d-357e-4ad8-ac1e-f68c58caf1e7" satisfied condition "success or failure"
Feb 24 20:29:53.552: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-dd586a6d-357e-4ad8-ac1e-f68c58caf1e7 container test-container: <nil>
STEP: delete the pod
Feb 24 20:29:53.605: INFO: Waiting for pod pod-dd586a6d-357e-4ad8-ac1e-f68c58caf1e7 to disappear
Feb 24 20:29:53.612: INFO: Pod pod-dd586a6d-357e-4ad8-ac1e-f68c58caf1e7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:29:53.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-840" for this suite.
Feb 24 20:30:01.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:30:01.809: INFO: namespace emptydir-840 deletion completed in 8.190023924s

• [SLOW TEST:10.518 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:30:01.817: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9671
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 20:30:01.992: INFO: Waiting up to 5m0s for pod "downwardapi-volume-240b761b-767b-4a58-b66f-a711fd750ab4" in namespace "projected-9671" to be "success or failure"
Feb 24 20:30:01.998: INFO: Pod "downwardapi-volume-240b761b-767b-4a58-b66f-a711fd750ab4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.697648ms
Feb 24 20:30:04.096: INFO: Pod "downwardapi-volume-240b761b-767b-4a58-b66f-a711fd750ab4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.103629708s
STEP: Saw pod success
Feb 24 20:30:04.096: INFO: Pod "downwardapi-volume-240b761b-767b-4a58-b66f-a711fd750ab4" satisfied condition "success or failure"
Feb 24 20:30:04.273: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downwardapi-volume-240b761b-767b-4a58-b66f-a711fd750ab4 container client-container: <nil>
STEP: delete the pod
Feb 24 20:30:04.522: INFO: Waiting for pod downwardapi-volume-240b761b-767b-4a58-b66f-a711fd750ab4 to disappear
Feb 24 20:30:04.528: INFO: Pod downwardapi-volume-240b761b-767b-4a58-b66f-a711fd750ab4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:30:04.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9671" for this suite.
Feb 24 20:30:10.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:30:10.681: INFO: namespace projected-9671 deletion completed in 6.144560919s

• [SLOW TEST:8.865 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:30:10.688: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6817
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-b791d225-8c5f-432d-9b97-fcfba39c95d6
STEP: Creating configMap with name cm-test-opt-upd-83557bb0-a20b-41c2-903b-df97b126b6f6
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-b791d225-8c5f-432d-9b97-fcfba39c95d6
STEP: Updating configmap cm-test-opt-upd-83557bb0-a20b-41c2-903b-df97b126b6f6
STEP: Creating configMap with name cm-test-opt-create-388facd5-03ac-475f-9049-ff55a25e6cc4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:31:34.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6817" for this suite.
Feb 24 20:31:46.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:31:46.702: INFO: namespace projected-6817 deletion completed in 12.171475727s

• [SLOW TEST:96.015 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:31:46.706: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9204
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9204.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9204.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 24 20:31:49.376: INFO: DNS probes using dns-9204/dns-test-6ecf965c-b3a0-4a53-a469-41119ac144a8 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:31:49.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9204" for this suite.
Feb 24 20:31:55.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:31:55.570: INFO: namespace dns-9204 deletion completed in 6.160905812s

• [SLOW TEST:8.864 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:31:55.575: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-6879
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:32:05.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6879" for this suite.
Feb 24 20:32:11.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:32:11.939: INFO: namespace job-6879 deletion completed in 6.190490474s

• [SLOW TEST:16.365 seconds]
[sig-apps] Job
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:32:11.944: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1286
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 24 20:32:14.203: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:32:14.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1286" for this suite.
Feb 24 20:32:20.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:32:20.577: INFO: namespace container-runtime-1286 deletion completed in 6.350790612s

• [SLOW TEST:8.634 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:32:20.585: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-3431
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:32:20.742: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Creating first CR 
Feb 24 20:32:23.729: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-24T20:32:23Z generation:1 name:name1 resourceVersion:42874 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:9aaf7dd1-bbb7-4285-bd3b-580324702e63] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Feb 24 20:32:33.743: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-24T20:32:33Z generation:1 name:name2 resourceVersion:42919 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:b77c56bc-e88c-45fd-9c57-b92dd0c24649] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Feb 24 20:32:43.750: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-24T20:32:23Z generation:2 name:name1 resourceVersion:42960 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:9aaf7dd1-bbb7-4285-bd3b-580324702e63] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Feb 24 20:32:53.759: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-24T20:32:33Z generation:2 name:name2 resourceVersion:43002 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:b77c56bc-e88c-45fd-9c57-b92dd0c24649] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Feb 24 20:33:03.945: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-24T20:32:23Z generation:2 name:name1 resourceVersion:43041 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:9aaf7dd1-bbb7-4285-bd3b-580324702e63] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Feb 24 20:33:13.952: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-24T20:32:33Z generation:2 name:name2 resourceVersion:43084 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:b77c56bc-e88c-45fd-9c57-b92dd0c24649] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:33:24.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-3431" for this suite.
Feb 24 20:33:30.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:33:31.020: INFO: namespace crd-watch-3431 deletion completed in 6.422615036s

• [SLOW TEST:70.435 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:33:31.021: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7215
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 24 20:33:31.208: INFO: Waiting up to 5m0s for pod "pod-958ca988-9a6f-4cf4-9e86-b9b067cbca13" in namespace "emptydir-7215" to be "success or failure"
Feb 24 20:33:31.225: INFO: Pod "pod-958ca988-9a6f-4cf4-9e86-b9b067cbca13": Phase="Pending", Reason="", readiness=false. Elapsed: 16.598271ms
Feb 24 20:33:33.229: INFO: Pod "pod-958ca988-9a6f-4cf4-9e86-b9b067cbca13": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020954459s
STEP: Saw pod success
Feb 24 20:33:33.229: INFO: Pod "pod-958ca988-9a6f-4cf4-9e86-b9b067cbca13" satisfied condition "success or failure"
Feb 24 20:33:33.234: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-958ca988-9a6f-4cf4-9e86-b9b067cbca13 container test-container: <nil>
STEP: delete the pod
Feb 24 20:33:33.281: INFO: Waiting for pod pod-958ca988-9a6f-4cf4-9e86-b9b067cbca13 to disappear
Feb 24 20:33:33.295: INFO: Pod pod-958ca988-9a6f-4cf4-9e86-b9b067cbca13 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:33:33.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7215" for this suite.
Feb 24 20:33:39.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:33:39.447: INFO: namespace emptydir-7215 deletion completed in 6.146937068s

• [SLOW TEST:8.426 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:33:39.451: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-6160
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:33:39.632: INFO: Waiting up to 5m0s for pod "busybox-user-65534-77284671-eac3-4132-964a-f795f2663098" in namespace "security-context-test-6160" to be "success or failure"
Feb 24 20:33:39.644: INFO: Pod "busybox-user-65534-77284671-eac3-4132-964a-f795f2663098": Phase="Pending", Reason="", readiness=false. Elapsed: 12.287248ms
Feb 24 20:33:41.651: INFO: Pod "busybox-user-65534-77284671-eac3-4132-964a-f795f2663098": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019149149s
Feb 24 20:33:43.655: INFO: Pod "busybox-user-65534-77284671-eac3-4132-964a-f795f2663098": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023557561s
Feb 24 20:33:43.656: INFO: Pod "busybox-user-65534-77284671-eac3-4132-964a-f795f2663098" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:33:43.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6160" for this suite.
Feb 24 20:33:51.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:33:53.057: INFO: namespace security-context-test-6160 deletion completed in 9.396735366s

• [SLOW TEST:13.607 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:33:53.063: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5944
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:33:53.297: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 24 20:33:58.302: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 24 20:33:58.302: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 24 20:34:00.305: INFO: Creating deployment "test-rollover-deployment"
Feb 24 20:34:00.321: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 24 20:34:02.333: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 24 20:34:02.340: INFO: Ensure that both replica sets have 1 created replica
Feb 24 20:34:02.346: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 24 20:34:02.356: INFO: Updating deployment test-rollover-deployment
Feb 24 20:34:02.356: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 24 20:34:04.406: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 24 20:34:04.486: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 24 20:34:04.493: INFO: all replica sets need to contain the pod-template-hash label
Feb 24 20:34:04.493: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173240, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173240, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173244, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173240, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 20:34:06.500: INFO: all replica sets need to contain the pod-template-hash label
Feb 24 20:34:06.501: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173240, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173240, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173244, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173240, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 20:34:08.500: INFO: all replica sets need to contain the pod-template-hash label
Feb 24 20:34:08.500: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173240, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173240, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173244, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173240, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 20:34:10.500: INFO: all replica sets need to contain the pod-template-hash label
Feb 24 20:34:10.501: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173240, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173240, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173244, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173240, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 20:34:12.499: INFO: all replica sets need to contain the pod-template-hash label
Feb 24 20:34:12.499: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173240, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173240, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173244, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173240, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 20:34:14.500: INFO: 
Feb 24 20:34:14.501: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 24 20:34:14.511: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-5944 /apis/apps/v1/namespaces/deployment-5944/deployments/test-rollover-deployment 1278789c-16ab-4109-a4e6-3f63269f4a4d 43461 2 2020-02-24 20:34:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0025fc408 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-02-24 20:34:00 +0000 UTC,LastTransitionTime:2020-02-24 20:34:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2020-02-24 20:34:14 +0000 UTC,LastTransitionTime:2020-02-24 20:34:00 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb 24 20:34:14.517: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-5944 /apis/apps/v1/namespaces/deployment-5944/replicasets/test-rollover-deployment-7d7dc6548c f50bfa53-6c6b-4a73-a7b7-f1c2fa221732 43453 2 2020-02-24 20:34:02 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 1278789c-16ab-4109-a4e6-3f63269f4a4d 0xc0025fc8c7 0xc0025fc8c8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0025fc928 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 24 20:34:14.517: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 24 20:34:14.517: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-5944 /apis/apps/v1/namespaces/deployment-5944/replicasets/test-rollover-controller 4d8c0645-b6ce-4490-bd5b-bd3eaec43674 43460 2 2020-02-24 20:33:53 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 1278789c-16ab-4109-a4e6-3f63269f4a4d 0xc0025fc7f7 0xc0025fc7f8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0025fc858 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 24 20:34:14.517: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-5944 /apis/apps/v1/namespaces/deployment-5944/replicasets/test-rollover-deployment-f6c94f66c 99db798a-f6ef-4aa8-b24f-0894a77811cc 43390 2 2020-02-24 20:34:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 1278789c-16ab-4109-a4e6-3f63269f4a4d 0xc0025fc990 0xc0025fc991}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0025fca08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 24 20:34:14.521: INFO: Pod "test-rollover-deployment-7d7dc6548c-k4cbg" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-k4cbg test-rollover-deployment-7d7dc6548c- deployment-5944 /api/v1/namespaces/deployment-5944/pods/test-rollover-deployment-7d7dc6548c-k4cbg f15a6717-d7d0-4079-b8f7-d97de5dbb526 43408 0 2020-02-24 20:34:02 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c f50bfa53-6c6b-4a73-a7b7-f1c2fa221732 0xc0025fcf77 0xc0025fcf78}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4r48k,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4r48k,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4r48k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-fss3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 20:34:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 20:34:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 20:34:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 20:34:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.2,PodIP:10.12.0.13,StartTime:2020-02-24 20:34:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 20:34:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:a606eaca41c3c69c7d2c8a142ec445e71156bae8526ae7970f62b6399e57761c,ContainerID:docker://707293acbae4ef61278096490a323e18d90f5806c9a133416423a0f462a1c9fa,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.12.0.13,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:34:14.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5944" for this suite.
Feb 24 20:34:22.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:34:22.967: INFO: namespace deployment-5944 deletion completed in 8.440290752s

• [SLOW TEST:29.904 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:34:22.978: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8205
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 20:34:24.075: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 20:34:26.085: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173264, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173264, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173264, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173264, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 20:34:29.181: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:34:29.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8205" for this suite.
Feb 24 20:34:35.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:34:35.575: INFO: namespace webhook-8205 deletion completed in 6.143604913s
STEP: Destroying namespace "webhook-8205-markers" for this suite.
Feb 24 20:34:41.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:34:41.731: INFO: namespace webhook-8205-markers deletion completed in 6.155555314s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.770 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:34:41.747: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6016
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Feb 24 20:34:46.052: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-651526472 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb 24 20:34:51.158: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:34:51.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6016" for this suite.
Feb 24 20:34:57.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:34:57.329: INFO: namespace pods-6016 deletion completed in 6.156772063s

• [SLOW TEST:15.582 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:34:57.333: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8555
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-d6fba52c-be65-483d-9947-a2291830615a
STEP: Creating a pod to test consume secrets
Feb 24 20:34:58.113: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-223e5ebd-4a97-49c7-847c-0cc09d3614e9" in namespace "projected-8555" to be "success or failure"
Feb 24 20:34:58.211: INFO: Pod "pod-projected-secrets-223e5ebd-4a97-49c7-847c-0cc09d3614e9": Phase="Pending", Reason="", readiness=false. Elapsed: 97.782141ms
Feb 24 20:35:00.215: INFO: Pod "pod-projected-secrets-223e5ebd-4a97-49c7-847c-0cc09d3614e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101834469s
Feb 24 20:35:02.219: INFO: Pod "pod-projected-secrets-223e5ebd-4a97-49c7-847c-0cc09d3614e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.10652043s
STEP: Saw pod success
Feb 24 20:35:02.219: INFO: Pod "pod-projected-secrets-223e5ebd-4a97-49c7-847c-0cc09d3614e9" satisfied condition "success or failure"
Feb 24 20:35:02.223: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-projected-secrets-223e5ebd-4a97-49c7-847c-0cc09d3614e9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 24 20:35:02.254: INFO: Waiting for pod pod-projected-secrets-223e5ebd-4a97-49c7-847c-0cc09d3614e9 to disappear
Feb 24 20:35:02.260: INFO: Pod pod-projected-secrets-223e5ebd-4a97-49c7-847c-0cc09d3614e9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:35:02.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8555" for this suite.
Feb 24 20:35:08.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:35:08.603: INFO: namespace projected-8555 deletion completed in 6.337154363s

• [SLOW TEST:11.271 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:35:08.607: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-466
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-49f9c7e4-e08a-4577-8b5e-a2285c0baf48
STEP: Creating a pod to test consume secrets
Feb 24 20:35:08.843: INFO: Waiting up to 5m0s for pod "pod-secrets-90fda628-e31f-4758-ac83-ebb01be2c9bb" in namespace "secrets-466" to be "success or failure"
Feb 24 20:35:08.855: INFO: Pod "pod-secrets-90fda628-e31f-4758-ac83-ebb01be2c9bb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.580586ms
Feb 24 20:35:10.859: INFO: Pod "pod-secrets-90fda628-e31f-4758-ac83-ebb01be2c9bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016232568s
STEP: Saw pod success
Feb 24 20:35:10.860: INFO: Pod "pod-secrets-90fda628-e31f-4758-ac83-ebb01be2c9bb" satisfied condition "success or failure"
Feb 24 20:35:10.863: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-secrets-90fda628-e31f-4758-ac83-ebb01be2c9bb container secret-volume-test: <nil>
STEP: delete the pod
Feb 24 20:35:10.890: INFO: Waiting for pod pod-secrets-90fda628-e31f-4758-ac83-ebb01be2c9bb to disappear
Feb 24 20:35:10.895: INFO: Pod pod-secrets-90fda628-e31f-4758-ac83-ebb01be2c9bb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:35:10.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-466" for this suite.
Feb 24 20:35:16.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:35:17.067: INFO: namespace secrets-466 deletion completed in 6.165956154s

• [SLOW TEST:8.460 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:35:17.070: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3899
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:35:22.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3899" for this suite.
Feb 24 20:35:28.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:35:28.891: INFO: namespace watch-3899 deletion completed in 6.15244943s

• [SLOW TEST:11.822 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:35:28.896: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-7025
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:35:29.106: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:35:39.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7025" for this suite.
Feb 24 20:35:45.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:35:46.030: INFO: namespace custom-resource-definition-7025 deletion completed in 6.138019772s

• [SLOW TEST:17.135 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:35:46.035: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2292
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-04811180-985a-40de-8414-ace4f02c4901
STEP: Creating a pod to test consume configMaps
Feb 24 20:35:46.236: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bf4e1ad3-0d57-4eb9-a31d-d367a70a959b" in namespace "projected-2292" to be "success or failure"
Feb 24 20:35:46.245: INFO: Pod "pod-projected-configmaps-bf4e1ad3-0d57-4eb9-a31d-d367a70a959b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.875321ms
Feb 24 20:35:48.249: INFO: Pod "pod-projected-configmaps-bf4e1ad3-0d57-4eb9-a31d-d367a70a959b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01188768s
STEP: Saw pod success
Feb 24 20:35:48.249: INFO: Pod "pod-projected-configmaps-bf4e1ad3-0d57-4eb9-a31d-d367a70a959b" satisfied condition "success or failure"
Feb 24 20:35:48.252: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-projected-configmaps-bf4e1ad3-0d57-4eb9-a31d-d367a70a959b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 20:35:48.283: INFO: Waiting for pod pod-projected-configmaps-bf4e1ad3-0d57-4eb9-a31d-d367a70a959b to disappear
Feb 24 20:35:48.287: INFO: Pod pod-projected-configmaps-bf4e1ad3-0d57-4eb9-a31d-d367a70a959b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:35:48.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2292" for this suite.
Feb 24 20:35:54.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:35:54.444: INFO: namespace projected-2292 deletion completed in 6.152544612s

• [SLOW TEST:8.410 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:35:54.448: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1609
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 20:35:55.034: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 20:35:57.130: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173355, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173355, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173355, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173355, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 20:36:00.804: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Feb 24 20:36:00.832: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:36:00.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1609" for this suite.
Feb 24 20:36:08.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:36:09.010: INFO: namespace webhook-1609 deletion completed in 8.15918928s
STEP: Destroying namespace "webhook-1609-markers" for this suite.
Feb 24 20:36:15.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:36:15.157: INFO: namespace webhook-1609-markers deletion completed in 6.146487944s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:20.726 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:36:15.174: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6348
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Feb 24 20:36:15.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 api-versions'
Feb 24 20:36:15.424: INFO: stderr: ""
Feb 24 20:36:15.424: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncloud.google.com/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nmigration.k8s.io/v1alpha1\nnetworking.gke.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\nnodemanagement.gke.io/v1alpha1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscalingpolicy.kope.io/v1alpha1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:36:15.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6348" for this suite.
Feb 24 20:36:21.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:36:21.595: INFO: namespace kubectl-6348 deletion completed in 6.16695011s

• [SLOW TEST:6.421 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:36:21.608: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7315
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:36:23.056: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"505ce6c3-33cf-46e9-9413-5e4db2e6be9b", Controller:(*bool)(0xc004f052a6), BlockOwnerDeletion:(*bool)(0xc004f052a7)}}
Feb 24 20:36:23.077: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"34aa11df-5de2-4666-8d5d-9b25469ac685", Controller:(*bool)(0xc004f054ae), BlockOwnerDeletion:(*bool)(0xc004f054af)}}
Feb 24 20:36:23.086: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"127fb9e0-df2c-40d1-81a0-35c572097728", Controller:(*bool)(0xc004f056ae), BlockOwnerDeletion:(*bool)(0xc004f056af)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:36:28.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7315" for this suite.
Feb 24 20:36:34.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:36:34.494: INFO: namespace gc-7315 deletion completed in 6.391122512s

• [SLOW TEST:12.886 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:36:34.501: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8312
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Feb 24 20:36:34.776: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:36:57.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8312" for this suite.
Feb 24 20:37:03.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:37:04.362: INFO: namespace crd-publish-openapi-8312 deletion completed in 6.820397807s

• [SLOW TEST:29.862 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:37:04.368: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3325
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:37:04.638: INFO: (0) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 38.187901ms)
Feb 24 20:37:04.645: INFO: (1) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 6.15467ms)
Feb 24 20:37:04.654: INFO: (2) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 9.399149ms)
Feb 24 20:37:04.677: INFO: (3) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 22.183872ms)
Feb 24 20:37:04.688: INFO: (4) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 11.528348ms)
Feb 24 20:37:04.697: INFO: (5) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 8.659789ms)
Feb 24 20:37:04.712: INFO: (6) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 14.40752ms)
Feb 24 20:37:04.727: INFO: (7) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 15.039941ms)
Feb 24 20:37:04.738: INFO: (8) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 10.43294ms)
Feb 24 20:37:04.745: INFO: (9) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 7.376273ms)
Feb 24 20:37:04.750: INFO: (10) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 4.807762ms)
Feb 24 20:37:04.755: INFO: (11) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 4.666056ms)
Feb 24 20:37:04.760: INFO: (12) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 5.462889ms)
Feb 24 20:37:04.765: INFO: (13) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 4.13359ms)
Feb 24 20:37:04.770: INFO: (14) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 4.739633ms)
Feb 24 20:37:04.775: INFO: (15) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 5.514273ms)
Feb 24 20:37:04.782: INFO: (16) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 6.390959ms)
Feb 24 20:37:04.789: INFO: (17) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 6.984731ms)
Feb 24 20:37:04.796: INFO: (18) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 7.47885ms)
Feb 24 20:37:04.803: INFO: (19) /api/v1/nodes/gke-c116p-default-pool-41de4435-50z7:10250/proxy/logs/: <pre>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">containers/</a>
<a href="... (200; 6.85674ms)
[AfterEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:37:04.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3325" for this suite.
Feb 24 20:37:10.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:37:10.974: INFO: namespace proxy-3325 deletion completed in 6.159771583s

• [SLOW TEST:6.607 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:37:10.980: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5027
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-8cef3f52-d19f-475d-aca2-8ac4f361c6f8
STEP: Creating a pod to test consume configMaps
Feb 24 20:37:11.176: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b1e5d171-de4d-41da-bf9a-9a7062c8a4a6" in namespace "projected-5027" to be "success or failure"
Feb 24 20:37:11.197: INFO: Pod "pod-projected-configmaps-b1e5d171-de4d-41da-bf9a-9a7062c8a4a6": Phase="Pending", Reason="", readiness=false. Elapsed: 20.43948ms
Feb 24 20:37:13.201: INFO: Pod "pod-projected-configmaps-b1e5d171-de4d-41da-bf9a-9a7062c8a4a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024462231s
STEP: Saw pod success
Feb 24 20:37:13.201: INFO: Pod "pod-projected-configmaps-b1e5d171-de4d-41da-bf9a-9a7062c8a4a6" satisfied condition "success or failure"
Feb 24 20:37:13.204: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-projected-configmaps-b1e5d171-de4d-41da-bf9a-9a7062c8a4a6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 20:37:13.240: INFO: Waiting for pod pod-projected-configmaps-b1e5d171-de4d-41da-bf9a-9a7062c8a4a6 to disappear
Feb 24 20:37:13.245: INFO: Pod pod-projected-configmaps-b1e5d171-de4d-41da-bf9a-9a7062c8a4a6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:37:13.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5027" for this suite.
Feb 24 20:37:21.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:37:21.413: INFO: namespace projected-5027 deletion completed in 8.163027756s

• [SLOW TEST:10.433 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:37:21.422: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1604
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 20:37:22.180: INFO: Waiting up to 5m0s for pod "downwardapi-volume-da684e1e-1f91-48cb-8256-c2b7262e06bc" in namespace "downward-api-1604" to be "success or failure"
Feb 24 20:37:22.293: INFO: Pod "downwardapi-volume-da684e1e-1f91-48cb-8256-c2b7262e06bc": Phase="Pending", Reason="", readiness=false. Elapsed: 113.012364ms
Feb 24 20:37:24.297: INFO: Pod "downwardapi-volume-da684e1e-1f91-48cb-8256-c2b7262e06bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.116296671s
Feb 24 20:37:26.300: INFO: Pod "downwardapi-volume-da684e1e-1f91-48cb-8256-c2b7262e06bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.120132288s
STEP: Saw pod success
Feb 24 20:37:26.301: INFO: Pod "downwardapi-volume-da684e1e-1f91-48cb-8256-c2b7262e06bc" satisfied condition "success or failure"
Feb 24 20:37:26.304: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downwardapi-volume-da684e1e-1f91-48cb-8256-c2b7262e06bc container client-container: <nil>
STEP: delete the pod
Feb 24 20:37:26.337: INFO: Waiting for pod downwardapi-volume-da684e1e-1f91-48cb-8256-c2b7262e06bc to disappear
Feb 24 20:37:26.340: INFO: Pod downwardapi-volume-da684e1e-1f91-48cb-8256-c2b7262e06bc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:37:26.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1604" for this suite.
Feb 24 20:37:32.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:37:32.496: INFO: namespace downward-api-1604 deletion completed in 6.152843069s

• [SLOW TEST:11.075 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:37:32.500: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7712
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Feb 24 20:37:32.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-7712 -- logs-generator --log-lines-total 100 --run-duration 20s'
Feb 24 20:37:33.164: INFO: stderr: ""
Feb 24 20:37:33.164: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Feb 24 20:37:33.164: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Feb 24 20:37:33.164: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-7712" to be "running and ready, or succeeded"
Feb 24 20:37:33.172: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 8.145338ms
Feb 24 20:37:35.176: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.012175527s
Feb 24 20:37:35.176: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Feb 24 20:37:35.176: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Feb 24 20:37:35.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 logs logs-generator logs-generator --namespace=kubectl-7712'
Feb 24 20:37:35.277: INFO: stderr: ""
Feb 24 20:37:35.277: INFO: stdout: "I0224 20:37:34.119393       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/755 501\nI0224 20:37:34.321622       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/4qr 278\nI0224 20:37:34.519570       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/hzvj 524\nI0224 20:37:34.719580       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/dn26 392\nI0224 20:37:34.919611       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/dn5 237\nI0224 20:37:35.119625       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/fs6 479\n"
STEP: limiting log lines
Feb 24 20:37:35.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 logs logs-generator logs-generator --namespace=kubectl-7712 --tail=1'
Feb 24 20:37:35.382: INFO: stderr: ""
Feb 24 20:37:35.382: INFO: stdout: "I0224 20:37:35.319569       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/d64w 241\n"
STEP: limiting log bytes
Feb 24 20:37:35.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 logs logs-generator logs-generator --namespace=kubectl-7712 --limit-bytes=1'
Feb 24 20:37:35.488: INFO: stderr: ""
Feb 24 20:37:35.488: INFO: stdout: "I"
STEP: exposing timestamps
Feb 24 20:37:35.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 logs logs-generator logs-generator --namespace=kubectl-7712 --tail=1 --timestamps'
Feb 24 20:37:35.597: INFO: stderr: ""
Feb 24 20:37:35.597: INFO: stdout: "2020-02-24T20:37:35.519768679Z I0224 20:37:35.519580       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/n799 289\n"
STEP: restricting to a time range
Feb 24 20:37:38.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 logs logs-generator logs-generator --namespace=kubectl-7712 --since=1s'
Feb 24 20:37:38.257: INFO: stderr: ""
Feb 24 20:37:38.257: INFO: stdout: "I0224 20:37:37.319589       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/hx4l 491\nI0224 20:37:37.519570       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/kvg 477\nI0224 20:37:37.719575       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/lf8g 488\nI0224 20:37:37.919602       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/c6hl 211\nI0224 20:37:38.119599       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/v5q 535\n"
Feb 24 20:37:38.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 logs logs-generator logs-generator --namespace=kubectl-7712 --since=24h'
Feb 24 20:37:38.374: INFO: stderr: ""
Feb 24 20:37:38.374: INFO: stdout: "I0224 20:37:34.119393       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/755 501\nI0224 20:37:34.321622       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/4qr 278\nI0224 20:37:34.519570       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/hzvj 524\nI0224 20:37:34.719580       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/dn26 392\nI0224 20:37:34.919611       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/dn5 237\nI0224 20:37:35.119625       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/fs6 479\nI0224 20:37:35.319569       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/d64w 241\nI0224 20:37:35.519580       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/n799 289\nI0224 20:37:35.719583       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/zbj2 265\nI0224 20:37:35.919588       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/dkpf 400\nI0224 20:37:36.119607       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/mwc 546\nI0224 20:37:36.319634       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/th9 433\nI0224 20:37:36.519571       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/98gj 317\nI0224 20:37:36.719597       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/t8s 594\nI0224 20:37:36.919603       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/pw9s 249\nI0224 20:37:37.119636       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/rnc 447\nI0224 20:37:37.319589       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/hx4l 491\nI0224 20:37:37.519570       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/kvg 477\nI0224 20:37:37.719575       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/lf8g 488\nI0224 20:37:37.919602       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/c6hl 211\nI0224 20:37:38.119599       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/v5q 535\nI0224 20:37:38.319627       1 logs_generator.go:76] 21 GET /api/v1/namespaces/default/pods/2wnf 596\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Feb 24 20:37:38.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 delete pod logs-generator --namespace=kubectl-7712'
Feb 24 20:37:50.519: INFO: stderr: ""
Feb 24 20:37:50.519: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:37:50.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7712" for this suite.
Feb 24 20:37:56.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:37:56.694: INFO: namespace kubectl-7712 deletion completed in 6.16686963s

• [SLOW TEST:24.194 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:37:56.702: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8821
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 20:37:56.870: INFO: Waiting up to 5m0s for pod "downwardapi-volume-26e5df18-5b4f-4b28-8a1b-0e5e969c83ec" in namespace "downward-api-8821" to be "success or failure"
Feb 24 20:37:56.877: INFO: Pod "downwardapi-volume-26e5df18-5b4f-4b28-8a1b-0e5e969c83ec": Phase="Pending", Reason="", readiness=false. Elapsed: 7.010004ms
Feb 24 20:37:58.984: INFO: Pod "downwardapi-volume-26e5df18-5b4f-4b28-8a1b-0e5e969c83ec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.114317032s
Feb 24 20:38:00.988: INFO: Pod "downwardapi-volume-26e5df18-5b4f-4b28-8a1b-0e5e969c83ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.118309805s
STEP: Saw pod success
Feb 24 20:38:00.988: INFO: Pod "downwardapi-volume-26e5df18-5b4f-4b28-8a1b-0e5e969c83ec" satisfied condition "success or failure"
Feb 24 20:38:00.992: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downwardapi-volume-26e5df18-5b4f-4b28-8a1b-0e5e969c83ec container client-container: <nil>
STEP: delete the pod
Feb 24 20:38:01.024: INFO: Waiting for pod downwardapi-volume-26e5df18-5b4f-4b28-8a1b-0e5e969c83ec to disappear
Feb 24 20:38:01.029: INFO: Pod downwardapi-volume-26e5df18-5b4f-4b28-8a1b-0e5e969c83ec no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:38:01.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8821" for this suite.
Feb 24 20:38:07.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:38:07.864: INFO: namespace downward-api-8821 deletion completed in 6.830738194s

• [SLOW TEST:11.163 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:38:07.869: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8550
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-8550
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-8550
STEP: Creating statefulset with conflicting port in namespace statefulset-8550
STEP: Waiting until pod test-pod will start running in namespace statefulset-8550
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-8550
Feb 24 20:38:12.133: INFO: Observed stateful pod in namespace: statefulset-8550, name: ss-0, uid: 0fd0dcd0-bb17-4626-9b0b-5a33e3eeab73, status phase: Pending. Waiting for statefulset controller to delete.
Feb 24 20:38:12.328: INFO: Observed stateful pod in namespace: statefulset-8550, name: ss-0, uid: 0fd0dcd0-bb17-4626-9b0b-5a33e3eeab73, status phase: Failed. Waiting for statefulset controller to delete.
Feb 24 20:38:12.347: INFO: Observed stateful pod in namespace: statefulset-8550, name: ss-0, uid: 0fd0dcd0-bb17-4626-9b0b-5a33e3eeab73, status phase: Failed. Waiting for statefulset controller to delete.
Feb 24 20:38:12.355: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-8550
STEP: Removing pod with conflicting port in namespace statefulset-8550
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-8550 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 24 20:38:14.427: INFO: Deleting all statefulset in ns statefulset-8550
Feb 24 20:38:14.444: INFO: Scaling statefulset ss to 0
Feb 24 20:38:24.464: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 20:38:24.469: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:38:24.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8550" for this suite.
Feb 24 20:38:30.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:38:30.664: INFO: namespace statefulset-8550 deletion completed in 6.165684168s

• [SLOW TEST:22.795 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:38:30.667: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5404
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 24 20:38:30.871: INFO: Waiting up to 5m0s for pod "downward-api-a59236cb-a983-43ce-ae94-ae5e6252c04b" in namespace "downward-api-5404" to be "success or failure"
Feb 24 20:38:30.875: INFO: Pod "downward-api-a59236cb-a983-43ce-ae94-ae5e6252c04b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.687788ms
Feb 24 20:38:32.879: INFO: Pod "downward-api-a59236cb-a983-43ce-ae94-ae5e6252c04b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007789962s
STEP: Saw pod success
Feb 24 20:38:32.879: INFO: Pod "downward-api-a59236cb-a983-43ce-ae94-ae5e6252c04b" satisfied condition "success or failure"
Feb 24 20:38:32.882: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downward-api-a59236cb-a983-43ce-ae94-ae5e6252c04b container dapi-container: <nil>
STEP: delete the pod
Feb 24 20:38:32.906: INFO: Waiting for pod downward-api-a59236cb-a983-43ce-ae94-ae5e6252c04b to disappear
Feb 24 20:38:32.910: INFO: Pod downward-api-a59236cb-a983-43ce-ae94-ae5e6252c04b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:38:32.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5404" for this suite.
Feb 24 20:38:38.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:38:39.185: INFO: namespace downward-api-5404 deletion completed in 6.270789093s

• [SLOW TEST:8.518 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:38:39.192: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4794
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 24 20:38:39.382: INFO: Waiting up to 5m0s for pod "pod-7041f876-55f3-4da3-8f0d-35c2353671e9" in namespace "emptydir-4794" to be "success or failure"
Feb 24 20:38:39.390: INFO: Pod "pod-7041f876-55f3-4da3-8f0d-35c2353671e9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.431285ms
Feb 24 20:38:41.395: INFO: Pod "pod-7041f876-55f3-4da3-8f0d-35c2353671e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012820675s
Feb 24 20:38:43.398: INFO: Pod "pod-7041f876-55f3-4da3-8f0d-35c2353671e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016385976s
STEP: Saw pod success
Feb 24 20:38:43.398: INFO: Pod "pod-7041f876-55f3-4da3-8f0d-35c2353671e9" satisfied condition "success or failure"
Feb 24 20:38:43.401: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-7041f876-55f3-4da3-8f0d-35c2353671e9 container test-container: <nil>
STEP: delete the pod
Feb 24 20:38:43.428: INFO: Waiting for pod pod-7041f876-55f3-4da3-8f0d-35c2353671e9 to disappear
Feb 24 20:38:43.432: INFO: Pod pod-7041f876-55f3-4da3-8f0d-35c2353671e9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:38:43.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4794" for this suite.
Feb 24 20:38:49.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:38:49.953: INFO: namespace emptydir-4794 deletion completed in 6.516217217s

• [SLOW TEST:10.761 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:38:49.960: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1581
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:38:58.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1581" for this suite.
Feb 24 20:39:06.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:39:06.331: INFO: namespace resourcequota-1581 deletion completed in 8.176405557s

• [SLOW TEST:16.371 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:39:06.334: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8032
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:39:06.507: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Feb 24 20:39:11.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-8032 create -f -'
Feb 24 20:39:12.376: INFO: stderr: ""
Feb 24 20:39:12.376: INFO: stdout: "e2e-test-crd-publish-openapi-4208-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Feb 24 20:39:12.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-8032 delete e2e-test-crd-publish-openapi-4208-crds test-foo'
Feb 24 20:39:12.476: INFO: stderr: ""
Feb 24 20:39:12.476: INFO: stdout: "e2e-test-crd-publish-openapi-4208-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Feb 24 20:39:12.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-8032 apply -f -'
Feb 24 20:39:12.724: INFO: stderr: ""
Feb 24 20:39:12.724: INFO: stdout: "e2e-test-crd-publish-openapi-4208-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Feb 24 20:39:12.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-8032 delete e2e-test-crd-publish-openapi-4208-crds test-foo'
Feb 24 20:39:12.846: INFO: stderr: ""
Feb 24 20:39:12.846: INFO: stdout: "e2e-test-crd-publish-openapi-4208-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Feb 24 20:39:12.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-8032 create -f -'
Feb 24 20:39:13.070: INFO: rc: 1
Feb 24 20:39:13.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-8032 apply -f -'
Feb 24 20:39:13.278: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Feb 24 20:39:13.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-8032 create -f -'
Feb 24 20:39:13.479: INFO: rc: 1
Feb 24 20:39:13.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 --namespace=crd-publish-openapi-8032 apply -f -'
Feb 24 20:39:13.686: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Feb 24 20:39:13.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 explain e2e-test-crd-publish-openapi-4208-crds'
Feb 24 20:39:13.929: INFO: stderr: ""
Feb 24 20:39:13.929: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4208-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Feb 24 20:39:13.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 explain e2e-test-crd-publish-openapi-4208-crds.metadata'
Feb 24 20:39:14.148: INFO: stderr: ""
Feb 24 20:39:14.148: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4208-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Feb 24 20:39:14.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 explain e2e-test-crd-publish-openapi-4208-crds.spec'
Feb 24 20:39:14.355: INFO: stderr: ""
Feb 24 20:39:14.355: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4208-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Feb 24 20:39:14.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 explain e2e-test-crd-publish-openapi-4208-crds.spec.bars'
Feb 24 20:39:14.590: INFO: stderr: ""
Feb 24 20:39:14.590: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4208-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Feb 24 20:39:14.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 explain e2e-test-crd-publish-openapi-4208-crds.spec.bars2'
Feb 24 20:39:14.833: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:39:19.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8032" for this suite.
Feb 24 20:39:25.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:39:25.639: INFO: namespace crd-publish-openapi-8032 deletion completed in 6.456788379s

• [SLOW TEST:19.305 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:39:25.643: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1482
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-397e63ec-dd6f-4a0e-8e4a-92d781c8b231 in namespace container-probe-1482
Feb 24 20:39:27.879: INFO: Started pod busybox-397e63ec-dd6f-4a0e-8e4a-92d781c8b231 in namespace container-probe-1482
STEP: checking the pod's current state and verifying that restartCount is present
Feb 24 20:39:27.883: INFO: Initial restart count of pod busybox-397e63ec-dd6f-4a0e-8e4a-92d781c8b231 is 0
Feb 24 20:40:14.284: INFO: Restart count of pod container-probe-1482/busybox-397e63ec-dd6f-4a0e-8e4a-92d781c8b231 is now 1 (46.400994707s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:40:14.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1482" for this suite.
Feb 24 20:40:20.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:40:20.618: INFO: namespace container-probe-1482 deletion completed in 6.308982348s

• [SLOW TEST:54.976 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:40:20.624: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2481
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:40:20.833: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:40:21.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2481" for this suite.
Feb 24 20:40:28.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:40:28.381: INFO: namespace custom-resource-definition-2481 deletion completed in 6.35927719s

• [SLOW TEST:7.758 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:40:28.385: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2153
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 24 20:40:28.561: INFO: Waiting up to 5m0s for pod "pod-6a652a0c-11b2-401f-817f-8c048d828534" in namespace "emptydir-2153" to be "success or failure"
Feb 24 20:40:28.572: INFO: Pod "pod-6a652a0c-11b2-401f-817f-8c048d828534": Phase="Pending", Reason="", readiness=false. Elapsed: 10.813862ms
Feb 24 20:40:30.575: INFO: Pod "pod-6a652a0c-11b2-401f-817f-8c048d828534": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014318273s
Feb 24 20:40:32.579: INFO: Pod "pod-6a652a0c-11b2-401f-817f-8c048d828534": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017509885s
STEP: Saw pod success
Feb 24 20:40:32.579: INFO: Pod "pod-6a652a0c-11b2-401f-817f-8c048d828534" satisfied condition "success or failure"
Feb 24 20:40:32.582: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-6a652a0c-11b2-401f-817f-8c048d828534 container test-container: <nil>
STEP: delete the pod
Feb 24 20:40:32.616: INFO: Waiting for pod pod-6a652a0c-11b2-401f-817f-8c048d828534 to disappear
Feb 24 20:40:32.620: INFO: Pod pod-6a652a0c-11b2-401f-817f-8c048d828534 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:40:32.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2153" for this suite.
Feb 24 20:40:38.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:40:38.789: INFO: namespace emptydir-2153 deletion completed in 6.164362537s

• [SLOW TEST:10.405 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:40:38.794: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2110
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 24 20:40:45.118: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 24 20:40:45.123: INFO: Pod pod-with-poststart-http-hook still exists
Feb 24 20:40:47.123: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 24 20:40:47.136: INFO: Pod pod-with-poststart-http-hook still exists
Feb 24 20:40:49.123: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 24 20:40:49.201: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:40:49.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2110" for this suite.
Feb 24 20:41:17.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:41:17.554: INFO: namespace container-lifecycle-hook-2110 deletion completed in 28.346389351s

• [SLOW TEST:38.761 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:41:17.558: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1182
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-2148efc4-9c90-48ef-8233-38e34737bf90 in namespace container-probe-1182
Feb 24 20:41:19.920: INFO: Started pod test-webserver-2148efc4-9c90-48ef-8233-38e34737bf90 in namespace container-probe-1182
STEP: checking the pod's current state and verifying that restartCount is present
Feb 24 20:41:19.923: INFO: Initial restart count of pod test-webserver-2148efc4-9c90-48ef-8233-38e34737bf90 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:45:20.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1182" for this suite.
Feb 24 20:45:26.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:45:26.697: INFO: namespace container-probe-1182 deletion completed in 6.233932062s

• [SLOW TEST:249.140 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:45:26.713: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-5922
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Feb 24 20:45:26.996: INFO: Waiting up to 5m0s for pod "var-expansion-103a89fc-276e-4206-8af3-3300c62c6fe7" in namespace "var-expansion-5922" to be "success or failure"
Feb 24 20:45:26.999: INFO: Pod "var-expansion-103a89fc-276e-4206-8af3-3300c62c6fe7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.001267ms
Feb 24 20:45:29.007: INFO: Pod "var-expansion-103a89fc-276e-4206-8af3-3300c62c6fe7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011485809s
STEP: Saw pod success
Feb 24 20:45:29.008: INFO: Pod "var-expansion-103a89fc-276e-4206-8af3-3300c62c6fe7" satisfied condition "success or failure"
Feb 24 20:45:29.015: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod var-expansion-103a89fc-276e-4206-8af3-3300c62c6fe7 container dapi-container: <nil>
STEP: delete the pod
Feb 24 20:45:29.069: INFO: Waiting for pod var-expansion-103a89fc-276e-4206-8af3-3300c62c6fe7 to disappear
Feb 24 20:45:29.081: INFO: Pod var-expansion-103a89fc-276e-4206-8af3-3300c62c6fe7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:45:29.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5922" for this suite.
Feb 24 20:45:35.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:45:35.250: INFO: namespace var-expansion-5922 deletion completed in 6.159164731s

• [SLOW TEST:8.537 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:45:35.258: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6704
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 24 20:45:39.840: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 24 20:45:39.913: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 24 20:45:41.913: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 24 20:45:41.917: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 24 20:45:43.913: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 24 20:45:43.917: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:45:43.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6704" for this suite.
Feb 24 20:45:57.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:45:58.880: INFO: namespace container-lifecycle-hook-6704 deletion completed in 14.946926695s

• [SLOW TEST:23.623 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:45:58.881: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5735
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 24 20:45:59.598: INFO: Waiting up to 5m0s for pod "downward-api-740691ee-9268-40de-a995-59690e26d28b" in namespace "downward-api-5735" to be "success or failure"
Feb 24 20:45:59.601: INFO: Pod "downward-api-740691ee-9268-40de-a995-59690e26d28b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.46224ms
Feb 24 20:46:01.605: INFO: Pod "downward-api-740691ee-9268-40de-a995-59690e26d28b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006821389s
STEP: Saw pod success
Feb 24 20:46:01.606: INFO: Pod "downward-api-740691ee-9268-40de-a995-59690e26d28b" satisfied condition "success or failure"
Feb 24 20:46:01.609: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downward-api-740691ee-9268-40de-a995-59690e26d28b container dapi-container: <nil>
STEP: delete the pod
Feb 24 20:46:01.632: INFO: Waiting for pod downward-api-740691ee-9268-40de-a995-59690e26d28b to disappear
Feb 24 20:46:01.637: INFO: Pod downward-api-740691ee-9268-40de-a995-59690e26d28b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:46:01.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5735" for this suite.
Feb 24 20:46:09.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:46:09.823: INFO: namespace downward-api-5735 deletion completed in 8.181736203s

• [SLOW TEST:10.942 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:46:09.824: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-3373
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Feb 24 20:46:14.546: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3373 pod-service-account-1a733e8d-0ed1-4b4e-b524-0484ba82cc25 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Feb 24 20:46:14.865: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3373 pod-service-account-1a733e8d-0ed1-4b4e-b524-0484ba82cc25 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Feb 24 20:46:15.132: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3373 pod-service-account-1a733e8d-0ed1-4b4e-b524-0484ba82cc25 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:46:15.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3373" for this suite.
Feb 24 20:46:21.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:46:22.308: INFO: namespace svcaccounts-3373 deletion completed in 6.761639075s

• [SLOW TEST:12.485 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:46:22.310: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2218
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb 24 20:46:22.599: INFO: PodSpec: initContainers in spec.initContainers
Feb 24 20:47:07.829: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-5e2007dd-812e-4a78-b7db-cdca620fadd1", GenerateName:"", Namespace:"init-container-2218", SelfLink:"/api/v1/namespaces/init-container-2218/pods/pod-init-5e2007dd-812e-4a78-b7db-cdca620fadd1", UID:"80261e06-5762-4961-a2ac-90de3f55a3a9", ResourceVersion:"47820", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63718173982, loc:(*time.Location)(0x84bfb00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"599445523"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-s46kt", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00375bf40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-s46kt", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-s46kt", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-s46kt", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002d24cc8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"gke-c116p-default-pool-41de4435-fss3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00494f560), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002d24d40)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002d24d60)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002d24d68), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002d24d6c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173982, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173982, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173982, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718173982, loc:(*time.Location)(0x84bfb00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.77.32.2", PodIP:"10.12.0.36", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.12.0.36"}}, StartTime:(*v1.Time)(0xc002c7f940), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002c10310)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002c10380)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:e004c2cc521c95383aebb1fb5893719aa7a8eae2e7a71f316a4410784edb00a9", ContainerID:"docker://8dc5226d92f39eb3df11b5c888ee5ba55e5c3bee41ec70b8cc83b19bef51abe5", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002c7f980), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002c7f960), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc002d24def)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:47:07.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2218" for this suite.
Feb 24 20:47:19.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:47:20.232: INFO: namespace init-container-2218 deletion completed in 12.385473766s

• [SLOW TEST:57.922 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:47:20.237: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1000
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 20:47:21.005: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 20:47:23.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718174040, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718174040, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718174041, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718174040, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 20:47:26.250: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:47:26.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1000" for this suite.
Feb 24 20:47:32.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:47:32.554: INFO: namespace webhook-1000 deletion completed in 6.290990551s
STEP: Destroying namespace "webhook-1000-markers" for this suite.
Feb 24 20:47:38.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:47:38.722: INFO: namespace webhook-1000-markers deletion completed in 6.167004348s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.505 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:47:38.742: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6714
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-6714
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 24 20:47:38.906: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 24 20:48:02.039: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.12.0.39:8080/dial?request=hostName&protocol=http&host=10.12.2.62&port=8080&tries=1'] Namespace:pod-network-test-6714 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 20:48:02.039: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:48:02.197: INFO: Waiting for endpoints: map[]
Feb 24 20:48:02.201: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.12.0.39:8080/dial?request=hostName&protocol=http&host=10.12.0.38&port=8080&tries=1'] Namespace:pod-network-test-6714 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 20:48:02.201: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:48:02.399: INFO: Waiting for endpoints: map[]
Feb 24 20:48:02.405: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.12.0.39:8080/dial?request=hostName&protocol=http&host=10.12.1.64&port=8080&tries=1'] Namespace:pod-network-test-6714 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 20:48:02.405: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 20:48:02.591: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:48:02.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6714" for this suite.
Feb 24 20:48:14.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:48:14.810: INFO: namespace pod-network-test-6714 deletion completed in 12.209464513s

• [SLOW TEST:36.068 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:48:14.813: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2846
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 20:48:15.178: INFO: Waiting up to 5m0s for pod "downwardapi-volume-17b62d22-5f4f-4b24-8f5f-57e3f9fd58b2" in namespace "downward-api-2846" to be "success or failure"
Feb 24 20:48:15.200: INFO: Pod "downwardapi-volume-17b62d22-5f4f-4b24-8f5f-57e3f9fd58b2": Phase="Pending", Reason="", readiness=false. Elapsed: 21.855623ms
Feb 24 20:48:17.204: INFO: Pod "downwardapi-volume-17b62d22-5f4f-4b24-8f5f-57e3f9fd58b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025616922s
STEP: Saw pod success
Feb 24 20:48:17.204: INFO: Pod "downwardapi-volume-17b62d22-5f4f-4b24-8f5f-57e3f9fd58b2" satisfied condition "success or failure"
Feb 24 20:48:17.207: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downwardapi-volume-17b62d22-5f4f-4b24-8f5f-57e3f9fd58b2 container client-container: <nil>
STEP: delete the pod
Feb 24 20:48:17.248: INFO: Waiting for pod downwardapi-volume-17b62d22-5f4f-4b24-8f5f-57e3f9fd58b2 to disappear
Feb 24 20:48:17.255: INFO: Pod downwardapi-volume-17b62d22-5f4f-4b24-8f5f-57e3f9fd58b2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:48:17.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2846" for this suite.
Feb 24 20:48:23.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:48:23.491: INFO: namespace downward-api-2846 deletion completed in 6.229579663s

• [SLOW TEST:8.679 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:48:23.495: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4937
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 24 20:48:23.689: INFO: Waiting up to 5m0s for pod "pod-acf0636e-d730-4918-a290-791213afe484" in namespace "emptydir-4937" to be "success or failure"
Feb 24 20:48:23.693: INFO: Pod "pod-acf0636e-d730-4918-a290-791213afe484": Phase="Pending", Reason="", readiness=false. Elapsed: 4.1657ms
Feb 24 20:48:25.697: INFO: Pod "pod-acf0636e-d730-4918-a290-791213afe484": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00770676s
STEP: Saw pod success
Feb 24 20:48:25.697: INFO: Pod "pod-acf0636e-d730-4918-a290-791213afe484" satisfied condition "success or failure"
Feb 24 20:48:25.700: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-acf0636e-d730-4918-a290-791213afe484 container test-container: <nil>
STEP: delete the pod
Feb 24 20:48:25.730: INFO: Waiting for pod pod-acf0636e-d730-4918-a290-791213afe484 to disappear
Feb 24 20:48:25.733: INFO: Pod pod-acf0636e-d730-4918-a290-791213afe484 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:48:25.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4937" for this suite.
Feb 24 20:48:31.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:48:31.950: INFO: namespace emptydir-4937 deletion completed in 6.21178142s

• [SLOW TEST:8.456 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:48:31.954: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-6323
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:48:32.186: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-80c0c3f6-ffaa-428b-8ac1-19c730f045ce" in namespace "security-context-test-6323" to be "success or failure"
Feb 24 20:48:32.192: INFO: Pod "alpine-nnp-false-80c0c3f6-ffaa-428b-8ac1-19c730f045ce": Phase="Pending", Reason="", readiness=false. Elapsed: 5.945204ms
Feb 24 20:48:34.196: INFO: Pod "alpine-nnp-false-80c0c3f6-ffaa-428b-8ac1-19c730f045ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00993972s
Feb 24 20:48:36.199: INFO: Pod "alpine-nnp-false-80c0c3f6-ffaa-428b-8ac1-19c730f045ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013639652s
Feb 24 20:48:36.200: INFO: Pod "alpine-nnp-false-80c0c3f6-ffaa-428b-8ac1-19c730f045ce" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:48:36.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6323" for this suite.
Feb 24 20:48:42.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:48:42.392: INFO: namespace security-context-test-6323 deletion completed in 6.173354329s

• [SLOW TEST:10.439 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:48:42.407: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-5772
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Feb 24 20:48:47.358: INFO: Successfully updated pod "adopt-release-2td6l"
STEP: Checking that the Job readopts the Pod
Feb 24 20:48:47.358: INFO: Waiting up to 15m0s for pod "adopt-release-2td6l" in namespace "job-5772" to be "adopted"
Feb 24 20:48:47.370: INFO: Pod "adopt-release-2td6l": Phase="Running", Reason="", readiness=true. Elapsed: 12.116661ms
Feb 24 20:48:49.376: INFO: Pod "adopt-release-2td6l": Phase="Running", Reason="", readiness=true. Elapsed: 2.017578644s
Feb 24 20:48:49.376: INFO: Pod "adopt-release-2td6l" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Feb 24 20:48:49.894: INFO: Successfully updated pod "adopt-release-2td6l"
STEP: Checking that the Job releases the Pod
Feb 24 20:48:49.894: INFO: Waiting up to 15m0s for pod "adopt-release-2td6l" in namespace "job-5772" to be "released"
Feb 24 20:48:49.909: INFO: Pod "adopt-release-2td6l": Phase="Running", Reason="", readiness=true. Elapsed: 15.188161ms
Feb 24 20:48:49.909: INFO: Pod "adopt-release-2td6l" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:48:49.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5772" for this suite.
Feb 24 20:49:33.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:49:34.376: INFO: namespace job-5772 deletion completed in 44.456880838s

• [SLOW TEST:51.970 seconds]
[sig-apps] Job
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:49:34.383: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2129
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb 24 20:49:34.570: INFO: Pod name pod-release: Found 0 pods out of 1
Feb 24 20:49:39.646: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:49:39.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2129" for this suite.
Feb 24 20:49:45.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:49:46.035: INFO: namespace replication-controller-2129 deletion completed in 6.249281114s

• [SLOW TEST:11.652 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:49:46.040: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6151
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 24 20:49:46.249: INFO: Waiting up to 5m0s for pod "pod-4946c77a-ff38-4832-a115-eef34fd27e36" in namespace "emptydir-6151" to be "success or failure"
Feb 24 20:49:46.261: INFO: Pod "pod-4946c77a-ff38-4832-a115-eef34fd27e36": Phase="Pending", Reason="", readiness=false. Elapsed: 11.462285ms
Feb 24 20:49:48.350: INFO: Pod "pod-4946c77a-ff38-4832-a115-eef34fd27e36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.100785096s
STEP: Saw pod success
Feb 24 20:49:48.350: INFO: Pod "pod-4946c77a-ff38-4832-a115-eef34fd27e36" satisfied condition "success or failure"
Feb 24 20:49:48.458: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-4946c77a-ff38-4832-a115-eef34fd27e36 container test-container: <nil>
STEP: delete the pod
Feb 24 20:49:48.888: INFO: Waiting for pod pod-4946c77a-ff38-4832-a115-eef34fd27e36 to disappear
Feb 24 20:49:49.034: INFO: Pod pod-4946c77a-ff38-4832-a115-eef34fd27e36 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:49:49.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6151" for this suite.
Feb 24 20:49:55.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:49:55.484: INFO: namespace emptydir-6151 deletion completed in 6.352105149s

• [SLOW TEST:9.445 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:49:55.488: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5493
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 24 20:49:55.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-5493'
Feb 24 20:49:55.967: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 24 20:49:55.967: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Feb 24 20:50:00.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 delete deployment e2e-test-httpd-deployment --namespace=kubectl-5493'
Feb 24 20:50:00.245: INFO: stderr: ""
Feb 24 20:50:00.245: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:50:00.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5493" for this suite.
Feb 24 20:50:12.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:50:12.425: INFO: namespace kubectl-5493 deletion completed in 12.166439124s

• [SLOW TEST:16.938 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:50:12.430: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-2578
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Feb 24 20:50:12.633: INFO: Waiting up to 1m0s for all nodes to be ready
Feb 24 20:51:12.657: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:51:12.660: INFO: Starting informer...
STEP: Starting pods...
Feb 24 20:51:12.894: INFO: Pod1 is running on gke-c116p-default-pool-41de4435-fss3. Tainting Node
Feb 24 20:51:17.129: INFO: Pod2 is running on gke-c116p-default-pool-41de4435-fss3. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Feb 24 20:51:30.503: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Feb 24 20:51:50.506: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:51:50.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-2578" for this suite.
Feb 24 20:51:56.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:51:56.703: INFO: namespace taint-multiple-pods-2578 deletion completed in 6.158596721s

• [SLOW TEST:104.273 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:51:56.704: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1539
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 24 20:52:01.617: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 24 20:52:01.620: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 24 20:52:03.620: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 24 20:52:03.797: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 24 20:52:05.620: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 24 20:52:05.624: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:52:05.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1539" for this suite.
Feb 24 20:52:17.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:52:17.773: INFO: namespace container-lifecycle-hook-1539 deletion completed in 12.143674077s

• [SLOW TEST:21.070 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:52:17.781: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7507
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7507.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-7507.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7507.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7507.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-7507.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7507.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 24 20:52:23.234: INFO: DNS probes using dns-7507/dns-test-f8259e74-c68c-4686-a8ab-85a0ad58b107 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:52:23.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7507" for this suite.
Feb 24 20:52:29.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:52:29.473: INFO: namespace dns-7507 deletion completed in 6.194355502s

• [SLOW TEST:11.692 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:52:29.481: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5822
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 20:52:29.674: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f53d53ae-1a71-4496-be34-10e1e347ed34" in namespace "downward-api-5822" to be "success or failure"
Feb 24 20:52:29.699: INFO: Pod "downwardapi-volume-f53d53ae-1a71-4496-be34-10e1e347ed34": Phase="Pending", Reason="", readiness=false. Elapsed: 24.428481ms
Feb 24 20:52:31.703: INFO: Pod "downwardapi-volume-f53d53ae-1a71-4496-be34-10e1e347ed34": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028529925s
Feb 24 20:52:33.711: INFO: Pod "downwardapi-volume-f53d53ae-1a71-4496-be34-10e1e347ed34": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03582875s
STEP: Saw pod success
Feb 24 20:52:33.711: INFO: Pod "downwardapi-volume-f53d53ae-1a71-4496-be34-10e1e347ed34" satisfied condition "success or failure"
Feb 24 20:52:33.714: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downwardapi-volume-f53d53ae-1a71-4496-be34-10e1e347ed34 container client-container: <nil>
STEP: delete the pod
Feb 24 20:52:33.772: INFO: Waiting for pod downwardapi-volume-f53d53ae-1a71-4496-be34-10e1e347ed34 to disappear
Feb 24 20:52:33.785: INFO: Pod downwardapi-volume-f53d53ae-1a71-4496-be34-10e1e347ed34 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:52:33.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5822" for this suite.
Feb 24 20:52:39.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:52:40.026: INFO: namespace downward-api-5822 deletion completed in 6.233165454s

• [SLOW TEST:10.546 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:52:40.031: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4674
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-087d4a4d-19fe-4f21-9851-6c804ed20633 in namespace container-probe-4674
Feb 24 20:52:42.330: INFO: Started pod liveness-087d4a4d-19fe-4f21-9851-6c804ed20633 in namespace container-probe-4674
STEP: checking the pod's current state and verifying that restartCount is present
Feb 24 20:52:42.409: INFO: Initial restart count of pod liveness-087d4a4d-19fe-4f21-9851-6c804ed20633 is 0
Feb 24 20:52:58.876: INFO: Restart count of pod container-probe-4674/liveness-087d4a4d-19fe-4f21-9851-6c804ed20633 is now 1 (16.466225444s elapsed)
Feb 24 20:53:18.956: INFO: Restart count of pod container-probe-4674/liveness-087d4a4d-19fe-4f21-9851-6c804ed20633 is now 2 (36.546572526s elapsed)
Feb 24 20:53:39.090: INFO: Restart count of pod container-probe-4674/liveness-087d4a4d-19fe-4f21-9851-6c804ed20633 is now 3 (56.680425344s elapsed)
Feb 24 20:53:59.132: INFO: Restart count of pod container-probe-4674/liveness-087d4a4d-19fe-4f21-9851-6c804ed20633 is now 4 (1m16.722415576s elapsed)
Feb 24 20:55:03.612: INFO: Restart count of pod container-probe-4674/liveness-087d4a4d-19fe-4f21-9851-6c804ed20633 is now 5 (2m21.202703193s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:55:03.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4674" for this suite.
Feb 24 20:55:10.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:55:10.277: INFO: namespace container-probe-4674 deletion completed in 6.385379583s

• [SLOW TEST:150.247 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:55:10.281: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2341
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Feb 24 20:55:10.489: INFO: Waiting up to 5m0s for pod "var-expansion-bfe01564-c890-4eac-a21b-7b091bf90d98" in namespace "var-expansion-2341" to be "success or failure"
Feb 24 20:55:10.495: INFO: Pod "var-expansion-bfe01564-c890-4eac-a21b-7b091bf90d98": Phase="Pending", Reason="", readiness=false. Elapsed: 5.779293ms
Feb 24 20:55:12.501: INFO: Pod "var-expansion-bfe01564-c890-4eac-a21b-7b091bf90d98": Phase="Running", Reason="", readiness=true. Elapsed: 2.011932841s
Feb 24 20:55:14.505: INFO: Pod "var-expansion-bfe01564-c890-4eac-a21b-7b091bf90d98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016011694s
STEP: Saw pod success
Feb 24 20:55:14.505: INFO: Pod "var-expansion-bfe01564-c890-4eac-a21b-7b091bf90d98" satisfied condition "success or failure"
Feb 24 20:55:14.511: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod var-expansion-bfe01564-c890-4eac-a21b-7b091bf90d98 container dapi-container: <nil>
STEP: delete the pod
Feb 24 20:55:14.545: INFO: Waiting for pod var-expansion-bfe01564-c890-4eac-a21b-7b091bf90d98 to disappear
Feb 24 20:55:14.549: INFO: Pod var-expansion-bfe01564-c890-4eac-a21b-7b091bf90d98 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:55:14.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2341" for this suite.
Feb 24 20:55:20.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:55:20.726: INFO: namespace var-expansion-2341 deletion completed in 6.172694018s

• [SLOW TEST:10.446 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:55:20.730: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7281
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 24 20:55:20.918: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7281 /api/v1/namespaces/watch-7281/configmaps/e2e-watch-test-resource-version 5ab76bb5-9234-4e9e-96b4-bb1181d8f1a0 50467 0 2020-02-24 20:55:20 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 24 20:55:20.919: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7281 /api/v1/namespaces/watch-7281/configmaps/e2e-watch-test-resource-version 5ab76bb5-9234-4e9e-96b4-bb1181d8f1a0 50468 0 2020-02-24 20:55:20 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:55:20.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7281" for this suite.
Feb 24 20:55:26.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:55:27.072: INFO: namespace watch-7281 deletion completed in 6.149076899s

• [SLOW TEST:6.343 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:55:27.081: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1092
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 20:55:27.265: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2ff6537a-691a-4a64-ac45-90e418a61291" in namespace "projected-1092" to be "success or failure"
Feb 24 20:55:27.268: INFO: Pod "downwardapi-volume-2ff6537a-691a-4a64-ac45-90e418a61291": Phase="Pending", Reason="", readiness=false. Elapsed: 3.478894ms
Feb 24 20:55:29.272: INFO: Pod "downwardapi-volume-2ff6537a-691a-4a64-ac45-90e418a61291": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006905687s
STEP: Saw pod success
Feb 24 20:55:29.272: INFO: Pod "downwardapi-volume-2ff6537a-691a-4a64-ac45-90e418a61291" satisfied condition "success or failure"
Feb 24 20:55:29.276: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downwardapi-volume-2ff6537a-691a-4a64-ac45-90e418a61291 container client-container: <nil>
STEP: delete the pod
Feb 24 20:55:29.301: INFO: Waiting for pod downwardapi-volume-2ff6537a-691a-4a64-ac45-90e418a61291 to disappear
Feb 24 20:55:29.305: INFO: Pod downwardapi-volume-2ff6537a-691a-4a64-ac45-90e418a61291 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:55:29.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1092" for this suite.
Feb 24 20:55:35.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:55:35.476: INFO: namespace projected-1092 deletion completed in 6.16603344s

• [SLOW TEST:8.396 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:55:35.486: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3128
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:55:35.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3128" for this suite.
Feb 24 20:55:41.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:55:41.830: INFO: namespace services-3128 deletion completed in 6.182428723s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.344 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:55:41.833: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1745
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-b5d57f79-2124-4435-a7dc-280f6d40d990
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:55:42.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1745" for this suite.
Feb 24 20:55:48.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:55:48.980: INFO: namespace secrets-1745 deletion completed in 6.971751287s

• [SLOW TEST:7.147 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:55:48.987: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4705
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 20:55:49.234: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:55:53.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4705" for this suite.
Feb 24 20:56:37.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:56:37.911: INFO: namespace pods-4705 deletion completed in 44.327574001s

• [SLOW TEST:48.924 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:56:37.914: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-301
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:56:38.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-301" for this suite.
Feb 24 20:56:44.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:56:44.575: INFO: namespace kubelet-test-301 deletion completed in 6.217746464s

• [SLOW TEST:6.661 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:56:44.578: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7132
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:56:56.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7132" for this suite.
Feb 24 20:57:02.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:57:05.173: INFO: namespace resourcequota-7132 deletion completed in 8.204512981s

• [SLOW TEST:20.595 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:57:05.181: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1976
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 20:57:05.831: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Feb 24 20:57:08.017: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718174625, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718174625, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718174625, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718174625, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 20:57:11.044: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 20:57:11.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1976" for this suite.
Feb 24 20:57:17.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:57:17.528: INFO: namespace webhook-1976 deletion completed in 6.158280281s
STEP: Destroying namespace "webhook-1976-markers" for this suite.
Feb 24 20:57:23.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 20:57:23.686: INFO: namespace webhook-1976-markers deletion completed in 6.15799349s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.524 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 20:57:23.709: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-3962
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb 24 20:57:24.155: INFO: Pod name wrapped-volume-race-a2444d21-20a6-49a3-b4dc-cff5ccbd941f: Found 0 pods out of 5
Feb 24 20:57:29.161: INFO: Pod name wrapped-volume-race-a2444d21-20a6-49a3-b4dc-cff5ccbd941f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-a2444d21-20a6-49a3-b4dc-cff5ccbd941f in namespace emptydir-wrapper-3962, will wait for the garbage collector to delete the pods
Feb 24 20:57:41.253: INFO: Deleting ReplicationController wrapped-volume-race-a2444d21-20a6-49a3-b4dc-cff5ccbd941f took: 13.59447ms
Feb 24 20:57:41.854: INFO: Terminating ReplicationController wrapped-volume-race-a2444d21-20a6-49a3-b4dc-cff5ccbd941f pods took: 600.54027ms
STEP: Creating RC which spawns configmap-volume pods
Feb 24 20:58:21.512: INFO: Pod name wrapped-volume-race-fb3ea73d-dbfb-4100-9544-d97d281a2f7f: Found 0 pods out of 5
Feb 24 20:58:26.518: INFO: Pod name wrapped-volume-race-fb3ea73d-dbfb-4100-9544-d97d281a2f7f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-fb3ea73d-dbfb-4100-9544-d97d281a2f7f in namespace emptydir-wrapper-3962, will wait for the garbage collector to delete the pods
Feb 24 20:58:40.646: INFO: Deleting ReplicationController wrapped-volume-race-fb3ea73d-dbfb-4100-9544-d97d281a2f7f took: 11.848925ms
Feb 24 20:58:41.247: INFO: Terminating ReplicationController wrapped-volume-race-fb3ea73d-dbfb-4100-9544-d97d281a2f7f pods took: 600.326774ms
STEP: Creating RC which spawns configmap-volume pods
Feb 24 20:59:21.381: INFO: Pod name wrapped-volume-race-98be1fec-1f8a-4693-a60e-7fc04d57e33a: Found 0 pods out of 5
Feb 24 20:59:26.391: INFO: Pod name wrapped-volume-race-98be1fec-1f8a-4693-a60e-7fc04d57e33a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-98be1fec-1f8a-4693-a60e-7fc04d57e33a in namespace emptydir-wrapper-3962, will wait for the garbage collector to delete the pods
Feb 24 20:59:40.480: INFO: Deleting ReplicationController wrapped-volume-race-98be1fec-1f8a-4693-a60e-7fc04d57e33a took: 9.563359ms
Feb 24 20:59:41.081: INFO: Terminating ReplicationController wrapped-volume-race-98be1fec-1f8a-4693-a60e-7fc04d57e33a pods took: 600.548478ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:00:21.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3962" for this suite.
Feb 24 21:00:27.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:00:27.975: INFO: namespace emptydir-wrapper-3962 deletion completed in 6.168744293s

• [SLOW TEST:184.267 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:00:27.980: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7227
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 24 21:00:28.171: INFO: Waiting up to 5m0s for pod "downward-api-52c7f519-176a-4c43-a8b8-3ed7dc24bce9" in namespace "downward-api-7227" to be "success or failure"
Feb 24 21:00:28.178: INFO: Pod "downward-api-52c7f519-176a-4c43-a8b8-3ed7dc24bce9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.996598ms
Feb 24 21:00:30.182: INFO: Pod "downward-api-52c7f519-176a-4c43-a8b8-3ed7dc24bce9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010609702s
STEP: Saw pod success
Feb 24 21:00:30.183: INFO: Pod "downward-api-52c7f519-176a-4c43-a8b8-3ed7dc24bce9" satisfied condition "success or failure"
Feb 24 21:00:30.185: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downward-api-52c7f519-176a-4c43-a8b8-3ed7dc24bce9 container dapi-container: <nil>
STEP: delete the pod
Feb 24 21:00:30.227: INFO: Waiting for pod downward-api-52c7f519-176a-4c43-a8b8-3ed7dc24bce9 to disappear
Feb 24 21:00:30.232: INFO: Pod downward-api-52c7f519-176a-4c43-a8b8-3ed7dc24bce9 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:00:30.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7227" for this suite.
Feb 24 21:00:36.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:00:36.382: INFO: namespace downward-api-7227 deletion completed in 6.144980527s

• [SLOW TEST:8.403 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:00:36.388: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5122
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-8b1e02ba-d243-44d9-bba9-2a90034d0c8d
STEP: Creating a pod to test consume configMaps
Feb 24 21:00:36.567: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8286146f-b98d-44b9-8785-d7d96eb63680" in namespace "projected-5122" to be "success or failure"
Feb 24 21:00:36.573: INFO: Pod "pod-projected-configmaps-8286146f-b98d-44b9-8785-d7d96eb63680": Phase="Pending", Reason="", readiness=false. Elapsed: 5.013514ms
Feb 24 21:00:38.583: INFO: Pod "pod-projected-configmaps-8286146f-b98d-44b9-8785-d7d96eb63680": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015306918s
STEP: Saw pod success
Feb 24 21:00:38.583: INFO: Pod "pod-projected-configmaps-8286146f-b98d-44b9-8785-d7d96eb63680" satisfied condition "success or failure"
Feb 24 21:00:38.586: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-projected-configmaps-8286146f-b98d-44b9-8785-d7d96eb63680 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 21:00:38.619: INFO: Waiting for pod pod-projected-configmaps-8286146f-b98d-44b9-8785-d7d96eb63680 to disappear
Feb 24 21:00:38.624: INFO: Pod pod-projected-configmaps-8286146f-b98d-44b9-8785-d7d96eb63680 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:00:38.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5122" for this suite.
Feb 24 21:00:44.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:00:44.775: INFO: namespace projected-5122 deletion completed in 6.146439936s

• [SLOW TEST:8.388 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:00:44.777: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-1721
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:00:47.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1721" for this suite.
Feb 24 21:00:55.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:00:55.219: INFO: namespace emptydir-wrapper-1721 deletion completed in 8.134663752s

• [SLOW TEST:10.442 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:00:55.226: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-356
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-d682ed9f-74c0-42f4-8747-16390648e426
STEP: Creating a pod to test consume secrets
Feb 24 21:00:55.452: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-483cef72-dfa4-4b04-8246-7c8b87a43272" in namespace "projected-356" to be "success or failure"
Feb 24 21:00:55.458: INFO: Pod "pod-projected-secrets-483cef72-dfa4-4b04-8246-7c8b87a43272": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01943ms
Feb 24 21:00:57.462: INFO: Pod "pod-projected-secrets-483cef72-dfa4-4b04-8246-7c8b87a43272": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009595374s
STEP: Saw pod success
Feb 24 21:00:57.462: INFO: Pod "pod-projected-secrets-483cef72-dfa4-4b04-8246-7c8b87a43272" satisfied condition "success or failure"
Feb 24 21:00:57.465: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-projected-secrets-483cef72-dfa4-4b04-8246-7c8b87a43272 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 24 21:00:57.488: INFO: Waiting for pod pod-projected-secrets-483cef72-dfa4-4b04-8246-7c8b87a43272 to disappear
Feb 24 21:00:57.495: INFO: Pod pod-projected-secrets-483cef72-dfa4-4b04-8246-7c8b87a43272 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:00:57.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-356" for this suite.
Feb 24 21:01:03.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:01:04.541: INFO: namespace projected-356 deletion completed in 7.042344599s

• [SLOW TEST:9.316 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:01:04.548: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8760
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-8760/configmap-test-c27296f5-fcae-4a17-b9fd-5734af83ae26
STEP: Creating a pod to test consume configMaps
Feb 24 21:01:04.731: INFO: Waiting up to 5m0s for pod "pod-configmaps-d29b7b6c-2a83-4a01-b0a9-7e027a40d492" in namespace "configmap-8760" to be "success or failure"
Feb 24 21:01:04.744: INFO: Pod "pod-configmaps-d29b7b6c-2a83-4a01-b0a9-7e027a40d492": Phase="Pending", Reason="", readiness=false. Elapsed: 12.577231ms
Feb 24 21:01:06.852: INFO: Pod "pod-configmaps-d29b7b6c-2a83-4a01-b0a9-7e027a40d492": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.120386855s
STEP: Saw pod success
Feb 24 21:01:06.852: INFO: Pod "pod-configmaps-d29b7b6c-2a83-4a01-b0a9-7e027a40d492" satisfied condition "success or failure"
Feb 24 21:01:06.962: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-configmaps-d29b7b6c-2a83-4a01-b0a9-7e027a40d492 container env-test: <nil>
STEP: delete the pod
Feb 24 21:01:07.498: INFO: Waiting for pod pod-configmaps-d29b7b6c-2a83-4a01-b0a9-7e027a40d492 to disappear
Feb 24 21:01:07.623: INFO: Pod pod-configmaps-d29b7b6c-2a83-4a01-b0a9-7e027a40d492 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:01:07.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8760" for this suite.
Feb 24 21:01:13.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:01:14.122: INFO: namespace configmap-8760 deletion completed in 6.417641235s

• [SLOW TEST:9.574 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:01:14.130: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3772
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 24 21:01:14.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-3772'
Feb 24 21:01:14.675: INFO: stderr: ""
Feb 24 21:01:14.676: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Feb 24 21:01:19.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pod e2e-test-httpd-pod --namespace=kubectl-3772 -o json'
Feb 24 21:01:19.904: INFO: stderr: ""
Feb 24 21:01:19.904: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2020-02-24T21:01:14Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-3772\",\n        \"resourceVersion\": \"52595\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-3772/pods/e2e-test-httpd-pod\",\n        \"uid\": \"c4e8335e-4b5b-487d-b04c-51b4f28d7afc\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-mbpjp\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"gke-c116p-default-pool-41de4435-fss3\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-mbpjp\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-mbpjp\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-24T21:01:14Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-24T21:01:16Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-24T21:01:16Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-24T21:01:14Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://132cdb1531f50324a5443882676dbd61e2f11f017a45c104e4f4e57bcedd5765\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-02-24T21:01:15Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.77.32.2\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.12.0.65\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.12.0.65\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-02-24T21:01:14Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 24 21:01:19.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 replace -f - --namespace=kubectl-3772'
Feb 24 21:01:20.382: INFO: stderr: ""
Feb 24 21:01:20.382: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Feb 24 21:01:20.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 delete pods e2e-test-httpd-pod --namespace=kubectl-3772'
Feb 24 21:01:23.043: INFO: stderr: ""
Feb 24 21:01:23.044: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:01:23.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3772" for this suite.
Feb 24 21:01:29.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:01:29.245: INFO: namespace kubectl-3772 deletion completed in 6.187860992s

• [SLOW TEST:15.116 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:01:29.250: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9432
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 21:01:29.422: INFO: Creating deployment "webserver-deployment"
Feb 24 21:01:29.437: INFO: Waiting for observed generation 1
Feb 24 21:01:31.458: INFO: Waiting for all required pods to come up
Feb 24 21:01:31.461: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 24 21:01:35.480: INFO: Waiting for deployment "webserver-deployment" to complete
Feb 24 21:01:35.487: INFO: Updating deployment "webserver-deployment" with a non-existent image
Feb 24 21:01:35.499: INFO: Updating deployment webserver-deployment
Feb 24 21:01:35.499: INFO: Waiting for observed generation 2
Feb 24 21:01:37.515: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 24 21:01:37.520: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 24 21:01:37.526: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Feb 24 21:01:37.551: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 24 21:01:37.552: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 24 21:01:37.557: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Feb 24 21:01:37.574: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Feb 24 21:01:37.574: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Feb 24 21:01:37.598: INFO: Updating deployment webserver-deployment
Feb 24 21:01:37.598: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Feb 24 21:01:37.688: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 24 21:01:37.720: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 24 21:01:39.750: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-9432 /apis/apps/v1/namespaces/deployment-9432/deployments/webserver-deployment 9cde6278-7511-4242-a0c6-2a3fc3ba3135 52927 3 2020-02-24 21:01:29 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0047acb58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-02-24 21:01:37 +0000 UTC,LastTransitionTime:2020-02-24 21:01:37 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-02-24 21:01:38 +0000 UTC,LastTransitionTime:2020-02-24 21:01:29 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Feb 24 21:01:39.754: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-9432 /apis/apps/v1/namespaces/deployment-9432/replicasets/webserver-deployment-c7997dcc8 f20944bf-1f8c-4e28-a61c-3adb9329943a 52926 3 2020-02-24 21:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 9cde6278-7511-4242-a0c6-2a3fc3ba3135 0xc0047ad077 0xc0047ad078}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0047ad0e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 24 21:01:39.754: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Feb 24 21:01:39.754: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-9432 /apis/apps/v1/namespaces/deployment-9432/replicasets/webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 52917 3 2020-02-24 21:01:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 9cde6278-7511-4242-a0c6-2a3fc3ba3135 0xc0047acfb7 0xc0047acfb8}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0047ad018 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Feb 24 21:01:39.767: INFO: Pod "webserver-deployment-595b5b9587-2c4hm" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2c4hm webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-2c4hm 3775d90d-ece3-4be6-a305-69c2bf10d301 52869 0 2020-02-24 21:01:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc0047ad5e7 0xc0047ad5e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-50z7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.3,PodIP:,StartTime:2020-02-24 21:01:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.767: INFO: Pod "webserver-deployment-595b5b9587-2kwsr" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2kwsr webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-2kwsr 00d64ff7-7a27-4ce8-9299-d2bfe2fceb65 52758 0 2020-02-24 21:01:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc0047ad730 0xc0047ad731}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-dz7p,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.4,PodIP:10.12.2.65,StartTime:2020-02-24 21:01:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 21:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://36e88dd301ada00335b29b7015d734070bc98c8e6cd1e913fa3f127e47ac7739,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.12.2.65,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.768: INFO: Pod "webserver-deployment-595b5b9587-454hc" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-454hc webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-454hc 0702cc27-2ad0-4408-baf8-bd725fc8ca5c 52887 0 2020-02-24 21:01:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc0047ad8b0 0xc0047ad8b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-dz7p,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.4,PodIP:,StartTime:2020-02-24 21:01:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.776: INFO: Pod "webserver-deployment-595b5b9587-5cg62" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-5cg62 webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-5cg62 c4227db7-34ec-43d1-823d-c59e29b60f5a 52773 0 2020-02-24 21:01:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc0047ada00 0xc0047ada01}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-fss3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.2,PodIP:10.12.0.66,StartTime:2020-02-24 21:01:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 21:01:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://fc1943169c6da8615e689afc6a08e42bda1932c590baed18a6a613c1ce33a502,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.12.0.66,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.776: INFO: Pod "webserver-deployment-595b5b9587-6jm6j" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6jm6j webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-6jm6j 94bf8a35-dba9-4628-907f-c9b9225f2be3 52766 0 2020-02-24 21:01:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc0047adb60 0xc0047adb61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-fss3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.2,PodIP:10.12.0.68,StartTime:2020-02-24 21:01:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 21:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://ccbe47bb27be8fc1efda7aa7413ea09e5b7e9f7d62939cb97ba515b9a8b634eb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.12.0.68,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.776: INFO: Pod "webserver-deployment-595b5b9587-6sj5d" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6sj5d webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-6sj5d 33b52ec8-7d53-42ee-9c5c-bad9a5fa3160 52936 0 2020-02-24 21:01:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc0047adcc0 0xc0047adcc1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-50z7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.3,PodIP:,StartTime:2020-02-24 21:01:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.785: INFO: Pod "webserver-deployment-595b5b9587-6z82z" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6z82z webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-6z82z 75341253-d096-4261-b303-d6b3e6f23125 52770 0 2020-02-24 21:01:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc0047ade00 0xc0047ade01}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-fss3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.2,PodIP:10.12.0.67,StartTime:2020-02-24 21:01:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 21:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://cf47bb467981b3e54f8f945b08f81e4ea6b7cd5c4cc28b14c1e562aa27444553,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.12.0.67,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.785: INFO: Pod "webserver-deployment-595b5b9587-7bdwb" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-7bdwb webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-7bdwb 9541d4df-37fe-4a3d-9920-796f31a2c3f0 52897 0 2020-02-24 21:01:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc0047adf60 0xc0047adf61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-fss3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.2,PodIP:,StartTime:2020-02-24 21:01:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.786: INFO: Pod "webserver-deployment-595b5b9587-c2qfw" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-c2qfw webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-c2qfw 1a40f84f-7cb2-4512-9bcb-2c9b1fa225ba 52862 0 2020-02-24 21:01:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc001b9e410 0xc001b9e411}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-dz7p,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.4,PodIP:,StartTime:2020-02-24 21:01:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.787: INFO: Pod "webserver-deployment-595b5b9587-gd442" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gd442 webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-gd442 f1a9c031-f10a-4970-ab7d-6367f7f4c78b 52754 0 2020-02-24 21:01:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc001b9e690 0xc001b9e691}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-50z7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.3,PodIP:10.12.1.80,StartTime:2020-02-24 21:01:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 21:01:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://7024b25fff9e04e1dc7ef3ba0f4b362cf239431700936dfa37f887acfd822345,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.12.1.80,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.787: INFO: Pod "webserver-deployment-595b5b9587-k22g5" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-k22g5 webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-k22g5 e4425301-3f5c-4e51-9b41-ff5bd55ddf1e 52909 0 2020-02-24 21:01:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc001b9eae0 0xc001b9eae1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-dz7p,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.4,PodIP:,StartTime:2020-02-24 21:01:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.788: INFO: Pod "webserver-deployment-595b5b9587-kh8rn" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-kh8rn webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-kh8rn 858d8c3b-2cc4-4c5d-8e28-8a90e47aa3c1 52905 0 2020-02-24 21:01:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc001b9ecd0 0xc001b9ecd1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-50z7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.3,PodIP:,StartTime:2020-02-24 21:01:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.796: INFO: Pod "webserver-deployment-595b5b9587-ldb6d" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-ldb6d webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-ldb6d 4cd116d0-bf6d-4da5-8596-8112496a776b 52938 0 2020-02-24 21:01:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc001b9ee20 0xc001b9ee21}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-50z7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:39 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:39 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.3,PodIP:,StartTime:2020-02-24 21:01:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.797: INFO: Pod "webserver-deployment-595b5b9587-p54pp" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-p54pp webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-p54pp 8f52db06-e0b1-437c-9bc7-eefa93e108c9 52930 0 2020-02-24 21:01:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc001b9ef60 0xc001b9ef61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-50z7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.3,PodIP:,StartTime:2020-02-24 21:01:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.797: INFO: Pod "webserver-deployment-595b5b9587-pdtdx" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pdtdx webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-pdtdx fcfbe76c-c909-465e-ab25-25529e100511 52751 0 2020-02-24 21:01:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc001b9f0b0 0xc001b9f0b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-50z7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.3,PodIP:10.12.1.81,StartTime:2020-02-24 21:01:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 21:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://8bc57ff47f6c921a4adeb3039ae5d014d1b4770aaecdb84fa0b1dece65109eb8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.12.1.81,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.799: INFO: Pod "webserver-deployment-595b5b9587-sxl99" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-sxl99 webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-sxl99 f5f14f66-7aeb-426c-9d27-a9acd7b3f1df 52763 0 2020-02-24 21:01:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc001b9f210 0xc001b9f211}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-dz7p,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.4,PodIP:10.12.2.64,StartTime:2020-02-24 21:01:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 21:01:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://3559c920e0a8cf73bab9215e7872148cfbb3baf86d4790ceac7de9cf88a97435,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.12.2.64,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.810: INFO: Pod "webserver-deployment-595b5b9587-t27hr" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-t27hr webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-t27hr 14d8db96-c36b-4c52-90ed-c6f85875136e 52929 0 2020-02-24 21:01:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc001b9f390 0xc001b9f391}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-dz7p,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.4,PodIP:,StartTime:2020-02-24 21:01:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.811: INFO: Pod "webserver-deployment-595b5b9587-t4c2p" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-t4c2p webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-t4c2p 2fa2619c-b7c1-43ed-ae92-b6dca4a91458 52871 0 2020-02-24 21:01:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc001b9f4d0 0xc001b9f4d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-fss3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.2,PodIP:,StartTime:2020-02-24 21:01:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.811: INFO: Pod "webserver-deployment-595b5b9587-v5m6v" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-v5m6v webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-v5m6v dea46193-5c6e-4366-8b84-6826d9ee4dfe 52895 0 2020-02-24 21:01:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc001b9f620 0xc001b9f621}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-50z7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.3,PodIP:,StartTime:2020-02-24 21:01:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.811: INFO: Pod "webserver-deployment-595b5b9587-v6pkp" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-v6pkp webserver-deployment-595b5b9587- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-595b5b9587-v6pkp f8cbd58d-fe27-4e1b-ab32-e8aaac796d5c 52778 0 2020-02-24 21:01:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 8c8942e7-db02-4133-8f64-9eb62365c796 0xc001b9f770 0xc001b9f771}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-fss3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.2,PodIP:10.12.0.69,StartTime:2020-02-24 21:01:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 21:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://2d0631200d206afdbc560d6f15f96bf8f505742d8852426bdc3a2d3435810add,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.12.0.69,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.823: INFO: Pod "webserver-deployment-c7997dcc8-2sjx2" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-2sjx2 webserver-deployment-c7997dcc8- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-c7997dcc8-2sjx2 0c137e2f-3b2f-4b16-afa3-6c544d63eae2 52810 0 2020-02-24 21:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f20944bf-1f8c-4e28-a61c-3adb9329943a 0xc001b9f8d0 0xc001b9f8d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-50z7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.3,PodIP:,StartTime:2020-02-24 21:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.823: INFO: Pod "webserver-deployment-c7997dcc8-2t4gt" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-2t4gt webserver-deployment-c7997dcc8- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-c7997dcc8-2t4gt 9f0d8b69-fe2d-4a93-b362-ac9f6dfe0b95 52834 0 2020-02-24 21:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f20944bf-1f8c-4e28-a61c-3adb9329943a 0xc001b9fa30 0xc001b9fa31}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-dz7p,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.4,PodIP:,StartTime:2020-02-24 21:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.823: INFO: Pod "webserver-deployment-c7997dcc8-8d5vl" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-8d5vl webserver-deployment-c7997dcc8- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-c7997dcc8-8d5vl 5e0fae0e-40df-4c24-b49f-8739790c0204 52899 0 2020-02-24 21:01:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f20944bf-1f8c-4e28-a61c-3adb9329943a 0xc001b9fb90 0xc001b9fb91}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-dz7p,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.4,PodIP:,StartTime:2020-02-24 21:01:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.823: INFO: Pod "webserver-deployment-c7997dcc8-8z6sw" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-8z6sw webserver-deployment-c7997dcc8- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-c7997dcc8-8z6sw acbfdcc1-f4f9-4619-b18c-dd10976ac0aa 52823 0 2020-02-24 21:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f20944bf-1f8c-4e28-a61c-3adb9329943a 0xc001b9fcf0 0xc001b9fcf1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-fss3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.2,PodIP:,StartTime:2020-02-24 21:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.826: INFO: Pod "webserver-deployment-c7997dcc8-gf2hc" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-gf2hc webserver-deployment-c7997dcc8- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-c7997dcc8-gf2hc 119f2ace-7714-465e-a669-e20efb7aadb7 52937 0 2020-02-24 21:01:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f20944bf-1f8c-4e28-a61c-3adb9329943a 0xc0036141f0 0xc0036141f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-50z7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:39 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:39 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.3,PodIP:,StartTime:2020-02-24 21:01:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.826: INFO: Pod "webserver-deployment-c7997dcc8-gjj85" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-gjj85 webserver-deployment-c7997dcc8- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-c7997dcc8-gjj85 d9d16ffe-323c-4f4b-84e7-493a4477a1e2 52918 0 2020-02-24 21:01:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f20944bf-1f8c-4e28-a61c-3adb9329943a 0xc003614770 0xc003614771}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-dz7p,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.4,PodIP:,StartTime:2020-02-24 21:01:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.826: INFO: Pod "webserver-deployment-c7997dcc8-glswv" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-glswv webserver-deployment-c7997dcc8- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-c7997dcc8-glswv 5e428cdb-bc22-4035-8df9-f222f9e67108 52916 0 2020-02-24 21:01:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f20944bf-1f8c-4e28-a61c-3adb9329943a 0xc003614e50 0xc003614e51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-50z7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.3,PodIP:,StartTime:2020-02-24 21:01:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.835: INFO: Pod "webserver-deployment-c7997dcc8-lr48f" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-lr48f webserver-deployment-c7997dcc8- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-c7997dcc8-lr48f 90e97c07-fd78-412e-a3ea-141da642f68e 52826 0 2020-02-24 21:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f20944bf-1f8c-4e28-a61c-3adb9329943a 0xc003615220 0xc003615221}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-dz7p,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.4,PodIP:,StartTime:2020-02-24 21:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.835: INFO: Pod "webserver-deployment-c7997dcc8-mp74m" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-mp74m webserver-deployment-c7997dcc8- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-c7997dcc8-mp74m fa0ff7ca-a67b-4ac8-abb5-a9e3711ba67e 52886 0 2020-02-24 21:01:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f20944bf-1f8c-4e28-a61c-3adb9329943a 0xc003615650 0xc003615651}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-fss3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.2,PodIP:,StartTime:2020-02-24 21:01:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.835: INFO: Pod "webserver-deployment-c7997dcc8-nm99f" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-nm99f webserver-deployment-c7997dcc8- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-c7997dcc8-nm99f f3611a7c-be1d-48aa-afe8-4b41f6a78d4a 52879 0 2020-02-24 21:01:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f20944bf-1f8c-4e28-a61c-3adb9329943a 0xc003615aa0 0xc003615aa1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-50z7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.3,PodIP:,StartTime:2020-02-24 21:01:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.836: INFO: Pod "webserver-deployment-c7997dcc8-vk8hr" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-vk8hr webserver-deployment-c7997dcc8- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-c7997dcc8-vk8hr 44b6c563-823c-4adf-bd02-b1455a215773 52837 0 2020-02-24 21:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f20944bf-1f8c-4e28-a61c-3adb9329943a 0xc003615dc0 0xc003615dc1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-50z7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.3,PodIP:,StartTime:2020-02-24 21:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.854: INFO: Pod "webserver-deployment-c7997dcc8-wx9kv" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-wx9kv webserver-deployment-c7997dcc8- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-c7997dcc8-wx9kv 839fecf2-26d5-4357-a943-e30f08c3bd7a 52907 0 2020-02-24 21:01:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f20944bf-1f8c-4e28-a61c-3adb9329943a 0xc006870070 0xc006870071}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-fss3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.2,PodIP:,StartTime:2020-02-24 21:01:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 21:01:39.854: INFO: Pod "webserver-deployment-c7997dcc8-zbjfv" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-zbjfv webserver-deployment-c7997dcc8- deployment-9432 /api/v1/namespaces/deployment-9432/pods/webserver-deployment-c7997dcc8-zbjfv 1eb02288-02aa-4f76-9f74-74480af42875 52866 0 2020-02-24 21:01:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f20944bf-1f8c-4e28-a61c-3adb9329943a 0xc0068701d0 0xc0068701d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fkslr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fkslr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fkslr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-c116p-default-pool-41de4435-fss3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 21:01:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.77.32.2,PodIP:,StartTime:2020-02-24 21:01:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:01:39.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9432" for this suite.
Feb 24 21:01:47.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:01:48.822: INFO: namespace deployment-9432 deletion completed in 8.955177767s

• [SLOW TEST:19.573 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:01:48.826: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5538
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Feb 24 21:01:49.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 create -f - --namespace=kubectl-5538'
Feb 24 21:01:49.895: INFO: stderr: ""
Feb 24 21:01:49.895: INFO: stdout: "pod/pause created\n"
Feb 24 21:01:49.895: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 24 21:01:49.895: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-5538" to be "running and ready"
Feb 24 21:01:49.908: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 12.714969ms
Feb 24 21:01:51.949: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054177067s
Feb 24 21:01:53.952: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.056684728s
Feb 24 21:01:53.952: INFO: Pod "pause" satisfied condition "running and ready"
Feb 24 21:01:53.952: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 24 21:01:53.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 label pods pause testing-label=testing-label-value --namespace=kubectl-5538'
Feb 24 21:01:54.059: INFO: stderr: ""
Feb 24 21:01:54.059: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 24 21:01:54.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pod pause -L testing-label --namespace=kubectl-5538'
Feb 24 21:01:54.168: INFO: stderr: ""
Feb 24 21:01:54.168: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 24 21:01:54.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 label pods pause testing-label- --namespace=kubectl-5538'
Feb 24 21:01:54.272: INFO: stderr: ""
Feb 24 21:01:54.272: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 24 21:01:54.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pod pause -L testing-label --namespace=kubectl-5538'
Feb 24 21:01:54.365: INFO: stderr: ""
Feb 24 21:01:54.365: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Feb 24 21:01:54.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 delete --grace-period=0 --force -f - --namespace=kubectl-5538'
Feb 24 21:01:54.474: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 24 21:01:54.474: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 24 21:01:54.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get rc,svc -l name=pause --no-headers --namespace=kubectl-5538'
Feb 24 21:01:54.579: INFO: stderr: "No resources found in kubectl-5538 namespace.\n"
Feb 24 21:01:54.579: INFO: stdout: ""
Feb 24 21:01:54.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 get pods -l name=pause --namespace=kubectl-5538 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 24 21:01:54.713: INFO: stderr: ""
Feb 24 21:01:54.713: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:01:54.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5538" for this suite.
Feb 24 21:02:02.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:02:02.930: INFO: namespace kubectl-5538 deletion completed in 8.210870233s

• [SLOW TEST:14.104 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:02:02.933: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3641
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-041a33f4-a3f6-47f6-ae5a-fb0745b39e74
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:02:08.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3641" for this suite.
Feb 24 21:02:20.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:02:20.157: INFO: namespace configmap-3641 deletion completed in 12.133873215s

• [SLOW TEST:17.225 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:02:20.160: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8471
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 21:02:20.366: INFO: Waiting up to 5m0s for pod "downwardapi-volume-678b0483-f479-4ddc-8f76-458a6861792b" in namespace "projected-8471" to be "success or failure"
Feb 24 21:02:20.380: INFO: Pod "downwardapi-volume-678b0483-f479-4ddc-8f76-458a6861792b": Phase="Pending", Reason="", readiness=false. Elapsed: 13.970111ms
Feb 24 21:02:22.486: INFO: Pod "downwardapi-volume-678b0483-f479-4ddc-8f76-458a6861792b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.11988633s
Feb 24 21:02:24.490: INFO: Pod "downwardapi-volume-678b0483-f479-4ddc-8f76-458a6861792b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.123444435s
STEP: Saw pod success
Feb 24 21:02:24.490: INFO: Pod "downwardapi-volume-678b0483-f479-4ddc-8f76-458a6861792b" satisfied condition "success or failure"
Feb 24 21:02:24.493: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downwardapi-volume-678b0483-f479-4ddc-8f76-458a6861792b container client-container: <nil>
STEP: delete the pod
Feb 24 21:02:24.521: INFO: Waiting for pod downwardapi-volume-678b0483-f479-4ddc-8f76-458a6861792b to disappear
Feb 24 21:02:24.526: INFO: Pod downwardapi-volume-678b0483-f479-4ddc-8f76-458a6861792b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:02:24.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8471" for this suite.
Feb 24 21:02:30.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:02:30.702: INFO: namespace projected-8471 deletion completed in 6.167135415s

• [SLOW TEST:10.543 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:02:30.707: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2040
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:02:30.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2040" for this suite.
Feb 24 21:02:42.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:02:43.164: INFO: namespace pods-2040 deletion completed in 12.199744242s

• [SLOW TEST:12.458 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:02:43.168: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2275
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:03:43.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2275" for this suite.
Feb 24 21:03:55.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:03:55.578: INFO: namespace container-probe-2275 deletion completed in 12.15701749s

• [SLOW TEST:72.411 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:03:55.582: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6167
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb 24 21:03:55.738: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:03:59.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6167" for this suite.
Feb 24 21:04:05.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:04:06.094: INFO: namespace init-container-6167 deletion completed in 6.32661579s

• [SLOW TEST:10.513 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:04:06.098: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1170
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 24 21:04:08.401: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:04:08.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1170" for this suite.
Feb 24 21:04:14.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:04:14.584: INFO: namespace container-runtime-1170 deletion completed in 6.156089218s

• [SLOW TEST:8.487 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:04:14.600: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2095
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-a58cebaf-37df-42ac-8d3d-f4ff9d280bc6
STEP: Creating a pod to test consume configMaps
Feb 24 21:04:14.830: INFO: Waiting up to 5m0s for pod "pod-configmaps-273ed720-9315-4dfa-9294-66471593bf7f" in namespace "configmap-2095" to be "success or failure"
Feb 24 21:04:14.841: INFO: Pod "pod-configmaps-273ed720-9315-4dfa-9294-66471593bf7f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.747107ms
Feb 24 21:04:16.845: INFO: Pod "pod-configmaps-273ed720-9315-4dfa-9294-66471593bf7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014142069s
STEP: Saw pod success
Feb 24 21:04:16.845: INFO: Pod "pod-configmaps-273ed720-9315-4dfa-9294-66471593bf7f" satisfied condition "success or failure"
Feb 24 21:04:16.850: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-configmaps-273ed720-9315-4dfa-9294-66471593bf7f container configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 21:04:16.883: INFO: Waiting for pod pod-configmaps-273ed720-9315-4dfa-9294-66471593bf7f to disappear
Feb 24 21:04:16.888: INFO: Pod pod-configmaps-273ed720-9315-4dfa-9294-66471593bf7f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:04:16.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2095" for this suite.
Feb 24 21:04:24.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:04:25.056: INFO: namespace configmap-2095 deletion completed in 8.161990583s

• [SLOW TEST:10.456 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:04:25.061: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9769
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 24 21:04:25.287: INFO: Waiting up to 5m0s for pod "downward-api-bdf10465-c40b-4b1e-86f3-ccf7673cc522" in namespace "downward-api-9769" to be "success or failure"
Feb 24 21:04:25.290: INFO: Pod "downward-api-bdf10465-c40b-4b1e-86f3-ccf7673cc522": Phase="Pending", Reason="", readiness=false. Elapsed: 2.83057ms
Feb 24 21:04:27.294: INFO: Pod "downward-api-bdf10465-c40b-4b1e-86f3-ccf7673cc522": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006147892s
STEP: Saw pod success
Feb 24 21:04:27.294: INFO: Pod "downward-api-bdf10465-c40b-4b1e-86f3-ccf7673cc522" satisfied condition "success or failure"
Feb 24 21:04:27.298: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downward-api-bdf10465-c40b-4b1e-86f3-ccf7673cc522 container dapi-container: <nil>
STEP: delete the pod
Feb 24 21:04:27.338: INFO: Waiting for pod downward-api-bdf10465-c40b-4b1e-86f3-ccf7673cc522 to disappear
Feb 24 21:04:27.348: INFO: Pod downward-api-bdf10465-c40b-4b1e-86f3-ccf7673cc522 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:04:27.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9769" for this suite.
Feb 24 21:04:33.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:04:33.882: INFO: namespace downward-api-9769 deletion completed in 6.527474664s

• [SLOW TEST:8.821 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:04:33.887: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4556
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 24 21:04:34.101: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 24 21:04:34.119: INFO: Waiting for terminating namespaces to be deleted...
Feb 24 21:04:34.123: INFO: 
Logging pods the kubelet thinks is on node gke-c116p-default-pool-41de4435-50z7 before test
Feb 24 21:04:34.153: INFO: kube-proxy-xxnbn from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 21:04:34.153: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 21:04:34.153: INFO: fluentd-gke-bljn7 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (2 container statuses recorded)
Feb 24 21:04:34.153: INFO: 	Container fluentd-gke ready: true, restart count 0
Feb 24 21:04:34.153: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 21:04:34.154: INFO: kube-dns-68b499d58-t8vrp from kube-system started at 2020-02-24 18:31:11 +0000 UTC (4 container statuses recorded)
Feb 24 21:04:34.154: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 24 21:04:34.154: INFO: 	Container kubedns ready: true, restart count 0
Feb 24 21:04:34.154: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 21:04:34.154: INFO: 	Container sidecar ready: true, restart count 0
Feb 24 21:04:34.154: INFO: event-exporter-gke-5998887ffd-wf7jq from kube-system started at 2020-02-24 18:31:11 +0000 UTC (2 container statuses recorded)
Feb 24 21:04:34.155: INFO: 	Container event-exporter ready: true, restart count 0
Feb 24 21:04:34.155: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 21:04:34.155: INFO: l7-default-backend-678889f899-2hc4d from kube-system started at 2020-02-24 18:31:11 +0000 UTC (1 container statuses recorded)
Feb 24 21:04:34.155: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 24 21:04:34.155: INFO: gke-metrics-agent-5hrbb from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 21:04:34.155: INFO: 	Container gke-metrics-agent ready: true, restart count 0
Feb 24 21:04:34.156: INFO: sonobuoy-systemd-logs-daemon-set-4d9132020e6e4914-5m24k from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 21:04:34.156: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 24 21:04:34.156: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 21:04:34.156: INFO: kube-dns-autoscaler-645f7d66cf-rmd2g from kube-system started at 2020-02-24 18:31:11 +0000 UTC (1 container statuses recorded)
Feb 24 21:04:34.156: INFO: 	Container autoscaler ready: true, restart count 0
Feb 24 21:04:34.156: INFO: fluentd-gke-scaler-84b9598957-hh4hk from kube-system started at 2020-02-24 18:31:11 +0000 UTC (1 container statuses recorded)
Feb 24 21:04:34.156: INFO: 	Container fluentd-gke-scaler ready: true, restart count 0
Feb 24 21:04:34.157: INFO: prometheus-to-sd-5gvqd from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 21:04:34.157: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 21:04:34.157: INFO: 
Logging pods the kubelet thinks is on node gke-c116p-default-pool-41de4435-dz7p before test
Feb 24 21:04:34.179: INFO: prometheus-to-sd-lhjg7 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 21:04:34.179: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 21:04:34.179: INFO: gke-metrics-agent-ttjqh from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 21:04:34.179: INFO: 	Container gke-metrics-agent ready: true, restart count 0
Feb 24 21:04:34.179: INFO: sonobuoy-systemd-logs-daemon-set-4d9132020e6e4914-mxsbf from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 21:04:34.179: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 24 21:04:34.179: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 21:04:34.179: INFO: kube-dns-68b499d58-zj88r from kube-system started at 2020-02-24 20:51:17 +0000 UTC (4 container statuses recorded)
Feb 24 21:04:34.179: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 24 21:04:34.179: INFO: 	Container kubedns ready: true, restart count 0
Feb 24 21:04:34.179: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 21:04:34.179: INFO: 	Container sidecar ready: true, restart count 0
Feb 24 21:04:34.179: INFO: metrics-server-v0.3.6-65d7cdc58b-rzf7x from kube-system started at 2020-02-24 18:31:26 +0000 UTC (2 container statuses recorded)
Feb 24 21:04:34.179: INFO: 	Container metrics-server ready: true, restart count 0
Feb 24 21:04:34.179: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Feb 24 21:04:34.179: INFO: sonobuoy from sonobuoy started at 2020-02-24 19:12:34 +0000 UTC (1 container statuses recorded)
Feb 24 21:04:34.179: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 24 21:04:34.179: INFO: sonobuoy-e2e-job-3461c811ccdb4a1e from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 21:04:34.179: INFO: 	Container e2e ready: true, restart count 0
Feb 24 21:04:34.179: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 21:04:34.179: INFO: fluentd-gke-5zt82 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (2 container statuses recorded)
Feb 24 21:04:34.179: INFO: 	Container fluentd-gke ready: true, restart count 0
Feb 24 21:04:34.179: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 21:04:34.179: INFO: kube-proxy-zsrrm from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 21:04:34.179: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 21:04:34.179: INFO: stackdriver-metadata-agent-cluster-level-749b475b87-hcp6f from kube-system started at 2020-02-24 18:31:59 +0000 UTC (2 container statuses recorded)
Feb 24 21:04:34.179: INFO: 	Container metadata-agent ready: true, restart count 0
Feb 24 21:04:34.179: INFO: 	Container metadata-agent-nanny ready: true, restart count 0
Feb 24 21:04:34.179: INFO: 
Logging pods the kubelet thinks is on node gke-c116p-default-pool-41de4435-fss3 before test
Feb 24 21:04:34.189: INFO: fluentd-gke-l65zn from kube-system started at 2020-02-24 18:31:12 +0000 UTC (2 container statuses recorded)
Feb 24 21:04:34.189: INFO: 	Container fluentd-gke ready: true, restart count 0
Feb 24 21:04:34.189: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Feb 24 21:04:34.189: INFO: sonobuoy-systemd-logs-daemon-set-4d9132020e6e4914-n8lq6 from sonobuoy started at 2020-02-24 19:12:35 +0000 UTC (2 container statuses recorded)
Feb 24 21:04:34.189: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 24 21:04:34.190: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 21:04:34.190: INFO: prometheus-to-sd-xws82 from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 21:04:34.190: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Feb 24 21:04:34.190: INFO: kube-proxy-28x7v from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 21:04:34.190: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 21:04:34.190: INFO: gke-metrics-agent-256cx from kube-system started at 2020-02-24 18:31:12 +0000 UTC (1 container statuses recorded)
Feb 24 21:04:34.191: INFO: 	Container gke-metrics-agent ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node gke-c116p-default-pool-41de4435-50z7
STEP: verifying the node has the label node gke-c116p-default-pool-41de4435-dz7p
STEP: verifying the node has the label node gke-c116p-default-pool-41de4435-fss3
Feb 24 21:04:34.259: INFO: Pod event-exporter-gke-5998887ffd-wf7jq requesting resource cpu=0m on Node gke-c116p-default-pool-41de4435-50z7
Feb 24 21:04:34.259: INFO: Pod fluentd-gke-5zt82 requesting resource cpu=0m on Node gke-c116p-default-pool-41de4435-dz7p
Feb 24 21:04:34.260: INFO: Pod fluentd-gke-bljn7 requesting resource cpu=0m on Node gke-c116p-default-pool-41de4435-50z7
Feb 24 21:04:34.260: INFO: Pod fluentd-gke-l65zn requesting resource cpu=0m on Node gke-c116p-default-pool-41de4435-fss3
Feb 24 21:04:34.260: INFO: Pod fluentd-gke-scaler-84b9598957-hh4hk requesting resource cpu=0m on Node gke-c116p-default-pool-41de4435-50z7
Feb 24 21:04:34.260: INFO: Pod gke-metrics-agent-256cx requesting resource cpu=2m on Node gke-c116p-default-pool-41de4435-fss3
Feb 24 21:04:34.260: INFO: Pod gke-metrics-agent-5hrbb requesting resource cpu=2m on Node gke-c116p-default-pool-41de4435-50z7
Feb 24 21:04:34.261: INFO: Pod gke-metrics-agent-ttjqh requesting resource cpu=2m on Node gke-c116p-default-pool-41de4435-dz7p
Feb 24 21:04:34.261: INFO: Pod kube-dns-68b499d58-t8vrp requesting resource cpu=260m on Node gke-c116p-default-pool-41de4435-50z7
Feb 24 21:04:34.261: INFO: Pod kube-dns-68b499d58-zj88r requesting resource cpu=260m on Node gke-c116p-default-pool-41de4435-dz7p
Feb 24 21:04:34.261: INFO: Pod kube-dns-autoscaler-645f7d66cf-rmd2g requesting resource cpu=20m on Node gke-c116p-default-pool-41de4435-50z7
Feb 24 21:04:34.261: INFO: Pod kube-proxy-28x7v requesting resource cpu=100m on Node gke-c116p-default-pool-41de4435-fss3
Feb 24 21:04:34.262: INFO: Pod kube-proxy-xxnbn requesting resource cpu=100m on Node gke-c116p-default-pool-41de4435-50z7
Feb 24 21:04:34.262: INFO: Pod kube-proxy-zsrrm requesting resource cpu=100m on Node gke-c116p-default-pool-41de4435-dz7p
Feb 24 21:04:34.262: INFO: Pod l7-default-backend-678889f899-2hc4d requesting resource cpu=10m on Node gke-c116p-default-pool-41de4435-50z7
Feb 24 21:04:34.262: INFO: Pod metrics-server-v0.3.6-65d7cdc58b-rzf7x requesting resource cpu=48m on Node gke-c116p-default-pool-41de4435-dz7p
Feb 24 21:04:34.262: INFO: Pod prometheus-to-sd-5gvqd requesting resource cpu=0m on Node gke-c116p-default-pool-41de4435-50z7
Feb 24 21:04:34.262: INFO: Pod prometheus-to-sd-lhjg7 requesting resource cpu=0m on Node gke-c116p-default-pool-41de4435-dz7p
Feb 24 21:04:34.263: INFO: Pod prometheus-to-sd-xws82 requesting resource cpu=0m on Node gke-c116p-default-pool-41de4435-fss3
Feb 24 21:04:34.263: INFO: Pod stackdriver-metadata-agent-cluster-level-749b475b87-hcp6f requesting resource cpu=98m on Node gke-c116p-default-pool-41de4435-dz7p
Feb 24 21:04:34.263: INFO: Pod sonobuoy requesting resource cpu=0m on Node gke-c116p-default-pool-41de4435-dz7p
Feb 24 21:04:34.263: INFO: Pod sonobuoy-e2e-job-3461c811ccdb4a1e requesting resource cpu=0m on Node gke-c116p-default-pool-41de4435-dz7p
Feb 24 21:04:34.263: INFO: Pod sonobuoy-systemd-logs-daemon-set-4d9132020e6e4914-5m24k requesting resource cpu=0m on Node gke-c116p-default-pool-41de4435-50z7
Feb 24 21:04:34.264: INFO: Pod sonobuoy-systemd-logs-daemon-set-4d9132020e6e4914-mxsbf requesting resource cpu=0m on Node gke-c116p-default-pool-41de4435-dz7p
Feb 24 21:04:34.264: INFO: Pod sonobuoy-systemd-logs-daemon-set-4d9132020e6e4914-n8lq6 requesting resource cpu=0m on Node gke-c116p-default-pool-41de4435-fss3
STEP: Starting Pods to consume most of the cluster CPU.
Feb 24 21:04:34.264: INFO: Creating a pod which consumes cpu=383m on Node gke-c116p-default-pool-41de4435-50z7
Feb 24 21:04:34.282: INFO: Creating a pod which consumes cpu=302m on Node gke-c116p-default-pool-41de4435-dz7p
Feb 24 21:04:34.311: INFO: Creating a pod which consumes cpu=586m on Node gke-c116p-default-pool-41de4435-fss3
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4ec74dd2-3f20-49e4-8678-1c567f4dd943.15f6728e41b024b6], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4556/filler-pod-4ec74dd2-3f20-49e4-8678-1c567f4dd943 to gke-c116p-default-pool-41de4435-dz7p]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4ec74dd2-3f20-49e4-8678-1c567f4dd943.15f6728ea42a2e6d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4ec74dd2-3f20-49e4-8678-1c567f4dd943.15f6728ea74a8383], Reason = [Created], Message = [Created container filler-pod-4ec74dd2-3f20-49e4-8678-1c567f4dd943]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4ec74dd2-3f20-49e4-8678-1c567f4dd943.15f6728eae500da8], Reason = [Started], Message = [Started container filler-pod-4ec74dd2-3f20-49e4-8678-1c567f4dd943]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ab68f75e-aeeb-4977-9d47-15a60c7eb82d.15f6728e46a6a843], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4556/filler-pod-ab68f75e-aeeb-4977-9d47-15a60c7eb82d to gke-c116p-default-pool-41de4435-fss3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ab68f75e-aeeb-4977-9d47-15a60c7eb82d.15f6728e746ea278], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ab68f75e-aeeb-4977-9d47-15a60c7eb82d.15f6728e7707ee15], Reason = [Created], Message = [Created container filler-pod-ab68f75e-aeeb-4977-9d47-15a60c7eb82d]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ab68f75e-aeeb-4977-9d47-15a60c7eb82d.15f6728e7f48180a], Reason = [Started], Message = [Started container filler-pod-ab68f75e-aeeb-4977-9d47-15a60c7eb82d]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-abb6731a-3fa5-4e07-ae6d-18e94b86d39f.15f6728e3c893914], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4556/filler-pod-abb6731a-3fa5-4e07-ae6d-18e94b86d39f to gke-c116p-default-pool-41de4435-50z7]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-abb6731a-3fa5-4e07-ae6d-18e94b86d39f.15f6728e6ed96178], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-abb6731a-3fa5-4e07-ae6d-18e94b86d39f.15f6728e7241d639], Reason = [Created], Message = [Created container filler-pod-abb6731a-3fa5-4e07-ae6d-18e94b86d39f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-abb6731a-3fa5-4e07-ae6d-18e94b86d39f.15f6728e7bc8ed3b], Reason = [Started], Message = [Started container filler-pod-abb6731a-3fa5-4e07-ae6d-18e94b86d39f]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15f6728f436189d0], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node gke-c116p-default-pool-41de4435-dz7p
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node gke-c116p-default-pool-41de4435-fss3
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node gke-c116p-default-pool-41de4435-50z7
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:04:39.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4556" for this suite.
Feb 24 21:04:45.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:04:45.872: INFO: namespace sched-pred-4556 deletion completed in 6.181697044s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:11.987 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:04:45.877: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-498
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 24 21:04:46.074: INFO: Waiting up to 5m0s for pod "pod-b5457add-142f-40ae-86ab-5017311f0b87" in namespace "emptydir-498" to be "success or failure"
Feb 24 21:04:46.089: INFO: Pod "pod-b5457add-142f-40ae-86ab-5017311f0b87": Phase="Pending", Reason="", readiness=false. Elapsed: 14.843871ms
Feb 24 21:04:48.186: INFO: Pod "pod-b5457add-142f-40ae-86ab-5017311f0b87": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.111983853s
STEP: Saw pod success
Feb 24 21:04:48.187: INFO: Pod "pod-b5457add-142f-40ae-86ab-5017311f0b87" satisfied condition "success or failure"
Feb 24 21:04:48.302: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-b5457add-142f-40ae-86ab-5017311f0b87 container test-container: <nil>
STEP: delete the pod
Feb 24 21:04:48.751: INFO: Waiting for pod pod-b5457add-142f-40ae-86ab-5017311f0b87 to disappear
Feb 24 21:04:48.837: INFO: Pod pod-b5457add-142f-40ae-86ab-5017311f0b87 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:04:48.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-498" for this suite.
Feb 24 21:04:55.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:04:55.390: INFO: namespace emptydir-498 deletion completed in 6.425281738s

• [SLOW TEST:9.514 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:04:55.394: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6206
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:05:10.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6206" for this suite.
Feb 24 21:05:16.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:05:16.464: INFO: namespace resourcequota-6206 deletion completed in 6.188208039s

• [SLOW TEST:21.070 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:05:16.467: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5904
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 21:05:17.214: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 21:05:19.249: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718175117, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718175117, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718175117, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718175117, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 21:05:22.344: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:05:33.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5904" for this suite.
Feb 24 21:05:41.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:05:41.524: INFO: namespace webhook-5904 deletion completed in 8.432654444s
STEP: Destroying namespace "webhook-5904-markers" for this suite.
Feb 24 21:05:47.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:05:47.702: INFO: namespace webhook-5904-markers deletion completed in 6.177234152s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:31.253 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:05:47.720: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6744
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-5ad049df-0706-452e-9129-fa2afcb2fe0f
STEP: Creating secret with name s-test-opt-upd-804118c3-97b9-4f1c-8433-0927448ac754
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-5ad049df-0706-452e-9129-fa2afcb2fe0f
STEP: Updating secret s-test-opt-upd-804118c3-97b9-4f1c-8433-0927448ac754
STEP: Creating secret with name s-test-opt-create-a3e10472-e149-4515-a9ec-9852386d86e3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:05:52.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6744" for this suite.
Feb 24 21:06:05.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:06:05.381: INFO: namespace secrets-6744 deletion completed in 12.425541119s

• [SLOW TEST:17.661 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:06:05.386: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5281
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
W0224 21:06:06.131451      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 24 21:06:06.131: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:06:06.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5281" for this suite.
Feb 24 21:06:12.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:06:12.285: INFO: namespace gc-5281 deletion completed in 6.147182303s

• [SLOW TEST:6.900 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:06:12.287: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3916
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-f1b7cafa-b2d2-4004-9a0d-0468e26cd1fd
STEP: Creating a pod to test consume configMaps
Feb 24 21:06:12.507: INFO: Waiting up to 5m0s for pod "pod-configmaps-ffafd5a9-6800-46ce-b24e-3bf3d4d0192b" in namespace "configmap-3916" to be "success or failure"
Feb 24 21:06:12.515: INFO: Pod "pod-configmaps-ffafd5a9-6800-46ce-b24e-3bf3d4d0192b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.901127ms
Feb 24 21:06:14.519: INFO: Pod "pod-configmaps-ffafd5a9-6800-46ce-b24e-3bf3d4d0192b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012015304s
STEP: Saw pod success
Feb 24 21:06:14.519: INFO: Pod "pod-configmaps-ffafd5a9-6800-46ce-b24e-3bf3d4d0192b" satisfied condition "success or failure"
Feb 24 21:06:14.522: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-configmaps-ffafd5a9-6800-46ce-b24e-3bf3d4d0192b container configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 21:06:14.550: INFO: Waiting for pod pod-configmaps-ffafd5a9-6800-46ce-b24e-3bf3d4d0192b to disappear
Feb 24 21:06:14.555: INFO: Pod pod-configmaps-ffafd5a9-6800-46ce-b24e-3bf3d4d0192b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:06:14.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3916" for this suite.
Feb 24 21:06:20.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:06:20.933: INFO: namespace configmap-3916 deletion completed in 6.373407752s

• [SLOW TEST:8.646 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:06:20.937: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6118
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:06:26.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6118" for this suite.
Feb 24 21:06:38.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:06:38.381: INFO: namespace replication-controller-6118 deletion completed in 12.235096534s

• [SLOW TEST:17.445 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:06:38.386: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9115
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Feb 24 21:06:38.574: INFO: Waiting up to 5m0s for pod "client-containers-bd423c83-00ec-4337-bf75-cd573756c956" in namespace "containers-9115" to be "success or failure"
Feb 24 21:06:38.592: INFO: Pod "client-containers-bd423c83-00ec-4337-bf75-cd573756c956": Phase="Pending", Reason="", readiness=false. Elapsed: 17.648814ms
Feb 24 21:06:40.596: INFO: Pod "client-containers-bd423c83-00ec-4337-bf75-cd573756c956": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021496382s
STEP: Saw pod success
Feb 24 21:06:40.596: INFO: Pod "client-containers-bd423c83-00ec-4337-bf75-cd573756c956" satisfied condition "success or failure"
Feb 24 21:06:40.602: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod client-containers-bd423c83-00ec-4337-bf75-cd573756c956 container test-container: <nil>
STEP: delete the pod
Feb 24 21:06:40.633: INFO: Waiting for pod client-containers-bd423c83-00ec-4337-bf75-cd573756c956 to disappear
Feb 24 21:06:40.637: INFO: Pod client-containers-bd423c83-00ec-4337-bf75-cd573756c956 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:06:40.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9115" for this suite.
Feb 24 21:06:46.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:06:46.809: INFO: namespace containers-9115 deletion completed in 6.167137833s

• [SLOW TEST:8.424 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:06:46.812: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1993
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-d945fe1e-037e-4015-9280-844dea6de607
STEP: Creating a pod to test consume secrets
Feb 24 21:06:47.052: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-94d037e3-b543-431b-b905-9c7f4fa482dd" in namespace "projected-1993" to be "success or failure"
Feb 24 21:06:47.056: INFO: Pod "pod-projected-secrets-94d037e3-b543-431b-b905-9c7f4fa482dd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.75627ms
Feb 24 21:06:49.177: INFO: Pod "pod-projected-secrets-94d037e3-b543-431b-b905-9c7f4fa482dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.125322282s
Feb 24 21:06:51.183: INFO: Pod "pod-projected-secrets-94d037e3-b543-431b-b905-9c7f4fa482dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.130777052s
STEP: Saw pod success
Feb 24 21:06:51.183: INFO: Pod "pod-projected-secrets-94d037e3-b543-431b-b905-9c7f4fa482dd" satisfied condition "success or failure"
Feb 24 21:06:51.186: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-projected-secrets-94d037e3-b543-431b-b905-9c7f4fa482dd container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 24 21:06:51.214: INFO: Waiting for pod pod-projected-secrets-94d037e3-b543-431b-b905-9c7f4fa482dd to disappear
Feb 24 21:06:51.218: INFO: Pod pod-projected-secrets-94d037e3-b543-431b-b905-9c7f4fa482dd no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:06:51.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1993" for this suite.
Feb 24 21:06:57.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:06:57.393: INFO: namespace projected-1993 deletion completed in 6.167677811s

• [SLOW TEST:10.582 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:06:57.400: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-723
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-723
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-723
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-723
Feb 24 21:06:57.628: INFO: Found 0 stateful pods, waiting for 1
Feb 24 21:07:07.719: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 24 21:07:07.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=statefulset-723 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 21:07:08.218: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 21:07:08.218: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 21:07:08.218: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 24 21:07:08.223: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 24 21:07:18.341: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 24 21:07:18.341: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 21:07:18.785: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999638s
Feb 24 21:07:19.789: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.897163004s
Feb 24 21:07:20.795: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.892685572s
Feb 24 21:07:21.894: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.887373004s
Feb 24 21:07:22.902: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.788360258s
Feb 24 21:07:23.905: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.780358303s
Feb 24 21:07:24.909: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.776635581s
Feb 24 21:07:25.914: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.772816314s
Feb 24 21:07:26.918: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.76777731s
Feb 24 21:07:27.922: INFO: Verifying statefulset ss doesn't scale past 1 for another 763.778061ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-723
Feb 24 21:07:28.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=statefulset-723 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 21:07:29.192: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 24 21:07:29.192: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 24 21:07:29.192: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 24 21:07:29.195: INFO: Found 1 stateful pods, waiting for 3
Feb 24 21:07:39.283: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 21:07:39.284: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 21:07:39.284: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 24 21:07:39.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=statefulset-723 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 21:07:39.593: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 21:07:39.593: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 21:07:39.593: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 24 21:07:39.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=statefulset-723 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 21:07:39.940: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 21:07:39.940: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 21:07:39.940: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 24 21:07:39.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=statefulset-723 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 21:07:40.262: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 21:07:40.262: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 21:07:40.262: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 24 21:07:40.262: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 21:07:40.265: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Feb 24 21:07:50.273: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 24 21:07:50.273: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 24 21:07:50.273: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 24 21:07:50.286: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999788s
Feb 24 21:07:51.290: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995471066s
Feb 24 21:07:52.391: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991120724s
Feb 24 21:07:53.396: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.890276608s
Feb 24 21:07:54.400: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.884944833s
Feb 24 21:07:55.404: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.88123708s
Feb 24 21:07:56.410: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.877334283s
Feb 24 21:07:57.481: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.871701734s
Feb 24 21:07:58.582: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.799869802s
Feb 24 21:07:59.586: INFO: Verifying statefulset ss doesn't scale past 3 for another 699.600558ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-723
Feb 24 21:08:00.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=statefulset-723 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 21:08:00.864: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 24 21:08:00.864: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 24 21:08:00.864: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 24 21:08:00.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=statefulset-723 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 21:08:01.171: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 24 21:08:01.171: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 24 21:08:01.171: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 24 21:08:01.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-651526472 exec --namespace=statefulset-723 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 21:08:01.445: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 24 21:08:01.445: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 24 21:08:01.445: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 24 21:08:01.445: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 24 21:08:21.468: INFO: Deleting all statefulset in ns statefulset-723
Feb 24 21:08:21.472: INFO: Scaling statefulset ss to 0
Feb 24 21:08:21.491: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 21:08:21.495: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:08:21.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-723" for this suite.
Feb 24 21:08:27.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:08:27.692: INFO: namespace statefulset-723 deletion completed in 6.158533402s

• [SLOW TEST:90.293 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:08:27.696: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9682
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 21:08:27.877: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c2057ffa-1446-433c-b1b0-d91f9d959a40" in namespace "projected-9682" to be "success or failure"
Feb 24 21:08:27.881: INFO: Pod "downwardapi-volume-c2057ffa-1446-433c-b1b0-d91f9d959a40": Phase="Pending", Reason="", readiness=false. Elapsed: 4.414166ms
Feb 24 21:08:29.886: INFO: Pod "downwardapi-volume-c2057ffa-1446-433c-b1b0-d91f9d959a40": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009055885s
Feb 24 21:08:31.889: INFO: Pod "downwardapi-volume-c2057ffa-1446-433c-b1b0-d91f9d959a40": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012228112s
STEP: Saw pod success
Feb 24 21:08:31.889: INFO: Pod "downwardapi-volume-c2057ffa-1446-433c-b1b0-d91f9d959a40" satisfied condition "success or failure"
Feb 24 21:08:31.892: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod downwardapi-volume-c2057ffa-1446-433c-b1b0-d91f9d959a40 container client-container: <nil>
STEP: delete the pod
Feb 24 21:08:31.919: INFO: Waiting for pod downwardapi-volume-c2057ffa-1446-433c-b1b0-d91f9d959a40 to disappear
Feb 24 21:08:31.925: INFO: Pod downwardapi-volume-c2057ffa-1446-433c-b1b0-d91f9d959a40 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:08:31.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9682" for this suite.
Feb 24 21:08:39.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:08:40.132: INFO: namespace projected-9682 deletion completed in 8.202735076s

• [SLOW TEST:12.436 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:08:40.135: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7697
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb 24 21:08:42.996: INFO: Successfully updated pod "labelsupdatebf4b87fc-83ff-49ef-8d4d-a0c54346d382"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:08:45.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7697" for this suite.
Feb 24 21:09:01.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:09:01.388: INFO: namespace downward-api-7697 deletion completed in 16.199209732s

• [SLOW TEST:21.253 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:09:01.396: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6010
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0224 21:09:12.704676      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 24 21:09:12.705: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:09:12.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6010" for this suite.
Feb 24 21:09:20.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:09:21.088: INFO: namespace gc-6010 deletion completed in 8.369723693s

• [SLOW TEST:19.693 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:09:21.092: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-605
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 24 21:09:27.478: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 24 21:09:27.481: INFO: Pod pod-with-prestop-http-hook still exists
Feb 24 21:09:29.481: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 24 21:09:29.484: INFO: Pod pod-with-prestop-http-hook still exists
Feb 24 21:09:31.484: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 24 21:09:31.487: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:09:31.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-605" for this suite.
Feb 24 21:09:43.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:09:43.955: INFO: namespace container-lifecycle-hook-605 deletion completed in 12.453732237s

• [SLOW TEST:22.863 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:09:43.960: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3147
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Feb 24 21:09:44.137: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
Feb 24 21:09:48.928: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:10:05.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3147" for this suite.
Feb 24 21:10:11.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:10:11.866: INFO: namespace crd-publish-openapi-3147 deletion completed in 6.156907062s

• [SLOW TEST:27.907 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:10:11.870: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4375
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb 24 21:10:14.672: INFO: Successfully updated pod "annotationupdate5d657a45-e7d6-4e1b-a565-ecef2029628f"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:10:18.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4375" for this suite.
Feb 24 21:10:31.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:10:31.360: INFO: namespace downward-api-4375 deletion completed in 12.404576084s

• [SLOW TEST:19.491 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:10:31.361: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6295
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6295
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Feb 24 21:10:31.585: INFO: Found 0 stateful pods, waiting for 3
Feb 24 21:10:41.591: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 21:10:41.591: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 21:10:41.591: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Feb 24 21:10:41.626: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 24 21:10:52.110: INFO: Updating stateful set ss2
Feb 24 21:10:52.324: INFO: Waiting for Pod statefulset-6295/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Feb 24 21:11:02.445: INFO: Found 1 stateful pods, waiting for 3
Feb 24 21:11:12.452: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 21:11:12.452: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 21:11:12.452: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 24 21:11:12.480: INFO: Updating stateful set ss2
Feb 24 21:11:12.507: INFO: Waiting for Pod statefulset-6295/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 24 21:11:22.579: INFO: Updating stateful set ss2
Feb 24 21:11:22.606: INFO: Waiting for StatefulSet statefulset-6295/ss2 to complete update
Feb 24 21:11:22.606: INFO: Waiting for Pod statefulset-6295/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 24 21:11:32.613: INFO: Deleting all statefulset in ns statefulset-6295
Feb 24 21:11:32.616: INFO: Scaling statefulset ss2 to 0
Feb 24 21:11:42.636: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 21:11:42.642: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:11:42.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6295" for this suite.
Feb 24 21:11:50.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:11:50.870: INFO: namespace statefulset-6295 deletion completed in 8.201294797s

• [SLOW TEST:79.510 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 21:11:50.877: INFO: >>> kubeConfig: /tmp/kubeconfig-651526472
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9486
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-jd92
STEP: Creating a pod to test atomic-volume-subpath
Feb 24 21:11:51.082: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-jd92" in namespace "subpath-9486" to be "success or failure"
Feb 24 21:11:51.087: INFO: Pod "pod-subpath-test-configmap-jd92": Phase="Pending", Reason="", readiness=false. Elapsed: 5.133803ms
Feb 24 21:11:53.101: INFO: Pod "pod-subpath-test-configmap-jd92": Phase="Running", Reason="", readiness=true. Elapsed: 2.019300332s
Feb 24 21:11:55.106: INFO: Pod "pod-subpath-test-configmap-jd92": Phase="Running", Reason="", readiness=true. Elapsed: 4.023599157s
Feb 24 21:11:57.109: INFO: Pod "pod-subpath-test-configmap-jd92": Phase="Running", Reason="", readiness=true. Elapsed: 6.027325322s
Feb 24 21:11:59.210: INFO: Pod "pod-subpath-test-configmap-jd92": Phase="Running", Reason="", readiness=true. Elapsed: 8.128101866s
Feb 24 21:12:01.215: INFO: Pod "pod-subpath-test-configmap-jd92": Phase="Running", Reason="", readiness=true. Elapsed: 10.13290964s
Feb 24 21:12:03.334: INFO: Pod "pod-subpath-test-configmap-jd92": Phase="Running", Reason="", readiness=true. Elapsed: 12.251959471s
Feb 24 21:12:05.339: INFO: Pod "pod-subpath-test-configmap-jd92": Phase="Running", Reason="", readiness=true. Elapsed: 14.257369845s
Feb 24 21:12:07.420: INFO: Pod "pod-subpath-test-configmap-jd92": Phase="Running", Reason="", readiness=true. Elapsed: 16.337966714s
Feb 24 21:12:09.424: INFO: Pod "pod-subpath-test-configmap-jd92": Phase="Running", Reason="", readiness=true. Elapsed: 18.341938645s
Feb 24 21:12:11.428: INFO: Pod "pod-subpath-test-configmap-jd92": Phase="Running", Reason="", readiness=true. Elapsed: 20.345824218s
Feb 24 21:12:13.431: INFO: Pod "pod-subpath-test-configmap-jd92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.349358692s
STEP: Saw pod success
Feb 24 21:12:13.431: INFO: Pod "pod-subpath-test-configmap-jd92" satisfied condition "success or failure"
Feb 24 21:12:13.435: INFO: Trying to get logs from node gke-c116p-default-pool-41de4435-fss3 pod pod-subpath-test-configmap-jd92 container test-container-subpath-configmap-jd92: <nil>
STEP: delete the pod
Feb 24 21:12:13.499: INFO: Waiting for pod pod-subpath-test-configmap-jd92 to disappear
Feb 24 21:12:13.507: INFO: Pod pod-subpath-test-configmap-jd92 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-jd92
Feb 24 21:12:13.507: INFO: Deleting pod "pod-subpath-test-configmap-jd92" in namespace "subpath-9486"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 21:12:13.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9486" for this suite.
Feb 24 21:12:21.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 21:12:23.061: INFO: namespace subpath-9486 deletion completed in 9.541324379s

• [SLOW TEST:32.185 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSFeb 24 21:12:23.062: INFO: Running AfterSuite actions on all nodes
Feb 24 21:12:23.062: INFO: Running AfterSuite actions on node 1
Feb 24 21:12:23.062: INFO: Skipping dumping logs from cluster

Ran 276 of 4731 Specs in 7171.477 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4455 Skipped
PASS

Ginkgo ran 1 suite in 1h59m33.834646131s
Test Suite Passed
